<!DOCTYPE html>
<html lang="de">
<head>
<title>
    Hadoop, Storm, Samza, Spark und Flink: Vergleich von Big Data Frameworks
</title>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<link rel="stylesheet" href="https://stackpath.bootstrapcdn.com/bootstrap/4.4.1/css/bootstrap.min.css" integrity="sha384-Vkoo8x4CGsO3+Hhxv8T/Q5PaXtkKtu6ug5TOeNV6gBiFeWPGFN9MuhOf23Q9Ifjh" crossorigin="anonymous">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.11.2/css/all.min.css" integrity="sha256-+N4/V/SbAFiW1MPBCXnfnP9QSN3+Keu+NlB+0ev/YKQ=" crossorigin="anonymous" />
<link rel="stylesheet" type="text/css" href="/static/global.css">
<script async src="https://www.googletagmanager.com/gtag/js?id=UA-131411870-1" type="1d6c4c0384383af98313a5eb-text/javascript"></script>
<script type="1d6c4c0384383af98313a5eb-text/javascript">
        window.dataLayer = window.dataLayer || [];
        function gtag(){dataLayer.push(arguments);}
        gtag('js', new Date());
        gtag('config', 'UA-131411870-1');
    </script>
<script data-ad-client="ca-pub-7450216517803275" async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js" type="1d6c4c0384383af98313a5eb-text/javascript"></script>
<script async src='/cdn-cgi/challenge-platform/h/b/scripts/cb/invisible.js?cb=71173ef4cb7b06e9'></script></head>
<body>
<header class="navbar navbar-expand-lg navbar-dark bg-dark">
<div class="navbar-nav-scroll">
<ul class="navbar-nav bd-navbar-nav flex-row">
<li class="nav-item">
<a class="nav-link " href="/de/">Home</a>
</li>
</ul>
</div>
</header>
<div class="container-fluid mt-5">
<div class="row flex-xl-nowarp">
<div class="col-lg-2 d-none d-lg-block sidebar">
<div class="card my-4 ad-sidebar">
<script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js" type="1d6c4c0384383af98313a5eb-text/javascript"></script>
<ins class="adsbygoogle" style="display:block" data-ad-client="ca-pub-7450216517803275" data-ad-slot="8195814284" data-ad-format="auto" data-full-width-responsive="true"></ins>
<script type="1d6c4c0384383af98313a5eb-text/javascript">
        (adsbygoogle = window.adsbygoogle || []).push({});
    </script>
</div>
<div class="card my-4 ad-sidebar">
<script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js" type="1d6c4c0384383af98313a5eb-text/javascript"></script>
<ins class="adsbygoogle" style="display:block" data-ad-client="ca-pub-7450216517803275" data-ad-slot="8195814284" data-ad-format="auto" data-full-width-responsive="true"></ins>
<script type="1d6c4c0384383af98313a5eb-text/javascript">
        (adsbygoogle = window.adsbygoogle || []).push({});
    </script>
</div>
<div class="card my-4 border-0 sticky-top">
<div class="card-body">
<h6 class="pt-3 position-relative bg-white">
TOC</h6>
<nav class="content-toc text-truncate">
</nav>
</div>
</div>
</div>
<div class="col-12 col-lg-7">
<script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js" type="1d6c4c0384383af98313a5eb-text/javascript"></script>

<ins class="adsbygoogle" style="display:block" data-ad-client="ca-pub-7450216517803275" data-ad-slot="9811086195" data-ad-format="auto" data-full-width-responsive="true"></ins>
<script type="1d6c4c0384383af98313a5eb-text/javascript">
     (adsbygoogle = window.adsbygoogle || []).push({});
</script>
<article class="content">
<h1 class="post-title text-truncate"> Hadoop, Storm, Samza, Spark und Flink: Vergleich von Big Data Frameworks</h1>
<div class="row">
<div class="post-meta pl-3">
<ul class="list-unstyled">
<li class="tag-links">
<a class="m-1 badge-tag rounded border" href=/de/tag/Big%20Data> Big Data</a>
<a class="m-1 badge-tag rounded border" href=/de/tag/Conceptual> Conceptual</a>
</li>
</ul>
</div>
</div>
<div class="row pl-3 mb-3">

<div class="a2a_kit a2a_kit_size_32 a2a_default_style">
<a class="a2a_button_facebook"></a>
<a class="a2a_button_tumblr"></a>
<a class="a2a_button_pinterest"></a>
<a class="a2a_button_pocket"></a>
<a class="a2a_button_evernote"></a>
<a class="a2a_button_twitter"></a>
<a class="a2a_button_line"></a>
<a class="a2a_button_email"></a>
<a class="a2a_button_reddit"></a>
<a class="a2a_button_digg"></a>
<a class="a2a_button_vk"></a>
<a class="a2a_dd" href="https://www.addtoany.com/share"></a>
</div>
<script type="1d6c4c0384383af98313a5eb-text/javascript">
    var a2a_config = a2a_config || {};
    a2a_config.onclick = 1;
</script>
<script async src="https://static.addtoany.com/menu/page.js" type="1d6c4c0384383af98313a5eb-text/javascript"></script>

</div>
<div class="article-content"> <div id="content">
<div class="sect3">
<h4 id="_einführung">Einführung</h4>
<div class="ulist">
<ul>
<li>
<p>Big Data * ist ein Sammelbegriff für die nicht traditionellen Strategien und Technologien, die zum Sammeln, Organisieren, Verarbeiten und Sammeln von Erkenntnissen aus großen Datenmengen erforderlich sind. Während das Problem der Arbeit mit Daten, die die Rechenleistung oder den Speicherplatz eines einzelnen Computers überschreiten, nicht neu ist, haben sich die Verbreitung, der Umfang und der Wert dieser Art von Datenverarbeitung in den letzten Jahren erheblich erweitert.</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>In einem früheren Leitfaden haben wir einige der in <a class="bare" href="https://www.digitalocean.com/community/tutorials/an-introduction-to-big-data-concepts-and-terminology">https://www.digitalocean.com/community/tutorials/an-introduction-to-big-data-concepts-and-terminology</a> verwendeten allgemeinen Konzepte, Verarbeitungsstufen und Terminologie besprochen Big-Data-Systeme]. In diesem Artikel befassen wir uns mit einer der wichtigsten Komponenten eines Big-Data-Systems: der Verarbeitung von Frameworks. Verarbeitungs-Frameworks berechnen die Daten im System, indem sie entweder aus dem nichtflüchtigen Speicher lesen oder wenn sie in das System aufgenommen werden. Beim Berechnen von Daten werden Informationen und Erkenntnisse aus großen Mengen einzelner Datenpunkte extrahiert.</p>
</div>
<div class="paragraph">
<p>Wir werden die folgenden Frameworks abdecken:</p>
</div>
<div class="ulist">
<ul>
<li>
<p>* Nur-Batch-Frameworks: *</p>
</li>
<li>
<p>* link: # apache-hadoop [Apache Hadoop] *</p>
</li>
<li>
<p>* Nur-Stream-Frameworks: *</p>
</li>
<li>
<p>* link: # apache-storm [Apache Storm] *</p>
</li>
<li>
<p>* link: # apache-samza [Apache Samza] *</p>
</li>
<li>
<p>* Hybride Frameworks: *</p>
</li>
<li>
<p>* link: # apache-spark [Apache Spark] *</p>
</li>
<li>
<p>* link: # apache-flink [Apache Flink] *</p>
</li>
</ul>
</div>
</div>
<div class="sect2">
<h3 id="_was_sind_big_data_processing_frameworks">Was sind Big Data Processing Frameworks?</h3>
<div class="ulist">
<ul>
<li>
<p>Processing Frameworks * und * Processing Engines * sind für das Rechnen über Daten in einem Datensystem verantwortlich. Während es keine autorisierende Definition gibt, die "Engines" von "Frameworks" unterscheidet, ist es manchmal nützlich, die erstere als die eigentliche Komponente zu definieren, die für das Verarbeiten von Daten verantwortlich ist, und die letztere als eine Gruppe von Komponenten, die dafür ausgelegt sind.</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>Zum Beispiel kann * Apache Hadoop * als <em>Prozess-Framework</em> mit * MapReduce * als Standard-<em>Prozess-Engine</em> betrachtet werden. Motoren und Frameworks können häufig ausgetauscht oder zusammen verwendet werden. Zum Beispiel kann sich * Apache Spark *, ein anderes Framework, in Hadoop einbinden, um MapReduce zu ersetzen. Diese Interoperabilität zwischen Komponenten ist einer der Gründe für die große Flexibilität von Big-Data-Systemen.</p>
</div>
<div class="paragraph">
<p>Während die Systeme, die diese Phase des Datenlebenszyklus bewältigen, komplex sein können, sind die Ziele auf breiter Ebene sehr ähnlich: Arbeiten Sie über Daten, um das Verständnis zu verbessern, Oberflächenmuster zu erhalten und Einblicke in komplexe Interaktionen zu erhalten.</p>
</div>
<div class="paragraph">
<p>Um die Erörterung dieser Komponenten zu vereinfachen, werden diese Verarbeitungsframeworks nach dem Status der Daten gruppiert, für die sie entwickelt wurden. Einige Systeme verarbeiten Daten in Stapeln, während andere Daten in einem kontinuierlichen Datenstrom verarbeiten, während sie in das System fließen. Wieder andere können auf eine dieser Arten mit Daten umgehen.</p>
</div>
<div class="paragraph">
<p>Wir werden jede Art der Verarbeitung als Konzept vorstellen, bevor wir auf die Besonderheiten und Konsequenzen verschiedener Implementierungen eingehen.</p>
</div>
</div>
<div class="sect2">
<h3 id="_stapelverarbeitungssysteme">Stapelverarbeitungssysteme</h3>
<div class="ulist">
<ul>
<li>
<p>Stapelverarbeitung * hat eine lange Geschichte in der Big-Data-Welt. Bei der Stapelverarbeitung wird ein großer statischer Datensatz bearbeitet und das Ergebnis nach Abschluss der Berechnung zu einem späteren Zeitpunkt zurückgegeben.</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>Die Datensätze in der Stapelverarbeitung sind in der Regel…</p>
</div>
<div class="ulist">
<ul>
<li>
<p>begrenzt: Batch-Datasets repräsentieren eine endliche Sammlung von Daten</p>
</li>
<li>
<p>persistent: Daten werden fast immer durch eine Art permanenten Speicher gesichert</p>
</li>
<li>
<p>Groß: Stapelverarbeitungen sind häufig die einzige Option für die Verarbeitung extrem großer Datenmengen</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>Die Stapelverarbeitung eignet sich gut für Berechnungen, bei denen Zugriff auf einen vollständigen Datensatz erforderlich ist. Beispielsweise müssen bei der Berechnung von Summen und Durchschnitten Datensätze ganzheitlich und nicht als Sammlung einzelner Datensätze behandelt werden. Diese Operationen erfordern, dass der Status für die Dauer der Berechnungen beibehalten wird.</p>
</div>
<div class="paragraph">
<p>Aufgaben, die sehr große Datenmengen erfordern, lassen sich häufig am besten im Stapelbetrieb erledigen. Egal, ob die Datensätze direkt aus dem permanenten Speicher verarbeitet oder in den Speicher geladen werden, Batch-Systeme sind auf große Mengen ausgelegt und verfügen über die Ressourcen, um diese zu verarbeiten. Da bei der Stapelverarbeitung große Mengen persistenter Daten verarbeitet werden, werden diese häufig mit Verlaufsdaten verwendet.</p>
</div>
<div class="paragraph">
<p>Der Kompromiss für die Verarbeitung großer Datenmengen ist eine längere Rechenzeit. Aus diesem Grund ist die Stapelverarbeitung in Situationen, in denen die Verarbeitungszeit besonders wichtig ist, nicht geeignet.</p>
</div>
<div class="sect3">
<h4 id="_apache_hadoop">Apache Hadoop</h4>
<div class="paragraph">
<p>Apache Hadoop ist ein Verarbeitungsframework, das ausschließlich Stapelverarbeitung bietet. Hadoop war das erste Big-Data-Framework, das in der Open-Source-Community beachtliche Fortschritte erzielte. Basierend auf mehreren Beiträgen und Präsentationen von Google zum Umgang mit enormen Datenmengen zu dieser Zeit hat Hadoop die Algorithmen und den Komponentenstapel neu implementiert, um die Stapelverarbeitung in großem Maßstab zugänglicher zu machen.</p>
</div>
<div class="paragraph">
<p>Moderne Versionen von Hadoop bestehen aus mehreren Komponenten oder Schichten, die zur Verarbeitung von Chargendaten zusammenarbeiten:</p>
</div>
<div class="ulist">
<ul>
<li>
<p>* HDFS *: HDFS ist die verteilte Dateisystemschicht, die die Speicherung und Replikation auf den Clusterknoten koordiniert. HDFS stellt sicher, dass die Daten trotz unvermeidlicher Hostfehler verfügbar bleiben. Es wird als Datenquelle verwendet, um Zwischenverarbeitungsergebnisse zu speichern und die endgültigen berechneten Ergebnisse beizubehalten.</p>
</li>
<li>
<p>* YARN *: YARN steht für Another Resource Negotiator und ist die Cluster-Koordinierungskomponente des Hadoop-Stacks. Es ist für die Koordination und Verwaltung der zugrunde liegenden Ressourcen und die Planung der auszuführenden Jobs verantwortlich. Mit YARN können auf einem Hadoop-Cluster wesentlich mehr Workloads ausgeführt werden als in früheren Iterationen, da es als Schnittstelle zu den Clusterressourcen fungiert.</p>
</li>
<li>
<p>* MapReduce *: MapReduce ist die native Stapelverarbeitungs-Engine von Hadoop.</p>
</li>
</ul>
</div>
<div class="sect4">
<h5 id="_stapelverarbeitungsmodell">Stapelverarbeitungsmodell</h5>
<div class="paragraph">
<p>Die Verarbeitungsfunktionalität von Hadoop stammt von der MapReduce-Engine. Die Verarbeitungstechnik von MapReduce folgt dem Map-, Shuffle- und Reduction-Algorithmus unter Verwendung von Schlüssel-Wert-Paaren. Das grundlegende Verfahren umfasst:</p>
</div>
<div class="ulist">
<ul>
<li>
<p>Lesen des Datensatzes aus dem HDFS-Dateisystem</p>
</li>
<li>
<p>Teilen Sie den Datensatz in Blöcke auf und verteilen Sie ihn auf die verfügbaren Knoten</p>
</li>
<li>
<p>Anwenden der Berechnung auf jeden Knoten auf die Teilmenge der Daten (die Zwischenergebnisse werden in HDFS zurückgeschrieben)</p>
</li>
<li>
<p>Umverteilung der Zwischenergebnisse auf Gruppierung nach Schlüssel</p>
</li>
<li>
<p>Reduzieren Sie den Wert jedes Schlüssels, indem Sie die von den einzelnen Knoten berechneten Ergebnisse zusammenfassen und kombinieren</p>
</li>
<li>
<p>Schreiben Sie die berechneten Endergebnisse zurück in HDFS</p>
</li>
</ul>
</div>
</div>
<div class="sect4">
<h5 id="_vorteile_und_einschränkungen">Vorteile und Einschränkungen</h5>
<div class="paragraph">
<p>Da diese Methode die permanente Speicherung, das mehrmalige Lesen und Schreiben pro Task in hohem Maße nutzt, ist sie in der Regel relativ langsam. Auf der anderen Seite bedeutet dies, dass MapReduce enorme Datenmengen verarbeiten kann, da Speicherplatz normalerweise eine der am häufigsten vorkommenden Serverressourcen ist. Dies bedeutet auch, dass MapReduce von Hadoop in der Regel auf kostengünstigerer Hardware als manche Alternativen ausgeführt werden kann, da nicht versucht wird, alles im Speicher zu speichern. MapReduce verfügt über ein unglaubliches Skalierbarkeitspotenzial und wurde in der Produktion auf Zehntausenden von Knoten verwendet.</p>
</div>
<div class="paragraph">
<p>MapReduce ist als Entwicklungsziel dafür bekannt, eine ziemlich steile Lernkurve zu haben. Andere Ergänzungen des Hadoop-Ökosystems können die Auswirkungen in unterschiedlichem Maße verringern, können aber dennoch ein Faktor für die schnelle Implementierung einer Idee in einem Hadoop-Cluster sein.</p>
</div>
<div class="paragraph">
<p>Hadoop verfügt über ein umfangreiches Ökosystem, wobei der Hadoop-Cluster selbst häufig als Baustein für andere Software verwendet wird. Viele andere Verarbeitungsframeworks und Engines verfügen über Hadoop-Integrationen, um HDFS und den YARN-Ressourcenmanager zu verwenden.</p>
</div>
</div>
<div class="sect4">
<h5 id="_zusammenfassung">Zusammenfassung</h5>
<div class="paragraph">
<p>Apache Hadoop und seine MapReduce-Verarbeitungsengine bieten ein bewährtes Stapelverarbeitungsmodell, das sich am besten für die Verarbeitung sehr großer Datenmengen eignet, bei denen die Zeit keine Rolle spielt. Die geringen Kosten für Komponenten, die für ein gut funktionierendes Hadoop-Cluster erforderlich sind, machen diese Verarbeitung für viele Anwendungsfälle kostengünstig und effektiv. Durch die Kompatibilität und Integration mit anderen Frameworks und Engines kann Hadoop häufig als Grundlage für mehrere Verarbeitungs-Workloads mit unterschiedlichen Technologien dienen.</p>
</div>
</div>
</div>
</div>
<div class="sect2">
<h3 id="_stream_verarbeitungssysteme">Stream-Verarbeitungssysteme</h3>
<div class="ulist">
<ul>
<li>
<p>Stream-Processing * -Systeme rechnen beim Eintritt in das System über Daten. Dies erfordert ein anderes Verarbeitungsmodell als das Batch-Paradigma. Anstatt Operationen zu definieren, die auf ein gesamtes Dataset angewendet werden sollen, definieren Stream-Prozessoren Operationen, die auf jedes einzelne Datenelement angewendet werden, wenn es das System durchläuft.</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>Die Datensätze in der Stream-Verarbeitung gelten als "unbegrenzt". Dies hat einige wichtige Auswirkungen:</p>
</div>
<div class="ulist">
<ul>
<li>
<p>Der Gesamtdatensatz ist nur als die Datenmenge definiert, die bisher in das System eingegangen ist.</p>
</li>
<li>
<p>Das <em>working</em>-Dataset ist möglicherweise relevanter und auf jeweils ein Element beschränkt.</p>
</li>
<li>
<p>Die Verarbeitung erfolgt ereignisbasiert und endet erst, wenn sie explizit gestoppt wird. Die Ergebnisse sind sofort verfügbar und werden laufend aktualisiert, sobald neue Daten eingehen.</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>Stream-Verarbeitungssysteme können eine nahezu unbegrenzte Datenmenge verarbeiten, verarbeiten jedoch jeweils nur ein (True-Stream-Verarbeitung) oder nur sehr wenige (Micro-Batch-Verarbeitung) Elemente, wobei der minimale Status zwischen den Datensätzen beibehalten wird. Während die meisten Systeme Methoden zur Aufrechterhaltung eines bestimmten Zustands bereitstellen, ist die Dampfverarbeitung für eine * funktionsfähigere * Verarbeitung mit wenigen Nebenwirkungen stark optimiert.</p>
</div>
<div class="paragraph">
<p>Funktionale Operationen konzentrieren sich auf diskrete Schritte, die begrenzte Zustände oder Nebenwirkungen haben. Wenn Sie dieselbe Operation für dasselbe Datenelement ausführen, wird die gleiche Ausgabe unabhängig von anderen Faktoren erstellt. Diese Art der Verarbeitung passt gut zu Streams, da der Status zwischen Elementen normalerweise eine Kombination aus schwierig, begrenzt und manchmal unerwünscht ist. Während also normalerweise eine Art von Zustandsmanagement möglich ist, sind diese Frameworks in ihrer Abwesenheit viel einfacher und effizienter.</p>
</div>
<div class="paragraph">
<p>Diese Art der Verarbeitung eignet sich für bestimmte Arten von Workloads. Die Verarbeitung mit nahezu Echtzeitanforderungen wird vom Streaming-Modell gut unterstützt. Analytics, Server- oder Anwendungsfehlerprotokollierung und andere zeitbasierte Metriken sind eine Selbstverständlichkeit, da das Reagieren auf Änderungen in diesen Bereichen für Geschäftsfunktionen von entscheidender Bedeutung sein kann. Die Stream-Verarbeitung eignet sich gut für Daten, bei denen Sie auf Änderungen oder Spitzen reagieren müssen und bei denen Sie über einen längeren Zeitraum an Trends interessiert sind.</p>
</div>
<div class="sect3">
<h4 id="_apache_storm">Apache Storm</h4>
<div class="paragraph">
<p>Apache Storm ist ein Framework für die Stream-Verarbeitung, das sich auf extrem niedrige Latenz konzentriert und möglicherweise die beste Option für Workloads ist, die eine zeitnahe Verarbeitung erfordern. Es kann sehr große Datenmengen verarbeiten und Ergebnisse mit einer geringeren Latenz als andere Lösungen liefern.</p>
</div>
<div class="sect4">
<h5 id="_stream_verarbeitungsmodell">Stream-Verarbeitungsmodell</h5>
<div class="paragraph">
<p>Die Storm Stream-Verarbeitung funktioniert, indem DAGs (Directed Acyclic Graphs) in einem Framework orchestriert werden, das sie * Topologien * nennt. Diese Topologien beschreiben die verschiedenen Transformationen oder Schritte, die für jedes eingehende Datenelement beim Eintritt in das System ausgeführt werden.</p>
</div>
<div class="paragraph">
<p>Die Topologien setzen sich zusammen aus:</p>
</div>
<div class="ulist">
<ul>
<li>
<p>* Streams *: Konventionelle Datenströme. Dies sind unbegrenzte Daten, die ständig im System ankommen.</p>
</li>
<li>
<p>* Ausläufe *: Quellen von Datenströmen am Rande der Topologie. Dies können APIs, Warteschlangen usw. sein. die zu bearbeitende Daten erzeugen.</p>
</li>
<li>
<p>* Bolzen *: Bolzen stellen einen Verarbeitungsschritt dar, der Streams verbraucht, eine Operation auf sie anwendet und das Ergebnis als Stream ausgibt. Die Bolzen werden mit jedem Auslauf verbunden und dann miteinander verbunden, um die gesamte erforderliche Verarbeitung zu veranlassen. Am Ende der Topologie kann die endgültige Schraubenausgabe als Eingabe für ein verbundenes System verwendet werden.</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>Die Idee hinter Storm ist es, kleine, diskrete Operationen unter Verwendung der obigen Komponenten zu definieren und diese dann zu einer Topologie zusammenzusetzen. Standardmäßig bietet Storm Garantien für die mindestens einmalige Verarbeitung. Dies bedeutet, dass garantiert werden kann, dass jede Nachricht mindestens einmal verarbeitet wird. In einigen Fehlerszenarien kann es jedoch zu Duplikaten kommen. Storm garantiert nicht, dass Nachrichten in der richtigen Reihenfolge verarbeitet werden.</p>
</div>
<div class="paragraph">
<p>Um eine genau einmalige, zustandsbehaftete Verarbeitung zu erreichen, steht auch eine Abstraktion mit dem Namen * Trident * zur Verfügung. Um genau zu sein, wird Storm without Trident oft als * Core Storm * bezeichnet. Trident ändert die Verarbeitungsdynamik von Storm erheblich, erhöht die Latenz, fügt der Verarbeitung einen Status hinzu und implementiert ein Mikro-Batching-Modell anstelle eines reinen Element-für-Element-Streaming-Systems.</p>
</div>
<div class="paragraph">
<p>Storm-Benutzer empfehlen normalerweise die Verwendung von Core Storm, wann immer dies möglich ist, um diese Nachteile zu vermeiden. Vor diesem Hintergrund ist die Garantie von Trident, dass Artikel genau einmal verarbeitet werden, in Fällen nützlich, in denen das System doppelte Nachrichten nicht intelligent verarbeiten kann. Trident ist auch die einzige Option in Storm, wenn Sie den Status zwischen Elementen beibehalten müssen, z. B. wenn Sie zählen, wie viele Benutzer innerhalb einer Stunde auf einen Link klicken. Trident gibt Storm Flexibilität, obwohl es die natürlichen Stärken des Frameworks nicht ausnutzt.</p>
</div>
<div class="paragraph">
<p>Dreizack-Topologien bestehen aus:</p>
</div>
<div class="ulist">
<ul>
<li>
<p>* Stream-Batches *: Hierbei handelt es sich um Mikro-Batches von Stream-Daten, die aufgeteilt werden, um eine Semantik für die Stapelverarbeitung bereitzustellen.</p>
</li>
<li>
<p>* Vorgänge *: Dies sind Stapelvorgänge, die mit den Daten ausgeführt werden können.</p>
</li>
</ul>
</div>
</div>
<div class="sect4">
<h5 id="advantages-and-limitations">Vorteile und Einschränkungen</h5>
<div class="paragraph">
<p>Storm ist wahrscheinlich die beste derzeit verfügbare Lösung für die Echtzeitverarbeitung. Es ist in der Lage, Daten mit extrem geringer Latenz für Workloads zu verarbeiten, die mit minimaler Verzögerung verarbeitet werden müssen. Storm ist häufig eine gute Wahl, wenn sich die Verarbeitungszeit direkt auf die Benutzererfahrung auswirkt, z. B. wenn das Feedback aus der Verarbeitung direkt auf die Seite eines Besuchers auf einer Website zurückgeführt wird.</p>
</div>
<div class="paragraph">
<p>Storm with Trident bietet Ihnen die Möglichkeit, Micro-Batches anstelle der reinen Stream-Verarbeitung zu verwenden. Dies gibt dem Benutzer zwar mehr Flexibilität bei der Anpassung des Tools an die beabsichtigte Verwendung, negiert jedoch tendenziell einige der größten Vorteile der Software gegenüber anderen Lösungen. Trotzdem ist es immer noch hilfreich, eine Auswahl für den Stream-Verarbeitungsstil zu haben.</p>
</div>
<div class="paragraph">
<p>Core Storm bietet keine Bestellgarantie für Nachrichten. Core Storm bietet mindestens einmalige Verarbeitungsgarantien, dh, die Verarbeitung jeder Nachricht kann garantiert werden, es können jedoch Duplikate auftreten. Trident bietet genau einmalige Garantien und kann Bestellungen zwischen Chargen anbieten, jedoch nicht innerhalb.</p>
</div>
<div class="paragraph">
<p>Im Hinblick auf die Interoperabilität kann Storm in Hadoops YARN-Ressourcen-Negotiator integriert werden, wodurch die Anbindung an eine vorhandene Hadoop-Bereitstellung vereinfacht wird. Storm bietet mehr als die meisten Verarbeitungsframeworks eine umfassende Sprachunterstützung und bietet Benutzern viele Optionen zum Definieren von Topologien.</p>
</div>
</div>
<div class="sect4">
<h5 id="summary">Zusammenfassung</h5>
<div class="paragraph">
<p>Für reine Stream-Verarbeitungs-Workloads mit sehr hohen Latenzanforderungen ist Storm wahrscheinlich die ausgereifteste Option. Es kann die Nachrichtenverarbeitung gewährleisten und kann mit einer großen Anzahl von Programmiersprachen verwendet werden. Da Storm keine Stapelverarbeitung durchführt, müssen Sie zusätzliche Software verwenden, wenn Sie diese Funktionen benötigen. Wenn Sie einen hohen Bedarf an Garantien für die einmalige Bearbeitung haben, kann Trident dies bereitstellen. Zu diesem Zeitpunkt könnten jedoch auch andere Stream-Processing-Frameworks besser passen.</p>
</div>
</div>
</div>
<div class="sect3">
<h4 id="_apache_samza">Apache Samza</h4>
<div class="paragraph">
<p>Apache Samza ist ein Stream-Processing-Framework, das eng mit dem Apache Kafka-Messaging-System verbunden ist. Während Kafka von vielen Stream-Verarbeitungssystemen verwendet werden kann, wurde Samza speziell entwickelt, um die einzigartige Architektur und die Garantien von Kafka zu nutzen. Es verwendet Kafka, um Fehlertoleranz, Pufferung und Zustandsspeicherung bereitzustellen.</p>
</div>
<div class="paragraph">
<p>Samza verwendet YARN für die Ressourcenverhandlung. Dies bedeutet, dass standardmäßig ein Hadoop-Cluster erforderlich ist (mindestens HDFS und YARN). Dies bedeutet jedoch auch, dass Samza sich auf die umfangreichen Funktionen von YARN verlassen kann.</p>
</div>
<div class="sect4">
<h5 id="stream-processing-model">Stream-Verarbeitungsmodell</h5>
<div class="paragraph">
<p>Samza verwendet die Semantik von Kafka, um die Art und Weise zu definieren, in der Streams verarbeitet werden. Kafka verwendet im Umgang mit Daten die folgenden Konzepte:</p>
</div>
<div class="ulist">
<ul>
<li>
<p>* Themen *: Jeder Datenstrom, der in ein Kafka-System eingeht, wird als Thema bezeichnet. Ein Thema ist im Grunde genommen ein Strom verwandter Informationen, die Verbraucher abonnieren können.</p>
</li>
<li>
<p>* Partitionen *: Um ein Thema auf Knoten zu verteilen, unterteilt Kafka die eingehenden Nachrichten in Partitionen. Die Partitionsunterteilungen basieren auf einem Schlüssel, sodass garantiert wird, dass jede Nachricht mit demselben Schlüssel an dieselbe Partition gesendet wird. Partitionen haben die Bestellung garantiert.</p>
</li>
<li>
<p>* Brokers *: Die einzelnen Knoten, aus denen ein Kafka-Cluster besteht, werden als Broker bezeichnet.</p>
</li>
<li>
<p>* Produzent *: Jede Komponente, die zu einem Kafka-Thema schreibt, wird als Produzent bezeichnet. Der Produzent stellt den Schlüssel bereit, der zum Partitionieren eines Themas verwendet wird.</p>
</li>
<li>
<p>* Verbraucher *: Verbraucher sind alle Komponenten, die aus einem Kafka-Thema lesen. Verbraucher sind dafür verantwortlich, Informationen über ihren eigenen Offset zu pflegen, damit sie wissen, welche Datensätze verarbeitet wurden, wenn ein Fehler auftritt.</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>Da Kafka ein unveränderliches Protokoll darstellt, handelt Samza mit unveränderlichen Streams. Dies bedeutet, dass alle Transformationen neue Streams erstellen, die von anderen Komponenten verwendet werden, ohne dass dies Auswirkungen auf den ursprünglichen Stream hat.</p>
</div>
</div>
<div class="sect4">
<h5 id="advantages-and-limitations">Vorteile und Einschränkungen</h5>
<div class="paragraph">
<p>Samzas Vertrauen in ein Kafka-ähnliches Warteschlangensystem scheint auf den ersten Blick restriktiv. Es bietet dem System jedoch einige einzigartige Garantien und Funktionen, die in anderen Stream-Verarbeitungssystemen nicht üblich sind.</p>
</div>
<div class="paragraph">
<p>Beispielsweise bietet Kafka bereits die replizierte Speicherung von Daten an, auf die mit geringer Latenz zugegriffen werden kann. Es bietet auch ein sehr einfaches und kostengünstiges Mehrteilnehmermodell für jede einzelne Datenpartition. Die gesamte Ausgabe, einschließlich der Zwischenergebnisse, wird ebenfalls an Kafka geschrieben und kann von den nachgeschalteten Stufen unabhängig verwendet werden.</p>
</div>
<div class="paragraph">
<p>In vielerlei Hinsicht spiegelt diese enge Abhängigkeit von Kafka die Art und Weise wider, in der die MapReduce-Engine häufig auf HDFS verweist. Während das Verweisen auf HDFS zwischen den einzelnen Berechnungen zu schwerwiegenden Leistungsproblemen bei der Stapelverarbeitung führt, werden bei der Stream-Verarbeitung eine Reihe von Problemen behoben.</p>
</div>
<div class="paragraph">
<p>Die enge Beziehung von Samza zu Kafka ermöglicht es, die Verarbeitungsschritte selbst sehr locker miteinander zu verknüpfen. Eine beliebige Anzahl von Teilnehmern kann ohne vorherige Koordination zu der Ausgabe jedes Schritts hinzugefügt werden. Dies kann für Organisationen sehr nützlich sein, in denen mehrere Teams möglicherweise auf ähnliche Daten zugreifen müssen. Alle Teams können das Thema der Daten abonnieren, die in das System eingegeben werden, oder sie können problemlos Themen abonnieren, die von anderen Teams erstellt wurden, die sich einer bestimmten Verarbeitung unterzogen haben. Dies ist möglich, ohne die lastsensitive Infrastruktur wie Datenbanken zusätzlich zu belasten.</p>
</div>
<div class="paragraph">
<p>Das direkte Schreiben an Kafka beseitigt auch die Probleme des * Gegendrucks *. Der Gegendruck tritt auf, wenn Lastspitzen einen Datenfluss mit einer Geschwindigkeit verursachen, die größer ist als die der Komponenten, die in Echtzeit verarbeitet werden können, was zu Verarbeitungsstillständen und potenziellem Datenverlust führt. Kafka ist darauf ausgelegt, Daten für sehr lange Zeiträume zu speichern. Dies bedeutet, dass Komponenten nach Belieben verarbeitet und ohne Konsequenzen neu gestartet werden können.</p>
</div>
<div class="paragraph">
<p>Samza kann den Status mithilfe eines fehlertoleranten Prüfpunktsystems speichern, das als lokaler Schlüsselwertspeicher implementiert ist. Auf diese Weise kann Samza eine mindestens einmalige Zustellgarantie anbieten, die jedoch keine genaue Wiederherstellung des aggregierten Zustands (z. B. Anzahl) im Falle eines Ausfalls ermöglicht, da Daten möglicherweise mehrmals zugestellt werden.</p>
</div>
<div class="paragraph">
<p>Samza bietet Abstraktionen auf hoher Ebene, mit denen in vielerlei Hinsicht einfacher gearbeitet werden kann als mit den von Systemen wie Storm bereitgestellten Grundelementen. Samza unterstützt derzeit nur JVM-Sprachen, was bedeutet, dass es nicht die gleiche Sprachflexibilität wie Storm hat.</p>
</div>
</div>
<div class="sect4">
<h5 id="summary">Zusammenfassung</h5>
<div class="paragraph">
<p>Apache Samza ist eine gute Wahl für Streaming-Workloads, bei denen Hadoop und Kafka entweder bereits verfügbar sind oder sinnvoll implementiert werden können. Samza selbst eignet sich gut für Organisationen mit mehreren Teams, die Datenströme in verschiedenen Phasen der Verarbeitung verwenden (aber nicht unbedingt eng koordinieren). Samza vereinfacht viele Teile der Stream-Verarbeitung erheblich und bietet eine geringe Latenzzeit. Dies ist möglicherweise keine gute Lösung, wenn die Bereitstellungsanforderungen nicht mit Ihrem aktuellen System kompatibel sind, wenn Sie eine Verarbeitung mit extrem geringer Latenz benötigen oder wenn Sie ein starkes Bedürfnis nach genau einmaliger Semantik haben.</p>
</div>
</div>
</div>
</div>
<div class="sect2">
<h3 id="_hybride_verarbeitungssysteme_batch_und_stream_prozessoren">Hybride Verarbeitungssysteme: Batch- und Stream-Prozessoren</h3>
<div class="paragraph">
<p>Einige Verarbeitungsframeworks können sowohl Batch- als auch Stream-Workloads verarbeiten. Diese Frameworks vereinfachen die verschiedenen Verarbeitungsanforderungen, indem für beide Datentypen dieselben oder verwandte Komponenten und APIs verwendet werden können.</p>
</div>
<div class="paragraph">
<p>Wie Sie sehen werden, variiert die Art und Weise, wie dies erreicht wird, erheblich zwischen Spark und Flink, den beiden Frameworks, die wir diskutieren werden. Dies hängt im Wesentlichen davon ab, wie die beiden Verarbeitungsparadigmen zusammengeführt werden und welche Annahmen über die Beziehung zwischen festen und nicht festgelegten Datensätzen getroffen werden.</p>
</div>
<div class="paragraph">
<p>Während Projekte, die sich auf einen Verarbeitungstyp konzentrieren, für bestimmte Anwendungsfälle gut geeignet sind, versuchen die Hybrid-Frameworks, eine allgemeine Lösung für die Datenverarbeitung anzubieten. Sie stellen nicht nur Methoden zur Datenverarbeitung bereit, sondern verfügen auch über eigene Integrationen, Bibliotheken und Tools, mit denen Sie beispielsweise Diagrammanalysen, maschinelles Lernen und interaktive Abfragen durchführen können.</p>
</div>
<div class="sect3">
<h4 id="_apache_spark">Apache Spark</h4>
<div class="paragraph">
<p>Apache Spark ist ein Stapelverarbeitungsframework der nächsten Generation mit Stream-Verarbeitungsfunktionen. Spark basiert auf vielen der gleichen Prinzipien der MapReduce-Engine von Hadoop und konzentriert sich hauptsächlich auf die Beschleunigung der Stapelverarbeitungs-Workloads, indem es vollständige In-Memory-Berechnung und -Prozessoptimierung bietet.</p>
</div>
<div class="paragraph">
<p>Spark kann als eigenständiger Cluster bereitgestellt werden (wenn eine Verbindung mit einer leistungsfähigen Speicherebene besteht) oder als Alternative zur MapReduce-Engine in Hadoop eingebunden werden.</p>
</div>
<div class="sect4">
<h5 id="batch-processing-model">Stapelverarbeitungsmodell</h5>
<div class="paragraph">
<p>Im Gegensatz zu MapReduce verarbeitet Spark alle Daten im Speicher und interagiert nur mit der Speicherebene, um die Daten zunächst in den Speicher zu laden und am Ende die endgültigen Ergebnisse beizubehalten. Alle Zwischenergebnisse werden im Speicher verwaltet.</p>
</div>
<div class="paragraph">
<p>Während die In-Memory-Verarbeitung wesentlich zur Geschwindigkeit beiträgt, ist Spark auch bei festplattenbezogenen Aufgaben schneller, da eine ganzheitliche Optimierung erzielt werden kann, indem der gesamte Aufgabensatz vorab analysiert wird. Dies wird durch die Erstellung von gerichteten azyklischen Diagrammen (Directed Acyclic Graphs, DAGs) erreicht, die alle auszuführenden Vorgänge, die zu bearbeitenden Daten sowie die Beziehungen zwischen ihnen darstellen. Auf diese Weise kann der Prozessor die Arbeit intelligenter koordinieren.</p>
</div>
<div class="paragraph">
<p>Zur Implementierung der In-Memory-Batch-Berechnung verwendet Spark ein Modell mit dem Namen Resilient Distributed Datasets (* RDDs *), um mit Daten zu arbeiten. Hierbei handelt es sich um unveränderliche Strukturen im Speicher, die Datensammlungen darstellen. Operationen an RDDs erzeugen neue RDDs. Jedes RDD kann seine Herkunft über seine übergeordneten RDDs und letztendlich bis zu den Daten auf der Festplatte zurückverfolgen. Grundsätzlich bieten RDDs eine Möglichkeit für Spark, die Fehlertoleranz aufrechtzuerhalten, ohne nach jedem Vorgang auf die Festplatte zurückschreiben zu müssen.</p>
</div>
</div>
<div class="sect4">
<h5 id="stream-processing-model">Stream-Verarbeitungsmodell</h5>
<div class="paragraph">
<p>Stream-Verarbeitungsfunktionen werden von Spark Streaming bereitgestellt. Spark selbst wurde für chargenorientierte Workloads entwickelt. Um die Diskrepanz zwischen dem Motorkonzept und den Merkmalen von Streaming-Workloads zu beseitigen, implementiert Spark ein Konzept mit dem Namen <em>micro-batches</em> *. Diese Strategie dient dazu, Datenströme als eine Reihe sehr kleiner Stapel zu behandeln, die unter Verwendung der nativen Semantik der Batch-Engine verarbeitet werden können.</p>
</div>
<div class="paragraph">
<p>Spark Streaming puffert den Stream in Schritten von weniger als einer Sekunde. Diese werden als kleine feste Datensätze für die Stapelverarbeitung gesendet. In der Praxis funktioniert dies recht gut, aber es führt zu einem anderen Leistungsprofil als bei echten Stream-Processing-Frameworks.</p>
</div>
</div>
<div class="sect4">
<h5 id="advantages-and-limitations">Vorteile und Einschränkungen</h5>
<div class="paragraph">
<p>Der offensichtliche Grund für die Verwendung von Spark über Hadoop MapReduce ist die Geschwindigkeit. Spark kann dieselben Datasets aufgrund seiner speicherinternen Berechnungsstrategie und seiner fortschrittlichen DAG-Planung erheblich schneller verarbeiten.</p>
</div>
<div class="paragraph">
<p>Ein weiterer großer Vorteil von Spark ist seine Vielseitigkeit. Es kann als eigenständiger Cluster bereitgestellt oder in einen vorhandenen Hadoop-Cluster integriert werden. Es kann sowohl Batch- als auch Stream-Verarbeitung ausführen, sodass Sie einen einzelnen Cluster betreiben können, um mehrere Verarbeitungsstile zu verarbeiten.</p>
</div>
<div class="paragraph">
<p>Abgesehen von den Funktionen der Engine selbst verfügt Spark auch über ein Bibliothekssystem, das für maschinelles Lernen, interaktive Abfragen usw. verwendet werden kann. Es wird allgemein anerkannt, dass Spark-Aufgaben einfacher zu schreiben sind als MapReduce, was erhebliche Auswirkungen auf die Produktivität haben kann.</p>
</div>
<div class="paragraph">
<p>Das Anpassen der Batch-Methode für die Stream-Verarbeitung umfasst das Puffern der Daten beim Eintritt in das System. Mit dem Puffer kann ein hohes Datenaufkommen verarbeitet werden, wodurch der Gesamtdurchsatz erhöht wird. Das Warten auf das Leeren des Puffers führt jedoch auch zu einer deutlichen Erhöhung der Latenz. Dies bedeutet, dass Spark Streaming möglicherweise nicht für die Verarbeitung geeignet ist, bei der eine geringe Latenz erforderlich ist.</p>
</div>
<div class="paragraph">
<p>Da RAM im Allgemeinen teurer ist als Festplattenspeicher, kann der Betrieb von Spark mehr kosten als bei festplattenbasierten Systemen. Die höhere Verarbeitungsgeschwindigkeit bedeutet jedoch, dass Aufgaben viel schneller erledigt werden können, was die Kosten vollständig ausgleichen kann, wenn Sie in einer Umgebung arbeiten, in der Sie stündlich für Ressourcen zahlen.</p>
</div>
<div class="paragraph">
<p>Eine weitere Konsequenz des In-Memory-Designs von Spark ist, dass die Ressourcenknappheit bei der Bereitstellung in gemeinsam genutzten Clustern ein Problem darstellen kann. Im Vergleich zu MapReduce von Hadoop verbraucht Spark deutlich mehr Ressourcen, wodurch andere Aufgaben beeinträchtigt werden können, die möglicherweise versuchen, den Cluster zu diesem Zeitpunkt zu verwenden. Im Wesentlichen ist Spark möglicherweise ein weniger rücksichtsvoller Nachbar als andere Komponenten, die auf dem Hadoop-Stapel ausgeführt werden können.</p>
</div>
</div>
<div class="sect4">
<h5 id="summary">Zusammenfassung</h5>
<div class="paragraph">
<p>Spark ist eine großartige Option für Benutzer mit unterschiedlichen Verarbeitungsaufgaben. Die Spark-Batch-Verarbeitung bietet unglaubliche Geschwindigkeitsvorteile und sorgt für eine hohe Speichernutzung. Spark Streaming ist eine gute Stream-Verarbeitungslösung für Workloads, bei denen Durchsatz und Latenz gleichermaßen wichtig sind.</p>
</div>
</div>
</div>
<div class="sect3">
<h4 id="_apache_flink">Apache Flink</h4>
<div class="paragraph">
<p>Apache Flink ist ein Stream-Processing-Framework, das auch Batch-Tasks verarbeiten kann. Batches werden einfach als Datenströme mit endlichen Grenzen betrachtet, und die Batch-Verarbeitung wird daher als Teilmenge der Stream-Verarbeitung behandelt. Dieser Stream-First-Ansatz für die gesamte Verarbeitung hat eine Reihe interessanter Nebenwirkungen.</p>
</div>
<div class="paragraph">
<p>Dieser Stream-First-Ansatz wird als * Kappa-Architektur * bezeichnet, im Gegensatz zur bekannteren Lambda-Architektur (bei der die Stapelverarbeitung als primäre Verarbeitungsmethode mit Streams verwendet wird, um frühe, aber nicht verfeinerte Ergebnisse zu ergänzen und bereitzustellen). Die Kappa-Architektur, in der Streams für alles verwendet werden, vereinfacht das Modell und ist erst seit kurzem möglich, da die Stream-Processing-Engines immer ausgefeilter werden.</p>
</div>
<div class="sect4">
<h5 id="stream-processing-model">Stream-Verarbeitungsmodell</h5>
<div class="paragraph">
<p>Das Stream-Verarbeitungsmodell von Flink behandelt eingehende Daten Element für Element als echten Stream. Flink stellt seine DataStream-API zur Verfügung, um mit unbegrenzten Datenströmen zu arbeiten. Die grundlegenden Komponenten, mit denen Flink arbeitet, sind:</p>
</div>
<div class="ulist">
<ul>
<li>
<p>* Streams * sind unveränderliche, unbegrenzte Datensätze, die durch das System fließen</p>
</li>
<li>
<p>* Operatoren * sind Funktionen, die Datenströme verarbeiten, um andere Datenströme zu erzeugen</p>
</li>
<li>
<p>* Quellen * sind der Einstiegspunkt für Streams, die in das System gelangen</p>
</li>
<li>
<p>* Senken * sind der Ort, an dem Streams aus dem Flink-System fließen. Sie können eine Datenbank oder einen Connector für ein anderes System darstellen</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>Stream-Verarbeitungs-Tasks erstellen während der Berechnung Momentaufnahmen zu festgelegten Zeitpunkten, die bei Problemen zur Wiederherstellung verwendet werden können. Zum Speichern des Status kann Flink mit einer Reihe von Status-Back-Ends arbeiten, die sich durch unterschiedliche Komplexität und Persistenz auszeichnen.</p>
</div>
<div class="paragraph">
<p>Darüber hinaus kann die Stream-Verarbeitung von Flink das Konzept der „Ereigniszeit“ verstehen, dh die Zeit, zu der das Ereignis tatsächlich eingetreten ist, und auch Sitzungen verarbeiten. Dies bedeutet, dass die Bestellung und Gruppierung auf interessante Weise garantiert werden kann.</p>
</div>
</div>
<div class="sect4">
<h5 id="batch-processing-model">Stapelverarbeitungsmodell</h5>
<div class="paragraph">
<p>Das Stapelverarbeitungsmodell von Flink ist in vielerlei Hinsicht nur eine Erweiterung des Stream-Verarbeitungsmodells. Anstatt aus einem kontinuierlichen Stream zu lesen, wird ein begrenzter Datensatz aus dem persistenten Speicher als Stream gelesen. Flink verwendet für beide Verarbeitungsmodelle genau dieselbe Laufzeit.</p>
</div>
<div class="paragraph">
<p>Flink bietet einige Optimierungen für Batch-Workloads. Da Batch-Vorgänge beispielsweise durch dauerhaften Speicher gesichert sind, entfernt Flink Snapshots aus Batch-Ladevorgängen. Die Daten können weiterhin wiederhergestellt werden, die normale Verarbeitung wird jedoch schneller abgeschlossen.</p>
</div>
<div class="paragraph">
<p>Eine weitere Optimierung besteht darin, Batch-Aufgaben aufzulösen, sodass Phasen und Komponenten nur bei Bedarf beteiligt sind. Dies hilft Flink, gut mit anderen Benutzern des Clusters zu spielen. Durch die vorbeugende Analyse der Aufgaben kann Flink auch optimieren, indem der gesamte Vorgangssatz, die Größe des Datensatzes und die Anforderungen der nachfolgenden Schritte angezeigt werden.</p>
</div>
</div>
<div class="sect4">
<h5 id="advantages-and-limitations">Vorteile und Einschränkungen</h5>
<div class="paragraph">
<p>Flink ist derzeit eine einzigartige Option in der Welt der Verarbeitungs-Frameworks. Während Spark die Stapel- und Stream-Verarbeitung durchführt, ist das Streaming aufgrund seiner Mikro-Batch-Architektur für viele Anwendungsfälle nicht geeignet. Der Stream-First-Ansatz von Flink bietet niedrige Latenzzeiten, hohen Durchsatz und echte Verarbeitung von Einträgen zu Einträgen.</p>
</div>
<div class="paragraph">
<p>Flink erledigt viele Dinge für sich. Etwas unkonventionell verwaltet es seinen eigenen Speicher, anstatt sich aus Leistungsgründen auf die systemeigenen Garbage Collection-Mechanismen von Java zu verlassen. Im Gegensatz zu Spark muss Flink nicht manuell optimiert und angepasst werden, wenn sich die Eigenschaften der verarbeiteten Daten ändern. Es übernimmt auch die automatische Partitionierung und Zwischenspeicherung von Daten.</p>
</div>
<div class="paragraph">
<p>Flink analysiert seine Arbeit und optimiert Aufgaben auf verschiedene Weise. Ein Teil dieser Analyse ähnelt dem, was SQL-Abfrageplaner in Beziehungsdatenbanken tun, um die effektivste Methode zum Implementieren einer bestimmten Aufgabe zu ermitteln. Es ist in der Lage, Phasen, die parallel abgeschlossen werden können, zu parallelisieren und gleichzeitig Daten für blockierende Aufgaben zusammenzuführen. Bei iterativen Aufgaben versucht Flink aus Performancegründen, Berechnungen auf den Knoten durchzuführen, auf denen die Daten gespeichert sind. Es kann auch eine "Delta-Iteration" oder eine Iteration nur für die Teile von Daten durchgeführt werden, die Änderungen aufweisen.</p>
</div>
<div class="paragraph">
<p>In Bezug auf die Benutzertools bietet Flink eine webbasierte Planungsansicht, mit der Aufgaben einfach verwaltet und das System angezeigt werden können. Benutzer können auch den Optimierungsplan für übermittelte Aufgaben anzeigen, um zu sehen, wie er tatsächlich im Cluster implementiert wird. Für Analyseaufgaben bietet Flink SQL-ähnliche Abfrage-, Grafikverarbeitungs- und Maschinenlernbibliotheken sowie In-Memory-Berechnungen.</p>
</div>
<div class="paragraph">
<p>Flink funktioniert gut mit anderen Komponenten. Es wird geschrieben, um ein guter Nachbar zu sein, wenn es innerhalb eines Hadoop-Stacks verwendet wird und nur die erforderlichen Ressourcen zu einem bestimmten Zeitpunkt beansprucht. Es lässt sich problemlos in YARN, HDFS und Kafka integrieren. Flink kann Aufgaben ausführen, die für andere Verarbeitungsframeworks wie Hadoop und Storm mit Kompatibilitätspaketen geschrieben wurden.</p>
</div>
<div class="paragraph">
<p>Einer der größten Nachteile von Flink ist derzeit, dass es sich um ein noch sehr junges Projekt handelt. Großeinsatz in freier Wildbahn ist immer noch nicht so verbreitet wie bei anderen Verarbeitungs-Frameworks, und die Skalierungsbeschränkungen von Flink wurden nicht eingehend untersucht. Mit dem schnellen Entwicklungszyklus und Funktionen wie den Kompatibilitätspaketen gibt es möglicherweise mehr Flink-Bereitstellungen, da Unternehmen die Möglichkeit haben, damit zu experimentieren.</p>
</div>
</div>
<div class="sect4">
<h5 id="summary">Zusammenfassung</h5>
<div class="paragraph">
<p>Flink bietet sowohl Stream-Verarbeitung mit geringer Latenz als auch Unterstützung für herkömmliche Batch-Aufgaben. Flink ist wahrscheinlich am besten für Unternehmen geeignet, die hohe Anforderungen an die Stream-Verarbeitung und einige stapelorientierte Aufgaben haben. Die Kompatibilität mit nativen Storm- und Hadoop-Programmen und die Fähigkeit, auf einem YARN-verwalteten Cluster ausgeführt zu werden, können die Evaluierung vereinfachen. Aufgrund seiner rasanten Entwicklung lohnt es sich, ein Auge darauf zu werfen.</p>
</div>
</div>
</div>
</div>
<div class="sect2">
<h3 id="_fazit">Fazit</h3>
<div class="paragraph">
<p>Innerhalb eines Big-Data-Systems gibt es zahlreiche Verarbeitungsmöglichkeiten.</p>
</div>
<div class="paragraph">
<p>Für reine Batch-Workloads, die nicht zeitkritisch sind, ist Hadoop eine gute Wahl, deren Implementierung wahrscheinlich kostengünstiger ist als bei einigen anderen Lösungen.</p>
</div>
<div class="paragraph">
<p>Für reine Streaming-Workloads bietet Storm eine breite Sprachunterstützung und kann eine sehr geringe Latenzzeit für die Verarbeitung bereitstellen, kann jedoch Duplikate bereitstellen und die Bestellung in der Standardkonfiguration nicht garantieren. Samza arbeitet eng mit YARN und Kafka zusammen, um Flexibilität, einfache Verwendung in mehreren Teams sowie eine unkomplizierte Replikation und Statusverwaltung zu gewährleisten.</p>
</div>
<div class="paragraph">
<p>Für gemischte Workloads bietet Spark Hochgeschwindigkeits-Stapelverarbeitung und Mikro-Stapelverarbeitung für das Streaming. Es bietet umfassende Unterstützung, integrierte Bibliotheken und Tools sowie flexible Integrationen. Flink bietet eine echte Stream-Verarbeitung mit Unterstützung für die Stapelverarbeitung. Es ist stark optimiert, kann Aufgaben ausführen, die für andere Plattformen geschrieben wurden, und bietet eine Verarbeitung mit geringer Latenz, steckt jedoch noch in den Anfängen der Einführung.</p>
</div>
<div class="paragraph">
<p>Die optimale Anpassung an Ihre Situation hängt in hohem Maße vom zu verarbeitenden Datenstatus, der zeitlichen Beschränkung Ihrer Anforderungen und den gewünschten Ergebnissen ab. Es gibt Kompromisse zwischen der Implementierung einer All-in-One-Lösung und der Arbeit mit eng fokussierten Projekten, und es gibt ähnliche Überlegungen, wenn neue und innovative Lösungen gegenüber ihren ausgereiften und erprobten Kollegen bewertet werden.</p>
</div>
</div>
</div></div>
<div class="row pl-3 mb-3">

<div class="a2a_kit a2a_kit_size_32 a2a_default_style">
<a class="a2a_button_facebook"></a>
<a class="a2a_button_tumblr"></a>
<a class="a2a_button_pinterest"></a>
<a class="a2a_button_pocket"></a>
<a class="a2a_button_evernote"></a>
<a class="a2a_button_twitter"></a>
<a class="a2a_button_line"></a>
<a class="a2a_button_email"></a>
<a class="a2a_button_reddit"></a>
<a class="a2a_button_digg"></a>
<a class="a2a_button_vk"></a>
<a class="a2a_dd" href="https://www.addtoany.com/share"></a>
</div>
<script type="1d6c4c0384383af98313a5eb-text/javascript">
    var a2a_config = a2a_config || {};
    a2a_config.onclick = 1;
</script>
<script async src="https://static.addtoany.com/menu/page.js" type="1d6c4c0384383af98313a5eb-text/javascript"></script>

</div>
</article>
<script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js" type="1d6c4c0384383af98313a5eb-text/javascript"></script>
<ins class="adsbygoogle" style="display:block" data-ad-format="autorelaxed" data-ad-client="ca-pub-7450216517803275" data-ad-slot="2842159643"></ins>
<script type="1d6c4c0384383af98313a5eb-text/javascript">
     (adsbygoogle = window.adsbygoogle || []).push({});
</script>
</div>
<div class="col-12 col-lg-3">
<div class="card my-4 ad-sidebar">
<script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js" type="1d6c4c0384383af98313a5eb-text/javascript"></script>
<ins class="adsbygoogle" style="display:block" data-ad-client="ca-pub-7450216517803275" data-ad-slot="8195814284" data-ad-format="auto" data-full-width-responsive="true"></ins>
<script type="1d6c4c0384383af98313a5eb-text/javascript">
        (adsbygoogle = window.adsbygoogle || []).push({});
    </script>
</div>
<div class="card my-4 ad-sidebar">
<script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js" type="1d6c4c0384383af98313a5eb-text/javascript"></script>
<ins class="adsbygoogle" style="display:block" data-ad-client="ca-pub-7450216517803275" data-ad-slot="8195814284" data-ad-format="auto" data-full-width-responsive="true"></ins>
<script type="1d6c4c0384383af98313a5eb-text/javascript">
        (adsbygoogle = window.adsbygoogle || []).push({});
    </script>
</div>
<div class="card my-4 sticky-top">
<h5 class="card-header">Related</h5>
<div class="card-body p-2">
<ul class="list-group list-group-flush">
<li class="list-group-item p-2">
<a href=/de/article/how-to-set-up-the-titan-graph-database-with-cassandra-and-elasticsearch-on-ubuntu-16-04>
So richten Sie die Titan Graph-Datenbank mit Cassandra und ElasticSearch unter Ubuntu 16.04 ein
</a>
</li>
<li class="list-group-item p-2">
<a href=/de/article/how-to-spin-up-a-hadoop-cluster-with-digitalocean-droplets>
So drehen Sie einen Hadoop-Cluster mit DigitalOcean-Tröpfchen auf
</a>
</li>
<li class="list-group-item p-2">
<a href=/de/article/an-introduction-to-hadoop>
Eine Einführung in Hadoop
</a>
</li>
<li class="list-group-item p-2">
<a href=/de/article/how-to-install-hadoop-in-stand-alone-mode-on-debian-9>
So installieren Sie Hadoop im Standalone-Modus unter Debian 9
</a>
</li>
<li class="list-group-item p-2">
<a href=/de/article/an-introduction-to-big-data-concepts-and-terminology>
Eine Einführung in Big Data-Konzepte und -Terminologie
</a>
</li>
<li class="list-group-item p-2">
<a href=/de/article/how-to-install-and-use-clickhouse-on-debian-9>
So installieren und verwenden Sie ClickHouse unter Debian 9
</a>
</li>
<li class="list-group-item p-2">
<a href=/de/article/how-to-install-hadoop-in-stand-alone-mode-on-ubuntu-18-04>
So installieren Sie Hadoop im Standalone-Modus unter Ubuntu 18.04
</a>
</li>
<li class="list-group-item p-2">
<a href=/de/article/user-data-collection-balancing-business-needs-and-user-privacy>
Benutzerdatenerfassung: Abwägen von Geschäftsanforderungen und Datenschutz
</a>
</li>
<li class="list-group-item p-2">
<a href=/de/article/how-to-install-hadoop-in-stand-alone-mode-on-ubuntu-16-04>
So installieren Sie Hadoop im Standalone-Modus unter Ubuntu 16.04
</a>
</li>
<li class="list-group-item p-2">
<a href=/de/article/an-introduction-to-the-kubernetes-dns-service>
Eine Einführung in den Kubernetes DNS Service
</a>
</li>
<li class="list-group-item p-2">
<a href=/de/article/understanding-nginx-server-and-location-block-selection-algorithms>
Grundlegendes zu Nginx Server- und Standortblockauswahlalgorithmen
</a>
</li>
<li class="list-group-item p-2">
<a href=/de/article/an-introduction-to-service-meshes>
Eine Einführung in Service Meshes
</a>
</li>
<li class="list-group-item p-2">
<a href=/de/article/what-is-immutable-infrastructure>
Was ist eine unveränderliche Infrastruktur?
</a>
</li>
<li class="list-group-item p-2">
<a href=/de/article/why-you-may-not-want-to-run-your-own-mail-server>
Warum möchten Sie möglicherweise keinen eigenen Mail-Server betreiben?
</a>
</li>
<li class="list-group-item p-2">
<a href=/de/article/an-introduction-to-json>
 Eine Einführung in JSON
</a>
</li>
<li class="list-group-item p-2">
<a href=/de/article/a-comparison-of-let-s-encrypt-commercial-and-private-certificate-authorities-and-self-signed-ssl-certificates>
Ein Vergleich von Let’s Encrypt, kommerziellen und privaten Zertifizierungsstellen und selbstsignierten SSL-Zertifikaten
</a>
</li>
<li class="list-group-item p-2">
<a href=/de/article/an-introduction-to-continuous-integration-delivery-and-deployment>
Eine Einführung in die kontinuierliche Integration, Bereitstellung und Bereitstellung
</a>
</li>
<li class="list-group-item p-2">
<a href=/de/article/an-introduction-to-let-s-encrypt>
Eine Einführung in Let’s Encrypt
</a>
</li>
<li class="list-group-item p-2">
<a href=/de/article/an-introduction-to-hadoop>
Eine Einführung in Hadoop
</a>
</li>
</ul>
</div>
</div>
</div>
</div>
</div>
<link rel="stylesheet" href="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.15.9/styles/androidstudio.min.css">
<script src="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.15.9/highlight.min.js" type="1d6c4c0384383af98313a5eb-text/javascript">
    </script>
<script type="1d6c4c0384383af98313a5eb-text/javascript">hljs.initHighlightingOnLoad();</script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/tocbot/4.4.2/tocbot.min.js" type="1d6c4c0384383af98313a5eb-text/javascript"></script>
<link rel="stylesheet" type="text/css" href="/static/toc.css">
<script type="1d6c4c0384383af98313a5eb-text/javascript">
        tocbot.init({
            // Where to render the table of contents.
            tocSelector: '.content-toc',
            // Where to grab the headings to build the table of contents.
            contentSelector: '.content',
            // Which headings to grab inside of the contentSelector element.
            
            // For headings inside relative or absolute positioned containers within content.
            hasInnerContainers: true,
        });
    </script>
<footer class="py-5 bg-dark">
<div class="container text-white">
<p> DMCA: dmca#codeflow.stie </p>
Copyright ©<span> 2022</span>
</div>
</footer>
<script src="/cdn-cgi/scripts/7d0fa10a/cloudflare-static/rocket-loader.min.js" data-cf-settings="1d6c4c0384383af98313a5eb-|49" defer=""></script><script type="text/javascript">(function(){window['__CF$cv$params']={r:'71173ef4cb7b06e9',m:'rBKh6Mw97G5KHwS02mq3BaQWbXcB48vgigd1DHWUXeg-1653575816-0-AYEFXeb6+oUkONEj6hPrDrzQfo2rHtG7SQ811MxfgxbzbPtoglZqEnYy4d8ST2qsTAPvCjBuYZfLiEKe++9MZWIIPJpdQZDi6FHvVYvKcm0zTrnMDPJY/zcB7cskziEhoKCeF8ub7m/VHu06P/1m/hspiotHPwlfCSSfZFD68SDLcOYOzc/fi72ednCvUHWIXYqLblrl3VfUhM6nLdcTe/Y=',s:[0x1ad1076c61,0x1b5b67cf8f],u:'/cdn-cgi/challenge-platform/h/b'}})();</script><script defer src="https://static.cloudflareinsights.com/beacon.min.js/v652eace1692a40cfa3763df669d7439c1639079717194" integrity="sha512-Gi7xpJR8tSkrpF7aordPZQlW2DLtzUlZcumS8dMQjwDHEnw9I7ZLyiOj/6tZStRBGtGgN6ceN6cMH8z7etPGlw==" data-cf-beacon='{"rayId":"71173ef4cb7b06e9","version":"2021.12.0","r":1,"token":"31f0c95707644adab8d1a3ff2c0f35eb","si":100}' crossorigin="anonymous"></script>
</body>
</html>