
<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="description" content="">
  <meta name="keywords" content="Message queue, requests, nat, kafka, Percentile, redis, IT, System under test">

  <meta property="og:description" content="">
  <meta property="og:site_name" content="dzone.com">
  <meta property="og:title" content="Benchmarking Message Queue Latency - DZone Performance">
  <meta property="og:url" content="https://dzone.com/articles/benchmarking-message-queue-latency">
  <meta property="og:image" content="https://dz2cdn2.dzone.com/storage/article-thumb/1225321-thumb.jpg">
  <meta property="og:type" content="article">

  <meta name="twitter:site" content="@DZoneInc">
  <meta name="twitter:image" content="https://dz2cdn2.dzone.com/storage/article-thumb/1225321-thumb.jpg">
  <meta name="twitter:card" content="summary_large_image">
  <meta name="twitter:description" content="">
  <meta name="twitter:title" content="Benchmarking Message Queue Latency - DZone Performance">

  <meta name="referrer" content="origin-when-cross-origin">
  <meta name="google-site-verification" content="kndbhxcupfEqWmZclhCpB6vlgOs7QSmx2UHAGGnP2mA">
  <meta name="df-verify" content="df0d76632b4543">

  <link rel="icon" type="image/x-icon" href="https://dz2cdn2.dzone.com/themes/dz20/images/favicon.png">
  <link rel="image_src" href="https://dz2cdn2.dzone.com/storage/article-thumb/1225321-thumb.jpg">
  <link rel="canonical" href="https://dzone.com/articles/benchmarking-message-queue-latency">

  <title>Benchmarking Message Queue Latency - DZone Performance</title>

  <link rel="preload" href="https://fonts.dzone.com/themes/dz20/font/fontello.woff?11773374" as="font" type="font/woff" crossorigin="anonymous">

  <link rel="stylesheet" media="all" href="https://dz2cdn2.dzone.com/themes/dz20/ftl/icons.css">
  <link rel="stylesheet" media="all" href="https://dz2cdn2.dzone.com/themes/dz20/lib/static/bootstrap/bootstrap.min.css">
  <link rel="stylesheet" media="all" href="https://dz2cdn2.dzone.com/themes/dz20/ftl/article/global.css">
  <link rel="stylesheet" media="all" href="https://dz2cdn2.dzone.com/themes/dz20/ftl/header/styles.css">
</head>
<body>
<div id="ftl-header">
  <div class="container-fluid header">
    <div class="row">
      <div class="col-md-12" style="padding: 0;">
        <div class="header-top">
          <div class="header-container">
            <div class="pull-left logo-container">
              <div class="logo">
                <a class="inner" href="/">
                  <picture>
                    <source srcset="https://dz2cdn2.dzone.com/themes/dz20/images/dz_logo_2021_cropped.webp" type="image/webp">
                    <source srcset="https://dz2cdn2.dzone.com/themes/dz20/images/dz_logo_2021_cropped.png" type="image/png">
                    <img src="https://dz2cdn2.dzone.com/themes/dz20/images/dz_logo_2021_cropped.png" width="160" height="52" alt="DZone">
                  </picture>
                </a>
              </div>

                <div class="active-portal"><a href="/apm-tools-performance-monitoring-optimization">Performance Zone</a></div>
            </div>

            <div class="pull-right login-and-search">
              <div id="authenticated-block" class="logged-in">
                <div class="welcome-back">Thanks for visiting DZone today,</div>
                <div id="user-header" class="user-info">
                  <button class="user-avatar">
                    <span id="header-username" class="username"></span>
                    <img id="header-avatar" src="" alt="user avatar">
                  </button>
                  <div id="user-dropdown" class="browse-user-menu">
                    <div class="user-content">
                      <a id="header-user-plug" href="#" class="user-description"></a>
                      <a id="header-user-edit" href="#" class="edit-profile">Edit Profile</a>
                    </div>
                    <ul class="user-actions">
                      <li id="first-user-action"><a id="header-dropdown-manage-email" href="#">Manage Email Subscriptions</a></li>
                      <li>
                        <a href="/articles/how-to-submit-a-post-to-dzone?utm_source=DZone&utm_medium=user_dropdown&utm_campaign=how_to_post">
                          How to Post to DZone
                        </a>
                      </li>
                      <li>
                        <a href="/articles/dzones-article-submission-guidelines">
                          Article Submission Guidelines
                        </a>
                      </li>
                    </ul>
                    <div class="bottom">
                      <a href="/users/logout.html" class="sign-out">Sign Out</a>
                      <a id="dropdown-view-profile" href="#" class="view-profile">View Profile</a>
                    </div>
                  </div>
                </div>

                <div class="post-content">
                  <button id="post-button" class="post-content--button">
                    <span class="post-class">Post</span>
                    <i class="icon-plus"></i>
                  </button>

                  <div id="post-menu" class="posting-links">
                    <div class="posting-links-menu">
                      <ul>
                        <li>
                          <img src="/themes/dz20/images/dz-postarticle.svg">
                          <a href="/content/article/post.html">Post an Article</a>
                        </li>
                        <li>
                          <a id="drafts-link" href="#">Manage My Drafts</a>
                        </li>
                      </ul>
                    </div>
                  </div>
                </div>
              </div>

              <div id="unauthenticated-block">
                <div class="dz-intro">Over 2 million developers have joined DZone.</div>
                <div class="mobile-invisible sign-in-join">
                  <a href="/users/login.html">Log In</a>
                  <span class="dz-intro-span">/</span>
                  <a href="/static/registration.html">Join</a>
                </div>
                <a class="join-icon" href="/users/login.html"><i class="icon-user"></i></a>
              </div>
              <div class="headerSearch">
                <a class="icon-search dropdown-toggle" href="/search"></a>
              </div>
            </div>
          </div>
        </div>

        <div class="header-bottom">


          <ul class="portals header-container scrollable-ul">
            <li>
              <a href="/refcardz" id="header-refcardz">
                <em>Refcardz</em>
              </a>
            </li>
            <li>
              <a href="/trendreports" id="header-research">
                <em>Trend Reports</em>
              </a>
            </li>
            <li>
              <a href="/webinars" id="header-webinars">
                <em>Webinars</em>
              </a>
            </li>
            <li class="last-portal-link">
              <a href="#" id="header-portals">
                <em>
                  Zones
                  <span id="zone-arrow" class="collapsible-toggle">
                    <i class="icon-angle-down"></i>
                    <i class="icon-angle-up"></i>
                  </span>
                </em>
              </a>
            </li>

            <li class="separator" aria-hidden="true" style="color: #d9dcdd;">|</li>
            <li id="portal-list" class="portal-topics">
              <ul>
                  <li>
                    <a href="/agile-methodology-training-tools-news" id="header-2">Agile</a>
                  </li>
                  <li>
                    <a href="/artificial-intelligence-tutorials-tools-news" id="header-4001">AI</a>
                  </li>
                  <li>
                    <a href="/big-data-analytics-tutorials-tools-news" id="header-3">Big Data</a>
                  </li>
                  <li>
                    <a href="/cloud-computing-tutorials-tools-news" id="header-4">Cloud</a>
                  </li>
                  <li>
                    <a href="/database-sql-nosql-tutorials-tools-news" id="header-5">Database</a>
                  </li>
                  <li>
                    <a href="/devops-tutorials-tools-news" id="header-6">DevOps</a>
                  </li>
                  <li>
                    <a href="/enterprise-integration-training-tools-news" id="header-7">Integration</a>
                  </li>
                  <li>
                    <a href="/iot-developer-tutorials-tools-news-reviews" id="header-8">IoT</a>
                  </li>
                  <li>
                    <a href="/java-jdk-development-tutorials-tools-news" id="header-1">Java</a>
                  </li>
                  <li>
                    <a href="/microservices-news-tutorials-tools" id="header-6001">Microservices</a>
                  </li>
                  <li>
                    <a href="/open-source-news-tutorials-tools" id="header-7001">Open Source</a>
                  </li>
                  <li>
                    <a href="/apm-tools-performance-monitoring-optimization" id="header-10">Performance</a>
                  </li>
                  <li>
                    <a href="/application-web-network-security" id="header-2001">Security</a>
                  </li>
                  <li>
                    <a href="/web-development-programming-tutorials-tools-news" id="header-11">Web Dev</a>
                  </li>
              </ul>
            </li>
          </ul>
        </div>
      </div>
    </div>
  </div>
</div>

<script async src="https://dz2cdn2.dzone.com/themes/dz20/ftl/header/bundle.js"></script><link rel="stylesheet" media="all" href="https://dz2cdn2.dzone.com/themes/dz20/ftl/article/styles.css">




<div id="ftl-article" >
  <div class="container-fluid body">
    <div class="row">
      <div class="col-md-12">
        <div class="articles-wrap">
              <div class="ad-container">
                <div id="div-gpt-ad-1435246566686-0" class="ads-billboard-article" data-gpt-slot="top"></div>
              </div>


          <div class="article-stream widget-top-border">
                <div class="content-right-images">
                  <div id="div-gpt-ad-1435246566686-2" class="sidebar-ad" data-gpt-desktop="true" data-gpt-slot="sidebar1"></div>
                </div>

                <script type="application/ld+json">
                  {
                    "@context": "http://schema.org",
                    "@type": "Article",
                    "headline": "Benchmarking Message Queue Latency",
                    "author": {
                      "@type": "Person",
                      "name": "Tyler Treat"
                    },
                    "audience": "software developers",
                    "keywords": "messaging,benchmarking,rabbitmq,kafka,redis,nats,latency",
                    "timeRequired": "PT10M",
                    "commentCount": 1,
                    "wordCount": "2348",
                    "accessMode": "textual, visual",
                    "dateCreated": "2016-02-17T01:16:00Z",
                    "datePublished": "2016-02-17T00:00:00Z",
                    "dateModified": "2017-03-12T08:37:24Z",
                    "articleSection": "apm-tools-performance-monitoring-optimization",
                    "publisher": {
                      "@type": "Organization",
                      "name": "DZone",
                      "url": "https://dzone.com",
                      "logo": {
                        "@type": "ImageObject",
                        "url": "https://dzone.com/themes/dz20/images/dz_logo_2021_cropped.png"
                      }
                    },
                    "articleBody": "about a year and a half ago, i published dissecting message queues , which broke down a few different messaging systems and did some performance benchmarking. it was a naive attempt and had a lot of problems , but it was also my first time doing any kind of system benchmarking. it turns out benchmarking systems correctly is actually pretty difficult and many folks get it wrong. i don’t claim to have gotten it right, but over the past year and a half, i’ve learned a lot, tried to build some better tools, and improve my methodology. tooling and methodology the dissecting message queues benchmarks used a framework i wrote which published a specified number of messages effectively as fast as possible, received them, and recorded the end-to-end latency. there are several problems with this. first, load generation and consumption run on the same machine. second, the system under test runs on the same machine as the benchmark client—both of these confound measurements. third, running “pedal to the metal” and looking at the resulting latency isn’t a very useful benchmark because it’s not representative of a production environment (as gil tene likes to say, this is like driving your car as fast as possible, crashing it into a pole, and looking at the shape of the bumper afterwards—it’s always going to look bad). lastly, the benchmark recorded average latency, which, for all intents and purposes, is a useless metric to look at . i wrote flotilla to automate “scaled-up” benchmarking—running the broker and benchmark clients on separate, distributed vms. flotilla also attempted to capture a better view of latency by looking at the latency distribution, though it only went up to the 99th percentile, which can sweep a lot of really bad things under the rug as we’ll see later. however, it still ran tests at full throttle, which isn’t great. bench is an attempt to get back to basics. it’s a simple, generic benchmarking library for measuring latency. it provides a straightforward requester interface which can be implemented for various systems under test. bench works by attempting to issue a fixed rate of requests per second and measuring the latency of each request issued synchronously. latencies are captured using hdr histogram , which observes the complete latency distribution and allows us to look, for example, at “six nines” latency. introducing a request schedule allows us to measure latency for different configurations of request rate and message size, but in a “closed-loop” test, it creates another problem called coordinated omission . the problem with a lot of benchmarks is that they end up measuring service time rather than response time , but the latter is likely what you care about because it’s what your users experience. the best way to describe service time vs. response time is to think of a cash register. the cashier might be able to ring up a customer in under 30 seconds 99% of the time, but 1% of the time it takes three minutes . the time it takes to ring up a customer is the service time, while the response time consists of the service time plus the time the customer waited in line. thus, the response time is dependent upon the variation in both service time and the rate of arrival. when we measure latency, we really want to measure response time. now, let’s think about how most latency benchmarks work. they usually do this: note timestamp before request, t 0 . make synchronous request. note timestamp after request, t 1 . record latency t 1 – t 0 . repeat as needed for request schedule. what’s the problem with this? nothing, as long as our requests fit within the specified request schedule. for example, if we’re issuing 100 requests per second and each request takes 10 ms to complete, we’re good. however, if one request takes 100 ms to complete, that means we issued only one request during those 100 ms when, according to our schedule, we should have issued 10 requests in that window. nine other requests should have been issued, but the benchmark effectively coordinated with the system under test by backing off. in reality, those nine requests waited in line—one for 100 ms, one for 90 ms, one for 80 ms, etc. most benchmarks don’t capture this time spent waiting in line, yet it can have a dramatic effect on the results. the graph below shows the same benchmark with coordinated omission both uncorrected (red) and corrected (blue): hdr histogram attempts to correct coordinated omission by filling in additional samples when a request falls outside of its expected interval. we can also deal with coordinated omission by simply avoiding it altogether—always issue requests according to the schedule. message queue benchmarks i benchmarked several messaging systems using bench—rabbitmq (3.6.0), kafka (0.8.2.2 and 0.9.0.0), redis (2.8.4) pub/sub, and nats (0.7.3). in this context, a “request” consists of publishing a message to the server and waiting for a response (i.e. a round trip). we attempt to issue requests at a fixed rate and correct for a coordinated omission, then plot the complete latency distribution all the way up to the 99.9999th percentile. we repeat this for several configurations of request rate and request size. it’s also important to note that each message going to and coming back from the server are of the specified size, i.e. the “response” is the same size as the “request.” the configurations used are listed below. each configuration is run for a sustained 30 seconds. 256b requests at 3,000 requests/sec (768 kb/s) 1kb requests at 3,000 requests/sec (3 mb/s) 5kb requests at 2,000 requests/sec (10 mb/s) 1kb requests at 20,000 requests/sec (20.48 mb/s) 1mb requests at 100 requests/sec (100 mb/s) these message sizes are mostly arbitrary, and there might be a better way to go about this. though i think it’s worth pointing out that the ethernet mtu is 1500 bytes, so accounting for headers, the maximum amount of data you’ll get in a single tcp packet will likely be between 1400 and 1500 bytes. the system under test and benchmarking client are on two different m4.xlarge ec2 instances (2.4 ghz intel xeon haswell, 16gb ram) with enhanced networking enabled. redis and nats redis pub/sub and nats have similar performance characteristics. both offer very lightweight, non-transactional messaging with no persistence options (discounting redis’ rdb and aof persistence, which don’t apply to pub/sub), and both support some level of topic pattern matching. i’m hesitant to call either a “message queue” in the traditional sense, so i usually just refer to them as message brokers or buses. because of their ephemeral nature, both are a nice choice for low-latency, lossy messaging. redis tail latency peaks around 1.5 ms. nats performance looks comparable to redis. latency peaks around 1.2 ms. the resemblance becomes more apparent when we overlay the two distributions for the 1kb and 5kb runs. nats tends to be about 0.1 to 0.4 ms faster. the 1kb, 20,000 requests/sec run uses 25 concurrent connections. with concurrent load, tail latencies jump up, peaking around 90 and 120 ms at the 99.9999th percentile in nats and redis, respectively. large messages (1mb) don’t hold up nearly as well, exhibiting large tail latencies starting around the 95th and 97th percentiles in nats and redis, respectively. 1mb is the default maximum message size in nats. the latency peaks around 214 ms. again, keep in mind these are synchronous, roundtrip latencies. apcera’s ivan kozlovic pointed out that the version of the nats client i was using didn’t include a recent performance optimization. before, the protocol parser scanned over each byte in the payload, but the newer version skips to the end (the previous benchmarks were updated to use the newer version). the optimization does have a noticeable effect, illustrated below. there was about a 30% speedup with the 5kb latencies. the difference is even more pronounced in the 1mb case, which has roughly a 90% speedup up to the 90th percentile. the linear scale in the graph below hides this fact, but at the 90th percentile, for example, the pre-optimization latency is 10 ms and the optimized latency is 3.8 ms. clearly, the large tail is mostly unaffected, however. in general, this shows that nats and redis are better suited to smaller messages (well below 1mb), in which latency tends to be sub-millisecond up to four nines. rabbitmq and kafka rabbitmq is a popular amqp implementation. unlike nats, it’s a more traditional message queue in the sense that it supports binding queues and transactional delivery semantics. consequently, rabbitmq is a more “heavyweight” queuing solution and tends to pay an additional premium with latency. in this benchmark, non-durable queues were used. as a result, we should see reduced latencies since we aren’t going to disk. latency tends to be sub-millisecond up to the 99.7th percentile, but we can see that it doesn’t hold up to nats beyond that point for the 1kb and 5kb payloads. kafka , on the other hand, requires disk persistence, but this doesn’t have a dramatic effect on latency until we look at the 94th percentile and beyond, when compared to rabbitmq. writes should be to page cache with flushes to disk happening asynchronously. the graphs below are for 0.8.2.2. once again, the 1kb, 20,000 requests/sec run is distributed across 25 concurrent connections. with rabbitmq, we see the dramatic increase in tail latencies as we did with redis and nats. the rabbitmq latencies in the concurrent case stay in line with the previous latencies up to about the 99th percentile. interestingly, kafka doesn’t appear to be significantly affected. the latencies of 20,000 requests/sec at 1kb per request are not terribly different than the latencies of 3,000 requests/sec at 1kb per request, both peaking around 250 ms. what’s particularly interesting is the behavior of 1mb messages vs. the rest. with rabbitmq, there’s almost a 14x difference in max latencies between the 5kb and 1mb runs with 1mb being the faster. with kafka 0.8.2.2, the difference is over 126x in the same direction. we can plot the 1mb latencies for rabbitmq and kafka since it’s difficult to discern them with a linear scale. i tried to understand what was causing this behavior. i’ve yet to find a reasonable explanation for rabbitmq. intuition tells me it’s a result of buffering—either at the os level or elsewhere—and the large messages cause more frequent flushing. remember that these benchmarks were with transient publishes. there should be no disk accesses occurring though my knowledge of rabbit’s internals is admittedly limited. the fact that this behavior occurs in rabbitmq and not redis or nats seems odd. nagle’s algorithm is disabled in all of the benchmarks (tcp_nodelay). after inspecting packets with wireshark, it doesn’t appear to be a problem with delayed acks. to show just how staggering the difference is, we can plot kafka 0.8.2.2 and rabbitmq 1mb latencies alongside redis and nats 5kb latencies. they are all within the same ballpark. whatever the case may be, both rabbitmq and kafka appear to handle large messages extremely well in contrast to redis and nats. this leads me to believe you’ll see better overall throughput, in terms of raw data, with rabbitmq and kafka, but more predictable, tighter tail latencies with redis and nats. where slas are important, it’s hard to beat nats. of course, it’s unfair to compare kafka with something like nats or redis or even rabbitmq since they are very different (and sometimes complementary), but it’s also worth pointing out that the former is much more operationally complex. however, benchmarking kafka 0.9.0.0 (blue and red) shows an astounding difference in tail latencies compared to 0.8.2.2 (orange and green). kafka 0.9’s performance is much more in line with rabbitmq’s at high percentiles as seen below. likewise, it’s a much closer comparison to nats when looking at the 1kb and 5kb runs. as with 0.8, kafka 0.9 does an impressive job dealing with 1mb messages in comparison to nats, especially when looking at the 92nd percentile and beyond. it’s hard to decipher in the graph below, but kafka 0.9’s 99th, 99.9th, and 99.99th percentile latencies are 0.66, 0.78, and 1.35 ms, respectively. my initial thought was that the difference between kafka 0.8 and 0.9 was attributed to a change in fsync behavior. to quote the kafka documentation : kafka always immediately writes all data to the filesystem and supports the ability to configure the flush policy that controls when data is forced out of the os cache and onto the disk using the flush. this flush policy can be controlled to force data to disk after a period of time or after a certain number of messages has been written. however, there don’t appear to be any changes in the default flushing configuration between 0.8 and 0.9. the default configuration disables application fsync entirely, instead relying on the os’s background flush. jay kreps indicates it’s a result of several “high percentile latency issues” that were fixed in 0.9. after scanning the 0.9 release notes , i was unable to determine specifically what those fixes might be. either way, the difference is certainly not something to scoff at. conclusion as always, interpret these benchmark results with a critical eye and perform your own tests if you’re evaluating these systems. this was more an exercise in benchmark methodology and tooling than an actual system analysis (and, as always, there’s still a lot of room for improvement). if anything, i think these results show how much we can miss by not looking beyond the 99th percentile. in almost all cases, everything looks pretty good up to that point, but after that things can get really bad . this is important to be conscious of when discussing slas. i think the key takeaway is to consider your expected load in production, benchmark configurations around that, determine your allowable service levels, and iterate or provision more resources until you’re within those limits. the other important takeaway with respect to benchmarking is to look at the complete latency distribution. otherwise, you’re not getting a clear picture of how your system actually behaves.",
                    "mainEntityOfPage": {
                      "@type": "WebPage",
                      "@id": "https://dzone.com/articles/benchmarking-message-queue-latency"
                    },
                    "image": {
                      "@type": "ImageObject",
                      "url": "https://dzone.com//dz2cdn2.dzone.com/storage/article-thumb/1225321-thumb.jpg"
                    }
                  }
                </script>

                  <script type="application/ld+json">
                    {
                      "@context": "https://schema.org",
                      "@type": "BreadcrumbList",
                      "itemListElement": [{
                        "@type": "ListItem",
                        "position": 1,
                        "name": "DZone",
                        "item": "https://dzone.com"
                      }, {
                        "@type": "ListItem",
                        "position": 2,
                        "name": "Performance Zone",
                        "item": "https://dzone.com/apm-tools-performance-monitoring-optimization"
                      }, {
                        "@type": "ListItem",
                        "position": 3,
                        "name": "Benchmarking Message Queue Latency",
                        "item": "https://dzone.com/articles/benchmarking-message-queue-latency"
                      }]
                    }
                  </script>

            <article>
              <div class="content">
                <div class="header">
                  <div class="col-xs-12 breadcrumb-padding">
                    <a href="/">DZone</a>
                    >
                      <a href="/apm-tools-performance-monitoring-optimization">Performance Zone</a>
                      >
                      <a href="#">Benchmarking Message Queue Latency</a>
                  </div>


                  <div class="header-title">
                    <div class="title">
                      <h1 class="article-title">Benchmarking Message Queue Latency</h1>
                    </div>

                    <div class="subhead">
                      <h3>Benchmarking systems is difficult because test systems aren't real systems, test load isn't real load, and latency doesn't scale linearly. With good tools, like the ones shown in this article, it's possible to characterize behavior under a wider variety of conditions and maybe even predict behavior, including inflection points, under real load.</h3>
                    </div>

                    <div class="publish-meta">
                        <div class="article-author-meta">
                          <img src="https://secure.gravatar.com/avatar/dcbf01e42178cd9698fb3d4806e33d84?d=identicon&r=PG" class="avatar" alt="Tyler Treat user avatar" width="40">
                          by

                          <div class="author-info">
                            <span class="author-name">
                              <a href="/users/1406643/tylertreat.html" rel="nofollow">Tyler Treat</a>
                            </span>
                          </div>


                            <div class="mvb-award">
                              <i title="Most Valuable Blogger" class="icon-mvb-1"></i>
                            </div>


                          &middot;
                        </div>
                      <span class="author-date">
                        Feb. 17, 16
                      </span>
                      &middot;
                        <a href="/apm-tools-performance-monitoring-optimization" id="portal-name">
                          <span class="portal-name">Performance Zone</span>
                        </a>
                      &middot;
                      <span>Analysis</span>
                    </div>
                  </div>
                </div>

                <div class="author-n-useraction">
                  <div class="like action">
                    <div id="activity-like-icon" class="dz-like icon-thumbs-up">
                      <span class="action-label">
                        <span id="activity-like-text">Like</span>
                      </span>
                      <a href="#">
                        <span id="activity-like-counter">(5)</span>
                      </a>
                    </div>
                  </div>

                  <div class="action">

                    <button class="comment">
                      <i class="icon-comment"></i>
                      Comment
                      <span id="activity-comment-counter" class="comment-count"></span>
                    </button>
                  </div>

                  <div class="save action">
                    <div id="activity-save-icon" class="save icon-star-empty">
                      <span id="activity-save-text" class="action-label">Save</span>
                    </div>
                  </div>

                  <div class="tweet action">
                    <a id="tweet-link" href="" class="title" target="_blank">
                      <span><i class="icon-twitter"></i></span>
                      <span class="action-label">Tweet</span>
                    </a>
                  </div>

                  <div class="pull-right">
                    <div id="activity-view-container" class="article-views action">
                      <i class="icon-eye"></i> 10.42K
                      <span class="action-label">Views</span>
                    </div>
                  </div>
                </div>

                    <div class="signin-prompt">
                      <p>Join the DZone community and get the full member experience.</p>
                      <a id="article-signin-prompt" href="/static/registration.html">Join For Free</a>
                    </div>
                    <div class="arrow-down"></div>

                  <div id="top-bumper-container"></div>

                <div>
                  <div class="content-html"><p>
 about a year and a half ago, i published
 <a href="http://bravenewgeek.com/dissecting-message-queues/" style="background-color: rgb(255, 255, 255); line-height: 1.45;">
  dissecting message queues
 </a>
 , which broke down a few different messaging systems and did some performance benchmarking. it was a naive attempt and had
 <a href="http://bravenewgeek.com/benchmark-responsibly/" style="background-color: rgb(255, 255, 255); line-height: 1.45;">
  a lot of problems
 </a>
 , but it was also my first time doing any kind of system benchmarking. it turns out benchmarking systems correctly is actually pretty difficult and many folks get it wrong. i don’t claim to have gotten it right, but over the past year and a half, i’ve learned a lot, tried to build some better tools, and improve my methodology.
</p>
<h2>
 tooling and methodology
</h2>
<p>
 the dissecting message queues benchmarks used a
 <a href="https://github.com/tylertreat/mq-benchmarking">
  framework
 </a>
 i wrote which published a specified number of messages effectively as fast as possible, received them, and recorded the end-to-end latency. there are several problems with this. first, load generation and consumption run on the same machine. second, the system under test runs on the same machine as the benchmark client—both of these confound measurements. third, running “pedal to the metal” and looking at the resulting latency isn’t a very useful benchmark because it’s not representative of a production environment (as
 <a href="https://twitter.com/giltene">
  gil tene
 </a>
 likes to say, this is like driving your car as fast as possible, crashing it into a pole, and looking at the shape of the bumper afterwards—it’s always going to look bad). lastly, the benchmark recorded average latency, which, for all intents and purposes, is a
 <a href="http://bravenewgeek.com/everything-you-know-about-latency-is-wrong/">
  <em>
   useless
  </em>
  metric to look at
 </a>
 .
</p>
<p>
 i wrote
 <a href="https://github.com/tylertreat/flotilla">
  flotilla
 </a>
 to automate “scaled-up” benchmarking—running the broker and benchmark clients on separate, distributed vms. flotilla also attempted to capture a better view of latency by looking at the latency distribution, though it only went up to the 99th percentile, which can sweep a lot of really bad things under the rug as we’ll see later. however, it still ran tests at full throttle, which isn’t great.
</p>
<p>
 <a href="https://github.com/tylertreat/bench">
  bench
 </a>
 is an attempt to get back to basics. it’s a simple, generic benchmarking library for measuring latency. it provides a straightforward requester interface which can be implemented for various systems under test. bench works by attempting to issue a fixed rate of requests per second and measuring the latency of each request issued synchronously. latencies are captured using
 <a href="https://github.com/codahale/hdrhistogram">
  hdr histogram
 </a>
 , which observes the complete latency distribution and allows us to look, for example, at “six nines” latency.
</p>
<p>
 introducing a request schedule allows us to measure latency for different configurations of request rate and message size, but in a “closed-loop” test, it creates another problem called
 <em>
  <a href="https://groups.google.com/forum/#!msg/mechanical-sympathy/icnzjejuhfe/bfdekfbes_sj">
   coordinated omission
  </a>
 </em>
 . the problem with a lot of benchmarks is that they end up measuring
 <em>
  service time
 </em>
 rather than
 <em>
  response time
 </em>
 , but the latter is likely what you care about because it’s what your users experience.
</p>
<p>
 the best way to describe service time vs. response time is to think of a cash register. the cashier might be able to ring up a customer in under 30 seconds 99% of the time, but 1% of the time it takes
 <em>
  three minutes
 </em>
 . the time it takes to ring up a customer is the service time, while the response time consists of the service time
 <em>
  plus
 </em>
 the time the customer waited in line. thus, the response time is dependent upon the variation in both service time and the rate of arrival. when we measure latency, we really want to measure response time.
</p>
<p>
 now, let’s think about how most latency benchmarks work. they usually do this:
</p>
<ol>
 <li>
  note timestamp before request,
  <em>
   t
   <sub>
    0
   </sub>
  </em>
  .
 </li>
 <li>
  make synchronous request.
 </li>
 <li>
  note timestamp after request,
  <em>
   t
   <sub>
    1
   </sub>
  </em>
  .
 </li>
 <li>
  record latency
  <em>
   t
   <sub>
    1
   </sub>
  </em>
  –
  <em>
   t
   <sub>
    0
   </sub>
  </em>
  .
 </li>
 <li>
  repeat as needed for request schedule.
 </li>
</ol>
<p>
 what’s the problem with this? nothing, as long as our requests fit within the specified request schedule.  for example, if we’re issuing 100 requests per second and each request takes 10 ms to complete, we’re good. however, if one request takes 100 ms to complete, that means we issued only one request during those 100 ms when, according to our schedule, we should have issued 10 requests in that window. nine other requests
 <em>
  should
 </em>
 have been issued, but the benchmark effectively coordinated with the system under test by backing off. in reality, those nine requests waited in line—one for 100 ms, one for 90 ms, one for 80 ms, etc. most benchmarks don’t capture this time spent waiting in line, yet it can have a
 <em>
  dramatic
 </em>
 effect on the results. the graph below shows the same benchmark with coordinated omission both uncorrected (red) and corrected (blue):
 <br/>
 <a href="http://bravenewgeek.com/wp-content/uploads/2016/02/coordinated_omission.png" rel="attachment wp-att-2178">
  <img alt="coordinated_omission" class="size-full wp-image-2178 aligncenter fr-fil fr-dib" src="https://dz2cdn1.dzone.com/storage/temp/14012734-coordinated_omission.png"/>
 </a>
</p>
<p>
 hdr histogram attempts to correct coordinated omission by filling in additional samples when a request falls outside of its expected interval. we can also deal with coordinated omission by simply avoiding it altogether—always issue requests according to the schedule.
</p>
<h2>
 message queue benchmarks
</h2>
<p>
 i benchmarked several messaging systems using bench—rabbitmq (3.6.0), kafka (0.8.2.2 and 0.9.0.0), redis (2.8.4) pub/sub, and nats (0.7.3). in this context, a “request” consists of publishing a message to the server and waiting for a response (i.e. a round trip). we attempt to issue requests at a fixed rate and correct for a coordinated omission, then plot the complete latency distribution all the way up to the 99.9999th percentile. we repeat this for several configurations of request rate and request size. it’s also important to note that each message going to and coming back from the server are of the specified size, i.e. the “response” is the same size as the “request.”
</p>
<p>
 the configurations used are listed below. each configuration is run for a sustained 30 seconds.
</p>
<ul>
 <li>
  256b requests at 3,000 requests/sec (768 kb/s)
 </li>
 <li>
  1kb requests at 3,000 requests/sec (3 mb/s)
 </li>
 <li>
  5kb requests at 2,000 requests/sec (10 mb/s)
 </li>
 <li>
  1kb requests at 20,000 requests/sec (20.48 mb/s)
 </li>
 <li>
  1mb requests at 100 requests/sec (100 mb/s)
 </li>
</ul>
<p>
 these message sizes are mostly arbitrary, and there might be a better way to go about this. though i think it’s worth pointing out that the ethernet mtu is 1500 bytes, so accounting for headers, the maximum amount of data you’ll get in a single tcp packet will likely be between 1400 and 1500 bytes.
</p>
<p>
 the system under test and benchmarking client are on two different
 <em>
  <a href="https://aws.amazon.com/ec2/instance-types/">
   m4.xlarge
  </a>
 </em>
 ec2 instances (2.4 ghz intel xeon haswell, 16gb ram) with
 <a href="http://docs.aws.amazon.com/awsec2/latest/userguide/enhanced-networking.html">
  enhanced networking
 </a>
 enabled.
</p>
<h2>
 redis and nats
</h2>
<p>
 <a href="http://redis.io/topics/pubsub">
  redis pub/sub
 </a>
 and
 <a href="http://nats.io/">
  nats
 </a>
 have similar performance characteristics. both offer very lightweight, non-transactional messaging with no persistence options (discounting redis’ rdb and aof persistence, which don’t apply to pub/sub), and both support some level of topic pattern matching. i’m hesitant to call either a “message queue” in the traditional sense, so i usually just refer to them as message brokers or buses. because of their ephemeral nature, both are a nice choice for low-latency, lossy messaging.
</p>
<p>
 redis tail latency peaks around 1.5 ms.
</p>
<p>
 <a href="http://bravenewgeek.com/wp-content/uploads/2016/02/redis_latency.png" rel="attachment wp-att-2180">
  <img alt="redis_latency" class="size-full wp-image-2180 aligncenter fr-dii fr-fil" src="http://bravenewgeek.com/wp-content/uploads/2016/02/redis_latency.png"/>
 </a>
</p>
<p>
 nats performance looks comparable to redis. latency peaks around 1.2 ms.
</p>
<p>
 <a href="http://bravenewgeek.com/wp-content/uploads/2016/02/nats_latency.png" rel="attachment wp-att-2232">
  <img alt="nats_latency" class="size-full wp-image-2232 aligncenter fr-dii fr-fil" src="http://bravenewgeek.com/wp-content/uploads/2016/02/nats_latency.png"/>
 </a>
</p>
<p>
 the resemblance becomes more apparent when we overlay the two distributions for the 1kb and 5kb runs. nats tends to be about 0.1 to 0.4 ms faster.
</p>
<p>
 <a href="http://bravenewgeek.com/wp-content/uploads/2016/02/redis_nats_latency.png" rel="attachment wp-att-2234">
  <img alt="redis_nats_latency" class="size-full wp-image-2234 aligncenter fr-fil fr-dii" src="http://bravenewgeek.com/wp-content/uploads/2016/02/redis_nats_latency.png"/>
 </a>
</p>
<p>
 the 1kb, 20,000 requests/sec run uses 25 concurrent connections. with concurrent load, tail latencies jump up, peaking around 90 and 120 ms at the 99.9999th percentile in nats and redis, respectively.
</p>
<p>
 <a href="http://bravenewgeek.com/wp-content/uploads/2016/02/redis_nats_1kb_20000_latency.png" rel="attachment wp-att-2215">
  <img alt="redis_nats_1kb_20000_latency" class="size-full wp-image-2215 aligncenter fr-dii fr-fil" src="http://bravenewgeek.com/wp-content/uploads/2016/02/redis_nats_1kb_20000_latency.png"/>
 </a>
</p>
<p>
 large messages (1mb) don’t hold up nearly as well, exhibiting large tail latencies starting around the 95th and 97th percentiles in nats and redis, respectively. 1mb is the default maximum message size in nats. the latency peaks around 214 ms. again, keep in mind these are synchronous, roundtrip latencies.
</p>
<p>
 <a href="http://bravenewgeek.com/wp-content/uploads/2016/02/redis_nats_1mb_latency.png" rel="attachment wp-att-2185">
  <img alt="redis_nats_1mb_latency" class="size-full wp-image-2185 aligncenter fr-dii fr-fil" src="http://bravenewgeek.com/wp-content/uploads/2016/02/redis_nats_1mb_latency.png"/>
 </a>
</p>
<p>
 apcera’s
 <a href="https://twitter.com/ivankozlovic">
  ivan kozlovic
 </a>
 pointed out that the version of the nats client i was using didn’t include a recent performance optimization. before, the protocol parser scanned over each byte in the payload, but the newer version skips to the end (the previous benchmarks were updated to use the newer version). the optimization does have a noticeable effect, illustrated below. there was about a 30% speedup with the 5kb latencies.
</p>
<p>
 <a href="http://bravenewgeek.com/wp-content/uploads/2016/02/nats_optimization_latency.png" rel="attachment wp-att-2241">
  <img alt="nats_optimization_latency" class="size-full wp-image-2241 aligncenter fr-dii fr-fil" src="http://bravenewgeek.com/wp-content/uploads/2016/02/nats_optimization_latency.png"/>
 </a>
</p>
<p>
 the difference is even more pronounced in the 1mb case, which has roughly a 90% speedup up to the 90th percentile. the linear scale in the graph below hides this fact, but at the 90th percentile, for example, the pre-optimization latency is 10 ms and the optimized latency is 3.8 ms. clearly, the large tail is mostly unaffected, however.
</p>
<p>
 <a href="http://bravenewgeek.com/wp-content/uploads/2016/02/nats_1mb_optimization_latency.png" rel="attachment wp-att-2242">
  <img alt="nats_1mb_optimization_latency" class="size-full wp-image-2242 aligncenter fr-dii fr-fil" src="http://bravenewgeek.com/wp-content/uploads/2016/02/nats_1mb_optimization_latency.png"/>
 </a>
</p>
<p>
 in general, this shows that nats and redis are better suited to smaller messages (well below 1mb), in which latency tends to be sub-millisecond up to four nines.
</p>
<h3>
 rabbitmq and kafka
</h3>
<p>
 <a href="https://www.rabbitmq.com/">
  rabbitmq
 </a>
 is a popular amqp implementation. unlike nats, it’s a more traditional message queue in the sense that it supports binding queues and transactional delivery semantics. consequently, rabbitmq is a more “heavyweight” queuing solution and tends to pay an additional premium with latency. in this benchmark, non-durable queues were used. as a result, we should see reduced latencies since we aren’t going to disk.
</p>
<p>
 <a href="http://bravenewgeek.com/wp-content/uploads/2016/02/rabbitmq_latency.png" rel="attachment wp-att-2188">
  <img alt="rabbitmq_latency" class="size-full wp-image-2188 aligncenter fr-dii fr-fil" src="http://bravenewgeek.com/wp-content/uploads/2016/02/rabbitmq_latency.png"/>
 </a>
</p>
<p>
 latency tends to be sub-millisecond up to the 99.7th percentile, but we can see that it doesn’t hold up to nats beyond that point for the 1kb and 5kb payloads.
</p>
<p>
 <a href="http://bravenewgeek.com/wp-content/uploads/2016/02/rabbitmq_nats_latency.png" rel="attachment wp-att-2237">
  <img alt="rabbitmq_nats_latency" class="size-full wp-image-2237 aligncenter fr-dii fr-fil" src="http://bravenewgeek.com/wp-content/uploads/2016/02/rabbitmq_nats_latency.png"/>
 </a>
</p>
<p>
 <a href="http://kafka.apache.org/">
  kafka
 </a>
 , on the other hand, requires disk persistence, but this doesn’t have a dramatic effect on latency until we look at the 94th percentile and beyond, when compared to rabbitmq. writes should be to page cache with flushes to disk happening asynchronously. the graphs below are for 0.8.2.2.
</p>
<p>
 <a href="http://bravenewgeek.com/wp-content/uploads/2016/02/kafka_latency.png" rel="attachment wp-att-2189">
  <img alt="kafka_latency" class="size-full wp-image-2189 aligncenter fr-dii fr-fil" src="http://bravenewgeek.com/wp-content/uploads/2016/02/kafka_latency.png"/>
 </a>
</p>
<p>
 <a href="http://bravenewgeek.com/wp-content/uploads/2016/02/rabbitmq_kafka_latency.png" rel="attachment wp-att-2190">
  <img alt="rabbitmq_kafka_latency" class="size-full wp-image-2190 aligncenter fr-dii fr-fil" src="http://bravenewgeek.com/wp-content/uploads/2016/02/rabbitmq_kafka_latency.png"/>
 </a>
</p>
<p>
 once again, the 1kb, 20,000 requests/sec run is distributed across 25 concurrent connections. with rabbitmq, we see the dramatic increase in tail latencies as we did with redis and nats. the rabbitmq latencies in the concurrent case stay in line with the previous latencies up to about the 99th percentile. interestingly, kafka doesn’t appear to be significantly affected. the latencies of 20,000 requests/sec at 1kb per request are not terribly different than the latencies of 3,000 requests/sec at 1kb per request, both peaking around 250 ms.
</p>
<p>
 <a href="http://bravenewgeek.com/wp-content/uploads/2016/02/rabbitmq_kafka_1kb_20000_latency.png" rel="attachment wp-att-2216">
  <img alt="rabbitmq_kafka_1kb_20000_latency" class="alignnone size-full wp-image-2216 fr-dii fr-fil" src="http://bravenewgeek.com/wp-content/uploads/2016/02/rabbitmq_kafka_1kb_20000_latency.png"/>
 </a>
</p>
<p>
 what’s particularly interesting is the behavior of 1mb messages vs. the rest. with rabbitmq, there’s almost a
 <em>
  14x
 </em>
 difference in max latencies between the 5kb and 1mb runs with 1mb being the faster. with kafka 0.8.2.2, the difference is
 <em>
  over 126x
 </em>
 in the same direction. we can plot the 1mb latencies for rabbitmq and kafka since it’s difficult to discern them with a linear scale.
</p>
<p>
 <a href="http://bravenewgeek.com/wp-content/uploads/2016/02/rabbitmq_kafka_1mb_latency.png" rel="attachment wp-att-2191">
  <img alt="rabbitmq_kafka_1mb_latency" class="size-full wp-image-2191 aligncenter fr-dii fr-fil" src="http://bravenewgeek.com/wp-content/uploads/2016/02/rabbitmq_kafka_1mb_latency.png"/>
 </a>
</p>
<p>
 i
 <a href="https://twitter.com/tyler_treat/status/688234055985283073">
  tried to understand
 </a>
 what was causing this behavior. i’ve
 <a href="https://twitter.com/tyler_treat/status/688840911292219392">
  yet to find a reasonable explanation
 </a>
 for rabbitmq. intuition tells me it’s a result of buffering—either at the os level or elsewhere—and the large messages cause more frequent flushing. remember that these benchmarks were with transient publishes. there should be no disk accesses occurring though my knowledge of rabbit’s internals is admittedly limited. the fact that this behavior occurs in rabbitmq and not redis or nats seems odd. nagle’s algorithm is disabled in all of the benchmarks (tcp_nodelay). after inspecting packets with wireshark, it doesn’t appear to be a problem with delayed acks.
</p>
<p>
 to show just how staggering the difference is, we can plot kafka 0.8.2.2 and rabbitmq 1mb latencies alongside redis and nats 5kb latencies. they are all within the same ballpark. whatever the case may be, both rabbitmq and kafka appear to handle large messages extremely well in contrast to redis and nats.
</p>
<p>
 <a href="http://bravenewgeek.com/wp-content/uploads/2016/02/rabbitmq_kafka_nats_redis_latency.png" rel="attachment wp-att-2239">
  <img alt="rabbitmq_kafka_nats_redis_latency" class="size-full wp-image-2239 aligncenter fr-dii fr-fil" src="http://bravenewgeek.com/wp-content/uploads/2016/02/rabbitmq_kafka_nats_redis_latency.png"/>
 </a>
</p>
<p>
 this leads me to believe you’ll see better overall throughput, in terms of raw data, with rabbitmq and kafka, but more predictable, tighter tail latencies with redis and nats. where slas are important, it’s hard to beat nats. of course, it’s unfair to compare kafka with something like nats or redis or even rabbitmq since they are very different (and sometimes complementary), but it’s also worth pointing out that the former is much more operationally complex.
</p>
<p>
 however, benchmarking kafka 0.9.0.0 (blue and red) shows an astounding difference in tail latencies compared to 0.8.2.2 (orange and green).
</p>
<p>
 <a href="http://bravenewgeek.com/wp-content/uploads/2016/02/kafka_0_8_0_9_latency.png" rel="attachment wp-att-2249">
  <img alt="kafka_0_8_0_9_latency" class="alignnone size-full wp-image-2249 fr-dii fr-fil" src="http://bravenewgeek.com/wp-content/uploads/2016/02/kafka_0_8_0_9_latency.png"/>
 </a>
</p>
<p>
 kafka 0.9’s performance is much more in line with rabbitmq’s at high percentiles as seen below.
</p>
<p>
 <a href="http://bravenewgeek.com/wp-content/uploads/2016/02/rabbitmq_kafka_0_9_latency.png" rel="attachment wp-att-2250">
  <img alt="rabbitmq_kafka_0_9_latency" class="size-full wp-image-2250 aligncenter fr-dii fr-fil" src="http://bravenewgeek.com/wp-content/uploads/2016/02/rabbitmq_kafka_0_9_latency.png"/>
 </a>
</p>
<p>
 likewise, it’s a much closer comparison to nats when looking at the 1kb and 5kb runs.
</p>
<p>
 <a href="http://bravenewgeek.com/wp-content/uploads/2016/02/kafka_nats_latency.png" rel="attachment wp-att-2251">
  <img alt="kafka_nats_latency" class="size-full wp-image-2251 aligncenter fr-dii fr-fil" src="http://bravenewgeek.com/wp-content/uploads/2016/02/kafka_nats_latency.png"/>
 </a>
</p>
<p>
 as with 0.8, kafka 0.9 does an impressive job dealing with 1mb messages in comparison to nats, especially when looking at the 92nd percentile and beyond. it’s hard to decipher in the graph below, but kafka 0.9’s 99th, 99.9th, and 99.99th percentile latencies are 0.66, 0.78, and 1.35 ms, respectively.
</p>
<p>
 <a href="http://bravenewgeek.com/wp-content/uploads/2016/02/kafka_0_9_nats_1mb.png" rel="attachment wp-att-2252">
  <img alt="kafka_0_9_nats_1mb" class="size-full wp-image-2252 aligncenter fr-dii fr-fil" src="http://bravenewgeek.com/wp-content/uploads/2016/02/kafka_0_9_nats_1mb.png"/>
 </a>
</p>
<p>
 my
 <a href="https://twitter.com/tyler_treat/status/698605429836763137">
  initial thought
 </a>
 was that the difference between kafka 0.8 and 0.9 was attributed to a change in fsync behavior. to quote the
 <a href="http://kafka.apache.org/documentation.html#appvsosflush">
  kafka documentation
 </a>
 :
</p>
<p>
 kafka always immediately writes all data to the filesystem and supports the ability to configure the flush policy that controls when data is forced out of the os cache and onto the disk using the flush. this flush policy can be controlled to force data to disk after a period of time or after a certain number of messages has been written.
</p>
<p>
 however, there don’t appear to be any changes in the default flushing configuration between 0.8 and 0.9. the default configuration disables application fsync entirely, instead relying on the os’s background flush.
 <a href="https://twitter.com/jaykreps/status/698612652860268544">
  jay kreps indicates
 </a>
 it’s a result of several “high percentile latency issues” that were fixed in 0.9. after scanning the 0.9
 <a href="http://apache.arvixe.com/kafka/0.9.0.0/release_notes.html">
  release notes
 </a>
 , i was unable to determine specifically
 <em>
  what
 </em>
 those fixes might be. either way, the difference is certainly not something to scoff at.
</p>
<h3>
 conclusion
</h3>
<p>
 as always, interpret these benchmark results with a critical eye and perform your own tests if you’re evaluating these systems. this was more an exercise in benchmark methodology and tooling than an actual system analysis (and, as always, there’s still a lot of room for improvement). if anything, i think these results show how much we can miss by not looking beyond the 99th percentile. in almost all cases, everything looks
 <em>
  pretty
 </em>
 good up to that point, but after that
 <em>
  things can get really bad
 </em>
 . this is important to be conscious of when discussing slas.
</p>
<p>
 i think the key takeaway is to consider your expected load in production, benchmark configurations around that, determine your allowable service levels, and iterate or provision more resources until you’re within those limits. the other important takeaway with respect to benchmarking is to look at the complete latency distribution. otherwise, you’re not getting a clear picture of how your system actually behaves.
</p></div>
                </div>

                  <div id="bottom-bumper-container"></div>
                  <div class="article-tag-pill-container">
                      <span class="article-tag-pill">Message queue</span>
                      <span class="article-tag-pill">Requests</span>
                      <span class="article-tag-pill">Nat (unit)</span>
                      <span class="article-tag-pill">kafka</span>
                      <span class="article-tag-pill">Percentile</span>
                      <span class="article-tag-pill">Redis (company)</span>
                      <span class="article-tag-pill">IT</span>
                      <span class="article-tag-pill">System under test</span>
                  </div>

                  <div class="attribution">
                      <p>Published at DZone with permission of <span>Tyler Treat<span>, DZone MVB</span></span>.
                        <span>
                          <a href="http://bravenewgeek.com/benchmarking-message-queue-latency/" target="_blank">See the original article here.
                            <i class="icon-link-ext-alt"></i>
                          </a>
                        </span>
                      </p>
                    <p>Opinions expressed by DZone contributors are their own.</p>
                  </div>

                    <div class="related">
                      <h3>Popular on DZone</h3>
                        <ul>
                            <li class="relateddiv">
                              <a href="/articles/9-extraordinary-terraform-best-practices-that-will?fromrel=true">9 Extraordinary Terraform Best Practices That Will Change Your Infra World</a>
                            </li>
                            <li class="relateddiv">
                              <a href="/articles/role-of-development-team-in-an-agile-environment?fromrel=true">Role of Development Team in an Agile Environment</a>
                            </li>
                            <li class="relateddiv">
                              <a href="/articles/functional-vs-non-functional-requirements-the-full?fromrel=true">Functional vs. Non-Functional Requirements: The Full Guide, Definitions, and Technical Examples</a>
                            </li>
                            <li class="relateddiv">
                              <a href="/articles/how-to-optimize-mysql-queries-for-speed-and-perfor?fromrel=true">How to Optimize MySQL Queries for Speed and Performance</a>
                            </li>
                        </ul>
                      </div>
<div class="comments-overlay"></div>
<div id="comment-box">
  <div class="comment-box-wrapper">
    <div id="comment-input-editor"></div>
  </div>
  <div class="info hidden"></div>
  <div class="comments-content">
    <div class="comment-header">
      <hr />
      <span class="icon-comment">
        <span class="numOfComments"></span> Comments
      </span>
    </div>
    <div class="comments"></div>
  </div>
</div>
            </article>
          </div>

            <div id="above-pr-ad" class="bottom-ad-container">
              <div id="div-gpt-ad-1435246566686-11" data-gpt-slot="bottom"></div>
            </div>
            <div class="layout-card widget-top-border partner-resources-block" style="width:100%; margin-bottom: 1em;">
              <div class="main-container">
                <div class="featured-header">
                  <h2>
                      Performance<span> Partner Resources</span>
                  </h2>
                </div>
                <div class="partner-resources-container">
                  <div id="div-gpt-ad-1435246566686-5" class="resource-block" data-gpt-slot="partner" data-gpt-position="pr1"></div>
                  <div id="div-gpt-ad-1435246566686-6" class="resource-block" data-gpt-slot="partner" data-gpt-position="pr2"></div>
                  <div id="div-gpt-ad-1435246566686-7" class="resource-block" data-gpt-slot="partner" data-gpt-position="pr3"></div>
                </div>
              </div>
            </div>
        </div>
      </div>
    </div>
  </div>

    <div id="bsa-parent" class="bottom-sticky-ad-container hide">
      <div class="container">
        <div class="col-md-9">
          <div class="fixed-bottom-div">
            <div class="inline-block">
              <div id="div-gpt-ad-1635294790718-12" data-gpt-desktop="true" class="bottom-sticky-ad"></div>
            </div>
            <div class="inline-block">
              <span id="close" class="bottom-sticky-ad-close-button" onclick="removeBottomStickyAd()">
                X
              </span>
            </div>
          </div>
        </div>
      </div>
    </div>

  <div class="modal fade bd-example-modal-lg" id="modal-message" tabindex="-1" role="dialog" aria-hidden="true">
    <div class="modal-dialog">
      <div class="modal-content">
        <div class="modal-header"></div>
        <div class="modal-body"></div>
      </div>
    </div>
  </div>
</div>

<script async>const articleTitle = 'Benchmarking Message Queue Latency'
const articleUrl = 'https://dzone.com/articles/benchmarking-message-queue-latency'

const retweetLink = document.querySelector('#tweet-link')

function retweet(event) {
    event.preventDefault()
    event.stopPropagation()

    const twitter = 'https://twitter.com/intent/tweet'
    const params = '?text=' + encodeURIComponent(articleTitle) + '&url=' + articleUrl + '&ref=dzone.com&via=DZoneInc'
    const win = window.open(twitter + params, '_blank')
    win.focus()
}

retweetLink.addEventListener('click', retweet);

function showStatusMessage(options) {
  var modal = document.getElementById("modal-message");

  if(modal) {
    modal.classList.add(options.type);
    var modalBody = modal.querySelector(".modal-content .modal-body");
    var modalHeader = modal.querySelector(".modal-content .modal-header");

    modalHeader.innerText = options.header ? options.header : "";
    modalBody.innerText = options.body ? options.body : "" ;

    $(modal).modal("show");

    $(modal).on('hidden.bs.modal', function () {
      modal.classList.remove(options.type);
    });
  }
}

function showConfirmMessage(options) {
  var modal = document.getElementById("modal-message");

  if(modal) {
    modal.classList.add(options.type);
    var modalBody = modal.querySelector(".modal-content .modal-body");
    var modalHeader = modal.querySelector(".modal-content .modal-header");

    modalHeader.innerText = options.header ? options.header : "";
    modalBody.innerText = options.body ? options.body : "" ;

    if (options.textarea) {
      const textareaDiv = document.createElement('div')
      const textareaLabel = document.createElement('label')
      textareaLabel.setAttribute('for', 'modal-textarea')
      textareaLabel.innerText = options.textarea.label

      const textarea = document.createElement('textarea')
      textarea.id = 'modal-textarea'
      textarea.placeholder = (options.textarea.placeholder || '')
      textarea.setAttribute('rows', (options.textarea.rows || 3))
      textarea.classList.add('form-control', 'not-resizable')

      if (options.textarea.maxlength) {
        textarea.maxLength = options.textarea.maxlength
      }

      textareaDiv.appendChild(textareaLabel)
      textareaDiv.appendChild(textarea)
      modalBody.appendChild(textareaDiv)
    }

    var btnContainer = document.createElement("div");
    btnContainer.classList.add("btn-container");

    var noBtn = document.createElement("button");
    noBtn.innerText = options.noBtnText ? options.noBtnText : "No";
    noBtn.classList.add("no-btn");

    var yesBtn = document.createElement("button");
    yesBtn.innerText = options.yesBtnText ? options.yesBtnText : "Yes";
    yesBtn.classList.add("yes-btn");

    btnContainer.appendChild(noBtn);
    btnContainer.appendChild(yesBtn);

    modalBody.appendChild(btnContainer);

    $(modal).modal("show");

    $(noBtn).one("click", function() {
      $(modal).modal("hide");

      if(options.noCallback) {
        $(modal).one('hidden.bs.modal', function () {
          options.noCallback();
        });
      }
    });

    $(yesBtn).one("click", function() {
      $(modal).modal("hide");

      if(options.yesCallback) {
        $(modal).one('hidden.bs.modal', function () {
          options.yesCallback();
        });
      }
    });

    $(modal).on('hidden.bs.modal', function () {
      modal.classList.remove(options.type);
    });
  }
}
</script><link rel="stylesheet" media="all" href="https://dz2cdn2.dzone.com/themes/dz20/ftl/footer/styles.css">

<div id="ftl-footer">
  <div class="container-fluid footerOuter">
    <div class="row">
      <div class="col-md-12">
        <div class="container">
          <div class="row footer">
            <div class="col-md-12 footerWidget">
              <div class="row footerContainer footer">
                <div class="left col-xs-12 col-sm-7">
                  <div class="col-xs-12 social-media-icons footer-mobile">
                    <ul class="icons-only">
                      <li class="rss-icon" id="rss-footer-1">
                        <a href="/pages/feeds" target="_blank" rel="noreferrer noopener">
                          <i class="icon-rss-1"></i>
                        </a>
                      </li>
                      <li class="twitter-icon">
                        <a href="https://twitter.com/DZoneInc" target="_blank" rel="noreferrer noopener">
                          <i class="icon-twitter"></i>
                        </a>
                      </li>
                      <li class="facebook-icon">
                        <a href="https://www.facebook.com/DZoneInc" target="_blank" rel="noreferrer noopener">
                          <i class="icon-facebook-1"></i>
                        </a>
                      </li>
                      <li class="linkedin-icon">
                        <a href="https://www.linkedin.com/company/dzone/" target="_blank"
                           rel="noreferrer noopener">
                          <i class="icon-linkedin-1"></i>
                        </a>
                      </li>
                    </ul>
                  </div>

                  <div class="top-section col-xs-12">
                    <div class="col-xs-12 col-sm-6">
                      <p class="section-header">ABOUT US</p>
                      <ul class="link-group">
                        <li><a href="/pages/about" rel="noreferrer noopener">About DZone</a></li>
                        <li><a href="mailto:support@dzone.com" rel="noreferrer noopener">Send feedback</a></li>
                        <li><a href="https://careers.dzone.com/" target="_blank" rel="noreferrer noopener">Careers</a></li>
                          <li><a href="/sitemap" rel="noreferrer noopener">Sitemap</a></li>
                      </ul>
                    </div>
                    <div class="col-xs-12 col-sm-6">
                      <p class="section-header">ADVERTISE</p>
                      <ul class="link-group">
                        <li><a href="https://advertise.dzone.com" target="_blank" rel="noreferrer noopener">Advertise with DZone</a></li>
                      </ul>
                    </div>
                  </div>

                  <div class="bottom-section col-xs-12">
                    <div class="col-xs-12 col-sm-6">
                      <p class="section-header">CONTRIBUTE ON DZONE</p>
                      <ul class="bottom-top-list link-group">
                        <li><a href="/articles/dzones-article-submission-guidelines">Article Submission Guidelines</a></li>
                        <li><a href="/pages/mvb" rel="noreferrer noopener">MVB Program</a></li>
                        <li><a href="/pages/contribute" rel="noreferrer noopener">Become a Contributor</a></li>
                        <li><a href="/writers-zone" rel="noreferrer noopener">Visit the Writers' Zone</a></li>
                      </ul>

                      <p class="section-header">LEGAL</p>
                      <ul class="link-group">
                        <li><a href="/pages/tos" rel="noreferrer noopener">Terms of Service</a></li>
                        <li><a href="/pages/privacy" rel="noreferrer noopener">Privacy Policy</a></li>
                      </ul>
                    </div>
                    <div class="col-xs-12 col-sm-6">
                      <p class="section-header">CONTACT US</p>
                      <ul class="link-group">
                        <li>600 Park Offices Drive</li>
                        <li>Suite 300</li>
                        <li>Durham, NC 27709</li>
                        <li><a href="mailto:support@dzone.com" rel="noreferrer noopener">support@dzone.com</a></li>
                        <li><a href="tel:+19196780300" rel="noreferrer noopener">+1 (919) 678-0300</a></li>
                      </ul>
                    </div>
                  </div>
                </div>

                <div class="right col-xs-12 col-sm-5">

                  <p class="connect-text">Let's be friends:</p>
                  <div class="col-xs-12 social-media-icons footer-wide">
                    <ul class="icons-only">
                      <li class="rss-icon" id="rss-footer-1">
                        <a href="/pages/feeds" target="_blank" rel="noreferrer noopener">
                          <i class="icon-rss-1"></i>
                        </a>
                      </li>
                      <li class="twitter-icon">
                        <a href="https://twitter.com/DZoneInc" target="_blank" rel="noreferrer noopener">
                          <i class="icon-twitter"></i>
                        </a>
                      </li>
                      <li class="facebook-icon">
                        <a href="https://www.facebook.com/DZoneInc" target="_blank" rel="noreferrer noopener">
                          <i class="icon-facebook-1"></i>
                        </a>
                      </li>
                      <li class="linkedin-icon">
                        <a href="https://www.linkedin.com/company/dzone/" target="_blank"
                           rel="noreferrer noopener">
                          <i class="icon-linkedin-1"></i>
                        </a>
                      </li>
                    </ul>
                  </div>

                  <div class="col-xs-12 powered-by">
                    <p>DZone.com is powered by&nbsp;</p>
                    <a href="https://devada.com/answerhub/" rel="noreferrer noopener">
                      <img src=""
                           data-src="https://dz2cdn2.dzone.com/themes/dz20/images/answerhub_logo_white_footer.png"
                           width="150"
                           height="56"
                           class="lazyload"
                           alt="AnswerHub logo">
                    </a>
                  </div>
                </div>
              </div>
            </div>
          </div>
        </div>
      </div>
    </div>
  </div>
</div>
  <script async src="https://securepubads.g.doubleclick.net/tag/js/gpt.js"></script>

  <script async>
      (function(w, d, s, l, i) {
          w[l] = w[l] || [];
          w[l].push({'gtm.start': new Date().getTime(), event: 'gtm.js'});
          var f = d.getElementsByTagName(s)[0], j = d.createElement(s), dl = l != 'dataLayer' ? '&l=' + l : '';
          j.async = true;
          j.src = 'https://www.googletagmanager.com/gtm.js?id=' + i + dl;
          f.parentNode.insertBefore(j,f);
      })(window, document, 'script', 'dataLayer', 'GTM-K25QL22');
  </script>

  <script>
      window.ga=window.ga||function(){(ga.q=ga.q||[]).push(arguments)};ga.l=+new Date;
      ga('create', 'UA-410289-1', 'auto');
      ga('require', 'linkid', 'linkid.js');
      ga('require', 'GTM-TSD9TZP');
      ga('set', 'siteSpeedSampleRate', 25);
  </script>
  <script async src="https://www.google-analytics.com/analytics.js"></script>
  <script async>const analytics = {
    'dimension1': 'performance',
    'dimension2': 'article/analysis',
    'dimension3': '2016-02-17',
    'dimension4': '0',
    'dimension5': '',
    'dimension7': 'Message queue, requests, nat, kafka, Percentile, redis, IT, System under test',
    'dimension8': 'tylertreat',
    'dimension9': 'undefined',
    'dimension10': 'undefined'
}

if (window.ga) {
    Object.keys(analytics).forEach(function(key) {
        window.ga('set', key, analytics[key])
    })

    window.ga('send', 'pageview')
}</script>

  <script>
      !function (e, o, n, i) {
          if (!e) {
              e = e || {}, window.permutive = e, e.q = [];
              var t = function () {
                  return ([1e7] + -1e3 + -4e3 + -8e3 + -1e11).replace(/[018]/g, function (e) {
                      return (e ^ (window.crypto || window.msCrypto).getRandomValues(new Uint8Array(1))[0] & 15 >> e / 4).toString(16)
                  })
              };
              e.config = i || {}, e.config.apiKey = o, e.config.workspaceId = n, e.config.environment = e.config.environment || "production", (window.crypto || window.msCrypto) && (e.config.viewId = t());
              for (var g = ["addon", "identify", "track", "trigger", "query", "segment", "segments", "ready", "on", "once", "user", "consent"], r = 0; r < g.length; r++) {
                  var w = g[r];
                  e[w] = function (o) {
                      return function () {
                          var n = Array.prototype.slice.call(arguments, 0);
                          e.q.push({
                              functionName: o,
                              arguments: n
                          })
                      }
                  }(w)
              }
          }
      }(window.permutive, "bca90777-e088-4f2a-96c2-13ad18deeccc", "18ad0c5b-460c-4d19-a729-dc537805538f", {});
      window.googletag = window.googletag || {}, window.googletag.cmd = window.googletag.cmd || [], window.googletag.cmd.push(function () {
          if (0 === window.googletag.pubads().getTargeting("permutive").length) {
              var e = window.localStorage.getItem("_pdfps");
              window.googletag.pubads().setTargeting("permutive", e ? JSON.parse(e) : []);
              var o = window.localStorage.getItem("permutive-id");
              o && (window.googletag.pubads().setTargeting("puid", o), window.googletag.pubads().setTargeting("ptime", Date.now().toString())), window.permutive.config.viewId && window.googletag.pubads().setTargeting("prmtvvid", window.permutive.config.viewId), window.permutive.config.workspaceId && window.googletag.pubads().setTargeting("prmtvwid", window.permutive.config.workspaceId)
          }
      });


      permutive.addon('web', {
          'page': {
              'category': 'Performance',
              'node': {
                  'authorCompany': '',
                  'authors': [1406643, ],
                  'publishDate': new Date(1455667200000),
                  'sponsorAuthor': false,
                  'tags': ['Message queue', 'requests', 'nat', 'kafka', 'Percentile', 'redis', 'IT', 'System under test', ],
                  'title': 'Benchmarking Message Queue Latency',
                  'type': 'article',
              },
              'section': 'article',
          }
      });
  </script>
  <script async src="https://18ad0c5b-460c-4d19-a729-dc537805538f.edge.permutive.app/18ad0c5b-460c-4d19-a729-dc537805538f-web.js"></script>

  <script>
      const csrf = '-5531387072184440498'
      const articleId = 1183821
      const likes = 5
      const assetDomain = 'https://dz2cdn2.dzone.com'
      const codemirrorVars = {
          modeURI: 'https://dz2cdn2.dzone.com/themes/dz20/lib/codemirror/mode/',
          requiredScripts: [
              'https://dz2cdn2.dzone.com/themes/dz20/lib/codemirror/lib/codemirror.js',
              'https://dz2cdn2.dzone.com/themes/dz20/lib/codemirror/mode/meta.js'
          ]
      }

      const gptTags = {
          'zone': 'performance',
          'topicTag': 'Message queue,requests,nat,kafka,Percentile,redis,IT,System under test',
          'company': '',
          'siteSection': 'Zones',
          'articleCategory': 'analysis',
          'nodeID': '1183821',
          'authorID': '1406643',
          'publishYear': '2016',
          'publishMonth': '02',
          'jobRole': '',
          'companySize': ''
      }

      const minCommentChar = 10;
      const peer39Enabled = true;
  </script>

  <script src="https://dz2cdn2.dzone.com/themes/dz20/lib/static/jquery/jquery.min.js"></script>
  <script async src="https://dz2cdn2.dzone.com/themes/dz20/lib/static/bootstrap/bootstrap.min.js"></script>
  <script async src="https://dz2cdn2.dzone.com/themes/dz20/ftl/article/ads.js"></script>



  <script>
      function loadScript(src) {
          return new Promise(function (resolve, reject) {
              const s = document.createElement('script')
              s.src = src
              s.onload = resolve
              s.onerror = reject
              document.head.appendChild(s)
          })
      }

      function loadStyle(href) {
          const link = document.createElement('link')
          link.rel = 'stylesheet'
          link.href = href
          document.head.appendChild(link)
      }

      function loadScriptsSync(deferred) {
          var p = Promise.resolve()
          for (var i = 0; i < deferred.length; i++) {
              let script = deferred[i]
              p = p.then(function() {
                  return loadScript(script)
              })
          }
          return p
      }

      function loadStyles() {
          const deferred = [
              'https://dz2cdn2.dzone.com/themes/dz20/lib/codemirror/lib/codemirror.css',
              'https://dz2cdn2.dzone.com/themes/dz20/ftl/comments/styles.css',
              'https://dz2cdn2.dzone.com/themes/dz20/lib/froala3/css/froala_editor.pkgd.min.css',
              'https://dz2cdn2.dzone.com/themes/dz20/lib/froala3/css/themes/gray.min.css',
              'https://dz2cdn2.dzone.com/themes/dz20/ftl/article/mini-profile.css'
          ]

          for (var i = 0; i < deferred.length; i++) {
              loadStyle(deferred[i])
          }
      }

      window.addEventListener('load', function(event) {
          loadStyles()
          loadScriptsSync([
              'https://dz2cdn2.dzone.com/themes/dz20/ftl/header/auth-status.js',
              'https://dz2cdn2.dzone.com/themes/dz20/lib/lazysizes.min.js',
              'https://dz2cdn2.dzone.com/themes/dz20/ftl/article/codeblocks.js',
              'https://dz2cdn2.dzone.com/themes/dz20/ftl/article/activity-bar.js',
              'https://dz2cdn2.dzone.com/themes/dz20/lib/froala3/js/froala_editor.pkgd.min.js',
              'https://dz2cdn2.dzone.com/themes/dz20/ftl/froala/content.js',
              'https://dz2cdn2.dzone.com/themes/dz20/ftl/comments/content.js',
              'https://dz2cdn2.dzone.com/themes/dz20/ftl/article/content.js'
          ])
      })
  </script>
</body>
</html>