<!DOCTYPE html><html lang="en"><head><meta charSet="utf-8"/><meta name="viewport" content="width=device-width, initial-scale=1"/><meta name="google-site-verification" content="nwLP652epfQ6kBRi13e7XbxNamGyOyWygaRaOc-GKZ4"/><title>Open Source ETL: Apache NiFi vs Streamsets - Cube Blog</title><meta name="application-name" content="Cube Blog"/><meta name="description" content="There are many open source ETL tools and frameworks, but most of them require writing code. Since data engineers are not necessarily good programmers, you can try visual ETL to directly connect them with data."/><meta property="og:locale" content="en_US"/><meta property="og:site_name" content="Cube Blog"/><meta property="og:type" content="article"/><meta property="og:title" content="Open Source ETL: Apache NiFi vs Streamsets - Cube Blog"/><meta property="og:description" content="There are many open source ETL tools and frameworks, but most of them require writing code. Since data engineers are not necessarily good programmers, you can try visual ETL to directly connect them with data."/><meta property="og:url" content="https://cube.dev/blog/open-source-etl"/><meta name="twitter:site" content="@thecubejs"/><meta name="twitter:creator" content="@thecubejs"/><meta name="twitter:card" content="summary_large_image"/><meta name="twitter:title" content="Open Source ETL: Apache NiFi vs Streamsets - Cube Blog"/><meta name="twitter:description" content="There are many open source ETL tools and frameworks, but most of them require writing code. Since data engineers are not necessarily good programmers, you can try visual ETL to directly connect them with data."/><meta property="og:image" content="https://cubedev-blog-images.s3.us-east-2.amazonaws.com/RYUhjX9gRi6ADjNLr6Ur.png"/><meta property="og:image:secure_url" content="https://cubedev-blog-images.s3.us-east-2.amazonaws.com/RYUhjX9gRi6ADjNLr6Ur.png"/><meta name="twitter:image" content="https://cubedev-blog-images.s3.us-east-2.amazonaws.com/RYUhjX9gRi6ADjNLr6Ur.png"/><meta property="article:publisher" content="https://www.facebook.com/Cubejs-661536697681609"/><meta property="article:published_time" content="2018-04-25T00:00:00Z"/><meta name="next-head-count" content="5"/><style>
            @font-face {
              font-family: Cera Pro;
              src: url(/blog/fonts/CeraPro-Regular.woff2) format('woff2'),
                url(/blog/fonts/CeraPro-Regular.woff) format('woff');
              font-weight: 400;
              font-display: block;
            }
            @font-face {
              font-family: Cera Pro;
              src: url(/blog/fonts/CeraPro-Regular-Italic.woff2) format('woff2'),
                url(/blog/fonts/CeraPro-Regular-Italic.woff) format('woff');
              font-weight: 400;
              font-style: italic;
              font-display: block;
            }
            @font-face {
              font-family: Cera Pro;
              src: url(/blog/fonts/CeraPro-Medium.woff2) format('woff2'),
                url(/blog/fonts/CeraPro-Medium.woff) format('woff');
              font-weight: 500;
              font-display: block;
            }
            @font-face {
              font-family: 'Cera Pro';
              src: url(/blog/fonts/CeraPro-Bold.woff2) format('woff2'),
                url(/blog/fonts/CeraPro-Bold.woff) format('woff');
              font-weight: 700;
              font-display: block;
            }
            @font-face {
              font-family: Source Code Pro;
              src: url(/blog/fonts/SourceCodePro-Regular.woff2) format('woff2'),
                url(/blog/fonts/SourceCodePro-Regular.woff) format('woff');
              font-weight: 400;
            }
          </style><script src="https://www.googletagmanager.com/gtag/js?id=UA-70480064-3"></script><script>
              window.dataLayer = window.dataLayer || [];
              function gtag(){dataLayer.push(arguments);}
              gtag('js', new Date());
              gtag('config', 'UA-70480064-3', {
                page_path: window.location.pathname,
              });
            </script><link rel="preload" href="/blog/_next/static/css/30026fc4e52394a0.css" as="style"/><link rel="stylesheet" href="/blog/_next/static/css/30026fc4e52394a0.css" data-n-g=""/><link rel="preload" href="/blog/_next/static/css/32631ce5228f34ac.css" as="style"/><link rel="stylesheet" href="/blog/_next/static/css/32631ce5228f34ac.css" data-n-p=""/><noscript data-n-css=""></noscript><script defer="" nomodule="" src="/blog/_next/static/chunks/polyfills-5cd94c89d3acac5f.js"></script><script src="/blog/_next/static/chunks/webpack-c6e85cc450395c4f.js" defer=""></script><script src="/blog/_next/static/chunks/framework-5f4595e5518b5600.js" defer=""></script><script src="/blog/_next/static/chunks/main-57b6009ba8173892.js" defer=""></script><script src="/blog/_next/static/chunks/pages/_app-0e4baaa5712a1658.js" defer=""></script><script src="/blog/_next/static/chunks/790-93870cfc39c5c3da.js" defer=""></script><script src="/blog/_next/static/chunks/pages/%5Bid%5D-654c53343b7fd9d3.js" defer=""></script><script src="/blog/_next/static/tYLrb3PX7MVWwci5Y_7pM/_buildManifest.js" defer=""></script><script src="/blog/_next/static/tYLrb3PX7MVWwci5Y_7pM/_ssgManifest.js" defer=""></script><script src="/blog/_next/static/tYLrb3PX7MVWwci5Y_7pM/_middlewareManifest.js" defer=""></script></head><body><div id="__next" data-reactroot=""><a target="_blank" style="padding-bottom:40px;color:rgb(255,255,255);text-decoration:none;font-size:16px;line-height:26px;font-weight:500"><div style="text-decoration:none;opacity:0;background-color:rgb(122, 119, 255);display:flex;align-items:center;justify-content:center;line-height:26px;word-spacing:2px;max-height:0;overflow:hidden;padding:0px 16px;margin:0;transition:max-height 1s ease-in-out, opacity 1s ease-in-out, padding 1s ease-in-out"></div></a><header class="Header_Header__1bDpK" id="header"><div class="Header_Header__logo__m2BqR"><a href="/" class="Logo_Logo__main__oYcSk"><svg xmlns="http://www.w3.org/2000/svg" width="98" height="28" fill="none"><path d="M26.13 7.04 14 0v4.87l12.13 7V7.05Z" fill="var(--pink)"></path><path d="M26.13 11.88 22.5 14 14 9.08l-4.85 2.8L5.5 9.91 14 4.87l12.12 7Z" fill="var(--dark)"></path><path d="M9.15 11.88 5.5 9.91V14l3.64-2.12Z" fill="#A14474"></path><path d="M1.87 20.96 14 14l12.13 6.96L14 28 1.87 20.96Z" fill="var(--dark)"></path><path d="M26.13 16.13 14 9.01V14l12.13 6.96v-4.83Z" fill="var(--pink)"></path><path d="M5.5 14V9.91L14 4.87V0L1.87 7.04v13.92L14 14V9l-8.5 5Z" fill="var(--purple)"></path><path d="M33.66 14.73c0-4.2 3.34-7.48 7.55-7.48a6.8 6.8 0 0 1 6 3.33l-2.14 1.7c-.93-1.32-2.12-2.2-3.83-2.2-2.62 0-4.47 2.05-4.47 4.65 0 2.66 1.85 4.68 4.47 4.68 1.68 0 2.87-.85 3.83-2.16l2.14 1.66a6.87 6.87 0 0 1-6 3.33 7.45 7.45 0 0 1-7.55-7.5ZM49.86 15.9V7.57h3.01v8.57a3.11 3.11 0 0 0 3.23 3.27c1.74 0 3.13-1.26 3.13-3.27V7.57h3.05v8.33c0 3.9-2.7 6.35-6.18 6.35-3.54 0-6.24-2.46-6.24-6.35ZM80.77 14.76c0 4.27-2.93 7.49-6.97 7.49-2.09 0-3.92-.85-4.99-2.31v1.99h-2.84V0h3.05v9.33a6.03 6.03 0 0 1 4.76-2.08c4.06 0 6.99 3.24 6.99 7.51Zm-3.14-.03c0-2.77-1.91-4.67-4.35-4.67-2.15 0-4.3 1.46-4.3 4.7 0 3.28 2.18 4.68 4.3 4.68 2.47 0 4.35-1.93 4.35-4.7ZM96.53 15.76H85.91c.4 2.36 2.2 3.77 4.64 3.77 1.66 0 2.96-.65 4.15-1.7l1.45 2.1a8.1 8.1 0 0 1-5.69 2.32c-4.4 0-7.66-3.25-7.66-7.49 0-4.2 3.22-7.51 7.37-7.51a6.4 6.4 0 0 1 6.6 6.58c0 .79-.15 1.55-.24 1.93Zm-10.56-2.4h7.75c-.06-2.25-1.72-3.51-3.66-3.51-2 0-3.63 1.38-4.1 3.5Z" fill="var(--dark)"></path></svg></a><a class="Logo_Logo__sub__9_rpT" href="/blog"><svg xmlns="http://www.w3.org/2000/svg" width="65" height="28" fill="none"><path d="M11.89 7.11c-1.95 0-3.64.75-4.7 2.04V0H4.17v21.5h2.81v-1.95a6.01 6.01 0 0 0 4.94 2.27c3.98 0 6.88-3.16 6.88-7.34 0-4.19-2.9-7.37-6.91-7.37Zm-.5 11.95c-2.08 0-4.23-1.37-4.23-4.58 0-3.18 2.12-4.62 4.24-4.62 2.4 0 4.3 1.87 4.3 4.59 0 2.72-1.86 4.61-4.3 4.61ZM21.97 21.5h3.01V0h-3v21.5ZM35.59 21.82a7.35 7.35 0 1 0 0-14.7 7.3 7.3 0 0 0-7.43 7.33c0 4.1 3.27 7.37 7.43 7.37Zm0-2.78c-2.5 0-4.36-1.95-4.36-4.56 0-2.64 1.86-4.62 4.39-4.62 2.46 0 4.35 1.98 4.35 4.62a4.4 4.4 0 0 1-4.38 4.56ZM57.27 7.43v2c-1.03-1.46-2.84-2.32-4.99-2.32-3.9 0-6.85 2.9-6.85 7.05 0 4.16 2.93 7.05 6.85 7.05 1.95 0 3.67-.71 4.76-2v1c0 2.7-1.72 4.02-4.21 4.02-2.07 0-3.56-.9-4.93-2.01l-1.67 2.1A9.73 9.73 0 0 0 53 26.97c4.19 0 7.05-2.41 7.05-6.94V7.43h-2.78Zm-4.44 11.15a4.2 4.2 0 0 1-4.3-4.42c0-2.64 1.89-4.36 4.3-4.36 2.12 0 4.24 1.27 4.24 4.33 0 3.07-2.1 4.45-4.24 4.45Z" fill="currentColor"></path></svg></a></div><button aria-label="Open menu" id="toggleMenuVisibilityButton" aria-expanded="false" class="Header_Header__openButton__nKV1R"><span class="Header_Header__openMenuIcon__h_sgn"><span></span><span></span><span></span></span></button><nav class="Header_Header__navigation__iQMOP" aria-controls="toggleMenuVisibilityButton"><ul class="Header_Header__linkList__nzhuT"><li class="Header_Header__listItem__gl_6V"><a class="Header_Header__linkItem__UIbHG" href="/blog/category/data">Data Engineering</a></li><li class="Header_Header__listItem__gl_6V"><a class="Header_Header__linkItem__UIbHG" href="/blog/category/apps">Application Development</a></li><li class="Header_Header__listItem__gl_6V"><a class="Header_Header__linkItem__UIbHG" href="/blog/category/cube">All Things Cube</a></li></ul><ul class="Header_Header__linkList__nzhuT Header_Header__linkList--actions__9_Bmv"><li class="Header_Header__listItem__gl_6V"><a href="https://slack.cube.dev/" class="Header_Header__linkItem__UIbHG">Join us on Slack</a></li><li class="Header_Header__listItem__gl_6V Header_Header__listItem--button__SSV9y"><a href="https://cubecloud.dev/auth/signup" class="Button_Button__VQ4Ej Header_Header__getCubeButton__EjI_v Button_Button--pink__t9gaM Button_Button--size-s__pw3fC">Get Cube</a></li></ul></nav></header><main class="style_App__main__OAYvT"><section class="PostPage_PostPage__c7lQj"><header class="PostPage_PostPage__header__hy6o4"><section class="SectionHeader_SectionHeader__RUW64 undefined"><h1 class="SectionHeader_SectionHeader__header__5Vhg1">Open Source ETL: Apache NiFi vs Streamsets</h1><p class="SectionHeader_SectionHeader__description__3bsDr">Choosing between mainstream open source ETL projects</p></section></header><aside class="PostPage_PostPage__aside__fWxjl"><time dateTime="2018-04-25T00:00:00Z" class="PostPage_PostPage__date__QuJxV">April 25, 2018</time><p class="PostPage_PostPage__category__iyHAP"><a class="PostCategory_PostCategories__item__Fl8yx PostCategory_PostCategories__item--link__AVAZs" href="/blog/category/etl">Extract, Load, Transform (ETL)</a></p><article class="Author_Author__hliDg"><img src="https://media.graphcms.com/hebfjoN4SmC7gWupOphp" role="presentation" class="Author_Author__image__DOwF1"/><address class="Author_Author__address__6Ihb4"><p class="Author_Author__name__0QsOG"><span>Dmitry Dorofeev</span></p></address></article></aside><img class="PostPage_PostPage__img__9LqVF" src="https://cubedev-blog-images.s3.us-east-2.amazonaws.com/RYUhjX9gRi6ADjNLr6Ur.png" alt="Open Source ETL: Apache NiFi vs Streamsets"/><aside class="PostPage_PostPage__tableOfContents__QQFpz"><h2 class="PostPage_PostPage__tableHeader__nB1PP">Table of Contents</h2><ul>
<li><a href="#dataflow-programming">Dataflow Programming</a></li>
<li><a href="#apache-nifi-vs-streamsets">Apache NiFi vs StreamSets</a></li>
<li><a href="#architecture-and-features">Architecture and features</a></li>
<li><a href="#ui">UI</a></li>
<li><a href="#conclusion">Conclusion</a></li>
</ul></aside><article class="PostPage_PostPage__content__pgvrR"><p>While working with <a href="https://github.com/statsbotco/cube.js">Cube.js framework</a> we&#x27;ve seen a lot of diffrent ETL tools used by data engineers nowadays. Most of them require writing code. But there are some  visual ETL you can try as well. We asked Dmitry Dorofeev, Head of R&amp;D at Luxms Group, to tell us about his experience with comparing Apache NiFi and Streamsets.</p>
<hr/>
<p>Our team at <a href="https://www.luxms.com/">Luxms Inc.</a> has recently faced a boring data integration problem: when some data is stored in Hadoop, some in Oracle, and a little bit is in Excel. The goal was to ETL all that data into Greenplum and finally provide some BI on top of it.</p>
<p>We quickly found 2 mainstream open source ETL projects: Apache NiFi and Streamsets, and it seemed an easy task to choose one product out of the two. <strong>In no way was it easy.</strong> I know that better than anyone since I was responsible for the product evaluation and the final choice. In this post, I’d like to share my experience and maybe save days of your life.</p>
<p><i>Spoiler:</i> There is no silver bullet. Apache NiFi is not necessarily better than Streamsets, nor Streamsets better than NiFi. Everything has its pros and cons. This post is my personal experience with these tools as a novice user without any introductory training.</p>
<h2 id="dataflow-programming">Dataflow Programming</h2>
<p>Programmers, analysts, and even managers often draw a box and arrow diagram to illustrate some flows. You can even use these boxes and arrows to create programs. We can track such attempts back to the 1960s when the <a href="https://en.wikipedia.org/wiki/Dataflow_programming">Dataflow Programming</a> paradigm was born in MIT.</p>
<p><em><a href="https://statsbot.co/blog/etl-tools-list/">ETL Tools List: Overview &amp; Pricing</a></em></p>
<p>Today, we have tens of Dataflow Programming tools where you can visually assemble programs from boxes and arrows, writing zero lines of code. Some of them are open source and some are suitable for ETL.</p>
<p>Yes, you don’t have to know any programming language. You just use ready-made “processors” represented with boxes, connect them with arrows, which represent exchange of data between “processors,” and that’s it.</p>
<blockquote>
<p>There are three main types of boxes: sources, processors, and sinks. Think Extract for sources, Transform for processors, and Load for sinks.</p>
</blockquote>
<p>Almost anything can be a source, for example, files on the disk or AWS, JDBC query, Hadoop, web service, MQTT, RabbitMQ, Kafka, Twitter, or UDP socket.</p>
<p>A processor can enhance, verify, filter, join, split, or adjust data. If ready-made processor boxes are not enough, you can code on Python, Shell, Groovy, or even Spark for data transformation.</p>
<p>Sinks are basically the same as sources, but they are designed for writing data.</p>
<h2 id="apache-nifi-vs-streamsets">Apache NiFi vs StreamSets</h2>
<p>When we faced yet another customer with complicated ETL requirements I decided to try visual dataflow tools. Visual might be attractive even if you use <a href="http://www.singer.io">Singer</a>, <a href="https://www.getdbt.com/">data build tool</a>, or other handy open source ETL tools, right?</p>
<p>Luckily, there are two open source visual tools with the web interface: <a href="https://nifi.apache.org/">Apache NiFi</a> and <a href="https://streamsets.com/products/sdc">StreamSets Data Collector</a> (SDC). NiFi was donated by the NSA to the Apache Foundation in 2014 and current development and support is provided mostly by Hortonworks. SDC was started by a California-based startup in 2014 as an open source ETL project available on <a href="https://github.com/streamsets/datacollector">GitHub</a>. The first release was published in June 2015.</p>
<p>Both products are written in Java and distributed under the Apache 2.0 license.</p>
<p>Here are some stats from GitHub for early 2018:</p>
<table><tr><th>Metric</th>
<th><a href="https://github.com/apache/nifi">Apache NiFi</a></th>
<th><a href="https://github.com/streamsets/datacollector">StreamSets</a></th></tr><tr><td>First release year</td>
<td>2007</td>
<td>2015</td></tr><tr><td>Forks</td>
<td>783</td>
<td>914</td></tr><tr><td>Releases</td>
<td>57</td>
<td>113</td></tr><tr><td>Stars</td>
<td>811</td>
<td>405</td></tr><tr><td>Version</td>
<td>1.5</td>
<td>3.1.0.0</td></tr></table>
<h2 id="architecture-and-features">Architecture and features</h2>
<p>Both tools encourage creation of long-running jobs which work with either streaming data or regular periodic batches. You can create manually managed jobs, but they might be tricky to set up. This is the greatest surprise and mind-shifting feature I personally had with these tools.</p>
<h3 id="apache-nifi">Apache NiFi</h3>
<p>Apache NiFi has a well-thought-out architecture. Once data is fetched from external sources, it is represented as <strong>FlowFile</strong> inside Apache NiFi dataflows. FlowFile is basically original data with meta-information attached to it. You can easily process not only CSV or other record-based data, but also pictures, videos, audio, or any binary data.</p>
<p><img src="https://media.graphcms.com/w4DLooFSLOBsZMtxeauy%22" alt=""/></p>
<p>A processor usually will have 3 outputs:</p>
<ul>
<li>Failure. If a FlowFile cannot be processed correctly, the original FlowFile will be routed to this output.</li>
<li>Original. Once an incoming FlowFile has been processed, the original FlowFile is routed to this output.</li>
<li>Success. FlowFiles that are successfully processed will be routed to this relationship.</li>
</ul>
<p>You can terminate outputs with checkboxes, so Apache NiFi will ignore terminated outputs and will not send any FlowFiles there.</p>
<p>Another handy feature is <strong>Process Groups</strong>. When a dataflow becomes complex, you can combine your dataflow elements into Process Group, which is graphically represented in the UI in the same way as standard processors. It behaves as a processor, so you can build very complex dataflows recursively.</p>
<p><strong>Controller Service</strong> is something that exists outside of your dataflows, but provides some useful information for your processors. It might be SSL certificates, JDBC connection and pool settings, schema definition, and so on. The idea is that rather than configure this information in every processor that might need it, the controller service provides it for any processor to use.</p>
<p>Processors are connected with... well, connections. Usually connections are just arrows, but not so with Apache NiFi. Every connection arrow has a small widget attached to it, representing a queue with back pressure and can be configured individually.</p>
<p><img src="https://media.graphcms.com/5hGEEssaT6WuQOMlKd1p" alt=""/></p>
<p>For example, if the LogAttribute processor becomes slow or freezes for some reason, FlowFiles generated by the GenerateFlowFile processor will be queued in the connection. After some time, back pressure will pause the GenerateFlowFile processor until the queue goes below the configured threshold.</p>
<p><img src="https://media.graphcms.com/BH5LMEAvSnGgfNkmkHW9%22" alt=""/></p>
<p>If you are not yet impressed, how about different queue policies like FIFO, LIFO, and others you can apply to queues in connections?</p>
<p><strong>Data Provenance</strong> is a Big Brother service which records almost everything in your dataflows as they process data. This is very handy, as you have recorded history of how your dataflow performed, including saved content of the FlowFiles. But that comes with a price, you should have enough disk space to keep the required backlog of provenance data.</p>
<p>Even with these awesome features and great architecture, I was not very comfortable with the Apache NiFi user interface. It is definitely usable, but not sexy.</p>
<h3 id="streamsets-data-collector">StreamSets Data Collector</h3>
<p>Then, I tried Streamsets.</p>
<p><img src="https://media.graphcms.com/kSAtWIITHGwHibqCWkUv" alt=""/></p>
<p>Processors in Streamsets exchange <strong>records</strong>. That means that everything you ingest into Streamsets is converted automatically into the standard record-oriented format and all processors can handle it as a stream of records. There are no queues in between processors, at least, they are not represented visually, like we saw it in Apache NiFi.</p>
<p>One nice thing about <strong>Streamsets is that it can process binary data</strong>. Some sources, such as Kafka Consumer, can read messages from the Kafka topic and pass them to other processors or external systems without parsing the structure of the binary message into the record format. This allows us to forward the efficient data to some other destination with minimum overhead.</p>
<p>The more powerful option is the <a href="https://streamsets.com/documentation/datacollector/latest/help/index.html#datacollector/UserGuide/Data_Formats/WholeFile.html#concept_nfc_qkh_xw">whole file data format</a>, supported by several origins, including S3, directory, FTP, and more. With the whole file format, the file is not parsed, but file metadata and a reference to the content is sent along the pipeline. Processors can optionally act on the content – script evaluators and custom processors can get an input stream to the content. But in the default case, once the whole file record arrives at the destination, the data is streamed directly from its source.</p>
<p>Even though there are some complaints about lack of binary data support in Streamsets, the whole file support has been there since version 1.6.0.0, released in September 2016.</p>
<p>In Apache NiFi the same processor <strong>should have different versions of itself to handle different formats</strong>. One version for CSV, one for JSON, and another for Avro, for example. You might guess that it is not very user and developer friendly. This was addressed in Apache NiFi 1.5, where most processors are using the Avro format, so you should convert to Avro early and it will be almost the same experience as in Streamsets after that.</p>
<blockquote>
<p>To change processor settings in Apache NiFi you must stop the processor, while in Streamsets you must stop the whole dataflow.</p>
</blockquote>
<p>That means that you always start your dataflow from the beginning after you make any changes in it with Streamsets. With Apache NiFi you have a chance to stop a misbehaving processor, fix it, and start again. Hopefully, queued FlowFiles will be sent to the fixed processor and you will not miss the data.</p>
<p>But that doesn’t mean that Streamsets dataflows are harder to debug. Actually it is easier, you have a nice-looking live dashboard displaying a lot of statistics for every processor while your dataflow is running. Errors are cleanly presented as red numbers on the processor icon and you can see individual errors for every faulty record with a mouse click. You may even put record filters on the connections between processors to inspect records in question. Filters can be applied while your dataflow is running, so I used it as live debugging tool.</p>
<p>Streamsets has 4 processor types:</p>
<ul>
<li>Origins: they get data from the external sources. You may have only one Origin Processor in your dataflow.</li>
<li>Processors: data transformers.</li>
<li>Destinations: they save data to the external systems or files.</li>
<li>Executors: they process events, generated by other processors.</li>
</ul>
<p>Some of the Streamsets processors may generate events, including errors. You should use special processors called <strong>Executors</strong> to handle that. For example, there is Email Executor, which can send emails when an error has occurred.</p>
<p>I am definitely more happy with the clean Apache NiFi architecture with just Processors and Controller Services, but the Streamsets design is also fine and can be quickly picked up.</p>
<h2 id="ui">UI</h2>
<h3 id="apache-nifi-1">Apache NiFi</h3>
<p>There is not much to say about the Apache NiFi UI. It feels spartan, and it is very easy to follow, thanks to the great architecture with minimum concepts. Probably the only drawback I discovered is that Apache NiFi will not autosize text fields for your long SQL queries, so you will have to manually resize popup text fields every time you want to edit it.</p>
<p><img src="https://media.graphcms.com/4kwaYmwVTvCsZkeVCthA" alt=""/></p>
<h3 id="streamsets">Streamsets</h3>
<p>Streamsets has a more attractive UI, but it is not perfect as well.</p>
<p>The first thing I quickly get annoyed with is the absence of Controller Services, especially for JDBC settings. You need to fill in all JDBC settings for every processor that reads data from the same JDBC source. There is just no user-friendly way to reuse such information.</p>
<p>Before you can run your dataflow, Streamsets will check each processor inside your dataflow to make sure all processors are correctly configured. <strong>It sounds like a good thing, and it helped me sometimes, but other times – harmed me.</strong> In Apache NiFi you can have disconnected processors and I usually leave them so for debugging purposes. In Streamsets you can not do the same, since all the processors must be connected to make dataflow pass validation.</p>
<p>Another annoyance is that you can not select several processors at once. At least I was unable to do so. Moving a dozen processors and reorganizing them one by one on the screen can make you mad.</p>
<p>Streamsets has syntax highlighting for SQL which is a nice feature, but not always useful. Our data engineer creates heavy SQL queries which can easily be a hundred lines long. The syntax highlighting process becomes slow and that results in another annoyance. If you edit the last lines of the long SQL query the caret unexpectedly moves to the beginning and what you type appears on the first line.</p>
<h2 id="conclusion">Conclusion</h2>
<p>I made a very brief introduction to Apache NiFi and Streamsets. They have plenty of useful features not covered in this blog post. Even if you do not find the required built-in or third-party processors, you can always use Python, Javascript, R, or even Apache Spark to program your complex data transformation logic in the Apache NiFi or Streamsets dataflows.</p>
<p>Both Apache NiFi and Streamsets are mature, open source ETL tools. They have very similar functionality and the only way to make a concise choice is to try both! That’s what I did. Even after 3 months of running both products I can not see a clear winner.</p>
<p>For me, live monitoring is the single feature in Streamsets that outweighs all its small glitches.</p>
<h3 id="apache-nifi-2">Apache NiFi</h3>
<p>Pros:</p>
<ul>
<li>Clean and well-thought-out implementation of the dataflow programming concept</li>
<li>Can handle binary data</li>
<li>Data Provenance</li>
</ul>
<p>Cons:</p>
<ul>
<li>Spartan User Interface</li>
<li>No live monitoring/debugging features with per-record statistics</li>
</ul>
<h3 id="streamsets-1">Streamsets</h3>
<p>Pros:</p>
<ul>
<li>Live monitoring/debugging features with visual per-record statistics for every processor</li>
<li>Sexy UI</li>
<li>Well-suited for record-based data and streaming</li>
</ul>
<p>Cons:</p>
<ul>
<li>You need to stop the whole dataflow to edit a single processor configuration</li>
<li>No reusable JDBC configuration for processors</li>
</ul></article><footer class="PostPage_PostPage__footer__35H4y"><div class="PostSocial_PostSocial__IKfZb"><p class="PostSocial_PostSocial__text__6sozi">Share this article</p><div class="PostSocial_PostSocial__list__RaFmV"><div role="button" tabindex="0" class="SocialMediaShareButton SocialMediaShareButton--facebook PostSocial_PostSocial__icon__5vV3B"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" class="SocialIcon_SocialIcon__DQ6pT"><path d="M20.63 2.63H3.38a.75.75 0 0 0-.75.75v17.25c0 .41.33.75.75.75h17.25c.41 0 .75-.34.75-.75V3.38a.75.75 0 0 0-.75-.75ZM18.45 8.1h-1.5c-1.17 0-1.4.56-1.4 1.38v1.8h2.8L18 14.11h-2.44v7.27h-2.92V14.1h-2.45v-2.83h2.45V9.2c0-2.42 1.48-3.74 3.64-3.74 1.03 0 1.92.07 2.18.1V8.1Z" fill="#4267B2"></path></svg></div><div role="button" tabindex="0" class="SocialMediaShareButton SocialMediaShareButton--twitter PostSocial_PostSocial__icon__5vV3B"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" class="SocialIcon_SocialIcon__DQ6pT" viewBox="0 0 24 24"><path d="M20.5 8.23c0 1.93-.45 3.8-1.36 5.59a11.62 11.62 0 0 1-3.97 4.56c-1.86 1.26-4 1.9-6.42 1.9-2.31 0-4.43-.64-6.35-1.9.3.03.62.03.98.03 1.92 0 3.64-.6 5.18-1.8-.92 0-1.73-.26-2.41-.83a4.3 4.3 0 0 1-1.44-2.06c.26.03.52.03.75.03.36 0 .75-.03 1.1-.13a4.1 4.1 0 0 1-2.37-1.5 4.03 4.03 0 0 1-.94-2.66v-.07c.58.34 1.2.54 1.85.57a4.3 4.3 0 0 1-1.33-1.53 4.43 4.43 0 0 1-.59-2.03c0-.73.2-1.43.59-2.13A10.87 10.87 0 0 0 7.55 7.4c1.5.76 3.06 1.2 4.75 1.3-.06-.34-.06-.64-.06-.97a4.4 4.4 0 0 1 2.05-3.7c.62-.4 1.3-.56 2.05-.56.62 0 1.17.13 1.66.37.49.23.98.56 1.37.96.94-.2 1.82-.53 2.64-1-.33 1-.92 1.77-1.83 2.33.78-.1 1.56-.33 2.38-.7a9.6 9.6 0 0 1-2.09 2.23c0 .17.04.34.04.57Z" fill="#2AA4F1"></path></svg></div><div role="button" tabindex="0" class="SocialMediaShareButton SocialMediaShareButton--linkedin PostSocial_PostSocial__icon__5vV3B"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" class="SocialIcon_SocialIcon__DQ6pT" viewBox="0 0 24 24"><path d="M20.28 3H3.72c-.4 0-.72.32-.72.72v16.56c0 .4.32.72.72.72h16.56c.4 0 .72-.32.72-.72V3.72c0-.4-.32-.72-.72-.72ZM8.34 18.34H5.67v-8.6h2.67v8.6ZM7 8.57a1.55 1.55 0 1 1 0-3.1 1.55 1.55 0 0 1 0 3.1Zm11.33 9.77h-2.67v-4.18c0-1-.02-2.28-1.39-2.28-1.39 0-1.6 1.09-1.6 2.2v4.26h-2.67v-8.6h2.56v1.18h.04a2.8 2.8 0 0 1 2.53-1.39c2.7 0 3.2 1.78 3.2 4.1v4.7Z" fill="#026899"></path></svg></div></div></div></footer></section></main><footer class="Footer_Footer__wOtNb"><section class="Footer_Footer__topSection__nQw5V"><article class="Footer_Footer__article__o8hQB Footer_Footer__article--startUsing__U5DjC"><h2 class="Footer_Footer__header__0Q8_X">Start using Cube Cloud today</h2><a href="https://cubecloud.dev/auth/signup" class="Button_Button__VQ4Ej Button_Button--pink__t9gaM Button_Button--size-m__DGRm_">Get started for free</a></article><article class="Footer_Footer__article__o8hQB SubscriptionForm_SubscriptionForm__2Iku8"><h2 class="SubscriptionForm_SubscriptionForm__header__XeG_1">Get Cube updates to your inbox</h2><form class="SubscriptionForm_SubscriptionForm__subscribeForm__8go2B"><label class="SubscriptionForm_SubscriptionForm__subscribeInputWrap__zKuz1"><span hidden="">Email</span><input type="email" placeholder="Email" required="" name="email" id="email_subscribe_input" autoComplete="email" class="SubscriptionForm_SubscriptionForm__subscribeInput__3EPHo" value=""/><p class="SubscriptionForm_SubscriptionForm__subscribeSuccess__RBJjx"><svg xmlns="http://www.w3.org/2000/svg" width="21" height="22" fill="none"><path d="M10.5.5a10.5 10.5 0 1 0 0 21 10.5 10.5 0 0 0 0-21Zm4.5 7-4.9 7a.7.7 0 0 1-1.2 0l-3-4.1c0-.2 0-.3.2-.3h1.1c.3 0 .5 0 .6.3l1.7 2.3 3.7-5.1c.1-.2.3-.3.6-.3h1c.2 0 .3.1.2.3Z" fill="#67C082"></path></svg>Subscribed!</p></label><button class="Button_Button__VQ4Ej SubscriptionForm_SubscriptionForm__subscribeButton__KFWxY Button_Button--purple__w2O5f Button_Button--size-m__DGRm_" type="submit" style="--loader-time:700ms">Subscribe</button></form></article><nav class="Footer_Footer__navigation__iBDRl"><article class="Footer_Footer__linkListBlock__wWA_5"><h2 class="Footer_Footer__header__0Q8_X">Blog</h2><ul class="Footer_Footer__linkList__mcVnX"><li class="Footer_Footer__linkItem__dyvnu"><a href="/blog/category/data">Data Engineering</a></li><li class="Footer_Footer__linkItem__dyvnu"><a href="/blog/category/apps">Application Development</a></li><li class="Footer_Footer__linkItem__dyvnu"><a href="/blog/category/cube">All Things Cube</a></li></ul></article><article class="Footer_Footer__linkListBlock__wWA_5"><h2 class="Footer_Footer__header__0Q8_X">Resources</h2><ul class="Footer_Footer__linkList__mcVnX"><li class="Footer_Footer__linkItem__dyvnu"><a href="/docs/">Documentation</a></li><li class="Footer_Footer__linkItem__dyvnu"><a href="/docs/examples">Tutorials &amp; Examples</a></li><li class="Footer_Footer__linkItem__dyvnu"><a href="/community">Community</a></li><li class="Footer_Footer__linkItem__dyvnu"><a href="/events">Events</a></li><li class="Footer_Footer__linkItem__dyvnu"><a href="https://awesome.cube.dev/">Awesome Tools</a></li></ul></article><article class="Footer_Footer__linkListBlock__wWA_5"><h2 class="Footer_Footer__header__0Q8_X">Cube</h2><ul class="Footer_Footer__linkList__mcVnX"><li class="Footer_Footer__linkItem__dyvnu"><a href="/about">About</a></li><li class="Footer_Footer__linkItem__dyvnu"><a href="/careers">Careers<span class="Footer_Footer__hiringMiniBanner__Pu_bE">We&#x27;re hiring!</span></a></li><li class="Footer_Footer__linkItem__dyvnu"><a href="https://cubecloud.dev/">Cube Cloud</a></li></ul></article><article class="Footer_Footer__linkListBlock__wWA_5 Footer_Footer__linkListBlock--follows__Davco"><h2 class="Footer_Footer__header__0Q8_X">Follow Us</h2><ul class="Footer_Footer__linkList__mcVnX Footer_Footer__linkList--horizontal__STfpL"><li class="Footer_Footer__linkItem__dyvnu"><a href="https://github.com/cube-js/cube.js"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" class="SocialIcon_SocialIcon__DQ6pT" viewBox="0 0 24 24"><path d="M11.86 1.6c1.9 0 3.67.44 5.3 1.31a9.8 9.8 0 0 1 5.24 8.75c0 2.27-.65 4.32-1.96 6.12a9.95 9.95 0 0 1-5.09 3.73c-.23.05-.4.03-.53-.07a.52.52 0 0 1-.2-.42v-3.46c0-.89-.22-1.5-.7-1.9 1.03-.1 1.8-.25 2.3-.42.79-.27 1.39-.7 1.81-1.24.48-.71.7-1.7.7-2.94 0-.52-.1-.99-.3-1.36-.14-.27-.4-.61-.8-1.03.1-.28.18-.62.2-1a4.67 4.67 0 0 0-.3-1.82c-.22-.05-.62.02-1.13.22-.32.15-.72.32-1.18.57l-.55.37a9.73 9.73 0 0 0-5.27 0l-.55-.37a8.54 8.54 0 0 0-1.2-.57c-.5-.2-.88-.24-1.13-.17a3.9 3.9 0 0 0-.3 1.83c0 .4.05.69.17.94-.32.42-.57.79-.73 1.13-.15.35-.22.77-.22 1.31 0 1.24.22 2.2.68 2.9.4.56.97 1 1.75 1.28.5.17 1.26.3 2.26.42-.35.32-.58.79-.68 1.4-.47.23-.92.3-1.38.25a2.02 2.02 0 0 1-1.68-1.1c-.17-.3-.4-.55-.68-.75l-.62-.3-.3-.05c-.3 0-.48.05-.48.15-.03.1.05.2.2.32l.2.18c.2.1.4.3.58.54.17.2.3.42.42.67l.18.32c.15.42.4.74.8.94a3 3 0 0 0 1.2.37c.33.02.69.02 1.06-.05l.45-.05.05 2.52c0 .17-.07.3-.2.42-.12.1-.3.15-.52.07a10.13 10.13 0 0 1-5.17-3.73 10.34 10.34 0 0 1-1.96-6.15c0-1.88.45-3.58 1.33-5.11a9.93 9.93 0 0 1 3.69-3.64 10.53 10.53 0 0 1 5.24-1.33ZM5.21 15.51c.05-.05.13-.07.2-.02.08.05.1.1.08.17-.03.07-.1.07-.2.02s-.1-.12-.08-.17Zm.45.35c.05-.05.13-.05.2.05.08.07.1.14.06.2-.05.04-.13.04-.2-.06-.1-.07-.1-.14-.06-.2Zm.43.52c.05-.03.1-.03.15-.03a.2.2 0 0 1 .1.1c.08.1.08.2 0 .25a.08.08 0 0 1-.1 0c-.02-.03-.1-.05-.15-.08-.05-.12-.05-.22 0-.24Zm.5.59c.03-.03.08-.03.13-.03l.15.08c.05.05.07.1.07.15.03.05 0 .1-.02.12-.08.07-.18.07-.3-.05a.22.22 0 0 1-.08-.17c0-.08.03-.08.05-.1Zm.68.52c.03-.1.1-.15.25-.1.15.05.2.1.2.17-.02.08-.05.13-.1.15-.05.02-.1.02-.17 0-.08-.02-.1-.07-.15-.1-.05-.05-.05-.07-.03-.12Zm1.28.17c0-.02-.02-.05-.08-.07a.4.4 0 0 0-.2-.05c-.15 0-.2.05-.2.17 0 .1.08.15.23.15.17-.03.25-.08.25-.2Zm.55-.25c.15 0 .23.05.23.13.02.07-.05.15-.2.2-.05 0-.1 0-.15-.03-.05-.02-.08-.07-.08-.15 0-.07.08-.12.2-.15Z" fill="#000000"></path></svg></a></li><li class="Footer_Footer__linkItem__dyvnu"><a href="https://slack.cube.dev/"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" class="SocialIcon_SocialIcon__DQ6pT" viewBox="0 0 24 24"><path d="M6.43 14.53a2.02 2.02 0 0 1-4.03 0c0-1.1.9-2.01 2.02-2.01h2.01v2.01ZM7.45 14.53a2.02 2.02 0 0 1 4.03 0v5.05a2.02 2.02 0 0 1-4.03 0v-5.05Z" fill="#DD295C"></path><path d="M9.47 6.43a2.02 2.02 0 0 1 0-4.03c1.1 0 2.01.9 2.01 2.02v2.01H9.47ZM9.47 7.45a2.02 2.02 0 0 1 0 4.03H4.42a2.02 2.02 0 0 1 0-4.03h5.05Z" fill="#40C6EE"></path><path d="M17.57 9.47a2.02 2.02 0 0 1 4.03 0c0 1.1-.9 2.01-2.02 2.01h-2.01V9.47ZM16.55 9.47a2.02 2.02 0 0 1-4.03 0V4.42a2.02 2.02 0 0 1 4.03 0v5.05Z" fill="#37B57F"></path><path d="M14.53 17.57a2.02 2.02 0 0 1 0 4.03c-1.1 0-2.01-.9-2.01-2.02v-2.01h2.01ZM14.53 16.55a2.02 2.02 0 0 1 0-4.03h5.05a2.02 2.02 0 0 1 0 4.03h-5.05Z" fill="#EBB13E"></path></svg></a></li><li class="Footer_Footer__linkItem__dyvnu"><a href="https://twitter.com/thecubejs"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" class="SocialIcon_SocialIcon__DQ6pT" viewBox="0 0 24 24"><path d="M20.5 8.23c0 1.93-.45 3.8-1.36 5.59a11.62 11.62 0 0 1-3.97 4.56c-1.86 1.26-4 1.9-6.42 1.9-2.31 0-4.43-.64-6.35-1.9.3.03.62.03.98.03 1.92 0 3.64-.6 5.18-1.8-.92 0-1.73-.26-2.41-.83a4.3 4.3 0 0 1-1.44-2.06c.26.03.52.03.75.03.36 0 .75-.03 1.1-.13a4.1 4.1 0 0 1-2.37-1.5 4.03 4.03 0 0 1-.94-2.66v-.07c.58.34 1.2.54 1.85.57a4.3 4.3 0 0 1-1.33-1.53 4.43 4.43 0 0 1-.59-2.03c0-.73.2-1.43.59-2.13A10.87 10.87 0 0 0 7.55 7.4c1.5.76 3.06 1.2 4.75 1.3-.06-.34-.06-.64-.06-.97a4.4 4.4 0 0 1 2.05-3.7c.62-.4 1.3-.56 2.05-.56.62 0 1.17.13 1.66.37.49.23.98.56 1.37.96.94-.2 1.82-.53 2.64-1-.33 1-.92 1.77-1.83 2.33.78-.1 1.56-.33 2.38-.7a9.6 9.6 0 0 1-2.09 2.23c0 .17.04.34.04.57Z" fill="#2AA4F1"></path></svg></a></li><li class="Footer_Footer__linkItem__dyvnu"><a href="https://www.youtube.com/channel/UC5jQrtiI85SUs9zj6FhdkfQ"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" class="SocialIcon_SocialIcon__DQ6pT" viewBox="0 0 24 24"><path d="M22.73 6.72a2.8 2.8 0 0 0-1.98-1.98C19.01 4.27 12 4.27 12 4.27s-7 0-8.75.47a2.8 2.8 0 0 0-1.98 1.98C.8 8.47.8 12.12.8 12.12s0 3.65.47 5.4a2.8 2.8 0 0 0 1.98 1.98c1.75.47 8.75.47 8.75.47s7 0 8.75-.47a2.8 2.8 0 0 0 1.98-1.98c.47-1.75.47-5.4.47-5.4s0-3.65-.47-5.4ZM9.78 15.47v-6.7l5.8 3.33-5.8 3.37Z" fill="#CE1E21"></path></svg></a></li><li class="Footer_Footer__linkItem__dyvnu"><a href="https://stackoverflow.com/questions/tagged/cube.js"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" class="SocialIcon_SocialIcon__DQ6pT" viewBox="0 0 24 24"><path d="M17.24 19.22v-5.57h1.85v7.42H2.4v-7.42h1.85v5.57h13Z" fill="#BCBBBB"></path><path d="m6.3 13.12 9.07 1.9.38-1.83-9.07-1.9-.39 1.83ZM7.5 8.8l8.4 3.91.77-1.68L8.26 7.1l-.77 1.7Zm2.32-4.13 7.13 5.93 1.18-1.42L11 3.25 9.82 4.67Zm4.61-4.4-1.49 1.1 5.53 7.45 1.49-1.1L14.43.27ZM6.1 17.35h9.27V15.5H6.1v1.85Z" fill="#F28032"></path></svg></a></li><li class="Footer_Footer__linkItem__dyvnu"><a href="https://www.linkedin.com/company/cube-dev/"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" class="SocialIcon_SocialIcon__DQ6pT" viewBox="0 0 24 24"><path d="M20.28 3H3.72c-.4 0-.72.32-.72.72v16.56c0 .4.32.72.72.72h16.56c.4 0 .72-.32.72-.72V3.72c0-.4-.32-.72-.72-.72ZM8.34 18.34H5.67v-8.6h2.67v8.6ZM7 8.57a1.55 1.55 0 1 1 0-3.1 1.55 1.55 0 0 1 0 3.1Zm11.33 9.77h-2.67v-4.18c0-1-.02-2.28-1.39-2.28-1.39 0-1.6 1.09-1.6 2.2v4.26h-2.67v-8.6h2.56v1.18h.04a2.8 2.8 0 0 1 2.53-1.39c2.7 0 3.2 1.78 3.2 4.1v4.7Z" fill="#026899"></path></svg></a></li></ul></article></nav></section><section class="Footer_Footer__bottomSection___C1tk"><div class="Footer_Footer__logo__DAlcN"><a class="Logo_Logo__main__oYcSk" href="/"><svg xmlns="http://www.w3.org/2000/svg" width="98" height="28" fill="none"><path d="M26.13 7.04 14 0v4.87l12.13 7V7.05Z" fill="var(--pink)"></path><path d="M26.13 11.88 22.5 14 14 9.08l-4.85 2.8L5.5 9.91 14 4.87l12.12 7Z" fill="var(--dark)"></path><path d="M9.15 11.88 5.5 9.91V14l3.64-2.12Z" fill="#A14474"></path><path d="M1.87 20.96 14 14l12.13 6.96L14 28 1.87 20.96Z" fill="var(--dark)"></path><path d="M26.13 16.13 14 9.01V14l12.13 6.96v-4.83Z" fill="var(--pink)"></path><path d="M5.5 14V9.91L14 4.87V0L1.87 7.04v13.92L14 14V9l-8.5 5Z" fill="var(--purple)"></path><path d="M33.66 14.73c0-4.2 3.34-7.48 7.55-7.48a6.8 6.8 0 0 1 6 3.33l-2.14 1.7c-.93-1.32-2.12-2.2-3.83-2.2-2.62 0-4.47 2.05-4.47 4.65 0 2.66 1.85 4.68 4.47 4.68 1.68 0 2.87-.85 3.83-2.16l2.14 1.66a6.87 6.87 0 0 1-6 3.33 7.45 7.45 0 0 1-7.55-7.5ZM49.86 15.9V7.57h3.01v8.57a3.11 3.11 0 0 0 3.23 3.27c1.74 0 3.13-1.26 3.13-3.27V7.57h3.05v8.33c0 3.9-2.7 6.35-6.18 6.35-3.54 0-6.24-2.46-6.24-6.35ZM80.77 14.76c0 4.27-2.93 7.49-6.97 7.49-2.09 0-3.92-.85-4.99-2.31v1.99h-2.84V0h3.05v9.33a6.03 6.03 0 0 1 4.76-2.08c4.06 0 6.99 3.24 6.99 7.51Zm-3.14-.03c0-2.77-1.91-4.67-4.35-4.67-2.15 0-4.3 1.46-4.3 4.7 0 3.28 2.18 4.68 4.3 4.68 2.47 0 4.35-1.93 4.35-4.7ZM96.53 15.76H85.91c.4 2.36 2.2 3.77 4.64 3.77 1.66 0 2.96-.65 4.15-1.7l1.45 2.1a8.1 8.1 0 0 1-5.69 2.32c-4.4 0-7.66-3.25-7.66-7.49 0-4.2 3.22-7.51 7.37-7.51a6.4 6.4 0 0 1 6.6 6.58c0 .79-.15 1.55-.24 1.93Zm-10.56-2.4h7.75c-.06-2.25-1.72-3.51-3.66-3.51-2 0-3.63 1.38-4.1 3.5Z" fill="var(--dark)"></path></svg></a></div><ul class="Footer_Footer__linkList__mcVnX Footer_Footer__linkList--horizontal__STfpL"><li class="Footer_Footer__linkItem__dyvnu"><a href="/terms-of-use">Terms of Use</a></li><li class="Footer_Footer__linkItem__dyvnu"><a href="/privacy-policy">Privacy Policy</a></li></ul><p class="Footer_Footer__copyright__o_mI2">© <!-- -->2022<!-- --> Cube Dev, Inc.</p></section></footer></div><script id="__NEXT_DATA__" type="application/json">{"props":{"pageProps":{"data":{"hidden":false,"url":"open-source-etl","date":{"utc":"2018-04-25T00:00:00Z","human":"April 25, 2018"},"cover":"https://cubedev-blog-images.s3.us-east-2.amazonaws.com/RYUhjX9gRi6ADjNLr6Ur.png","title":"Open Source ETL: Apache NiFi vs Streamsets","subtitle":"Choosing between mainstream open source ETL projects","sections":[{"slug":"etl","title":"Extract, Load, Transform (ETL)","description":"Data processing tools used for copying data from one or more sources into a destination.","parent":{"slug":"data","title":"Data Engineering","description":"Data pipelines, data modeling, and BI tools to collect, store, and analyze data at scale.","children":[{"slug":"bi","title":"BI \u0026 Data Exploration","description":"Platforms and tools for business intelligence bringing data insight to internal users.","children":[{"slug":"superset","title":"Apache Superset","description":"Widespread open-source data exploration and visualization platform supporting a variety of data sources.","icon":true},{"slug":"tableau","title":"Tableau","description":"One of the most popular data analytics visualization platforms on the market.","icon":true}]},{"slug":"warehouses","title":"Cloud Data Warehouses (CDW)","description":"Popular cloud-based scalable data stores optimized for BI and analytics.","children":[{"slug":"redshift","title":"Amazon Redshift","description":"Petabyte-scale data warehouse of Amazon Web Services.","icon":true},{"slug":"bigquery","title":"Google BigQuery","description":"Serverless data warehouse of Google Cloud Platform.","icon":true},{"slug":"snowflake","title":"Snowflake","description":"Cloud-agnostic data platform supporting AWS, GCP, and Azure.","icon":true}]},{"slug":"oltp","title":"Transactional Databases (OLTP)","description":"Widespread relational and mostly row-based data stores.","children":[{"slug":"postgres","title":"PostgreSQL","description":"Open-source RDBMs emphasizing extensibility and SQL compliance.","icon":true},{"slug":"aurora","title":"Amazon Aurora","description":"MySQL and PostgreSQL-compatible relational database built for AWS.","icon":true}]},{"slug":"olap","title":"Analytical Databases (OLAP)","description":"Mostly column-based data stores optimized for business intelligence analysis.","children":[{"slug":"clickhouse","title":"ClickHouse","description":"Open-source column-oriented data store optimized for performance.","icon":true}]},{"slug":"time-series","title":"Time Series Databases (TSDB)","description":"Data stores optimized for processing timestamps with associated values.","children":[{"slug":"questdb","title":"QuestDB","description":"Fast Postgres-compatible open source time series database.","icon":true}]},{"slug":"streaming","title":"Streaming Databases (RTDB)","description":"Data stores built for stream processing and building real-time applications.","children":[{"slug":"materialize","title":"Materialize","description":"Postgres-compatible streaming database for real-time applications.","icon":true}]},{"slug":"nosql","title":"NoSQL \u0026 Document Databases","description":"Key-value and document-based data stores.","children":[{"slug":"mongo","title":"MongoDB","description":"Source-available document-oriented data store.","icon":true}]},{"slug":"etl","title":"Extract, Load, Transform (ETL)","description":"Data processing tools used for copying data from one or more sources into a destination."},{"slug":"modeling","title":"Data Modeling","description":"Architecturing data storage and solving common analytical tasks with SQL."},{"slug":"performance","title":"Performance","description":"Optimizing query latency and concurrency for better UX and lesser time-to-insight."}]}}],"seo":{"description":"There are many open source ETL tools and frameworks, but most of them require writing code. Since data engineers are not necessarily good programmers, you can try visual ETL to directly connect them with data.","canonicalUrl":""},"authors":[{"name":"Dmitry Dorofeev","image":"https://media.graphcms.com/hebfjoN4SmC7gWupOphp"}]},"postToc":{"compiledSource":"/*@jsxRuntime automatic @jsxImportSource react*/\nconst {jsx: _jsx, jsxs: _jsxs} = arguments[0];\nconst {useMDXComponents: _provideComponents} = arguments[0];\nfunction MDXContent(props = {}) {\n  const {wrapper: MDXLayout} = Object.assign({}, _provideComponents(), props.components);\n  return MDXLayout ? _jsx(MDXLayout, Object.assign({}, props, {\n    children: _jsx(_createMdxContent, {})\n  })) : _createMdxContent();\n  function _createMdxContent() {\n    const _components = Object.assign({\n      ul: \"ul\",\n      li: \"li\",\n      a: \"a\"\n    }, _provideComponents(), props.components);\n    return _jsxs(_components.ul, {\n      children: [\"\\n\", _jsx(_components.li, {\n        children: _jsx(_components.a, {\n          href: \"#dataflow-programming\",\n          children: \"Dataflow Programming\"\n        })\n      }), \"\\n\", _jsx(_components.li, {\n        children: _jsx(_components.a, {\n          href: \"#apache-nifi-vs-streamsets\",\n          children: \"Apache NiFi vs StreamSets\"\n        })\n      }), \"\\n\", _jsx(_components.li, {\n        children: _jsx(_components.a, {\n          href: \"#architecture-and-features\",\n          children: \"Architecture and features\"\n        })\n      }), \"\\n\", _jsx(_components.li, {\n        children: _jsx(_components.a, {\n          href: \"#ui\",\n          children: \"UI\"\n        })\n      }), \"\\n\", _jsx(_components.li, {\n        children: _jsx(_components.a, {\n          href: \"#conclusion\",\n          children: \"Conclusion\"\n        })\n      }), \"\\n\"]\n    });\n  }\n}\nreturn {\n  default: MDXContent\n};\n","frontmatter":{},"scope":{}},"postContent":{"compiledSource":"/*@jsxRuntime automatic @jsxImportSource react*/\nconst {Fragment: _Fragment, jsx: _jsx, jsxs: _jsxs} = arguments[0];\nconst {useMDXComponents: _provideComponents} = arguments[0];\nfunction MDXContent(props = {}) {\n  const {wrapper: MDXLayout} = Object.assign({}, _provideComponents(), props.components);\n  return MDXLayout ? _jsx(MDXLayout, Object.assign({}, props, {\n    children: _jsx(_createMdxContent, {})\n  })) : _createMdxContent();\n  function _createMdxContent() {\n    const _components = Object.assign({\n      p: \"p\",\n      a: \"a\",\n      hr: \"hr\",\n      strong: \"strong\",\n      h2: \"h2\",\n      em: \"em\",\n      blockquote: \"blockquote\",\n      h3: \"h3\",\n      img: \"img\",\n      ul: \"ul\",\n      li: \"li\"\n    }, _provideComponents(), props.components);\n    return _jsxs(_Fragment, {\n      children: [_jsxs(_components.p, {\n        children: [\"While working with \", _jsx(_components.a, {\n          href: \"https://github.com/statsbotco/cube.js\",\n          children: \"Cube.js framework\"\n        }), \" we've seen a lot of diffrent ETL tools used by data engineers nowadays. Most of them require writing code. But there are some  visual ETL you can try as well. We asked Dmitry Dorofeev, Head of R\u0026D at Luxms Group, to tell us about his experience with comparing Apache NiFi and Streamsets.\"]\n      }), \"\\n\", _jsx(_components.hr, {}), \"\\n\", _jsxs(_components.p, {\n        children: [\"Our team at \", _jsx(_components.a, {\n          href: \"https://www.luxms.com/\",\n          children: \"Luxms Inc.\"\n        }), \" has recently faced a boring data integration problem: when some data is stored in Hadoop, some in Oracle, and a little bit is in Excel. The goal was to ETL all that data into Greenplum and finally provide some BI on top of it.\"]\n      }), \"\\n\", _jsxs(_components.p, {\n        children: [\"We quickly found 2 mainstream open source ETL projects: Apache NiFi and Streamsets, and it seemed an easy task to choose one product out of the two. \", _jsx(_components.strong, {\n          children: \"In no way was it easy.\"\n        }), \" I know that better than anyone since I was responsible for the product evaluation and the final choice. In this post, I’d like to share my experience and maybe save days of your life.\"]\n      }), \"\\n\", _jsxs(_components.p, {\n        children: [_jsx(\"i\", {\n          children: \"Spoiler:\"\n        }), \" There is no silver bullet. Apache NiFi is not necessarily better than Streamsets, nor Streamsets better than NiFi. Everything has its pros and cons. This post is my personal experience with these tools as a novice user without any introductory training.\"]\n      }), \"\\n\", _jsx(_components.h2, {\n        id: \"dataflow-programming\",\n        children: \"Dataflow Programming\"\n      }), \"\\n\", _jsxs(_components.p, {\n        children: [\"Programmers, analysts, and even managers often draw a box and arrow diagram to illustrate some flows. You can even use these boxes and arrows to create programs. We can track such attempts back to the 1960s when the \", _jsx(_components.a, {\n          href: \"https://en.wikipedia.org/wiki/Dataflow_programming\",\n          children: \"Dataflow Programming\"\n        }), \" paradigm was born in MIT.\"]\n      }), \"\\n\", _jsx(_components.p, {\n        children: _jsx(_components.em, {\n          children: _jsx(_components.a, {\n            href: \"https://statsbot.co/blog/etl-tools-list/\",\n            children: \"ETL Tools List: Overview \u0026 Pricing\"\n          })\n        })\n      }), \"\\n\", _jsx(_components.p, {\n        children: \"Today, we have tens of Dataflow Programming tools where you can visually assemble programs from boxes and arrows, writing zero lines of code. Some of them are open source and some are suitable for ETL.\"\n      }), \"\\n\", _jsx(_components.p, {\n        children: \"Yes, you don’t have to know any programming language. You just use ready-made “processors” represented with boxes, connect them with arrows, which represent exchange of data between “processors,” and that’s it.\"\n      }), \"\\n\", _jsxs(_components.blockquote, {\n        children: [\"\\n\", _jsx(_components.p, {\n          children: \"There are three main types of boxes: sources, processors, and sinks. Think Extract for sources, Transform for processors, and Load for sinks.\"\n        }), \"\\n\"]\n      }), \"\\n\", _jsx(_components.p, {\n        children: \"Almost anything can be a source, for example, files on the disk or AWS, JDBC query, Hadoop, web service, MQTT, RabbitMQ, Kafka, Twitter, or UDP socket.\"\n      }), \"\\n\", _jsx(_components.p, {\n        children: \"A processor can enhance, verify, filter, join, split, or adjust data. If ready-made processor boxes are not enough, you can code on Python, Shell, Groovy, or even Spark for data transformation.\"\n      }), \"\\n\", _jsx(_components.p, {\n        children: \"Sinks are basically the same as sources, but they are designed for writing data.\"\n      }), \"\\n\", _jsx(_components.h2, {\n        id: \"apache-nifi-vs-streamsets\",\n        children: \"Apache NiFi vs StreamSets\"\n      }), \"\\n\", _jsxs(_components.p, {\n        children: [\"When we faced yet another customer with complicated ETL requirements I decided to try visual dataflow tools. Visual might be attractive even if you use \", _jsx(_components.a, {\n          href: \"http://www.singer.io\",\n          children: \"Singer\"\n        }), \", \", _jsx(_components.a, {\n          href: \"https://www.getdbt.com/\",\n          children: \"data build tool\"\n        }), \", or other handy open source ETL tools, right?\"]\n      }), \"\\n\", _jsxs(_components.p, {\n        children: [\"Luckily, there are two open source visual tools with the web interface: \", _jsx(_components.a, {\n          href: \"https://nifi.apache.org/\",\n          children: \"Apache NiFi\"\n        }), \" and \", _jsx(_components.a, {\n          href: \"https://streamsets.com/products/sdc\",\n          children: \"StreamSets Data Collector\"\n        }), \" (SDC). NiFi was donated by the NSA to the Apache Foundation in 2014 and current development and support is provided mostly by Hortonworks. SDC was started by a California-based startup in 2014 as an open source ETL project available on \", _jsx(_components.a, {\n          href: \"https://github.com/streamsets/datacollector\",\n          children: \"GitHub\"\n        }), \". The first release was published in June 2015.\"]\n      }), \"\\n\", _jsx(_components.p, {\n        children: \"Both products are written in Java and distributed under the Apache 2.0 license.\"\n      }), \"\\n\", _jsx(_components.p, {\n        children: \"Here are some stats from GitHub for early 2018:\"\n      }), \"\\n\", _jsxs(\"table\", {\n        children: [_jsxs(\"tr\", {\n          children: [_jsx(\"th\", {\n            children: \"Metric\"\n          }), \"\\n\", _jsx(\"th\", {\n            children: _jsx(\"a\", {\n              href: \"https://github.com/apache/nifi\",\n              children: \"Apache NiFi\"\n            })\n          }), \"\\n\", _jsx(\"th\", {\n            children: _jsx(\"a\", {\n              href: \"https://github.com/streamsets/datacollector\",\n              children: \"StreamSets\"\n            })\n          })]\n        }), _jsxs(\"tr\", {\n          children: [_jsx(\"td\", {\n            children: \"First release year\"\n          }), \"\\n\", _jsx(\"td\", {\n            children: \"2007\"\n          }), \"\\n\", _jsx(\"td\", {\n            children: \"2015\"\n          })]\n        }), _jsxs(\"tr\", {\n          children: [_jsx(\"td\", {\n            children: \"Forks\"\n          }), \"\\n\", _jsx(\"td\", {\n            children: \"783\"\n          }), \"\\n\", _jsx(\"td\", {\n            children: \"914\"\n          })]\n        }), _jsxs(\"tr\", {\n          children: [_jsx(\"td\", {\n            children: \"Releases\"\n          }), \"\\n\", _jsx(\"td\", {\n            children: \"57\"\n          }), \"\\n\", _jsx(\"td\", {\n            children: \"113\"\n          })]\n        }), _jsxs(\"tr\", {\n          children: [_jsx(\"td\", {\n            children: \"Stars\"\n          }), \"\\n\", _jsx(\"td\", {\n            children: \"811\"\n          }), \"\\n\", _jsx(\"td\", {\n            children: \"405\"\n          })]\n        }), _jsxs(\"tr\", {\n          children: [_jsx(\"td\", {\n            children: \"Version\"\n          }), \"\\n\", _jsx(\"td\", {\n            children: \"1.5\"\n          }), \"\\n\", _jsx(\"td\", {\n            children: \"3.1.0.0\"\n          })]\n        })]\n      }), \"\\n\", _jsx(_components.h2, {\n        id: \"architecture-and-features\",\n        children: \"Architecture and features\"\n      }), \"\\n\", _jsx(_components.p, {\n        children: \"Both tools encourage creation of long-running jobs which work with either streaming data or regular periodic batches. You can create manually managed jobs, but they might be tricky to set up. This is the greatest surprise and mind-shifting feature I personally had with these tools.\"\n      }), \"\\n\", _jsx(_components.h3, {\n        id: \"apache-nifi\",\n        children: \"Apache NiFi\"\n      }), \"\\n\", _jsxs(_components.p, {\n        children: [\"Apache NiFi has a well-thought-out architecture. Once data is fetched from external sources, it is represented as \", _jsx(_components.strong, {\n          children: \"FlowFile\"\n        }), \" inside Apache NiFi dataflows. FlowFile is basically original data with meta-information attached to it. You can easily process not only CSV or other record-based data, but also pictures, videos, audio, or any binary data.\"]\n      }), \"\\n\", _jsx(_components.p, {\n        children: _jsx(_components.img, {\n          src: \"https://media.graphcms.com/w4DLooFSLOBsZMtxeauy%22\",\n          alt: \"\"\n        })\n      }), \"\\n\", _jsx(_components.p, {\n        children: \"A processor usually will have 3 outputs:\"\n      }), \"\\n\", _jsxs(_components.ul, {\n        children: [\"\\n\", _jsx(_components.li, {\n          children: \"Failure. If a FlowFile cannot be processed correctly, the original FlowFile will be routed to this output.\"\n        }), \"\\n\", _jsx(_components.li, {\n          children: \"Original. Once an incoming FlowFile has been processed, the original FlowFile is routed to this output.\"\n        }), \"\\n\", _jsx(_components.li, {\n          children: \"Success. FlowFiles that are successfully processed will be routed to this relationship.\"\n        }), \"\\n\"]\n      }), \"\\n\", _jsx(_components.p, {\n        children: \"You can terminate outputs with checkboxes, so Apache NiFi will ignore terminated outputs and will not send any FlowFiles there.\"\n      }), \"\\n\", _jsxs(_components.p, {\n        children: [\"Another handy feature is \", _jsx(_components.strong, {\n          children: \"Process Groups\"\n        }), \". When a dataflow becomes complex, you can combine your dataflow elements into Process Group, which is graphically represented in the UI in the same way as standard processors. It behaves as a processor, so you can build very complex dataflows recursively.\"]\n      }), \"\\n\", _jsxs(_components.p, {\n        children: [_jsx(_components.strong, {\n          children: \"Controller Service\"\n        }), \" is something that exists outside of your dataflows, but provides some useful information for your processors. It might be SSL certificates, JDBC connection and pool settings, schema definition, and so on. The idea is that rather than configure this information in every processor that might need it, the controller service provides it for any processor to use.\"]\n      }), \"\\n\", _jsx(_components.p, {\n        children: \"Processors are connected with... well, connections. Usually connections are just arrows, but not so with Apache NiFi. Every connection arrow has a small widget attached to it, representing a queue with back pressure and can be configured individually.\"\n      }), \"\\n\", _jsx(_components.p, {\n        children: _jsx(_components.img, {\n          src: \"https://media.graphcms.com/5hGEEssaT6WuQOMlKd1p\",\n          alt: \"\"\n        })\n      }), \"\\n\", _jsx(_components.p, {\n        children: \"For example, if the LogAttribute processor becomes slow or freezes for some reason, FlowFiles generated by the GenerateFlowFile processor will be queued in the connection. After some time, back pressure will pause the GenerateFlowFile processor until the queue goes below the configured threshold.\"\n      }), \"\\n\", _jsx(_components.p, {\n        children: _jsx(_components.img, {\n          src: \"https://media.graphcms.com/BH5LMEAvSnGgfNkmkHW9%22\",\n          alt: \"\"\n        })\n      }), \"\\n\", _jsx(_components.p, {\n        children: \"If you are not yet impressed, how about different queue policies like FIFO, LIFO, and others you can apply to queues in connections?\"\n      }), \"\\n\", _jsxs(_components.p, {\n        children: [_jsx(_components.strong, {\n          children: \"Data Provenance\"\n        }), \" is a Big Brother service which records almost everything in your dataflows as they process data. This is very handy, as you have recorded history of how your dataflow performed, including saved content of the FlowFiles. But that comes with a price, you should have enough disk space to keep the required backlog of provenance data.\"]\n      }), \"\\n\", _jsx(_components.p, {\n        children: \"Even with these awesome features and great architecture, I was not very comfortable with the Apache NiFi user interface. It is definitely usable, but not sexy.\"\n      }), \"\\n\", _jsx(_components.h3, {\n        id: \"streamsets-data-collector\",\n        children: \"StreamSets Data Collector\"\n      }), \"\\n\", _jsx(_components.p, {\n        children: \"Then, I tried Streamsets.\"\n      }), \"\\n\", _jsx(_components.p, {\n        children: _jsx(_components.img, {\n          src: \"https://media.graphcms.com/kSAtWIITHGwHibqCWkUv\",\n          alt: \"\"\n        })\n      }), \"\\n\", _jsxs(_components.p, {\n        children: [\"Processors in Streamsets exchange \", _jsx(_components.strong, {\n          children: \"records\"\n        }), \". That means that everything you ingest into Streamsets is converted automatically into the standard record-oriented format and all processors can handle it as a stream of records. There are no queues in between processors, at least, they are not represented visually, like we saw it in Apache NiFi.\"]\n      }), \"\\n\", _jsxs(_components.p, {\n        children: [\"One nice thing about \", _jsx(_components.strong, {\n          children: \"Streamsets is that it can process binary data\"\n        }), \". Some sources, such as Kafka Consumer, can read messages from the Kafka topic and pass them to other processors or external systems without parsing the structure of the binary message into the record format. This allows us to forward the efficient data to some other destination with minimum overhead.\"]\n      }), \"\\n\", _jsxs(_components.p, {\n        children: [\"The more powerful option is the \", _jsx(_components.a, {\n          href: \"https://streamsets.com/documentation/datacollector/latest/help/index.html#datacollector/UserGuide/Data_Formats/WholeFile.html#concept_nfc_qkh_xw\",\n          children: \"whole file data format\"\n        }), \", supported by several origins, including S3, directory, FTP, and more. With the whole file format, the file is not parsed, but file metadata and a reference to the content is sent along the pipeline. Processors can optionally act on the content – script evaluators and custom processors can get an input stream to the content. But in the default case, once the whole file record arrives at the destination, the data is streamed directly from its source.\"]\n      }), \"\\n\", _jsx(_components.p, {\n        children: \"Even though there are some complaints about lack of binary data support in Streamsets, the whole file support has been there since version 1.6.0.0, released in September 2016.\"\n      }), \"\\n\", _jsxs(_components.p, {\n        children: [\"In Apache NiFi the same processor \", _jsx(_components.strong, {\n          children: \"should have different versions of itself to handle different formats\"\n        }), \". One version for CSV, one for JSON, and another for Avro, for example. You might guess that it is not very user and developer friendly. This was addressed in Apache NiFi 1.5, where most processors are using the Avro format, so you should convert to Avro early and it will be almost the same experience as in Streamsets after that.\"]\n      }), \"\\n\", _jsxs(_components.blockquote, {\n        children: [\"\\n\", _jsx(_components.p, {\n          children: \"To change processor settings in Apache NiFi you must stop the processor, while in Streamsets you must stop the whole dataflow.\"\n        }), \"\\n\"]\n      }), \"\\n\", _jsx(_components.p, {\n        children: \"That means that you always start your dataflow from the beginning after you make any changes in it with Streamsets. With Apache NiFi you have a chance to stop a misbehaving processor, fix it, and start again. Hopefully, queued FlowFiles will be sent to the fixed processor and you will not miss the data.\"\n      }), \"\\n\", _jsx(_components.p, {\n        children: \"But that doesn’t mean that Streamsets dataflows are harder to debug. Actually it is easier, you have a nice-looking live dashboard displaying a lot of statistics for every processor while your dataflow is running. Errors are cleanly presented as red numbers on the processor icon and you can see individual errors for every faulty record with a mouse click. You may even put record filters on the connections between processors to inspect records in question. Filters can be applied while your dataflow is running, so I used it as live debugging tool.\"\n      }), \"\\n\", _jsx(_components.p, {\n        children: \"Streamsets has 4 processor types:\"\n      }), \"\\n\", _jsxs(_components.ul, {\n        children: [\"\\n\", _jsx(_components.li, {\n          children: \"Origins: they get data from the external sources. You may have only one Origin Processor in your dataflow.\"\n        }), \"\\n\", _jsx(_components.li, {\n          children: \"Processors: data transformers.\"\n        }), \"\\n\", _jsx(_components.li, {\n          children: \"Destinations: they save data to the external systems or files.\"\n        }), \"\\n\", _jsx(_components.li, {\n          children: \"Executors: they process events, generated by other processors.\"\n        }), \"\\n\"]\n      }), \"\\n\", _jsxs(_components.p, {\n        children: [\"Some of the Streamsets processors may generate events, including errors. You should use special processors called \", _jsx(_components.strong, {\n          children: \"Executors\"\n        }), \" to handle that. For example, there is Email Executor, which can send emails when an error has occurred.\"]\n      }), \"\\n\", _jsx(_components.p, {\n        children: \"I am definitely more happy with the clean Apache NiFi architecture with just Processors and Controller Services, but the Streamsets design is also fine and can be quickly picked up.\"\n      }), \"\\n\", _jsx(_components.h2, {\n        id: \"ui\",\n        children: \"UI\"\n      }), \"\\n\", _jsx(_components.h3, {\n        id: \"apache-nifi-1\",\n        children: \"Apache NiFi\"\n      }), \"\\n\", _jsx(_components.p, {\n        children: \"There is not much to say about the Apache NiFi UI. It feels spartan, and it is very easy to follow, thanks to the great architecture with minimum concepts. Probably the only drawback I discovered is that Apache NiFi will not autosize text fields for your long SQL queries, so you will have to manually resize popup text fields every time you want to edit it.\"\n      }), \"\\n\", _jsx(_components.p, {\n        children: _jsx(_components.img, {\n          src: \"https://media.graphcms.com/4kwaYmwVTvCsZkeVCthA\",\n          alt: \"\"\n        })\n      }), \"\\n\", _jsx(_components.h3, {\n        id: \"streamsets\",\n        children: \"Streamsets\"\n      }), \"\\n\", _jsx(_components.p, {\n        children: \"Streamsets has a more attractive UI, but it is not perfect as well.\"\n      }), \"\\n\", _jsx(_components.p, {\n        children: \"The first thing I quickly get annoyed with is the absence of Controller Services, especially for JDBC settings. You need to fill in all JDBC settings for every processor that reads data from the same JDBC source. There is just no user-friendly way to reuse such information.\"\n      }), \"\\n\", _jsxs(_components.p, {\n        children: [\"Before you can run your dataflow, Streamsets will check each processor inside your dataflow to make sure all processors are correctly configured. \", _jsx(_components.strong, {\n          children: \"It sounds like a good thing, and it helped me sometimes, but other times – harmed me.\"\n        }), \" In Apache NiFi you can have disconnected processors and I usually leave them so for debugging purposes. In Streamsets you can not do the same, since all the processors must be connected to make dataflow pass validation.\"]\n      }), \"\\n\", _jsx(_components.p, {\n        children: \"Another annoyance is that you can not select several processors at once. At least I was unable to do so. Moving a dozen processors and reorganizing them one by one on the screen can make you mad.\"\n      }), \"\\n\", _jsx(_components.p, {\n        children: \"Streamsets has syntax highlighting for SQL which is a nice feature, but not always useful. Our data engineer creates heavy SQL queries which can easily be a hundred lines long. The syntax highlighting process becomes slow and that results in another annoyance. If you edit the last lines of the long SQL query the caret unexpectedly moves to the beginning and what you type appears on the first line.\"\n      }), \"\\n\", _jsx(_components.h2, {\n        id: \"conclusion\",\n        children: \"Conclusion\"\n      }), \"\\n\", _jsx(_components.p, {\n        children: \"I made a very brief introduction to Apache NiFi and Streamsets. They have plenty of useful features not covered in this blog post. Even if you do not find the required built-in or third-party processors, you can always use Python, Javascript, R, or even Apache Spark to program your complex data transformation logic in the Apache NiFi or Streamsets dataflows.\"\n      }), \"\\n\", _jsx(_components.p, {\n        children: \"Both Apache NiFi and Streamsets are mature, open source ETL tools. They have very similar functionality and the only way to make a concise choice is to try both! That’s what I did. Even after 3 months of running both products I can not see a clear winner.\"\n      }), \"\\n\", _jsx(_components.p, {\n        children: \"For me, live monitoring is the single feature in Streamsets that outweighs all its small glitches.\"\n      }), \"\\n\", _jsx(_components.h3, {\n        id: \"apache-nifi-2\",\n        children: \"Apache NiFi\"\n      }), \"\\n\", _jsx(_components.p, {\n        children: \"Pros:\"\n      }), \"\\n\", _jsxs(_components.ul, {\n        children: [\"\\n\", _jsx(_components.li, {\n          children: \"Clean and well-thought-out implementation of the dataflow programming concept\"\n        }), \"\\n\", _jsx(_components.li, {\n          children: \"Can handle binary data\"\n        }), \"\\n\", _jsx(_components.li, {\n          children: \"Data Provenance\"\n        }), \"\\n\"]\n      }), \"\\n\", _jsx(_components.p, {\n        children: \"Cons:\"\n      }), \"\\n\", _jsxs(_components.ul, {\n        children: [\"\\n\", _jsx(_components.li, {\n          children: \"Spartan User Interface\"\n        }), \"\\n\", _jsx(_components.li, {\n          children: \"No live monitoring/debugging features with per-record statistics\"\n        }), \"\\n\"]\n      }), \"\\n\", _jsx(_components.h3, {\n        id: \"streamsets-1\",\n        children: \"Streamsets\"\n      }), \"\\n\", _jsx(_components.p, {\n        children: \"Pros:\"\n      }), \"\\n\", _jsxs(_components.ul, {\n        children: [\"\\n\", _jsx(_components.li, {\n          children: \"Live monitoring/debugging features with visual per-record statistics for every processor\"\n        }), \"\\n\", _jsx(_components.li, {\n          children: \"Sexy UI\"\n        }), \"\\n\", _jsx(_components.li, {\n          children: \"Well-suited for record-based data and streaming\"\n        }), \"\\n\"]\n      }), \"\\n\", _jsx(_components.p, {\n        children: \"Cons:\"\n      }), \"\\n\", _jsxs(_components.ul, {\n        children: [\"\\n\", _jsx(_components.li, {\n          children: \"You need to stop the whole dataflow to edit a single processor configuration\"\n        }), \"\\n\", _jsx(_components.li, {\n          children: \"No reusable JDBC configuration for processors\"\n        }), \"\\n\"]\n      })]\n    });\n  }\n}\nreturn {\n  default: MDXContent\n};\n","frontmatter":{},"scope":{}}},"__N_SSG":true},"page":"/[id]","query":{"id":"open-source-etl"},"buildId":"tYLrb3PX7MVWwci5Y_7pM","assetPrefix":"/blog","runtimeConfig":{"assetPrefix":"/blog","title":"Cube Blog","domain":"https://cube.dev/blog"},"isFallback":false,"gsp":true,"scriptLoader":[]}</script></body></html>