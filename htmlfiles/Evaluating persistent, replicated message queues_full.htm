<!DOCTYPE html><html lang=""><head><!-- Google Tag Manager --><script>;if(!navigator.userAgent.match(/nsights|ighth/i)){(function(e,n,g,t,s){e[t]=e[t]||[];e[t].push({'gtm.start':new Date().getTime(),event:'gtm.js'});var r=n.getElementsByTagName(g)[0],a=n.createElement(g),i=t!='dataLayer'?'&l='+t:'';a.async=!0;a.src='https://www.googletagmanager.com/gtm.js?id='+s+i;r.parentNode.insertBefore(a,r)})(window,document,'script','dataLayer','GTM-KWFZJ7W')};</script><!-- End Google Tag Manager --><meta charset="utf-8" /><meta name="robots" content="index,follow" /><meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0" /><meta name="facebook-domain-verification" content="g8uff77fe9ogvytjfvs3km0ftzr4as" /><meta name="generator" content="softwaremill" /><meta name="description" content="How do SQS, RabbitMQ, ActiveMQ Artemis, EventStore, Kafka, Pulsar, RedPanda, RocketMQ, PostgreSQL, NATS Streaming, Redis Streams and MongoDB compare when it comes to queueing?" /><meta name="title" content="Evaluating persistent, replicated message queues (2020 edition)" /><link rel="preload" href="https://fonts.googleapis.com/css?family=Open+Sans:300i,400,600,700&display=swap&subset=latin-ext" as="style"><link href="https://fonts.googleapis.com/css?family=Open+Sans:300i,400,600,700&display=swap&subset=latin-ext" rel="stylesheet" type="text/css"><link href="/user/plugins/markdown-notices/assets/notices.css" type="text/css" rel="stylesheet"><link href="/user/plugins/form/assets/form-styles.css" type="text/css" rel="stylesheet"><link href="/user/plugins/langswitcher/css/langswitcher.css" type="text/css" rel="stylesheet"><link href="/user/plugins/youtube/css/youtube.css" type="text/css" rel="stylesheet"><link href="/user/themes/softwaremill/_/dist/main.css" type="text/css" rel="stylesheet"><link href="/user/themes/softwaremill/_/dist/styles.css" type="text/css" rel="stylesheet"><link href="/user/plugins/login/css/login.css" type="text/css" rel="stylesheet"><link rel="shortcut icon" type="image/png" href="/user/themes/softwaremill/assets/favicon.png" /><link rel="alternate" type="application/atom+xml" title="SoftwareMill Atom Feed" href="/blog.atom" /><link rel="alternate" type="application/rss+xml" title="SoftwareMill RSS Feed" href="/blog.rss" /><link rel="alternate" type="application/json" title="SoftwareMill JSON Feed" href="/blog.json" /><title>Evaluating persistent, replicated message queues</title></head><body data-gtmpage="Evaluating persistent, replicated message queues"><!-- Google Tag Manager (noscript) --><noscript><iframe src="https://www.googletagmanager.com/ns.html?id=GTM-KWFZJ7W" height="0" width="0" style="display:none;visibility:hidden"></iframe></noscript><!-- End Google Tag Manager (noscript) --><header id="header-top" class="header-top header--black animated" data-app-header><div class="viewport"><div class="header__layout"><section class="header__branding"><a class="header__logo" href="/"><figure class="logo__text"><svg xmlns="http://www.w3.org/2000/svg" width="183.465" height="14.333"><g fill="#19191e"><path class="svg__ico" data-name="Path 15" d="M0 12.078l.97-1.148a6.6 6.6 0 0 0 4.751 1.959c1.862 0 3.089-.991 3.089-2.356v-.039c0-1.286-.694-2.019-3.6-2.634C2.019 7.166.554 6.138.554 3.861v-.039C.554 1.644 2.475.04 5.106.04a7.238 7.238 0 0 1 4.872 1.7l-.911 1.209a6.089 6.089 0 0 0-4-1.5c-1.8 0-2.947.991-2.947 2.237v.039c0 1.307.711 2.04 3.76 2.694 3.089.672 4.514 1.8 4.514 3.918v.035c0 2.374-1.979 3.92-4.732 3.92A8.108 8.108 0 0 1 0 12.078z"/><path class="svg__ico" data-name="Path 16" d="M14.608 7.206v-.04a7.068 7.068 0 1 1 14.136-.039v.039a7.068 7.068 0 1 1-14.136.04zm12.512 0v-.04a5.51 5.51 0 0 0-5.465-5.721 5.445 5.445 0 0 0-5.424 5.683v.039a5.51 5.51 0 0 0 5.465 5.721 5.444 5.444 0 0 0 5.424-5.682z"/><path class="svg__ico" data-name="Path 17" d="M33.689.237h9.96v1.445h-8.4v4.949h7.5v1.426h-7.5v6.039h-1.56z"/><path class="svg__ico" data-name="Path 18" d="M52.558 1.682h-4.653V.237h10.89v1.445h-4.654v12.413h-1.583z"/><path class="svg__ico" data-name="Path 19" d="M62.294.238h1.7l3.959 11.543L71.757.199h1.289l3.8 11.582L80.806.238h1.643l-4.95 13.956h-1.326l-3.8-11.244-3.822 11.244h-1.307z"/><path class="svg__ico" data-name="Path 20" d="M90.265.138h1.465l6.316 13.958h-1.682l-1.625-3.662h-7.543l-1.643 3.662h-1.6zm3.861 8.889l-3.149-7.069-3.168 7.069z"/><path class="svg__ico" data-name="Path 21" d="M101.838.237h5.959a5.457 5.457 0 0 1 3.939 1.386 3.834 3.834 0 0 1 1.07 2.732v.04c0 2.3-1.584 3.642-3.763 4.039l4.257 5.662h-1.92l-4.019-5.386h-3.964v5.386h-1.56V.237zm5.821 7.069c2.078 0 3.563-1.07 3.563-2.852v-.039c0-1.7-1.306-2.733-3.543-2.733h-4.276v5.624z"/><path class="svg__ico" data-name="Path 22" d="M118.949.237h10.018v1.427h-8.454v4.73h7.563v1.425h-7.563v4.852h8.552v1.424h-10.116z"/><path class="svg__ico" data-name="Path 23" d="M134.939.237h3.285l3.642 5.86 3.645-5.86h3.285v13.858h-3.033V5.048l-3.9 5.92h-.078l-3.862-5.86v8.988h-2.988V.237z"/><path class="svg__ico" data-name="Path 24" d="M153.901.237h3.049v13.858h-3.049z"/><path class="svg__ico" data-name="Path 25" d="M175.37.237h3.048v11.087h5.047v2.772h-8.095z"/><path class="svg__ico" data-name="Path 26" d="M162.635.237h3.048v11.087h5.047v2.772h-8.095z"/></g></svg></figure><figure class="logo__shapes"><svg version="1.1" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" x="0px" y="0px" viewBox="-893 457.8 131.3 46.2" enable-background="new -893 457.8 131.3 46.2" xml:space="preserve"><rect class="svg__ico" x="-876" y="457.8" fill="#2E80BF" width="12.2" height="38.9"/><rect class="svg__ico" x="-790.9" y="457.8" fill="#5BBA47" width="12.2" height="38.9"/><rect class="svg__ico" x="-841.9" y="457.8" fill="#975CA5" width="12.2" height="38.9"/><rect class="svg__ico" x="-824.9" y="465.1" fill="#F06CA8" width="12.2" height="38.9"/><rect class="svg__ico" x="-807.9" y="457.8" fill="#B370AE" width="12.2" height="38.9"/><path class="svg__ico" fill="#67C2DC" d="M-846.8,463.9c0,3.4-2.7,6.1-6.1,6.1c-3.4,0-6.1-2.7-6.1-6.1c0-3.4,2.7-6.1,6.1-6.1 c0,0,0,0,0,0C-849.5,457.8-846.8,460.5-846.8,463.9z"/><path class="svg__ico" fill="#36539A" d="M-880.8,490.6c0,3.4-2.7,6.1-6.1,6.1c-3.4,0-6.1-2.7-6.1-6.1c0-3.4,2.7-6.1,6.1-6.1 C-883.6,484.5-880.8,487.3-880.8,490.6L-880.8,490.6z"/><path class="svg__ico" fill="#B2D235" d="M-761.7,490.6c0,3.4-2.7,6.1-6.1,6.1c-3.4,0-6.1-2.7-6.1-6.1c0-3.4,2.7-6.1,6.1-6.1 C-764.4,484.5-761.7,487.3-761.7,490.6z"/></svg></figure></a><a class="header__ui ui-nav do-toggle-nav" href="#" role="button"><span></span><span></span><span></span><span></span></a></section><section class="header__menu"><nav id="nav-top" class="nav-top" data-app-nav-mobile><ul class="nav__menu menu--top"><li class="menu__item item--has-submenu "><a href="#/" data-gtmevent="menu-click" data-gtmvalue="#" data-gtmlabel="Services"> Services</a><ul class="nav__submenu"><span class="submenu__title"><a href="#" class="do-close-subnav">Services</a></span><li class="menu__item item--submenu"><a href="/services/" data-gtmevent="submenu-click" data-gtmvalue="/services" data-gtmlabel="Main services"> Main services </a></li><li class="menu__item item--submenu"><a href="/services/backend-development/" data-gtmevent="submenu-click" data-gtmvalue="/services/backend-development" data-gtmlabel="Backend Development"> Backend Development </a></li><li class="menu__item item--submenu"><a href="/services/java-development/" data-gtmevent="submenu-click" data-gtmvalue="/services/java-development" data-gtmlabel="Java Software Development"> Java Software Development </a></li><li class="menu__item item--submenu"><a href="/services/scala/" data-gtmevent="submenu-click" data-gtmvalue="/services/scala" data-gtmlabel="Scala-Akka Development"> Scala-Akka Development </a></li><li class="menu__item item--submenu"><a href="/services/machine-learning-services/" data-gtmevent="submenu-click" data-gtmvalue="/services/machine-learning-services" data-gtmlabel="Machine Learning services"> Machine Learning services </a></li><li class="menu__item item--submenu"><a href="/services/blockchain/" data-gtmevent="submenu-click" data-gtmvalue="/services/blockchain" data-gtmlabel="Blockchain Development"> Blockchain Development </a></li><li class="menu__item item--submenu"><a href="/services/private-blockchain-for-business/" data-gtmevent="submenu-click" data-gtmvalue="/services/private-blockchain-for-business" data-gtmlabel="Private Blockchain for business"> Private Blockchain for business </a></li><li class="menu__item item--submenu"><a href="/services/big-data-software-development/" data-gtmevent="submenu-click" data-gtmvalue="/services/big-data-software-development" data-gtmlabel="Big Data solutions"> Big Data solutions </a></li><li class="menu__item item--submenu"><a href="/services/frontend-development-team/" data-gtmevent="submenu-click" data-gtmvalue="/services/frontend-development-team" data-gtmlabel="Frontend Development"> Frontend Development </a></li><li class="menu__item item--submenu"><a href="/academy/" data-gtmevent="submenu-click" data-gtmvalue="/academy" data-gtmlabel="SoftwareMill Academy"> SoftwareMill Academy </a></li><li class="menu__item item--submenu"><a href="/services/internet-of-things/" data-gtmevent="submenu-click" data-gtmvalue="/services/internet-of-things" data-gtmlabel="Internet of Things"> Internet of Things </a></li></ul></li><li class="menu__item item--has-submenu "><a href="/" data-gtmevent="menu-click" data-gtmvalue="" data-gtmlabel="Industries"> Industries</a><ul class="nav__submenu"><span class="submenu__title"><a href="#" class="do-close-subnav">Industries</a></span><li class="menu__item item--submenu"><a href="/industries/software-development-financial/" data-gtmevent="submenu-click" data-gtmvalue="/industries/software-development-financial" data-gtmlabel="FinTech"> FinTech </a></li><li class="menu__item item--submenu"><a href="/industries/software-development-healthcare/" data-gtmevent="submenu-click" data-gtmvalue="/industries/software-development-healthcare" data-gtmlabel="Healthcare"> Healthcare </a></li><li class="menu__item item--submenu"><a href="/industries/software-development-entertainment/" data-gtmevent="submenu-click" data-gtmvalue="/industries/software-development-entertainment" data-gtmlabel="Media and Enterteinment"> Media and Enterteinment </a></li><li class="menu__item item--submenu"><a href="/industries/software-development-education/" data-gtmevent="submenu-click" data-gtmvalue="/industries/software-development-education" data-gtmlabel="Education"> Education </a></li><li class="menu__item item--submenu"><a href="/industries/telecom-software-development/" data-gtmevent="submenu-click" data-gtmvalue="/industries/telecom-software-development" data-gtmlabel="Telecommunications"> Telecommunications </a></li></ul></li><li class="menu__item item--has-submenu "><a href="/how-we-work/" data-gtmevent="menu-click" data-gtmvalue="/how-we-work" data-gtmlabel="How we work"> How we work</a><ul class="nav__submenu"><span class="submenu__title"><a href="#" class="do-close-subnav">How we work</a></span><li class="menu__item item--submenu"><a href="/how-we-work/" data-gtmevent="submenu-click" data-gtmvalue="/how-we-work" data-gtmlabel="How we work"> How we work </a></li><li class="menu__item item--submenu"><a href="/faq/" data-gtmevent="submenu-click" data-gtmvalue="/faq" data-gtmlabel="FAQ"> FAQ </a></li><li class="menu__item item--submenu"><a href="/how-we-work/our-story/" data-gtmevent="submenu-click" data-gtmvalue="/how-we-work/our-story" data-gtmlabel="Our story"> Our story </a></li></ul></li><li class="menu__item item--has-submenu "><a href="#/" data-gtmevent="menu-click" data-gtmvalue="#" data-gtmlabel="Portfolio"> Portfolio</a><ul class="nav__submenu"><span class="submenu__title"><a href="#" class="do-close-subnav">Portfolio</a></span><li class="menu__item item--submenu"><a href="/portfolio-clients/" data-gtmevent="submenu-click" data-gtmvalue="/portfolio-clients" data-gtmlabel="Client projects"> Client projects </a></li><li class="menu__item item--submenu"><a href="/open-source/" data-gtmevent="submenu-click" data-gtmvalue="/open-source" data-gtmlabel="Open source"> Open source </a></li><li class="menu__item item--submenu"><a href="/portfolio-products/" data-gtmevent="submenu-click" data-gtmvalue="/portfolio-products" data-gtmlabel="Our products"> Our products </a></li><li class="menu__item item--submenu"><a href="https://softwaremill.com/kafka-visualisation/" target="_blank" data-gtmevent="submenu-click" data-gtmvalue="https://softwaremill.com/kafka-visualisation" data-gtmlabel="Kafka Visualisation Tool"> Kafka Visualisation Tool </a></li></ul></li><li class="menu__item item--has-submenu "><a href="#/" data-gtmevent="menu-click" data-gtmvalue="#" data-gtmlabel="Company"> Company</a><ul class="nav__submenu"><span class="submenu__title"><a href="#" class="do-close-subnav">Company</a></span><li class="menu__item item--submenu"><a href="/team/" data-gtmevent="submenu-click" data-gtmvalue="/team" data-gtmlabel="Team"> Team </a></li><li class="menu__item item--submenu"><a href="/about-us/" data-gtmevent="submenu-click" data-gtmvalue="/about-us" data-gtmlabel="About us"> About us </a></li><li class="menu__item item--submenu"><a href="/company-community/" data-gtmevent="submenu-click" data-gtmvalue="/company-community" data-gtmlabel="Community"> Community </a></li><li class="menu__item item--submenu"><a href="/company-remote/" data-gtmevent="submenu-click" data-gtmvalue="/company-remote" data-gtmlabel="Remote"> Remote </a></li><li class="menu__item item--submenu"><a href="/scala/" data-gtmevent="submenu-click" data-gtmvalue="/scala" data-gtmlabel="Scala"> Scala </a></li></ul></li><li class="menu__item item--has-submenu "><a href="/join-us/" data-gtmevent="menu-click" data-gtmvalue="/join-us" data-gtmlabel="Join us"> Join us</a><ul class="nav__submenu"><span class="submenu__title"><a href="#" class="do-close-subnav">Join us</a></span><li class="menu__item item--submenu"><a href="/join-us/" data-gtmevent="submenu-click" data-gtmvalue="/join-us" data-gtmlabel="Join the team"> Join the team </a></li><li class="menu__item item--submenu"><a href="/ebooks/handbook-for-new-employees/" target="_blank" data-gtmevent="submenu-click" data-gtmvalue="/ebooks/handbook-for-new-employees" data-gtmlabel="Handbook for new employees"> Handbook for new employees </a></li><li class="menu__item item--submenu"><a href="/show-your-devskin/" data-gtmevent="submenu-click" data-gtmvalue="/show-your-devskin" data-gtmlabel="Show your DevSkin"> Show your DevSkin </a></li></ul></li><li class="menu__item item--has-submenu "><a href="/blog/" data-gtmevent="menu-click" data-gtmvalue="/blog" data-gtmlabel="Blog"> Blog</a><ul class="nav__submenu"><span class="submenu__title"><a href="#" class="do-close-subnav">Blog</a></span><li class="menu__item item--submenu"><a href="/blog/" data-gtmevent="submenu-click" data-gtmvalue="/blog" data-gtmlabel="Articles"> Articles </a></li><li class="menu__item item--submenu"><a href="/datatimes/" data-gtmevent="submenu-click" data-gtmvalue="/datatimes" data-gtmlabel="Data Times news flash"> Data Times news flash </a></li><li class="menu__item item--submenu"><a href="https://kafka.softwaremill.com/" target="_blank" data-gtmevent="submenu-click" data-gtmvalue="https://kafka.softwaremill.com" data-gtmlabel="Kafka Ebook"> Kafka Ebook </a></li><li class="menu__item item--submenu"><a href="https://remotework.softwaremill.com/" target="_blank" data-gtmevent="submenu-click" data-gtmvalue="https://remotework.softwaremill.com" data-gtmlabel="Remote Software Development Ebook"> Remote Software Development Ebook </a></li><li class="menu__item item--submenu"><a href="/ebooks/audit-whitepaper/" data-gtmevent="submenu-click" data-gtmvalue="/ebooks/audit-whitepaper" data-gtmlabel="Audit Whitepaper"> Audit Whitepaper </a></li></ul></li><li class="menu__item item--cta"><a href="/contact/" data-gtmevent="menu-click" data-gtmvalue="/contact" data-gtmlabel="Hire us!"> Hire us!</a></li></ul></nav></section><section class="header__socialmedia"><div class="block-socialmedia"><ul class="socialmedia__list"><li><a target="_blank" href="https://twitter.com/softwaremill" data-gtmevent="footer-sm-click" data-gtmvalue="twitter" title="Twitter"><figure class="socialmedia__ico ui-ico ico--twitter"><svg version="1.1" class="ico-twitter" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" x="0px" y="0px" viewBox="-947 470.9 24.2 20.1" enable-background="new -947 470.9 24.2 20.1" xml:space="preserve"><path class="svg__ico" fill="#FFFFFF" d="M-923.4,471.2c-1,0.6-2.1,1-3.2,1.2c-0.9-1-2.3-1.6-3.6-1.6c-2.8,0-5,2.2-5,5c0,0,0,0,0,0.1 c0,0.4,0.1,0.8,0.2,1.2c-4-0.2-7.8-2.1-10.3-5.2c-1.3,2.3-0.6,5.3,1.6,6.8c-0.8,0-1.6-0.2-2.2-0.7v0.1c0,2.4,1.7,4.5,4.1,5 c-0.4,0.1-0.9,0.2-1.3,0.2c-0.3,0-0.6,0-0.9-0.1c0.6,2.1,2.6,3.5,4.7,3.5c-1.8,1.4-4,2.1-6.2,2.2c-0.4,0-0.8,0-1.2-0.1 c2.3,1.5,5,2.2,7.7,2.2c9.3,0,14.3-7.7,14.3-14.4V476c0.8-0.8,1.6-1.8,2.2-2.7c-0.9,0.4-1.9,0.7-2.9,0.8 C-924.6,473.4-923.8,472.4-923.4,471.2z"/></svg></figure></a></li><li><a target="_blank" data-gtmevent="footer-sm-click" data-gtmvalue="facebook" href="https://www.facebook.com/softwaremill" title="Facebook"><figure class="socialmedia__ico ui-ico ico--facebook"><svg version="1.1" class="ico-facebook" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" x="0px" y="0px" viewBox="-953 469.3 12.5 24" enable-background="new -953 469.3 12.5 24" xml:space="preserve"><path class="svg__ico" fill="#FFFFFF" d="M-949.3,493.3h4.4v-11h3.7l0.5-4.3h-4.2v-2.7c0-1.3,0.3-2,2.1-2h2.3v-3.8 c-1.1-0.1-2.2-0.2-3.3-0.2c-3.2,0-5.5,2-5.5,5.6v3.1h-3.7v4.3h3.7V493.3z"/></svg></figure></a></li><li><a target="_blank" data-gtmevent="footer-sm-click" data-gtmvalue="linkedin" href="https://www.linkedin.com/company/808422" title="LinkedIn"><figure class="socialmedia__ico ui-ico ico--linkedin"><svg version="1.1" class="ico-linkedin" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" x="0px" y="0px" viewBox="-949 471.7 20.9 19.3" enable-background="new -949 471.7 20.9 19.3" xml:space="preserve"><rect class="svg__ico" x="-948.5" y="477.9" fill="#FFFFFF" width="4.1" height="13"/><path class="svg__ico" fill="#FFFFFF" d="M-933.3,477.9c-2.3,0-3.8,1.3-4.1,2.2v-2h-4.6c0.1,1,0,13,0,13h4.6v-7.1c0-0.4,0-0.7,0.1-1.1 c0.3-1,1.2-1.6,2.2-1.6c1.6,0,2.3,1.2,2.3,2.9v6.7h4.7v-7.2C-928.1,479.7-930.4,477.9-933.3,477.9z"/><path class="svg__ico" fill="#FFFFFF" d="M-946.3,471.7c-0.1,0-0.1,0-0.2,0c-1.3-0.1-2.4,0.9-2.5,2.1c0,0,0,0.1,0,0.1c0,1.2,1,2.3,2.2,2.3 c0.1,0,0.1,0,0.2,0c1.2,0.1,2.4-0.8,2.5-2c0-0.1,0-0.2,0-0.2C-944.1,472.8-945.1,471.8-946.3,471.7z"/></svg></figure></a></li><li><a target="_blank" data-gtmevent="footer-sm-click" data-gtmvalue="github" href="https://github.com/softwaremill" title="Github"><figure class="socialmedia__ico ui-ico ico--github"><svg version="1.1" class="ico-github" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" x="0px" y="0px" viewBox="-946 469 25.9 25" enable-background="new -946 469 25.9 25" xml:space="preserve"><path class="svg__ico" fill="#FFFFFF" d="M-933.2,469c-7.1,0-12.8,5.8-12.8,12.8c0,5.5,3.6,10.4,8.8,12.1c0.7,0.1,0.9-0.3,0.9-0.6v-2.2 c-3.6,0.8-4.3-1.7-4.3-1.7c-0.2-0.8-0.7-1.5-1.4-1.9c-1.2-0.8,0.1-0.7,0.1-0.7c0.8,0.1,1.6,0.6,2,1.3c0.7,1.3,2.3,1.8,3.6,1.1 c0,0,0.1,0,0.1,0c0-0.7,0.3-1.3,0.8-1.7c-2.8-0.3-5.8-1.4-5.8-6.3c0-1.3,0.4-2.5,1.3-3.4c-0.4-1.1-0.4-2.3,0.2-3.4 c0,0,1.1-0.3,3.5,1.3c1.1-0.3,2.1-0.4,3.2-0.4c1.1,0,2.2,0.2,3.2,0.4c2.4-1.7,3.5-1.3,3.5-1.3c0.4,1.1,0.5,2.3,0.2,3.4 c0.9,0.9,1.3,2.1,1.3,3.4c0,4.9-3,6-5.8,6.3c0.6,0.6,0.9,1.5,0.8,2.4v3.5c0,0.3,0.2,0.8,0.9,0.6c5.2-1.8,8.7-6.6,8.7-12.2 C-920.3,474.7-926.1,469.1-933.2,469z"/></svg></figure></a></li><li><a target="_blank" data-gtmevent="footer-sm-click" data-gtmvalue="youtube" href="https://www.youtube.com/c/SoftwareMillCom" title="YouTube"><figure class="socialmedia__ico ui-ico ico--yt"><svg version="1.1" class="ico-yt" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" x="0px" y="0px" viewBox="-948.5 471.7 23.5 17.8" enable-background="new -948.5 471.7 23.5 17.8" xml:space="preserve"><path class="svg__ico" fill="#FFFFFF" d="M-926.6,473.5c-0.6-0.6-1.4-1-2.3-1c-3.2-0.3-7.8-0.3-7.8-0.3s-4.8,0-7.8,0.3 c-0.9,0-1.7,0.4-2.3,1c-0.5,0.7-0.8,1.5-0.9,2.4c-0.2,1.3-0.2,2.5-0.3,3.8v1.9c0,1.3,0.1,2.6,0.3,3.8c0.1,0.8,0.4,1.6,0.9,2.3 c0.7,0.6,1.6,1,2.5,1c1.8,0.2,7.7,0.2,7.7,0.2s4.8,0,7.8-0.2c0.9,0,1.7-0.4,2.3-1c0.5-0.7,0.8-1.5,0.9-2.4c0,0,0.2-1.8,0.2-3.7v-1.8 c0-1.3-0.1-2.6-0.3-3.9C-925.8,475-926.1,474.2-926.6,473.5z M-939.5,484.8v-8.4l7,4.2L-939.5,484.8z"/></svg></figure></a></li><li><a target="_blank" data-gtmevent="footer-sm-click" data-gtmvalue="instagram" href="https://instagram.com/softwaremill_vibes" title="Instagram"><figure class="socialmedia__ico ui-ico ico--instagram"><?xml version="1.0" encoding="UTF-8" standalone="no"?><svg viewBox="0 0 256 256" version="1.1" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" preserveAspectRatio="xMidYMid"><g class="svg__ico" fill="#FFFFFF"><path d="M127.999746,23.06353 C162.177385,23.06353 166.225393,23.1936027 179.722476,23.8094161 C192.20235,24.3789926 198.979853,26.4642218 203.490736,28.2166477 C209.464938,30.5386501 213.729395,33.3128586 218.208268,37.7917319 C222.687141,42.2706052 225.46135,46.5350617 227.782844,52.5092638 C229.535778,57.0201472 231.621007,63.7976504 232.190584,76.277016 C232.806397,89.7746075 232.93647,93.8226147 232.93647,128.000254 C232.93647,162.177893 232.806397,166.225901 232.190584,179.722984 C231.621007,192.202858 229.535778,198.980361 227.782844,203.491244 C225.46135,209.465446 222.687141,213.729903 218.208268,218.208776 C213.729395,222.687649 209.464938,225.461858 203.490736,227.783352 C198.979853,229.536286 192.20235,231.621516 179.722476,232.191092 C166.227425,232.806905 162.179418,232.936978 127.999746,232.936978 C93.8200742,232.936978 89.772067,232.806905 76.277016,232.191092 C63.7971424,231.621516 57.0196391,229.536286 52.5092638,227.783352 C46.5345536,225.461858 42.2700971,222.687649 37.7912238,218.208776 C33.3123505,213.729903 30.538142,209.465446 28.2166477,203.491244 C26.4637138,198.980361 24.3784845,192.202858 23.808908,179.723492 C23.1930946,166.225901 23.0630219,162.177893 23.0630219,128.000254 C23.0630219,93.8226147 23.1930946,89.7746075 23.808908,76.2775241 C24.3784845,63.7976504 26.4637138,57.0201472 28.2166477,52.5092638 C30.538142,46.5350617 33.3123505,42.2706052 37.7912238,37.7917319 C42.2700971,33.3128586 46.5345536,30.5386501 52.5092638,28.2166477 C57.0196391,26.4642218 63.7971424,24.3789926 76.2765079,23.8094161 C89.7740994,23.1936027 93.8221066,23.06353 127.999746,23.06353 M127.999746,0 C93.2367791,0 88.8783247,0.147348072 75.2257637,0.770274749 C61.601148,1.39218523 52.2968794,3.55566141 44.1546281,6.72008828 C35.7374966,9.99121548 28.5992446,14.3679613 21.4833489,21.483857 C14.3674532,28.5997527 9.99070739,35.7380046 6.71958019,44.1551362 C3.55515331,52.2973875 1.39167714,61.6016561 0.769766653,75.2262718 C0.146839975,88.8783247 0,93.2372872 0,128.000254 C0,162.763221 0.146839975,167.122183 0.769766653,180.774236 C1.39167714,194.398852 3.55515331,203.703121 6.71958019,211.845372 C9.99070739,220.261995 14.3674532,227.400755 21.4833489,234.516651 C28.5992446,241.632547 35.7374966,246.009293 44.1546281,249.28042 C52.2968794,252.444847 61.601148,254.608323 75.2257637,255.230233 C88.8783247,255.85316 93.2367791,256 127.999746,256 C162.762713,256 167.121675,255.85316 180.773728,255.230233 C194.398344,254.608323 203.702613,252.444847 211.844864,249.28042 C220.261995,246.009293 227.400247,241.632547 234.516143,234.516651 C241.632039,227.400755 246.008785,220.262503 249.279912,211.845372 C252.444339,203.703121 254.607815,194.398852 255.229725,180.774236 C255.852652,167.122183 256,162.763221 256,128.000254 C256,93.2372872 255.852652,88.8783247 255.229725,75.2262718 C254.607815,61.6016561 252.444339,52.2973875 249.279912,44.1551362 C246.008785,35.7380046 241.632039,28.5997527 234.516143,21.483857 C227.400247,14.3679613 220.261995,9.99121548 211.844864,6.72008828 C203.702613,3.55566141 194.398344,1.39218523 180.773728,0.770274749 C167.121675,0.147348072 162.762713,0 127.999746,0 Z M127.999746,62.2703115 C91.698262,62.2703115 62.2698034,91.69877 62.2698034,128.000254 C62.2698034,164.301738 91.698262,193.730197 127.999746,193.730197 C164.30123,193.730197 193.729689,164.301738 193.729689,128.000254 C193.729689,91.69877 164.30123,62.2703115 127.999746,62.2703115 Z M127.999746,170.667175 C104.435741,170.667175 85.3328252,151.564259 85.3328252,128.000254 C85.3328252,104.436249 104.435741,85.3333333 127.999746,85.3333333 C151.563751,85.3333333 170.666667,104.436249 170.666667,128.000254 C170.666667,151.564259 151.563751,170.667175 127.999746,170.667175 Z M211.686338,59.6734287 C211.686338,68.1566129 204.809755,75.0337031 196.326571,75.0337031 C187.843387,75.0337031 180.966297,68.1566129 180.966297,59.6734287 C180.966297,51.1902445 187.843387,44.3136624 196.326571,44.3136624 C204.809755,44.3136624 211.686338,51.1902445 211.686338,59.6734287 Z"></path></g></svg></figure></a></li><li><a target="_blank" data-gtmevent="footer-sm-click" data-gtmvalue="slideshare" href="http://www.slideshare.net/softwaremill" title="Slideshare"><figure class="socialmedia__ico ui-ico ico--slideshare"><svg version="1.1" class="ico-slideshare" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" x="0px" y="0px" viewBox="-944 470.1 30.9 20.9" enable-background="new -944 470.1 30.9 20.9" xml:space="preserve"><path class="svg__ico" fill="#FFFFFF" d="M-923.9,476.9c1.9,0,3.4-1.5,3.4-3.4c0,0,0-0.1,0-0.1c0-1.9-1.5-3.4-3.4-3.4c-1.9,0-3.4,1.5-3.4,3.4 c0,0,0,0,0,0C-927.3,475.4-925.8,476.9-923.9,476.9z"/><path class="svg__ico" fill="#FFFFFF" d="M-932.9,476.9C-932.9,476.9-932.8,476.9-932.9,476.9c1.9,0,3.5-1.5,3.5-3.4c0,0,0-0.1,0-0.1 c0-1.9-1.5-3.4-3.4-3.4c-1.9,0-3.4,1.5-3.4,3.4c0,0,0,0,0,0C-936.3,475.4-934.8,476.9-932.9,476.9z"/><path class="svg__ico" fill="#FFFFFF" d="M-914.6,475.8c-1,1.2-5.4,2.6-6,2.6h-4.8c-1.1,0-2.9,0.3-2.9,1v0.6c-0.1,0-0.1-0.1-0.2-0.1 c-0.7-0.9-1.9-1.3-3-1.3c-2.3,0-4.5-0.2-6.8-0.7c-2-0.4-5.3-3.3-5.6-2.5c-0.3,0.8,0.3,1.3,1.3,2.5c1.1,1.3,5.5,3,5.5,3v5.3 c0,1.6,3.2,3.9,4.8,3.9s2.9-1.1,2.9-1.9v-4.9c0.3,0.1,0.7,0.3,1,0.3v4.5c0,0.8,1.1,2.8,4.5,2.8c3.3,0,4.3-4,4.3-4.7v-4.9 c2.3-1.3,4.8-1.9,6-4.2C-912.5,475.1-913.5,474.7-914.6,475.8z"/></svg></figure></a></li><li><a target="_blank" data-gtmevent="footer-sm-click" data-gtmvalue="clutch" href="https://clutch.co/profile/softwaremill" title="Clutch"><figure class="socialmedia__ico ui-ico ico--clutch"><svg version="1.1" class="ico-clutch" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" x="0px" y="0px" viewBox="-949 469.5 20.8 23.5" enable-background="new -949 469.5 20.8 23.5" xml:space="preserve"><path class="svg__ico" fill="#FFFFFF" d="M-937.1,487.8c-3.6,0.1-6.6-2.7-6.7-6.2c0-0.1,0-0.2,0-0.3c-0.1-3.5,2.7-6.4,6.2-6.5c0.2,0,0.4,0,0.6,0 c2,0,3.9,0.8,5.2,2.3l3.7-3.7c-2.3-2.5-5.5-3.9-8.9-3.9c-7.6,0-12,5.2-12,11.6c-0.1,6.4,4.9,11.7,11.3,11.8c0.2,0,0.4,0,0.6,0 c3.4,0,6.7-1.4,8.9-3.9l-3.7-3.6C-933.2,487-935.1,487.8-937.1,487.8z"/><path class="svg__ico" fill="#FFFFFF" d="M-937.4,477.4c-2.1,0-3.9,1.7-3.9,3.9c0,0,0,0,0,0c0,2.1,1.7,3.9,3.9,3.9c2.1,0,3.9-1.7,3.9-3.9 C-933.5,479.2-935.3,477.4-937.4,477.4C-937.4,477.4-937.4,477.4-937.4,477.4z"/></svg></figure></a></li><li><a target="_blank" data-gtmevent="footer-sm-click" data-gtmvalue="medium" href="https://blog.softwaremill.com/?gi=854e7326b87a" title="Medium"><figure class="socialmedia__ico ui-ico ico--medium"><svg version="1.1" class="ico-medium" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" x="0px" y="0px" viewBox="-947 469 25 25" enable-background="new -947 469 25 25" xml:space="preserve"><path class="svg__ico" fill="#FFFFFF" d="M-934.5,469c-6.9,0-12.5,5.6-12.5,12.5c0,6.9,5.6,12.5,12.5,12.5c6.9,0,12.5-5.6,12.5-12.5c0,0,0,0,0,0 C-922,474.6-927.6,469-934.5,469z M-927.4,477.3L-927.4,477.3h-0.6c-0.3,0-0.5,0.2-0.5,0.5v7.1c0.1,0.2,0.3,0.4,0.5,0.5h0.6v1.7 h-5.2v-1.7h1.1v-7.4h-0.1l-2.5,9.1h-2l-2.5-9.1h-0.1v7.4h1.1v1.7h-4.3v-1.7h0.6c0.3,0,0.5-0.2,0.5-0.5v-7.1 c-0.1-0.3-0.3-0.5-0.5-0.5h-0.6v-1.7h5.4l1.8,6.6h0l1.8-6.6h5.4V477.3z"/></svg></figure></a></li><li><a target="_blank" data-gtmevent="footer-sm-click" data-gtmvalue="dribble" href="https://dribbble.com/softwaremill" title="Dribble"><figure class="socialmedia__ico ui-ico ico--dribble"><svg width="24" height="24" viewBox="0 0 24 24" fill="none" xmlns="http://www.w3.org/2000/svg"><path class="svg__ico" d="M12 0C5.3724 0 0 5.3724 0 12C0 18.6276 5.3724 24 12 24C18.6276 24 24 18.6276 24 12C24 5.3724 18.6276 0 12 0ZM12 1.7388C14.6142 1.7388 17.0004 2.7168 18.8124 4.326C17.481 6.0822 15.4584 7.2516 13.4316 8.043C12.2842 5.95341 10.9984 3.94292 9.5826 2.025C10.3744 1.83414 11.1861 1.73807 12.0006 1.7388H12ZM7.6344 2.7108C8.9724 4.7124 10.2684 6.5682 11.4522 8.6688C8.4582 9.4446 5.0748 9.9102 1.9494 9.918C2.6082 6.7212 4.7556 4.0668 7.6344 2.7114V2.7108ZM19.9506 5.5128C21.4334 7.32477 22.249 9.59091 22.2612 11.9322C19.8876 11.4642 17.5272 11.3418 15.1236 11.5842C14.8536 10.9104 14.526 10.2702 14.2122 9.5802C16.284 8.7444 18.4992 7.314 19.9506 5.5122V5.5128ZM12.2856 10.2564C12.5424 10.8024 12.84 11.382 13.1196 11.9742C9.7776 13.4478 6.2226 15.417 4.3776 18.8694C2.6064 16.9094 1.66248 14.3399 1.7436 11.6994C5.3226 11.6826 8.8356 11.235 12.2856 10.2564V10.2564ZM17.7084 13.0542C19.2017 13.0545 20.6888 13.2461 22.1334 13.6242C21.9107 15.0139 21.4044 16.343 20.646 17.5287C19.8876 18.7144 18.8934 19.7314 17.7252 20.5164C17.1744 18.0114 16.6494 15.6144 15.7212 13.1976C16.3791 13.1017 17.043 13.0536 17.7078 13.0536L17.7084 13.0542ZM22.1868 13.2402C22.1796 13.299 22.173 13.3566 22.1646 13.4142C22.173 13.356 22.1802 13.2984 22.1868 13.2402ZM13.8228 13.6662C14.7684 16.11 15.5106 18.816 16.0086 21.4494C14.7409 21.9873 13.3777 22.2636 12.0006 22.2618C9.71931 22.2651 7.50256 21.5047 5.7036 20.1018C7.5618 17.0874 10.44 14.8062 13.8222 13.6668L13.8228 13.6662Z" fill="white"/></svg></figure></a></li><li><a target="_blank" data-gtmevent="footer-sm-click" data-gtmvalue="rss" href="https://softwaremill.com/blog.rss" title="RSS"><figure class="socialmedia__ico ui-ico ico--rss"><svg width="17" height="16" viewBox="0 0 17 16" fill="none" xmlns="http://www.w3.org/2000/svg"><g clip-path="url(#clip0)"><path d="M13.5495 16C13.5495 8.979 7.771 3.2005 0.75 3.2005V0C9.526 0 16.75 7.224 16.75 16H13.5495ZM2.9425 11.6095C3.52512 11.6106 4.08358 11.8425 4.49555 12.2544C4.90753 12.6664 5.13944 13.2249 5.1405 13.8075C5.1405 15.016 4.1485 16 2.9375 16C1.729 16 0.75 15.018 0.75 13.8075C0.75 12.597 1.7345 11.6095 2.9425 11.6095ZM11.357 16H8.245C8.245 11.888 4.862 8.5025 0.75 8.5025V5.393C6.5675 5.393 11.357 10.182 11.357 16Z" fill="white"/></g><defs><clipPath id="clip0"><rect width="16" height="16" fill="white" transform="translate(0.75)"/></clipPath></defs></svg></figure></a></li></ul></div></section></div></div><!-- /viewport --></header><div class="page-container " id="page-container"><section id="content" role="main" class="main-content content--mqperf"><section class="content__section section-post"><div class="viewport"><div class="post__menu post__menu-mobile"><h4>Contents <figure class="ui-ico"><svg xmlns="http://www.w3.org/2000/svg" viewBox="-944 451.6 30.6 58.4"><path class="svg__ico" fill="none" stroke="#FFF" stroke-width="2" stroke-miterlimit="10" d="M-914.1 452.3l-28.5 28.5 28.5 28.5"/></svg></figure></h4></div><div class="post__grid grid--content"><article class="post__content text--rich" role="main" data-blog-post data-submenu="1" data-submenu_h1=1 data-submenu_h2=><div class="title-area"><h1 class="banner__title">Evaluating persistent, replicated message queues</h1><div class="taxonomy__tags"><ul class="article__tags tags__list"><li class="list__item item--tag"><a href="/blog#tags=kafka" class="no-border">Kafka</a></li><li class="list__item item--tag"><a href="/blog#tags=performance" class="no-border">Performance</a></li><li class="list__item item--tag"><a href="/blog#tags=postgresql" class="no-border">PostgreSQL</a></li><li class="list__item item--tag"><a href="/blog#tags=mongodb" class="no-border">mongodb</a></li><li class="list__item item--tag"><a href="/blog#tags=redis" class="no-border">Redis</a></li><li class="list__item item--tag"><a href="/blog#tags=pulsar" class="no-border">Pulsar</a></li><li class="list__item item--tag"><a href="/blog#tags=message queue" class="no-border">Message Queue</a></li><li class="list__item item--tag"><a href="/blog#tags=messaging" class="no-border">Messaging</a></li><li class="list__item item--tag"><a href="/blog#tags=clustering" class="no-border">Clustering</a></li><li class="list__item item--tag"><a href="/blog#tags=event streaming" class="no-border">Event Streaming</a></li><li class="list__item item--tag"><a href="/blog#tags=nats" class="no-border">NATS</a></li><li class="list__item item--tag"><a href="/blog#tags=sqs" class="no-border">SQS</a></li><li class="list__item item--tag"><a href="/blog#tags=eventstore" class="no-border">EventStore</a></li><li class="list__item item--tag"><a href="/blog#tags=rocketmq" class="no-border">RocketMQ</a></li><li class="list__item item--tag"><a href="/blog#tags=split-brain" class="no-border">Split-brain</a></li><li class="list__item item--tag"><a href="/blog#tags=rabbitmq" class="no-border">RabbitMQ</a></li><li class="list__item item--tag"><a href="/blog#tags=activemq" class="no-border">ActiveMQ</a></li><li class="list__item item--tag"><a href="/blog#tags=redpanda" class="no-border">RedPanda</a></li><li class="list__item item--tag"><a href="/blog#tags=mqperf" class="no-border">mqperf</a></li></ul></div><div class="block-author author--big"><div class="grid--two-columns"><div class="author__meta"><a href="/blog#authors=Adam%20Warski"><figure alt="webp image" class="employee__image" style="background-image:url('/user/webp/user/themes/softwaremill/assets/team/5UM2bvwWkeS4XlH.webp')"></figure></a><div class="author__desc"><p class="name"><a href="/blog#authors=Adam%20Warski">Adam Warski</a></p><p><a href="/blog#authors=Adam%20Warski"><span class="date">26 Jul 2021.</span><span class="time-to-read">52 minutes read</span></a></p></div></div><div class="author__social-media"><div class="author__socialmedia block-socialmedia"><ul class="socialmedia__list"><li><a target="_blank" href="https://linkedin.com/in/adamwarski"><figure class="socialmedia__ico ui-ico ico--black ico--linkedin"><svg version="1.1" class="ico-linkedin" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" x="0px" y="0px" viewBox="-949 471.7 20.9 19.3" enable-background="new -949 471.7 20.9 19.3" xml:space="preserve"><rect class="svg__ico" x="-948.5" y="477.9" fill="#FFFFFF" width="4.1" height="13"/><path class="svg__ico" fill="#FFFFFF" d="M-933.3,477.9c-2.3,0-3.8,1.3-4.1,2.2v-2h-4.6c0.1,1,0,13,0,13h4.6v-7.1c0-0.4,0-0.7,0.1-1.1 c0.3-1,1.2-1.6,2.2-1.6c1.6,0,2.3,1.2,2.3,2.9v6.7h4.7v-7.2C-928.1,479.7-930.4,477.9-933.3,477.9z"/><path class="svg__ico" fill="#FFFFFF" d="M-946.3,471.7c-0.1,0-0.1,0-0.2,0c-1.3-0.1-2.4,0.9-2.5,2.1c0,0,0,0.1,0,0.1c0,1.2,1,2.3,2.2,2.3 c0.1,0,0.1,0,0.2,0c1.2,0.1,2.4-0.8,2.5-2c0-0.1,0-0.2,0-0.2C-944.1,472.8-945.1,471.8-946.3,471.7z"/></svg></figure></a></li><li><a target="_blank" href="https://twitter.com/adamwarski"><figure class="socialmedia__ico ui-ico ico--black ico--twitter"><svg version="1.1" class="ico-twitter" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" x="0px" y="0px" viewBox="-947 470.9 24.2 20.1" enable-background="new -947 470.9 24.2 20.1" xml:space="preserve"><path class="svg__ico" fill="#FFFFFF" d="M-923.4,471.2c-1,0.6-2.1,1-3.2,1.2c-0.9-1-2.3-1.6-3.6-1.6c-2.8,0-5,2.2-5,5c0,0,0,0,0,0.1 c0,0.4,0.1,0.8,0.2,1.2c-4-0.2-7.8-2.1-10.3-5.2c-1.3,2.3-0.6,5.3,1.6,6.8c-0.8,0-1.6-0.2-2.2-0.7v0.1c0,2.4,1.7,4.5,4.1,5 c-0.4,0.1-0.9,0.2-1.3,0.2c-0.3,0-0.6,0-0.9-0.1c0.6,2.1,2.6,3.5,4.7,3.5c-1.8,1.4-4,2.1-6.2,2.2c-0.4,0-0.8,0-1.2-0.1 c2.3,1.5,5,2.2,7.7,2.2c9.3,0,14.3-7.7,14.3-14.4V476c0.8-0.8,1.6-1.8,2.2-2.7c-0.9,0.4-1.9,0.7-2.9,0.8 C-924.6,473.4-923.8,472.4-923.4,471.2z"/></svg></figure></a></li><li><a target="_blank" href="https://github.com/adamw"><figure class="socialmedia__ico ui-ico ico--black ico--github"><svg version="1.1" class="ico-github" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" x="0px" y="0px" viewBox="-946 469 25.9 25" enable-background="new -946 469 25.9 25" xml:space="preserve"><path class="svg__ico" fill="#FFFFFF" d="M-933.2,469c-7.1,0-12.8,5.8-12.8,12.8c0,5.5,3.6,10.4,8.8,12.1c0.7,0.1,0.9-0.3,0.9-0.6v-2.2 c-3.6,0.8-4.3-1.7-4.3-1.7c-0.2-0.8-0.7-1.5-1.4-1.9c-1.2-0.8,0.1-0.7,0.1-0.7c0.8,0.1,1.6,0.6,2,1.3c0.7,1.3,2.3,1.8,3.6,1.1 c0,0,0.1,0,0.1,0c0-0.7,0.3-1.3,0.8-1.7c-2.8-0.3-5.8-1.4-5.8-6.3c0-1.3,0.4-2.5,1.3-3.4c-0.4-1.1-0.4-2.3,0.2-3.4 c0,0,1.1-0.3,3.5,1.3c1.1-0.3,2.1-0.4,3.2-0.4c1.1,0,2.2,0.2,3.2,0.4c2.4-1.7,3.5-1.3,3.5-1.3c0.4,1.1,0.5,2.3,0.2,3.4 c0.9,0.9,1.3,2.1,1.3,3.4c0,4.9-3,6-5.8,6.3c0.6,0.6,0.9,1.5,0.8,2.4v3.5c0,0.3,0.2,0.8,0.9,0.6c5.2-1.8,8.7-6.6,8.7-12.2 C-920.3,474.7-926.1,469.1-933.2,469z"/></svg></figure></a></li></ul></div></div></div></div></div><p><img alt="Intro" src="/user/pages/blog/mqperf/evaluating-message-queues.png?g-c73dd6a3" /></p><h1>Introduction</h1><p>Message queues are central to many distributed systems and often provide a backbone for asynchronous processing and communication between (micro)services. They are useful in a number of situations. Any time we want to <strong>execute a task</strong> asynchronously, we put the task on a queue; some executor (could be another thread, process, or machine) eventually runs it. Or, one component might produce a <strong>stream of events</strong> that are stored by the <a href="https://softwaremill.com/using-kafka-as-a-message-queue">message queue</a>. Other, decoupled components, consume the events asynchronously, either on-line or after some period of time.</p><p>Various message queue implementations can give various guarantees on message persistence and delivery. For some use-cases, it is enough to have an in-memory, volatile message queue. For others, we want to be sure that once the message send completes, the message is <strong>persistently enqueued</strong> and will be eventually delivered, despite node or system crashes.</p><p>The mqperf tests inspect systems on the 'safe' side of this spectrum, which try to make sure that messages are not lost by:</p><ul><li>persisting messages to disk</li><li>replicating messages across the network</li></ul><p>We will examine the characteristics of a number of message queueing and data streaming systems, comparing their features, replication schemes, supported protocols, operational complexity and performance. All of these factors might impact which system is best suited for a given task. In some cases, you might need top-performance, which might come with tradeoffs in terms of other features. In others, performance isn’t the main factor, but instead compatibility with existing protocols, message routing capabilities or deployment overhead play the central role.</p><p>When talking about performance, we’ll take into account both <strong>how many messages per second</strong> a given queueing system can process, but also at the <strong>processing latency</strong>, which is an important factor in systems which should react to new data in near real-time (as is often the case with various event streams). Another important aspect is message <strong>send latency</strong>, that is how long it takes for a client to be sure a message is persisted in the queueing system. This may directly impact e.g. the latency of http endpoints and end-user experience.</p><h2>Version history</h2><table><tbody><tr><td>26 Jul 2021</td><td> Refresh of the 2020 edition. Tests of RedPanda and Redis Streams. Added encryption and compression info to the summary. Co-authored with <a href="https://github.com/bturos">Bartłomiej Turos</a> and <a href="https://github.com/robert-dziewonski">Robert Dziewoński</a>. </td></tr><tr><td>8 Dec 2020</td><td> 2020 edition: extended feature comparison, updated benchmarks, new queues (Pulsar, PostgreSQL, Nats Streaming); dropping ActiveMQ 5 in favor of ActiveMQ Artemis. Co-authored with <a href="https://twitter.com/kkondzielski">Kasper Kondzielski</a>. </td></tr><tr><td>1 August 2017</td><td>Updated the results for Artemis, using memory-mapped journal type and improved JMS test client</td></tr><tr><td>18 July 2017</td><td><a href="/mqperf-2017">2017 edition</a>: updating with new versions; adding latency measurements; adding Artemis and EventStore. Co-authored with <a href="https://stackoverflow.com/users/542270/opal">Maciej Opała</a></td></tr><tr><td>4 May 2015</td><td><a href="/mqperf-2015">2015 edition</a>: updated with new versions, added ActiveMQ; new site</td></tr><tr><td>1 July 2014</td><td>original at <a href="http://www.warski.org/blog/2014/07/evaluating-persistent-replicated-message-queues/">Adam Warski's blog</a></td></tr></tbody></table><h2>Tested queues</h2><p>There is a number of open-source messaging projects available, but only some support both persistence and replication. We'll evaluate the performance and characteristics of 12 message queues, in no particular order:</p><ul><li><a href="http://aws.amazon.com/sqs/">Amazon SQS</a></li><li><a href="http://www.mongodb.com/">MongoDB</a></li><li><a href="https://www.postgresql.org">PostgreSQL</a></li><li><a href="http://www.rabbitmq.com/">RabbitMq</a></li><li><a href="https://kafka.apache.org/">Kafka</a></li><li><a href="https://pulsar.apache.org">Pulsar</a></li><li><a href="http://activemq.apache.org/components/artemis/">ActiveMQ Artemis</a></li><li><a href="https://rocketmq.apache.org">RocketMQ</a></li><li><a href="https://docs.nats.io/developing-with-nats-streaming/streaming">NATS Streaming</a></li><li><a href="https://www.eventstore.com">EventStore</a></li><li><a href="https://vectorized.io">RedPanda</a></li><li><a href="https://redis.io/topics/streams-intro">Redis Streams</a></li></ul><p>You might rightfully notice that not all of these are message queueing systems. Both MongoDB and PostgreSQL (and to some degree, EventStore) are general-purpose databases. However, using some of their mechanisms it’s possible to implement a message queue on top of them. If such a simple queue meets the requirements and the database system is already deployed for other purposes, it might be reasonable to reuse it and reduce operational costs.</p><p>Except for SQS, all of the systems are open-source, and can be self-hosted on your own servers or using any of the cloud providers, both directly or through Kubernetes. Some systems are also available as hosted, as-a-service offerings.</p><h1>Queue characteristics</h1><p>We’ll be testing and examining the performance of a single, specific queue usage scenario in detail, as well as discussing other possible queue-specific use-cases more generally.</p><p>In our scenario, as mentioned in the introduction, we’ll put a focus on safety. The scenario tries to reflect a reasonable default that you might start with when developing applications leveraging a message queue, however by definition we’ll cover only a fraction of possible use-cases.</p><p>There are three basic operations on a queue which we'll be using:</p><ul><li><strong>sending</strong> a message to the queue</li><li><strong>receiving</strong> a message from the queue</li><li><strong>acknowledging</strong> that a message has been processed</li></ul><p>On the <strong>sender</strong> side, we want to have a guarantee that if a message send call completes successfully, the message will be eventually processed. Of course, we will never get a 100% "guarantee", so we have to accept some scenarios in which messages will be lost, such as a catastrophic failure destroying all of our geographically distributed servers. Still, we want to minimise message loss. That's why:</p><ul><li>messages should survive a restart of the server, that is messages should be <em>persisted</em> to a durable store (hard disk). However, we accept losing messages due to unflushed disk buffers (we do not require <code>fsync</code>s to be done for each message).</li><li>messages should survive a permanent failure of a server, that is messages should be <em>replicated</em> to other servers. We'll be mostly interested in <strong>synchronous replication</strong>, that is when the send call can only complete after the data is replicated. Note that this additionally protects from message loss due to hard disk buffers not being flushed. Some systems also offer <strong>asynchronous replication</strong>, where messages are accepted before being replicated, and thus there's more potential for message loss. We'll make it clear later which systems offer what kind of replication.</li></ul><p>On the <strong>receiver</strong> side, we want to be able to receive a message and then <strong>acknowledge</strong> that the message was processed successfully. Note that receiving alone should not remove the message from the queue, as the receiver may crash at any time (including right after receiving, before processing). But that could also lead to messages being processed twice (e.g. if the receiver crashes after processing, before acknowledging); hence our queue should support <strong>at-least-once delivery</strong>.</p><p>With at-least-once delivery, message processing should be <em>idempotent</em>, that is processing a message twice shouldn't cause any problems. Once we assume that characteristic, a lot of things are simplified; message acknowledgments can be done asynchronously, as no harm is done if an ack is lost and the message re-delivered. We also don't have to worry about distributed transactions. In fact, no system can provide exactly-once delivery when integrating with external systems (and if it claims otherwise: read the fine print); it's always a choice between at-most-once and at-least-once.</p><p>By requiring idempotent processing, the life of the message broker is easier, however, the cost is shifted to writing application code appropriately.</p><h1>Performance testing methodology</h1><p>We'll be performing three measurements during the tests:</p><ul><li><strong>throughput in messages/second</strong>: how fast on average the queue is, that is how many messages per second can be sent, and how many messages per second can be received &amp; acknowledged</li><li><strong>95th percentile of processing latency</strong> (over a 1-minute window): how much time (in milliseconds) passes between a message send and a message receive. That is, how fast the broker passes the message from the sender to the receiver</li><li><strong>95th percentile of send latency</strong> (over a 1-minute window): how long it takes for a message send to complete. That's when we are sure that the message is safely persisted in the cluster, and can e.g. respond to our client's http request "message received".</li></ul><p>When setting up the queues, our goal is to have 3 identical, replicated nodes running the message queue server, with automatic fail-over. That’s not always possible with every queue implementation, hence we’ll make it explicit what’s the replication setup in each case.</p><p>The sources for the tests as well as the Ansible scripts used to setup the queues are <a href="https://github.com/softwaremill/mqperf">available on GitHub</a>.</p><p>Each test run is parametrised by the type of the message queue tested, optional message queue parameters, number of client nodes, number of threads on each client node and message count. A client node is either sending or receiving messages; in the tests we used from 1 to 20 client nodes of each type, each running from 1 to 100 threads. By default there are twice as many receiver nodes as sender nodes, but that’s not a strict rule and we’re modifying these proportions basing on what’s working best for a given queue implementation.</p><p>Each <a href="https://github.com/softwaremill/mqperf/blob/master/src/main/scala/com/softwaremill/mqperf/Sender.scala">Sender</a> thread tries to send the given number of messages as fast as possible, in batches of random size between 1 and 10 messages. The messages are picked from a pool of messages, randomly generated on startup.</p><p>The <a href="https://github.com/softwaremill/mqperf/blob/master/src/main/scala/com/softwaremill/mqperf/Receiver.scala">Receiver</a> tries to receive messages (also in batches of up to 10 messages), and after receiving them, acknowledges their delivery (which should cause the message to be removed from the queue). The test ends when no messages are received for a minute.</p><p><img alt="MQ test setup" src="/user/pages/blog/mqperf/mqtestsetup.83a9fe43.png?g-c73dd6a3" /></p><p>The queues have to implement the <a href="https://github.com/softwaremill/mqperf/blob/master/src/main/scala/com/softwaremill/mqperf/mq/Mq.scala">Mq</a> interface. The methods should have the following characteristics:</p><ul><li><code>send</code> should be synchronous, that is when it completes, we want to be sure (what "sure" means exactly may vary) that the messages are sent</li><li><code>receive</code> should receive messages from the queue and block them from being received by other clients; if the node crashes, the messages should be returned to the queue and re-delivered, either immediately or after a time-out</li><li><code>ack</code> should acknowledge delivery and processing of the messages. Acknowledgments can be asynchronous, that is we don't have to be sure that the messages really got deleted</li></ul><h2>Server setup</h2><p>Both the clients, and the messaging servers used <a href="http://aws.amazon.com/ec2/instance-types/">r5.2xlarge memory-optimized EC2 instances</a>; each such instance has 8 virtual CPUs, 64GiB of RAM and SSD storage (in some cases additional <code>gp2</code> disks where used).</p><p>All instances were started in a <em>single</em> availability zone (eu-west-1). While for production deployments it is certainly better to have the replicas distributed across different locations (in EC2 terminology - different availability zones), but as the aim of the test was to measure performance, a single availability zone was used to minimise the effects of network latency as much as possible.</p><p>The servers were provisioned automatically using <a href="https://www.ansible.com">Ansible</a>. All of the playbooks are available in the <a href="https://github.com/softwaremill/mqperf/tree/master/ansible">github repository</a>, hence the tests should be reproducible.</p><p>Test results were aggregated using <a href="https://prometheus.io">Prometheus</a> and visualized using <a href="https://grafana.com">Grafana</a>. We'll see some dashboard snapshots with specific results later.</p><p>While the above might not guarantee the best possible performance for each queue (we might have used <code>r5.24xlarge</code> for example), the goal was to get some common ground for comparison between the various systems. Hence, the results should be treated only comparatively, and the tests should always be repeated in the target environment before making any decisions.</p><h1>MongoDB</h1><table><tbody><tr><td><em>Version</em></td><td>server 4.2, java driver 3.12.5</td></tr><tr><td><em>Replication</em></td><td>configurable, asynchronous &amp; synchronous</td></tr><tr><td><em>Replication type</em></td><td>active-passive</td></tr></tbody></table><p>Mongo has two main features which make it possible to easily implement a durable, replicated message queue on top of it: very simple replication setup (we'll be using a 3-node replica set), and various document-level atomic operations, like <code>find-and-modify</code>. The implementation is just a handful of lines of code; take a look at <a href="https://github.com/softwaremill/mqperf/blob/master/src/main/scala/com/softwaremill/mqperf/mq/MongoMq.scala">MongoMq</a>.</p><p>Replication in Mongo follows a leader-follower setup, that is there’s a single node handling writes, which get replicated to follower nodes. As an optimization, reads can be offloaded to followers, but we won’t be using this feature here. Horizontal scaling is possible by sharding and using multiple replica sets, but as far as message queueing is concerned this would make the queue implementation significantly more complex. Hence this queue implementation is bound by the capacity of the leader node.</p><p>Network partitions (split-brain scenarios), which are one of the most dangerous fault types in replicated databases, <a href="https://docs.mongodb.com/manual/core/replica-set-elections/#network-partition">are handled</a> by making sure that only the partition with the majority of nodes is operational.</p><p>We are able to control the guarantees which <code>send</code> gives us by using an appropriate write concern when writing new messages:</p><ul><li><code>WriteConcern.W1</code> ensures that once a send completes, the messages have been written to disk (but the buffers may not be yet flushed, so it's not a 100% guarantee) on a single node; this corresponds to asynchronous replication</li><li><code>WriteConcern.W2</code> ensures that a message is written to at least 2 nodes (as we have 3 nodes in total, that's a majority) in the cluster; this corresponds to synchronous replication</li></ul><p>The main downside of the Mongo-based queue is that:</p><ul><li>messages can't be received in bulk – the <code>find-and-modify</code> operation only works on a single document at a time</li><li>when there's a lot of connections trying to receive messages, the collection will encounter a lot of contention, and all operations are serialised.</li></ul><p>And this shows in the results: sends are much faster than receives. But the performance isn’t bad despite this.</p><p>A single-thread, single-node, synchronous replication setup achieves <strong>958 msgs/s</strong> sent and received. The maximum send throughput with multiple thread/nodes that we were able to achieve is about 11 286 msgs/s (25 threads, 2 nodes), while the maximum receive rate is <strong>7 612 msgs/s</strong> (25 threads, 2 nodes). An interesting thing to note is that the receive throughput quickly achieves its maximum value, and adding more threads (clients) only decreases performance. The more concurrency, the lower overall throughput.</p><p><img alt="MongoDB" src="/user/pages/blog/mqperf/mongodb.png?g-c73dd6a3" /></p><p>With asynchronous replication, the results are of course better: up to 38 120 msg/s sent and 8 130 msgs/s received. As you can see, here the difference between send and receive performance is even bigger.</p><p>What about latencies? In both synchronous and asynchronous tests, the send latency is about <strong>48 ms</strong>, and this doesn't deteriorate when adding more concurrent clients.</p><p>As for the processing latency, measurements only make sense when the receive rate is the same as the sending rate. When the clients aren't able to receive messages as fast as they are sent, the processing time goes arbitrarily up.</p><p>With 2 nodes running 5 threads each, Mongo achieved a throughput of <strong>3 913 msgs/s</strong> with a processing latency of <strong>48 ms</strong>. Anything above that caused receives to fall back behind sends. Here's the dashboard for that test:</p><p><a href="https://snapshot.raintank.io/dashboard/snapshot/29VhWbdaTCaL5j3JqC5cz5yexuQ9WWm1" target="_blank"><br /><img alt="MongoDB grafana" src="/user/pages/blog/mqperf/mongodb grafana.png?g-c73dd6a3" /><br /></a></p><p>Performance results in detail when using synchronous replication are as follows:</p><table><thead><tr><th>Threads</th><th>Sender nodes</th><th>Receiver nodes</th><th>Send msgs/s</th><th>Receive msgs/s</th><th>Processing latency</th><th>Send latency</th></tr></thead><tbody><tr><td>1</td><td>1</td><td>2</td><td>958,00</td><td>958,00</td><td>48,00</td><td>48,00</td></tr><tr><td>5</td><td>1</td><td>2</td><td>3 913,00</td><td>3 913,00</td><td>48,00</td><td>48,00</td></tr><tr><td>25</td><td>1</td><td>2</td><td>10 090,00</td><td>7 612,00</td><td>60000,00</td><td>48,00</td></tr><tr><td>1</td><td>2</td><td>4</td><td>1 607,00</td><td>1 607,00</td><td>48,00</td><td>48,00</td></tr><tr><td>5</td><td>2</td><td>4</td><td>5 532,00</td><td>5 440,00</td><td>60000,00</td><td>48,00</td></tr><tr><td>25</td><td>2</td><td>4</td><td>11 286,00</td><td>4 489,00</td><td>60000,00</td><td>53,00</td></tr></tbody></table><p>Overall, if you are already using Mongo in your application, you have small traffic and don’t need to use any of the more advanced messaging protocols or features, a queue implementation on top of Mongo might work just fine.</p><h1>PostgreSQL</h1><table><tbody><tr><td><em>Version</em></td><td>server 12.4, java driver 42.2.12</td></tr><tr><td><em>Replication</em></td><td>configurable, asynchronous &amp; synchronous</td></tr><tr><td><em>Replication type</em></td><td>active-passive</td></tr></tbody></table><p>When implementing a queue on top of PostgreSQL, we are using a single <code>jobs</code> table:</p><pre><code class="language-sql">CREATE TABLE IF NOT EXISTS jobs(
  id UUID PRIMARY KEY, 
  content TEXT NOT NULL, 
  next_delivery TIMESTAMPTZ NOT NULL)</code></pre><p>Sending a message amounts to inserting data to the table. Receiving a message bumps the next delivery timestamp, making the message invisible for other receivers for some period of time (during which we assume that the message should be processed, or is otherwise redelivered). This is similar to how SQS works, which is discussed next. Acknowledging a message amounts to deleting the message from the database.</p><p>When receiving messages, we issue two queries (in a single transaction!). The first looks up the messages to receive, and puts a write lock on them. The second updates the next delivery timestamp:</p><pre><code class="language-sql">SELECT id, content FROM jobs WHERE next_delivery &lt;= $now FOR UPDATE SKIP LOCKED LIMIT n
UPDATE jobs SET next_delivery = $nextDelivery WHERE id IN (...)</code></pre><p>Thanks to transactionality, we make sure that a single message is received by a single receiver at any time. Using write locks, <code>FOR UPDATE</code> and <code>SKIP LOCKED</code> help improve the performance by allowing multiple clients to receive messages concurrently, trying to minimise contention.</p><p>As with other messaging systems, we replicate data. PostgreSQL uses leader-follower replication, by setting the following configuration options, as described <a href="https://blog.softwaremill.com/quorum-replication-on-postgresql-7dbf2f340cd">in a blog post by Kasper</a>:</p><ul><li><code>synchronous_standby_names</code> is set to <code>ANY 1 (slave1, slave2)</code></li><li><code>synchronous_commit</code> is set to <code>remote_write</code></li></ul><p>It’s also possible to configure asynchronous replication, as well as require an fsync after each write. However, an important limitation of PostgreSQL is that by default, there’s <strong>no automatic failover</strong>. In case the leader fails, one of the followers must be promoted by hand (which, in a way, solves the split brain problem). There are however both open-source and commercial solutions, which provide modules for automatic failover.</p><p>In terms of performance, a baseline single-thread setup achieves around <strong>3 800 msgs/s</strong> sent and received. Such a queue can handle at most <strong>23 000 msgs/s</strong> sent and received using 5 threads on 2 sending and 4 receiving nodes:</p><p><a href="https://snapshot.raintank.io/dashboard/snapshot/zGh0t1KlScAvA2zScYZxw2KbW8FQr72W" target="_blank"><br /><img alt="PostgreSQL grafana" src="/user/pages/blog/mqperf/postgresql grafana.png?g-c73dd6a3" /><br /></a></p><p>Increasing concurrency above that causes receive performance to degrade:</p><p><img alt="PostgreSQL" src="/user/pages/blog/mqperf/postgresql.png?g-c73dd6a3" /></p><p>Send latency is usually at 48ms. However, total processing latency is quite poor. As with Mongo, taking into account only the tests where the send throughput was on par with receive throughput, processing latency varied from <strong>1172 ms</strong> to <strong>17 975 ms</strong>. Here are the results in full:</p><table><thead><tr><th>Threads</th><th>Sender nodes</th><th>Receiver nodes</th><th>Send msgs/s</th><th>Receive msgs/s</th><th>Processing latency</th><th>Send latency</th></tr></thead><tbody><tr><td>1</td><td>1</td><td>2</td><td>4 034,00</td><td>3 741,00</td><td>60000,00</td><td>47,00</td></tr><tr><td>5</td><td>1</td><td>2</td><td>15 073,00</td><td>15 263,00</td><td>5738,00</td><td>48,00</td></tr><tr><td>25</td><td>1</td><td>2</td><td>2 267,00</td><td>2 317,00</td><td>17957,00</td><td>846,00</td></tr><tr><td>1</td><td>2</td><td>4</td><td>6 648,00</td><td>7 530,00</td><td>60000,00</td><td>48,00</td></tr><tr><td>5</td><td>2</td><td>4</td><td>23 220,00</td><td>23 070,00</td><td>1172,00</td><td>48,00</td></tr><tr><td>25</td><td>2</td><td>4</td><td>28 867,00</td><td>20 492,00</td><td>60000,00</td><td>49,00</td></tr><tr><td>1</td><td>4</td><td>8</td><td>11 621,00</td><td>11 624,00</td><td>1372,00</td><td>48,00</td></tr><tr><td>5</td><td>4</td><td>8</td><td>23 300,00</td><td>23 216,00</td><td>4730,00</td><td>48,00</td></tr><tr><td>8</td><td>4</td><td>8</td><td>22 300,00</td><td>20 869,00</td><td>60000,00</td><td>49,00</td></tr></tbody></table><p>Same as with MongoDB, if you require a very basic message queue implementation without a lot of traffic, and already have a replicated PostgreSQL instance in your deployment, such an implementation might be a good choice. Things to look out for in this case are long processing latencies and manual failover, unless third-party extensions are used.</p><h1>Event Store</h1><table><tbody><tr><td><em>Version</em></td><td>20.6.1, JVM client 7.3.0</td></tr><tr><td><em>Replication</em></td><td>synchronous</td></tr><tr><td><em>Replication type</em></td><td>active-passive</td></tr></tbody></table><p><a href="https://www.eventstore.com">EventStore</a> is first and foremost a database for <strong>event sourcing</strong> and complex event processing. However, it also supports the competing consumers pattern, or as we know it: message queueing. How does it stack up comparing to other message brokers?</p><p>EventStore offers a lot in terms of creating event streams, subscribing to them and transforming through projections. In the tests we'll only be writing events to a stream (each message will become an event), and create persistent subscriptions (that is, subscriptions where the consumption state is stored on the server) to read events on the clients. You can read more about event sourcing, competing consumers and subscription types <a href="https://www.eventstore.com/blog/what-is-event-sourcing">in the docs</a>.</p><p>To safely replicate data, EventStore uses <strong>quorum-based replication</strong>, using a gossip protocol to disseminate knowledge about the cluster state. A majority of nodes has to confirm every write for it to be considered successful. That’s also how resilience against split brain is implemented.</p><p>As all of the tests are JVM-based, we'll be using the <a href="https://github.com/EventStore/EventStore.JVM">JVM client</a>, which is built on top of <a href="http://akka.io">Akka</a> and hence fully non-blocking. However, the test framework is synchronous - because of that, the <a href="https://github.com/softwaremill/mqperf/blob/master/src/main/scala/com/softwaremill/mqperf/mq/EventStoreMq.scala">EventStoreMq</a> implementation hides the asynchronous nature behind synchronous sender and receiver interfaces. Even though the tests will be using multiple threads, all of them will be using only one connection to EventStore per node.</p><p>Comparing to the default configuration, the client has a few modified options:</p><ul><li><code>readBatchSize</code>, <code>historyBufferSize</code> and <code>maxCheckPointSize</code> are all bumped to <code>1000</code> to allow more messages to be pre-fetched</li><li>the in-flight messages buffer size is increased from the default <code>10</code> to a <code>1000</code>. As this is by default not configurable in the JVM client, we had to copy some code from the driver and adjust the properties (see the <code>MyPersistentSubscriptionActor</code> class)</li></ul><p>How does EventStore perform? A baseline setup achieves <strong>793 msgs/s</strong>, and when using 3 sender with 25 threads, and 4 receiver nodes, in the tests we have achieved a throughput of <strong>33 427 msgs/s</strong> with the 95th percentile of processing latency being at most <strong>251 ms</strong> and the send latency <strong>49 ms</strong>. Receive rates are stable, as are the latencies:</p><p><a href="https://snapshot.raintank.io/dashboard/snapshot/hFfYHxCQZ3gwxw3SHeJZZLicAbucoVho?orgId=2" target="_blank"><br /><img alt="EventStore grafna" src="/user/pages/blog/mqperf/eventstore grafana.png?g-c73dd6a3" /><br /></a></p><p>Here's a summary of the EventStore tests that we've run:</p><table><thead><tr><th>Threads</th><th>Sender nodes</th><th>Receiver nodes</th><th>Send msgs/s</th><th>Receive msgs/s</th><th>Processing latency</th><th>Send latency</th></tr></thead><tbody><tr><td>1</td><td>1</td><td>2</td><td>793,00</td><td>792,00</td><td>116,00</td><td>48,00</td></tr><tr><td>25</td><td>1</td><td>2</td><td>16 243,00</td><td>16 241,00</td><td>123,00</td><td>48,00</td></tr><tr><td>25</td><td>2</td><td>4</td><td>29 076,00</td><td>29 060,00</td><td>128,00</td><td>48,00</td></tr><tr><td>25</td><td>3</td><td>4</td><td>33 427,00</td><td>33 429,00</td><td>251,00</td><td>49,00</td></tr><tr><td>25</td><td>4</td><td>4</td><td>29 321,00</td><td>27 792,00</td><td>60000,00</td><td>48,00</td></tr></tbody></table><p><img alt="EventStore" src="/user/pages/blog/mqperf/eventstore.png?g-c73dd6a3" /></p><p>EventStore also provides a handy web console. Comparing to the other general-purpose databases (PostgreSQL and MongoDB), EventStore offers the best performance, but it’s also the most specialised, oriented towards working with event streams in the first place.</p><h1>SQS</h1><table><tbody><tr><td><em>Version</em></td><td>Amazon Java SDK 1.11.797</td></tr><tr><td><em>Replication</em></td><td>?</td></tr><tr><td><em>Replication type</em></td><td>?</td></tr></tbody></table><p>SQS, <a href="http://aws.amazon.com/sqs">Simple Message Queue</a>, is a message-queue-as-a-service offering from Amazon Web Services. It supports only a handful of messaging operations, far from the complexity of e.g. <a href="http://www.amqp.org/">AMQP</a>, but thanks to the easy to understand interfaces, and the as-a-service nature, it is very useful in a number of situations.</p><p>The primary interface to access SQS and send messages is using an SQS-specific HTTP API. SQS provides at-least-once delivery. It also guarantees that if a send completes, the message is replicated to multiple nodes; quoting from <a href="http://docs.aws.amazon.com/AWSSimpleQueueService/latest/SQSDeveloperGuide/Welcome.html">the website</a>:</p><blockquote><p>"Amazon SQS runs within Amazon's high-availability data centers, so queues will be available whenever applications need them. To prevent messages from being lost or becoming unavailable, all messages are stored redundantly across multiple servers and data centers."</p></blockquote><p>When receiving a message, it is blocked from other receivers for a period of time called the visibility timeout. If the message isn’t deleted (acknowledged) before that time passes, it will be re-delivered, as the system assumes that previous processing has failed. SQS also offers features such as deduplication ids and FIFO queues. For testing, the <a href="https://github.com/softwaremill/elasticmq">ElasticMQ</a> projects offers an in-memory implementation.</p><p>We don't really know how SQS is implemented, but it most probably spreads the load across many servers, so including it here is a bit of an unfair competition: the other systems use a single fixed 3-node replicated cluster, while SQS can employ multiple replicated clusters and route/balance the messages between them. Still, it might be interesting to compare to self-hosted solutions.</p><p>A baseline single thread setup achieves <strong>592 msgs/s</strong> sent and the same number of msgs received, with a processing latency of <strong>113 ms</strong> and send latency of <strong>49 ms</strong>.</p><p>These results are not impressive, but SQS scales nicely both when increasing the number of threads, and the number of nodes. On a single node, with 50 threads, we can send up to <strong>22 687 msgs/s</strong>, and receive on two nodes up to <strong>14 423 msgs/s</strong>.</p><p>With 12 sender and 24 receiver nodes, these numbers go up to <strong>130 956 msgs/s</strong> sent, and <strong>130 976 msgs/s</strong> received! However, at these message rates, the service costs might outweigh the costs of setting up a self-hosted message broker.</p><p><img alt="SQS" src="/user/pages/blog/mqperf/sqs.png?g-c73dd6a3" /></p><p>As for latencies, SQS can be quite unpredictable compared to other queues which we’ll cover later. We've observed processing latency from 94 ms up to <strong>1 960 ms</strong>. Send latencies are more constrained and are usually around <strong>50 ms</strong>.</p><p>Here's the dashboard for the test using 4 nodes, each running 5 threads.</p><p><a href="https://snapshot.raintank.io/dashboard/snapshot/n9Ke2g8kZu3iTDav8oFwAf4307W0ADJQ" target="_blank"><br /><img alt="SQS grafana" src="/user/pages/blog/mqperf/sqs grafana.png?g-c73dd6a3" /><br /></a></p><p>And full test results:</p><table><thead><tr><th>Threads</th><th>Sender nodes</th><th>Receiver nodes</th><th>Send msgs/s</th><th>Receive msgs/s</th><th>Processing latency</th><th>Send latency</th></tr></thead><tbody><tr><td>1</td><td>1</td><td>2</td><td>528,00</td><td>529,00</td><td>113,00</td><td>49,00</td></tr><tr><td>5</td><td>1</td><td>2</td><td>2 680,00</td><td>2 682,00</td><td>277,00</td><td>49,00</td></tr><tr><td>25</td><td>1</td><td>2</td><td>13 345,00</td><td>13 370,00</td><td>1 960,00</td><td>49,00</td></tr><tr><td>50</td><td>1</td><td>2</td><td>22 687,00</td><td>14 423,00</td><td>60 000,00</td><td>49,00</td></tr><tr><td>1</td><td>2</td><td>4</td><td>1 068,00</td><td>1 068,00</td><td>97,00</td><td>49,00</td></tr><tr><td>5</td><td>2</td><td>4</td><td>5 383,00</td><td>5 377,00</td><td>106,00</td><td>49,00</td></tr><tr><td>25</td><td>2</td><td>4</td><td>26 576,00</td><td>26 557,00</td><td>302,00</td><td>49,00</td></tr><tr><td>1</td><td>4</td><td>8</td><td>2 244,00</td><td>2 245,00</td><td>97,00</td><td>48,00</td></tr><tr><td>5</td><td>4</td><td>8</td><td>11 353,00</td><td>11 356,00</td><td>90,00</td><td>48,00</td></tr><tr><td>25</td><td>4</td><td>8</td><td>44 586,00</td><td>44 590,00</td><td>256,00</td><td>50,00</td></tr><tr><td>1</td><td>8</td><td>16</td><td>3 651,00</td><td>3 651,00</td><td>97,00</td><td>50,00</td></tr><tr><td>5</td><td>8</td><td>16</td><td>17 575,00</td><td>17 577,00</td><td>94,00</td><td>50,00</td></tr><tr><td>25</td><td>8</td><td>16</td><td>84 512,00</td><td>84 512,00</td><td>237,00</td><td>50,00</td></tr><tr><td>1</td><td>12</td><td>24</td><td>5 168,00</td><td>5 168,00</td><td>96,00</td><td>50,00</td></tr><tr><td>5</td><td>12</td><td>24</td><td>25 735,00</td><td>25 738,00</td><td>94,00</td><td>50,00</td></tr><tr><td>25</td><td>12</td><td>24</td><td>130 956,00</td><td>130 976,00</td><td>213,00</td><td>50,00</td></tr></tbody></table><h1>RabbitMQ</h1><table><tbody><tr><td><em>Version</em></td><td>3.8.5-1, java amqp client 5.9.0</td></tr><tr><td><em>Replication</em></td><td>synchronous</td></tr><tr><td><em>Replication type</em></td><td>active-passive</td></tr></tbody></table><p>RabbitMQ is one of the leading open-source messaging systems. It is written in Erlang, implements <a href="http://www.amqp.org/">AMQP</a> and is a very popular choice when messaging is involved; using RabbitMQ it is possible to define complex message delivery topologies. It supports both message persistence and replication.</p><p>We'll be testing a 3-node Rabbit cluster, using <a href="https://www.rabbitmq.com/quorum-queues.html">quorum queues</a>, which are a relatively new addition to what RabbitMQ offers. Quorum queues are based on the Raft consensus algorithm; a leader is automatically elected in case of node failure, as long as a majority of nodes are available. That way, data is safe also in case of network partitions.</p><p>To be sure that sends complete successfully, we'll be using <a href="http://www.rabbitmq.com/confirms.html">publisher confirms</a>, a Rabbit extension to AMQP, instead of transactions:</p><blockquote><p>"Using standard AMQP 0-9-1, the only way to guarantee that a message isn't lost is by using transactions -- make the channel transactional, publish the message, commit. In this case, transactions are unnecessarily heavyweight and decrease throughput by a factor of 250. To remedy this, a confirmation mechanism was introduced."</p></blockquote><p>A message is confirmed after it has been replicated to a majority of nodes (this is where Raft is used). Moreover, messages have to be written to disk and fsynced.</p><p>Such strong guarantees are probably one of the reasons for mediocre performance. A basic single-thread setup achieves around <strong>2 000 msgs/s</strong> sent&amp;received, with a processing latency of <strong>18 000 ms</strong> and send latency of <strong>48 ms</strong>. The queue can be scaled up to <strong>19 000 msgs/s</strong> using 25 threads, 4 sender nodes and 8 receiver nodes:</p><table><thead><tr><th>Threads</th><th>Sender nodes</th><th>Receiver nodes</th><th>Send msgs/s</th><th>Receive msgs/s</th><th>Processing latency</th><th>Send latency</th></tr></thead><tbody><tr><td>1</td><td>1</td><td>2</td><td>2 064,00</td><td>1 991,00</td><td>18 980,00</td><td>48,00</td></tr><tr><td>5</td><td>1</td><td>2</td><td>8 146,00</td><td>8 140,00</td><td>98,00</td><td>48,00</td></tr><tr><td>25</td><td>1</td><td>2</td><td>17 334,00</td><td>17 321,00</td><td>122,00</td><td>48,00</td></tr><tr><td>1</td><td>2</td><td>4</td><td>3 994,00</td><td>3 983,00</td><td>1 452,00</td><td>48,00</td></tr><tr><td>5</td><td>2</td><td>4</td><td>12 714,00</td><td>12 730,00</td><td>99,00</td><td>48,00</td></tr><tr><td>25</td><td>2</td><td>4</td><td>19 120,00</td><td>19 126,00</td><td>142,00</td><td>48,00</td></tr><tr><td>1</td><td>4</td><td>8</td><td>6 939,00</td><td>6 941,00</td><td>98,00</td><td>48,00</td></tr><tr><td>5</td><td>4</td><td>8</td><td>16 687,00</td><td>16 685,00</td><td>116,00</td><td>48,00</td></tr><tr><td>25</td><td>4</td><td>8</td><td>19 035,00</td><td>19 034,00</td><td>190,00</td><td>71,00</td></tr></tbody></table><p><img alt="RabbitMQ" src="/user/pages/blog/mqperf/rabbitmq.png?g-c73dd6a3" /></p><p>Let’s take a closer look at the test which achieves highest performance:</p><p><a href="https://snapshot.raintank.io/dashboard/snapshot/QotKxMwyYw7F1jSIngM8P4wp1Ap6GE8d" target="_blank"><br /><img alt="RabbitMQ grafana" src="/user/pages/blog/mqperf/rabbitmq grafana.png?g-c73dd6a3" /><br /></a></p><p>As you can see, the receive rate, send and processing latencies are quite stable - which is also an important characteristic to examine under load. The processing latency is around <strong>190 ms</strong>, while the send latency in this case is <strong>71 ms</strong>.</p><p>Note that messages are always sent and received at the same rate, which would indicate that message sending is the limiting factor when it comes to throughput. Rabbit's performance is a consequence of some of the features it offers, for a comparison with Kafka see for example <a href="https://www.quora.com/Why-does-Kafka-scale-better-than-other-messaging-systems-like-RabbitMQ">this Quora question</a>.</p><p>The <a href="https://github.com/softwaremill/mqperf/blob/master/src/main/scala/com/softwaremill/mqperf/mq/RabbitMq.scala">RabbitMq</a> implementation of the Mq interface is again pretty straightforward. We are using the mentioned publisher confirms, and setting the quality-of-service when receiving so that at most 100 messages are delivered unconfirmed (in-flight).</p><p>An important side-node: RabbitMQ has a great web-based console, available with almost no setup, which offers some very good insights into how the queue is performing.</p><h1>ActiveMQ Artemis</h1><table><tbody><tr><td><em>Version</em></td><td>2.15.0, java driver 2.15.0</td></tr><tr><td><em>Replication</em></td><td>synchronous</td></tr><tr><td><em>Replication type</em></td><td>active-passive</td></tr></tbody></table><p><a href="http://activemq.apache.org/artemis/">Artemis</a> is the successor to popular ActiveMQ 5 (which hasn’t seen any significant development lately). Artemis emerged from a donation of the <a href="http://hornetq.jboss.org">HornetQ</a> code to Apache, and is being developed by both RedHat and ActiveMQ developers. Like RabbitMQ, it supports AMQP, as well as other messaging protocols, for example STOMP and MQTT.</p><p>Artemis supports a couple of high availability deployment options, either using <a href="https://activemq.apache.org/components/artemis/documentation/latest/ha.html">replication or a shared store</a>. We’ll be using the over-the-network setup, that is replication.</p><p>Unlike other tested brokers, Artemis replicates data to one backup node. The basic unit here is a <strong>live-backup pair</strong>. The backup happens synchronously, that is a message is considered sent only when it is replicated to the other server. Failover and failback can be configured to happen automatically, without operator intervention.</p><p>Moreover, queues in Artemis can be sharded across multiple live-backup pairs. That is, we can deploy a couple of such pairs and use them as a single cluster. As we aren’t able to create a three-node cluster, instead we’ll use a six-node setup in a “star” configuration: three live (leader) servers, all of which serve traffic of the queue used for tests. Each of them has a backup server.</p><p>Split-brain issues are addressed by an implementation of <a href="https://activemq.apache.org/components/artemis/documentation/latest/network-isolation.html">quorum voting</a>. This is similar to what we’ve seen e.g. in the RabbitMQ implementation.</p><p>The Artemis test client code is based on JMS, and doesn’t contain any Artmis-specific code - uses only standard JMS concepts - sending messages, receiving and transactions. We only need to use an Artemis-specific connection factory, see <a href="https://github.com/softwaremill/mqperf/blob/master/src/main/scala/com/softwaremill/mqperf/mq/ArtemisMq.scala">ArtemisMq</a>.</p><p>The <a href="https://github.com/softwaremill/mqperf/blob/master/ansible/roles/artemis/templates/broker.xml.j2">configuration changes</a> comparing to the default are:</p><ul><li>the <code>Xmx</code> java parameter bumped to <code>48G</code></li><li>in <code>broker.xml</code>, the <code>global-max-size</code> setting changed to <code>48G</code></li><li><code>journal-type</code> set to <code>MAPPED</code></li><li><code>journal-datasync</code>, <code>journal-sync-non-transactional</code> and <code>journal-sync-transactional</code> all set to <code>false</code></li></ul><p>Performance wise, Artemis does very well. Our baseline single-thread setup achieves <strong>13 650 msgs/s</strong>. By adding nodes, we can scale that result to <strong>52 820 msgs/s</strong> using 4 sending nodes, 8 receiver nodes each running 25 threads:</p><p><img alt="Artemis" src="/user/pages/blog/mqperf/artemis.png?g-c73dd6a3" /></p><p>In that last case, the 95th percentile of send latency is a stable <strong>48 ms</strong> and maximum processing latency of <strong>49 ms</strong>:</p><p><a href="https://snapshot.raintank.io/dashboard/snapshot/B8uS0BtsxL19pop34pB7HwRIaf0ljQ72" target="_blank"><br /><img alt="Artemis grafana" src="/user/pages/blog/mqperf/artemis grafana.png?g-c73dd6a3" /><br /></a></p><p>However, as the Artemis team <a href="https://github.com/softwaremill/mqperf/pull/58">noted</a>, the addressing model currently implemented in Artemis isn't the best fit for the mqperf benchmark. Consuming messages from a single queue on a single broker is basically a single-thread process - which on one hand ensures that messages are consumed in-order, but on the other prevents scaling as more consumers are added (quite the contrary!). This can be alleviated by using dedicated queues for consumers, or broadcast topics with filtering, however we then need application-side coordination code which assigns queues to consumers, ensures that there's at least one consumer for each queue, and performs rebalancing on failure.</p><p>Here are all of the results:</p><table><thead><tr><th>Threads</th><th>Sender nodes</th><th>Receiver nodes</th><th>Send msgs/s</th><th>Receive msgs/s</th><th>Processing latency</th><th>Send latency</th></tr></thead><tbody><tr><td>1</td><td>1</td><td>2</td><td>13 647,00</td><td>13 648,00</td><td>48,00</td><td>44,00</td></tr><tr><td>5</td><td>1</td><td>2</td><td>36 035,00</td><td>36 021,00</td><td>47,00</td><td>46,00</td></tr><tr><td>25</td><td>1</td><td>2</td><td>43 643,00</td><td>43 630,00</td><td>48,00</td><td>48,00</td></tr><tr><td>1</td><td>2</td><td>4</td><td>21 380,00</td><td>21 379,00</td><td>47,00</td><td>45,00</td></tr><tr><td>5</td><td>2</td><td>4</td><td>39 320,00</td><td>39 316,00</td><td>48,00</td><td>47,00</td></tr><tr><td>25</td><td>2</td><td>4</td><td>51 089,00</td><td>51 090,00</td><td>48,00</td><td>48,00</td></tr><tr><td>1</td><td>4</td><td>8</td><td>35 538,00</td><td>35 525,00</td><td>47,00</td><td>46,00</td></tr><tr><td>5</td><td>4</td><td>8</td><td>42 881,00</td><td>42 882,00</td><td>48,00</td><td>47,00</td></tr><tr><td>25</td><td>4</td><td>8</td><td>52 820,00</td><td>52 826,00</td><td>49,00</td><td>48,00</td></tr><tr><td>5</td><td>6</td><td>12</td><td>44 435,00</td><td>44 436,00</td><td>48,00</td><td>48,00</td></tr><tr><td>25</td><td>6</td><td>12</td><td>49 279,00</td><td>49 278,00</td><td>77,00</td><td>48,00</td></tr></tbody></table><p>Artemis also offers a web console which helps to visualise the current cluster state.</p><p><img alt="Artemis dashboard" src="/user/pages/blog/mqperf/artemis dashboard.png?g-c73dd6a3" /></p><h1>NATS Streaming</h1><table><tbody><tr><td><em>Version</em></td><td>0.19.0, java driver 2.2.3</td></tr><tr><td><em>Replication</em></td><td>synchronous</td></tr><tr><td><em>Replication type</em></td><td>active-passive</td></tr></tbody></table><p><a href="https://nats.io">NATS</a> is a lightweight messaging system, popular especially in the domain of IoT applications. It supports a number of communication patterns, such as request-reply, publish-subscribe and wildcard subscriptions. NATS offers clients in most popular languages, as well as integrations with many external systems. However, in itself, NATS doesn’t offer clustering, replication or message acknowledgments.</p><p>For that purpose, <a href="https://docs.nats.io/nats-streaming-concepts/intro">NATS Streaming</a> builds upon NATS, providing support for replicated, persistent messaging, durable subscriptions and, using acknowledgements, guarantees at-least-once delivery. It embeds a NATS server, extending its protocol with additional capabilities.</p><p>A NATS Streaming server stores an <strong>ever-growing log of messages</strong>, which are deleted after reaching the configured size, message count or message age limit (in this respect, the design is similar to a Kafka topic’s retention policy). The server is simple to setup - not a lot of configuration is needed. The client APIs are similarly straightforward to use.</p><p>As with other queue implementations discussed previously, NATS Streaming uses the <strong>Raft protocol</strong> for replicating data in a cluster. A write is successful only after a successful consensus round - when the majority of nodes accept it. Hence, this design should be resilient against split-brain scenarios.</p><p>There’s a single leader node, which accepts writes. This means (as the documentation <a href="https://docs.nats.io/nats-streaming-concepts/clustering">emphasises</a>), that this setup isn’t horizontally scalable. An alternate version of a NATS-based clustered system - <a href="https://github.com/nats-io/jetstream">JetStream</a> is being developed, which promises horizontal scalability.</p><p>What’s interesting is a <a href="https://docs.nats.io/developing-with-nats-streaming/streaming">whole section</a> in the docs dedicated to the use-cases of at-least-once, persistent messaging - when to use it, and more importantly, when not to use it:</p><blockquote><p>Just be aware that using an at least once guarantee is the facet of messaging with the highest cost in terms of compute and storage. The NATS Maintainers highly recommend a strategy of defaulting to core NATS using a service pattern (request/reply) to guarantee delivery at the application level and using streaming only when necessary.</p></blockquote><p>It’s always good to consider your architectural requirements, but in our tests of course we’ll focus on the replicated &amp; persistent setup. Speaking of tests, our baseline test achieved <strong>1 725 msgs/s</strong>. This scales up to <strong>27 400 msgs/s</strong> when using 25 threads on 6 senders nodes, and 12 receiver nodes.</p><p><img alt="NATS Streaming" src="/user/pages/blog/mqperf/nats.png?g-c73dd6a3" /></p><p>Latencies are also looking good, with 95th send percentile being at most <strong>95 ms</strong>, while messages have been usually processed within <strong>148 ms</strong>.</p><p><a href="https://snapshot.raintank.io/dashboard/snapshot/xIInK5XsACVZO2VS0RxYhHapJxKDrXrS" target="_blank"><br /><img alt="NATS Streaming grafana" src="/user/pages/blog/mqperf/nats grafana.png?g-c73dd6a3" /><br /></a></p><p>Here’s a summary of the test runs:</p><table><thead><tr><th>Threads</th><th>Sender nodes</th><th>Receiver nodes</th><th>Send msgs/s</th><th>Receive msgs/s</th><th>Processing latency</th><th>Send latency</th></tr></thead><tbody><tr><td>1</td><td>1</td><td>2</td><td>1 725,00</td><td>1 725,00</td><td>105,00</td><td>48,00</td></tr><tr><td>5</td><td>1</td><td>2</td><td>3 976,00</td><td>3 995,00</td><td>142,00</td><td>48,00</td></tr><tr><td>25</td><td>1</td><td>2</td><td>10 642,00</td><td>10 657,00</td><td>145,00</td><td>48,00</td></tr><tr><td>1</td><td>2</td><td>4</td><td>1 870,00</td><td>1 870,00</td><td>138,00</td><td>48,00</td></tr><tr><td>5</td><td>2</td><td>4</td><td>5 958,00</td><td>5 957,00</td><td>143,00</td><td>48,00</td></tr><tr><td>25</td><td>2</td><td>4</td><td>18 023,00</td><td>18 026,00</td><td>145,00</td><td>48,00</td></tr><tr><td>1</td><td>4</td><td>8</td><td>3 379,00</td><td>3 377,00</td><td>143,00</td><td>48,00</td></tr><tr><td>5</td><td>4</td><td>8</td><td>10 014,00</td><td>10 015,00</td><td>145,00</td><td>48,00</td></tr><tr><td>25</td><td>4</td><td>8</td><td>24 834,00</td><td>24 828,00</td><td>146,00</td><td>48,00</td></tr><tr><td>25</td><td>6</td><td>12</td><td>27 392,00</td><td>27 388,00</td><td>147,00</td><td>75,00</td></tr><tr><td>25</td><td>8</td><td>16</td><td>26 699,00</td><td>26 696,00</td><td>148,00</td><td>95,00</td></tr></tbody></table><h1>Redis Streams</h1><table><tbody><tr><td><em>Version</em></td><td>6.2.4, jedis client 3.6.1</td></tr><tr><td><em>Replication</em></td><td>active-passive</td></tr><tr><td><em>Replication type</em></td><td>asynchronous</td></tr></tbody></table><p><a href="https://redis.io">Redis</a> is probably best known as a really fast and useful key-value cache/database. It might be less known that Redis supports both <a href="https://redis.io/topics/persistence">persistence</a> and <a href="https://redis.io/topics/replication">replication</a>, as well as fail-over and sharding using <a href="https://redis.io/topics/cluster-tutorial">cluster</a>.</p><p>However, Redis also offers a streaming component. The logical design borrows some concepts from Kafka (such as consumer groups), however, the internal implementation is entirely different. The documentation includes a <a href="https://redis.io/topics/streams-intro">comprehensive tutorial</a>, providing usage guidelines and detailing the design along with its limitations.</p><p>Using streams with Redis is implemented using the <code>XADD</code>, <code>XRANGE</code>, <code>XREAD</code>, <code>XREADGROUP</code> and <code>XACK</code> commands. In addition to the basic operation of adding an element to a stream, it offers three basic modes of accessing data:</p><ul><li>range scans to read an arbitrary stream element or elements</li><li>fan-out reads where every consumer reads every message (topic semantics)</li><li>consumer group reads where every consumer reads a dedicated set of messages (queue semantics)</li></ul><p>We'll be using the consumer group functionality. Each consumer group and each consumer within a group is identified by a unique identifier. To receive a message, a consumer needs to issue the <code>XREADGROUP</code> command with the stream name, consumer group id, and consumer id. When a message is processed, it needs to be acknowledged using <code>XACK</code>.</p><p>For each stream and consumer group, Redis maintains server-side state which determines which consumer received which messages, which messages are not yet received by any consumer, and which have been acknowledged. What's important is that consumer ids have to be managed by the application. This means that if a consumer with a given id goes offline permanently, it's possible that some messages will get stuck in a received, but not acknowledged state. To remedy the situation, other consumers should periodically issue a <code>XAUTOCLAIM</code> command, which reassigns messages, if they haven't been processed for the given amount of time. This is a mechanism similar to SQS's visibility timeouts, however, initiated by the client, not the server.</p><p>Moreover, after a consumer restarts, it should first check if there are some unacknowledged messages which are assigned to its id. If so, they should be reprocessed. Combined with auto-claiming, we get an implementation of at-least-once delivery. Unlike in Kafka or other messaging systems, the clients need to take care and implement this correctly to make sure no messages are lost.</p><p>Replication in Redis is asynchronous, unless we use the <code>WAIT</code> command after each operation to make sure it's propagated across the cluster. We won't be using this option in our tests, as it goes against the way Redis should be used and even the documentation states that it will make the system very slow. Hence, upon failure, some data loss is possible. Note that it is recommended to have persistence enabled when using replication, as otherwise it's possible to have the entire state truncated upon a node restart.</p><p>Persistence, by default, flushes data to disk asynchronously (every second) but this can be configured to flush after each command - however, again, causing a huge performance penalty.</p><p>Additional features of Redis Streams include message delivery counters (allowing implementing a dead letter queue), observability commands and specifying a maximum number of elements in a stream, truncating the stream if that limit is exceeded. What's worth noting is a dedicated section in the documentation, explicitly stating the features and limitations of the persistence &amp; replication system, clearly stating when data loss might occur. This leaves no doubt when choosing the right tradeoffs in a system's design.</p><p>Finally, let's focus on scaling Redis Streams. All of the streaming operations above operate on a single Redis key, residing on a single Redis master server (operations are then replicated to slaves). What if we'd like to scale our system above that? One solution is to use Redis Cluster and multiple stream keys. When sending data, we then have to choose a stream key, either randomly or in some deterministic fashion. This resembles Kafka's partitions and partition keys. On the consumer side, we might consume from all keys at once; we could also have dedicated consumers for keys, but then we'd need some way to maintain a cluster-wide view of the consumer &lt;-&gt; key association, to ensure that each key is consumed by some consumer, which isn't an easy task. The number of keys also needs to be large enough to ensure that they are evenly distributed across the shards (distribution is based on key hash values).</p><p>Let's look at the performance test results. A 3-node active-passive setup achieved up to <strong>41 600 msgs/s</strong>:</p><p><a href="https://snapshot.raintank.io/dashboard/snapshot/WnfdD4OMvylP7DD03p5E26U28Yq4qtqv" target="_blank"><br /><img alt="Redis streams grafana" src="/user/pages/blog/mqperf/redis streams grafana.png?g-c73dd6a3" /><br /></a></p><p>However, when we employ a sharded cluster of 9 nodes, that is 3x(master + 2 replicas), and with 100 stream keys, we can get up to <strong>84 000 msgs/s</strong>, however with quite high latencies:</p><p><a href="https://snapshot.raintank.io/dashboard/snapshot/tVU9M1swJh3RsYH0fQGHr0JUW1JcR7eS " target="_blank"><br /><img alt="Redis streams 9 grafana" src="/user/pages/blog/mqperf/redis streams 9 grafana.png?g-c73dd6a3" /><br /></a></p><p>Here are the test results in full:</p><table><thead><tr><th>Threads</th><th>Sender nodes</th><th>Receiver nodes</th><th>Send msgs/s</th><th>Receive msgs/s</th><th>Processing latency</th><th>Send latency</th></tr></thead><tbody><tr><td>1</td><td>2</td><td>4</td><td>20 114</td><td>20 116</td><td>45</td><td>45</td></tr><tr><td>10</td><td>2</td><td>4</td><td>32 879</td><td>32 878</td><td>47</td><td>47</td></tr><tr><td>10</td><td>6</td><td>6</td><td>39 792</td><td>38 796</td><td>48</td><td>48</td></tr><tr><td>10/15</td><td>8</td><td>12</td><td>39 744</td><td>39 743</td><td>48</td><td>48</td></tr><tr><td>20/15</td><td>8</td><td>12</td><td>39 387</td><td>39 391</td><td>48</td><td>48</td></tr><tr><td>60/15</td><td>8</td><td>12</td><td>42 750</td><td>42 748</td><td>108</td><td>137</td></tr><tr><td>80/15</td><td>8</td><td>12</td><td>41 592</td><td>41 628</td><td>144</td><td>178</td></tr></tbody></table><h1>Pulsar</h1><table><tbody><tr><td><em>Version</em></td><td>2.6.2</td></tr><tr><td><em>Replication</em></td><td>configurable, asynchronous &amp; synchronous</td></tr><tr><td><em>Replication type</em></td><td>active-active</td></tr></tbody></table><p><a href="https://pulsar.apache.org">Apache Pulsar</a> is a distributed streaming and messaging platform. It is often positioned in a similar segment as Apache Kafka, and the two platforms are often <a href="https://blog.softwaremill.com/comparing-apache-kafka-and-apache-pulsar-3bd44e00f304">compared and contrasted</a>.</p><p>Pulsar was initially developed at Yahoo!, and now continues to evolve as an open-source project. It builds upon two other Apache projects:</p><ul><li><a href="https://zookeeper.apache.org">ZooKeeper</a> for cluster discovery and coordination</li><li><a href="https://bookkeeper.apache.org">BookKeeper</a> as the replicated storage service</li></ul><p>A Pulsar deployment consists of nodes which take on one of three roles:</p><ul><li>bookie: handles persistent storage of messages</li><li>broker: a stateless service which accepts messages from producers, dispatches messages to consumers and communicates with bookies to store data</li><li>zookeeper: which provides coordination services for the above two</li></ul><p>Hence, a minimal deployment should in fact consist of more than 3 nodes (although we can colocate a couple of roles on a single machine). For our tests we have decided to use separate machines for separate roles, and hence we ended up with 3 zookeeper nodes, 3 bookie nodes and 2 broker nodes.</p><p>When working with Pulsar, we’re dealing with <a href="https://pulsar.apache.org/docs/en/concepts-messaging">three main concepts</a>: <strong>messages, topics and subscriptions</strong>. Producers send messages to topics, either individually or in batches. Consumers can subscribe to a topic in four modes: <code>exclusive</code>, <code>failover</code>, <code>shared</code> and <code>key_shared</code>, providing a subscription name.</p><p>Combining a shared or unique <strong>subscription name</strong>, with one of the four <strong>consumption modes</strong>, we can achieve pub-sub topics, message queues, or a combination of these behaviours. Pulsar is very flexible in this regard.</p><p>Messages in Pulsar are deleted after they are acknowledged, and this is tracked per-subscription. That is, if there are no subscribers to a topic, messages will be marked for deletion right after being sent. Acknowledging a message in one subscription doesn’t affect other subscriptions. Additionally, we can specify a message retention policy, to keep messages for a longer time.</p><p>Moreover, topics can be <strong>partitioned</strong>. Behind the scenes, Pulsar creates an internal topic for every partition (these partitions are something quite different than in Kafka!). However, from the producers' and consumers' point of view such a topic behaves as a single one. As a single topic is always handled by a single broker, increasing the number of partitions, we can increase throughput by allowing multiple brokers to accept and dispatch messages.</p><p>As mentioned above, all storage is handled by Apache BookKeeper. Entries (messages) are stored in sequences called <strong>ledgers</strong>. We can configure how many copies of a ledger are created (<code>managedLedgerDefaultEnsembleSize</code>), in how many copies a message is stored (<code>managedLedgerDefaultWriteQuorum</code>) and how many nodes have to acknowledge a write (<code>managedLedgerDefaultAckQuorum</code>). Following our persistence requirements, we’ve been using 3 ledger copies, and requiring at least 2 copies of each message.</p><p>The setting above corresponds to synchronous replication, but by setting the quorum to 1 or 0, we would get an asynchronous one.</p><p>Unlike previously discussed queues, pulsar is an <strong>active-active system</strong>: that is, every node is equal and can handle user requests. Coordination is performed via Zookeeper, which also secures the cluster against split-brain problems.</p><p>Pulsar offers a number of additional features, such as Pulsar Functions, SQL, transactions, geo replication, multi-tenancy, connectors to many popular data processing systems (Pulsar IO), a schema registry and others.</p><p>Performance-wise, it shows that each node can handle messaging traffic. A baseline setup using a single partition achieves <strong>1 300 msgs/s</strong>. Using 8 sender and 16 receiver nodes, each running 25 threads, we get <strong>147 000 msgs/s</strong>.</p><p>However, we can also increase the number of partitions, thus increasing concurrency. We achieved the best results using 4 partitions (that is, a single broker was handling 2 partitions on average); adding more partitions didn’t further increase performance. Here, we got up to <strong>358 000 msgs/s</strong> using 8 sender nodes each running 100 threads, and 16 receiver nodes each running 25 threads.</p><p><img alt="Pulsar" src="/user/pages/blog/mqperf/pulsar.png?g-c73dd6a3" /></p><p>Send latencies are stable, and the 95th percentile is <strong>48 ms</strong>. Processing latencies vary from <strong>48 ms</strong>, to at most <strong>214 ms</strong> in the test which achieved highest throughput.</p><p><a href="https://snapshot.raintank.io/dashboard/snapshot/fiQeLTljkKFRs7TdGgkly3aZMKxIktt9" target="_blank"><br /><img alt="Pulsar grafana" src="/user/pages/blog/mqperf/pulsar grafana.png?g-c73dd6a3" /><br /></a></p><p>Here are the full test results, for 1 partition:</p><table><thead><tr><th>Threads</th><th>Sender nodes</th><th>Receiver nodes</th><th>Send msgs/s</th><th>Receive msgs/s</th><th>Processing latency</th><th>Send latency</th></tr></thead><tbody><tr><td>1</td><td>1</td><td>2</td><td>1 298,00</td><td>1 298,00</td><td>48,00</td><td>48,00</td></tr><tr><td>5</td><td>1</td><td>2</td><td>6 711,00</td><td>6 711,00</td><td>112,00</td><td>48,00</td></tr><tr><td>25</td><td>1</td><td>2</td><td>31 497,00</td><td>31 527,00</td><td>48,00</td><td>48,00</td></tr><tr><td>1</td><td>2</td><td>4</td><td>2 652,00</td><td>2 652,00</td><td>48,00</td><td>48,00</td></tr><tr><td>5</td><td>2</td><td>4</td><td>12 787,00</td><td>12 789,00</td><td>107,00</td><td>48,00</td></tr><tr><td>25</td><td>2</td><td>4</td><td>55 621,00</td><td>55 677,00</td><td>50,00</td><td>48,00</td></tr><tr><td>1</td><td>4</td><td>8</td><td>5 156,00</td><td>5 156,00</td><td>72,00</td><td>48,00</td></tr><tr><td>5</td><td>4</td><td>8</td><td>24 048,00</td><td>24 054,00</td><td>94,00</td><td>48,00</td></tr><tr><td>25</td><td>4</td><td>8</td><td>96 154,00</td><td>96 272,00</td><td>50,00</td><td>48,00</td></tr><tr><td>25</td><td>6</td><td>12</td><td>124 152,00</td><td>124 273,00</td><td>50,00</td><td>48,00</td></tr><tr><td>50</td><td>6</td><td>12</td><td>160 237,00</td><td>160 254,00</td><td>102,00</td><td>48,00</td></tr><tr><td>25</td><td>8</td><td>16</td><td>147 348,00</td><td>147 405,00</td><td>50,00</td><td>48,00</td></tr></tbody></table><p>And using 4 partitions:</p><table><thead><tr><th>Threads</th><th>Sender nodes</th><th>Receiver nodes</th><th>Send msgs/s</th><th>Receive msgs/s</th><th>Processing latency</th><th>Send latency</th></tr></thead><tbody><tr><td>1</td><td>4</td><td>8</td><td>5 248,00</td><td>5 237,00</td><td>61,00</td><td>48,00</td></tr><tr><td>25</td><td>4</td><td>8</td><td>102 821,00</td><td>102 965,00</td><td>50,00</td><td>48,00</td></tr><tr><td>25</td><td>6</td><td>12</td><td>141 462,00</td><td>141 977,00</td><td>50,00</td><td>48,00</td></tr><tr><td>50</td><td>6</td><td>12</td><td>228 875,00</td><td>228 958,00</td><td>73,00</td><td>48,00</td></tr><tr><td>25</td><td>8</td><td>16</td><td>176 439,00</td><td>176 388,00</td><td>50,00</td><td>48,00</td></tr><tr><td>50</td><td>8</td><td>16</td><td>259 133,00</td><td>259 203,00</td><td>64,00</td><td>48,00</td></tr><tr><td>75/25</td><td>8</td><td>16</td><td>333 622,00</td><td>333 643,00</td><td>65,00</td><td>48,00</td></tr><tr><td>100/25</td><td>8</td><td>16</td><td>358 323,00</td><td>358 648,00</td><td>214,00</td><td>49,00</td></tr><tr><td>50</td><td>10</td><td>20</td><td>260 070,00</td><td>260 165,00</td><td>94,00</td><td>48,00</td></tr><tr><td>100/25</td><td>10</td><td>16</td><td>320 853,00</td><td>320 315,00</td><td>2 698,00</td><td>49,00</td></tr></tbody></table><h1>RocketMQ</h1><table><tbody><tr><td><em>Version</em></td><td>4.7.1</td></tr><tr><td><em>Replication</em></td><td>configurable, asynchronous &amp; synchronous</td></tr><tr><td><em>Replication type</em></td><td>active-passive</td></tr></tbody></table><p><a href="https://rocketmq.apache.org">RocketMQ</a> is a unified messaging engine and lightweight data processing platform. The message broker was initially created as a replacement for ActiveMQ 5 (not the Artemis version we discussed before, but its predecessor). It aims to support similar use-cases, provides JMS and native interfaces (among others), and puts a focus on performance.</p><p>There are three node types from which a RocketMQ cluster is created:</p><ul><li>broker master, which accepts client connections, receives and sends messages</li><li>broker slave, which replicates data from the master</li><li>name server, which provides service discovery and routing</li></ul><p>Each broker cluster can work in synchronous or asynchronous replication modes, which is configured on the broker level. In our tests, we’ve been using synchronous replication.</p><p>In theory, it should be possible to deploy a broker cluster with a single master and two slaves, to achieve a replication factor of 3. However, we couldn’t get this setup to work. Hence instead, we’ve settled on a similar configuration as with ActiveMQ Artemis - <strong>three copies of master-slave</strong> pairs. Like with Artemis, a queue can be deployed on multiple brokers, and the messages are sharded/load-balanced when producing and consuming from the topic.</p><p>Additionally, we’ve deployed a single name server, but in production deployments, this component should be clustered as well, with a minimum of three nodes.</p><p>Speaking of topics, RocketMQ supports both pub-sub topics, as well as typical message queues, where each message is consumed by a single consumer. This corresponds to <code>BROADCAST</code> and <code>CLUSTERING</code> message consumption modes. Moreover, messages can be consumed in-order, or concurrently (we’ve been using the latter option).</p><p>Messages are consumed and acknowledged per <strong>consumer-group</strong>, which is specified when configuring the consumer. When creating a new consumer group, historical messages can be received, as long as they are still available; by default, RocketMQ retains messages for 2 days.</p><p>RocketMQ supports transactions, however there’s no built-in deduplication. Moreover, the documentation is quite basic, making this system a bit challenging to setup and understand. There’s no mention if and which consensus algorithm is used, and if split-brain scenarios are in any way addressed; however, there is a recommendation to deploy at least 3 name servers, which would hint at a quorum-based approach.</p><p>However, RocketMQ definitely makes up for these deficiencies in performance. Our baseline test with a single sender and 1 thread achieved <strong>13 600 msgs/s</strong>. However, processing latency was quite large in that particular test - 37 seconds. It’s quite easy to overwhelm RocketMQ with sends so that the receiver threads can’t keep up. The most we’ve been able to achieve where sends are receives are on par is with 4 sender nodes, 4 receiver nodes running 25 threads each. In that case, the broker processed <strong>485 000 msgs/s</strong>.</p><p><img alt="RocketMQ" src="/user/pages/blog/mqperf/rocketmq.png?g-c73dd6a3" /></p><p>Send latencies are always within <strong>44-47ms</strong>, however as mentioned, processing latencies get high pretty quickly. The highest throughput with reasonable processing latencies (<strong>162 ms</strong>) achieved <strong>129 100 msgs/s</strong>.</p><p><a href="https://snapshot.raintank.io/dashboard/snapshot/7aGk4raOj9lhTfjDXGslhqlA79uOAegn" target="_blank"><br /><img alt="RocketMQ grafana" src="/user/pages/blog/mqperf/rocketmq grafana.png?g-c73dd6a3" /><br /></a></p><p>Here’s a summary of our tests:</p><table><thead><tr><th>Threads</th><th>Sender nodes</th><th>Receiver nodes</th><th>Send msgs/s</th><th>Receive msgs/s</th><th>Processing latency</th><th>Send latency</th></tr></thead><tbody><tr><td>1</td><td>1</td><td>2</td><td>13 605,00</td><td>14 183,00</td><td>37 056,00</td><td>44,00</td></tr><tr><td>5</td><td>1</td><td>2</td><td>64 638,00</td><td>64 635,00</td><td>94,00</td><td>44,00</td></tr><tr><td>25</td><td>1</td><td>2</td><td>260 093,00</td><td>252 308,00</td><td>18 859,00</td><td>45,00</td></tr><tr><td>1</td><td>2</td><td>4</td><td>29 076,00</td><td>29 075,00</td><td>135,00</td><td>43,00</td></tr><tr><td>5</td><td>2</td><td>4</td><td>129 106,00</td><td>129 097,00</td><td>162,00</td><td>44,00</td></tr><tr><td>25</td><td>2</td><td>4</td><td>411 923,00</td><td>410 891,00</td><td>17 436,00</td><td>46,00</td></tr><tr><td>25</td><td>3</td><td>6</td><td>451 454,00</td><td>422 619,00</td><td>60 000,00</td><td>46,00</td></tr><tr><td>1</td><td>4</td><td>8</td><td>55 662,00</td><td>55 667,00</td><td>960,00</td><td>44,00</td></tr><tr><td>5</td><td>4</td><td>8</td><td>202 110,00</td><td>147 859,00</td><td>60 000,00</td><td>45,00</td></tr><tr><td>25</td><td>4</td><td>4</td><td>485 322,00</td><td>416 900,00</td><td>60 000,00</td><td>47,00</td></tr></tbody></table><h1>Kafka</h1><table><tbody><tr><td><em>Version</em></td><td>2.6.0</td></tr><tr><td><em>Replication</em></td><td>configurable, asynchronous &amp; synchronous</td></tr><tr><td><em>Replication type</em></td><td>active-active</td></tr></tbody></table><p><a href="https://kafka.apache.org">Kafka</a> is a distributed event-streaming platform. It is widely deployed and has gained considerable popularity in recent years. Originally developed at LinkedIn, it is now an open-source project, with commercial extensions and support offered by <a href="https://www.confluent.io">Confluent</a>.</p><p>A Kafka cluster consists of a number of <strong>broker nodes</strong>, which handle persistence, replication, client connections: they both accept and send messages. In addition, there’s a <strong>ZooKeeper cluster</strong> which is used for service discovery and coordination. However, there are plans to replace that component with one built directly into the Kafka broker.</p><p>Kafka takes a different approach to messaging, compared to what we’ve seen before. The server itself is a streaming publish-subscribe system, or at an even more basic level, a distributed log. Each Kafka topic can have multiple partitions; by using more partitions, the consumers of the messages (and the throughput) may be scaled and concurrency of processing increased. It’s not uncommon for a topic to have 10s or 100s of partitions.</p><p>On top of the publish-subscribe system, which persists messages within partitions, point-to-point messaging (queueing) is built, by putting a <strong>significant amount of logic into the consumers</strong>. This again contrasts Kafka when comparing with other messaging systems we've looked at: there, usually it was the server that contained most of the message-consumed-by-one-consumer logic. Here it's the consumer.</p><p>Each consumer in a <strong>consumer group</strong> reads messages from a number of dedicated partitions; hence it doesn't make sense to have more consumer threads than partitions. Or in other words, a single partition is consumed by exactly one consumer within a consumer group (as long as there are any consumers).</p><p>Messages aren't acknowledged on the server (which is a very important design difference!), but instead processed message offsets are managed by consumers and written per-parition back to a special Kafka store (or a client-specific store), either automatically in the background, or manually. This allows Kafka to achieve much better performance.</p><p>Such a design has a couple of consequences:</p><ul><li>only messages from each partition are processed in-order. A custom partition-routing strategy can be defined</li><li>all consumers should consume messages at the same speed. Messages from a slow consumer won't be "taken over" by a fast consumer</li><li>messages are acknowledged "up to" an offset. That is messages can't be selectively acknowledged.</li><li>no "advanced" messaging options are available, such as routing or delaying message delivery.</li></ul><p>You can read more about the design of the consumer in <a href="http://kafka.apache.org/documentation.html">Kafka's docs</a>, which are quite comprehensive and provide a good starting point when setting up the broker.</p><p>It is also possible to add a layer on top of Kafka to implement individual message acknowledgments and re-delivery, see <a href="https://softwaremill.com/kafka-with-selective-acknowledgments-performance/">our article on the performance of kmq</a> and the <a href="https://github.com/softwaremill/kmq">KMQ</a> project. This scheme uses an additional topic to track message acknowledgements. In case a message isn’t acknowledged within specified time, it is re-delivered. This is quite similar to how SQS works. When testing Kafka, we’ve primarily tested “vanilla” Kafka, but also included a KMQ test for comparison.</p><p>To achieve guaranteed sends and at-least-once delivery, we used the following configuration (see the <a href="https://github.com/softwaremill/mqperf/blob/master/src/main/scala/com/softwaremill/mqperf/mq/KafkaMq.scala">KafkaMq class</a>):</p><ul><li>topic is created with a <code>replication-factor</code> of <code>3</code></li><li>for the sender, the <code>request.required.acks</code> option is set to <code>-1</code> (synchronous replication; in conjunction with <code>min.insync.replicas</code> topic config set to <code>2</code> a send request blocks until it is accepted by at least 2 replicas - a quorum when we have 3 nodes in total). If you'd like asynchronous replication, this can be set to <code>1</code> (a send request blocks until it is accepted by the partition leader)</li><li>consumer offsets are committed every 10 seconds manually; during that time, message receiving is blocked (a read-write lock is used to assure that). That way we can achieve at-least-once delivery (only committing when messages have been "observed").</li></ul><p>It’s important to get the above configuration right. You can read more about proper no-data-loss Kafka configuration <a href="https://blog.softwaremill.com/help-kafka-ate-my-data-ae2e5d3e6576">on our blog</a>, as well as how to <a href="https://blog.softwaremill.com/does-kafka-really-guarantee-the-order-of-messages-3ca849fd19d2">guarantee message ordering</a>: by default, even within a partition, messages might be reordered!</p><p>As Kafka uses ZooKeeper, network partitions are handled at that level. Kafka has a number of features which are useful when designing a messaging or data streaming system, such as deduplication, transactions, a SQL interface, connectors to multiple popular data processing systems, a schema registry and a streaming framework with in-Kafka exactly-once processing guarantees.</p><p>Let’s look at the performance tests. Here, Kafka has no equals, the numbers are impressive. A baseline test achieved around <strong>7 000 msgs/s</strong>. Using 8 sender nodes and 16 receiver nodes, running 25 threads each, we can achieve <strong>270 000 msgs/s</strong>.</p><p>However, we didn’t stop here. It turns out that the sending part is the bottleneck (and it might not be surprising, as that’s where most coordination happens: we wait for messages to be persisted and acknowledged; while on the receiver side, we allow asynchronous, periodic offset commits). By using 200 threads on 16 sender nodes, with 16 receiver nodes, but running only 5 threads each, we achieved <strong>828 000 msgs/s</strong>.</p><p><img alt="Kafka" src="/user/pages/blog/mqperf/kafka.png?g-c73dd6a3" /></p><p>We’ve been using at least 64 partitions for the tests, scaling this up if there were more total receiver threads, to 80 or 100 partitions.</p><p>What about latencies? They are very stable, even under high load. 95th percentile of <strong>both</strong> send and receives latencies is steadily at <strong>48 ms</strong>. Here’s the dashboard from the test run with the biggest throughput:</p><p><a href="https://snapshot.raintank.io/dashboard/snapshot/wya8hCjrVGe2FCVZUggbnSlkdi2dY1T1" target="_blank"><br /><img alt="Kafka grafana" src="/user/pages/blog/mqperf/kafka grafana.png?g-c73dd6a3" /><br /></a></p><p>As mentioned before, we’ve also tested a setup with selective message acknowledgments, using KMQ (the implementation is <a href="https://github.com/softwaremill/mqperf/blob/master/src/main/scala/com/softwaremill/mqperf/mq/KmqMq.scala">here</a>). Adding another topic for tracking redeliveries, and performing additional message marker sends did impact performance, but not that much. Using 100 threads on 20 senders, and 5 threads on 16 senders, we’ve achieved a throughput of <strong>676 800 msgs/s</strong>. However, processing latencies went up to about <strong>1 812 ms</strong>:</p><p><a href="https://snapshot.raintank.io/dashboard/snapshot/XDUgTNnW6fuGju44Iip0PPHH1MEPWlLI?orgId=2" target="_blank"><br /><img alt="KMQ grafana" src="/user/pages/blog/mqperf/kmq grafana.png?g-c73dd6a3" /><br /></a></p><p>Finally, here are our Kafka test results in full:</p><table><thead><tr><th>Threads</th><th>Sender nodes</th><th>Receiver nodes</th><th>Send msgs/s</th><th>Receive msgs/s</th><th>Processing latency</th><th>Send latency</th></tr></thead><tbody><tr><td>1</td><td>1</td><td>2</td><td>7 458,00</td><td>7 463,00</td><td>47,00</td><td>47,00</td></tr><tr><td>5</td><td>1</td><td>2</td><td>31 350,00</td><td>31 361,00</td><td>47,00</td><td>47,00</td></tr><tr><td>25</td><td>1</td><td>2</td><td>92 373,00</td><td>92 331,00</td><td>81,00</td><td>47,00</td></tr><tr><td>1</td><td>2</td><td>4</td><td>15 184,00</td><td>15 175,00</td><td>47,00</td><td>47,00</td></tr><tr><td>5</td><td>2</td><td>4</td><td>55 402,00</td><td>55 355,00</td><td>47,00</td><td>47,00</td></tr><tr><td>25</td><td>2</td><td>4</td><td>127 274,00</td><td>127 345,00</td><td>50,00</td><td>48,00</td></tr><tr><td>1</td><td>4</td><td>8</td><td>27 044,00</td><td>27 045,00</td><td>47,00</td><td>47,00</td></tr><tr><td>5</td><td>4</td><td>8</td><td>84 234,00</td><td>84 223,00</td><td>48,00</td><td>47,00</td></tr><tr><td>25</td><td>4</td><td>8</td><td>188 557,00</td><td>188 524,00</td><td>48,00</td><td>48,00</td></tr><tr><td>25</td><td>6</td><td>12</td><td>233 379,00</td><td>233 228,00</td><td>48,00</td><td>48,00</td></tr><tr><td>25</td><td>8</td><td>16</td><td>272 828,00</td><td>272 705,00</td><td>48,00</td><td>48,00</td></tr><tr><td>25/5</td><td>8</td><td>16</td><td>235 782,00</td><td>235 802,00</td><td>48,00</td><td>48,00</td></tr><tr><td>50/5</td><td>8</td><td>16</td><td>338 591,00</td><td>338 614,00</td><td>48,00</td><td>48,00</td></tr><tr><td>75/5</td><td>8</td><td>16</td><td>432 049,00</td><td>432 071,00</td><td>48,00</td><td>48,00</td></tr><tr><td>100/5</td><td>8</td><td>16</td><td>498 528,00</td><td>498 498,00</td><td>48,00</td><td>48,00</td></tr><tr><td>25/5</td><td>10</td><td>20</td><td>245 284,00</td><td>245 304,00</td><td>48,00</td><td>48,00</td></tr><tr><td>50/5</td><td>16</td><td>16</td><td>507 393,00</td><td>507 475,00</td><td>48,00</td><td>48,00</td></tr><tr><td>100/5</td><td>16</td><td>16</td><td>678 255,00</td><td>678 279,00</td><td>48,00</td><td>48,00</td></tr><tr><td>150/5</td><td>16</td><td>16</td><td>745 203,00</td><td>745 163,00</td><td>49,00</td><td>49,00</td></tr><tr><td>200/5</td><td>16</td><td>16</td><td>828 836,00</td><td>828 827,00</td><td>49,00</td><td>49,00</td></tr><tr><td>200/5</td><td>20</td><td>16</td><td>810 555,00</td><td>810 553,00</td><td>77,00</td><td>77,00</td></tr></tbody></table><h1>RedPanda</h1><table><tbody><tr><td><em>Version</em></td><td>21.7.4</td></tr><tr><td><em>Replication</em></td><td>configurable, asynchronous &amp; synchronous</td></tr><tr><td><em>Replication type</em></td><td>active-active</td></tr></tbody></table><p>The <a href="https://vectorized.io">RedPanda</a> system targets mission-critical workloads and exposes a Kafka-compatible API. Hence, the way messaging works in RedPanda carries over from Kafka - we've got topics, partitions, consumer groups, etc. In fact, we're using exactly the same client code to test both RedPanda and Kafka. However, the devil lies in the details!</p><p>Let's start with data safety. RedPanda's motto, "Zero data loss" indicates its focus on mission-critical systems. By default, RedPanda's configuration for a 3-node cluster <a href="https://vectorized.io/blog/kafka-redpanda-availability/">corresponds</a> to the following Kafka properties:</p><ul><li><code>acks=-1</code></li><li><code>min.insync.replicas=2</code> (quorum)</li><li><code>log.flush.interval.messages=1</code></li></ul><p>The last one is especially interesting as that's where RedPanda differs from what you'd often use in a synchronously-replicated Kafka setup, and also from what we've used in our tests. In Kafka, setting <code>log.flush.interval.messages</code> to <code>1</code> ensures that the disk cache is flushed on every message, and that's what happens in RedPanda as well. In other words, once a message is accepted by the quorum, it is guaranteed that it will be persistently stored on disk (the default in Kafka, and in our tests, is an unbounded number of messages, hence disk flushes happen asynchronously). This approach to disk safety is similar to what we've seen in RabbitMQ. Keep this in mind while reading the results.</p><p>On the inside, RedPanda uses a mixture of C++ and Go, while Kafka is JVM-based. Moreover, one of the main selling points of RedPanda is that it eliminates the dependency on ZooKeeper. Instead, it uses the Raft consensus protocol. This has very practical consequences: RedPanda will accept a write once a majority of nodes (the quorum) accepts it; Kafka, on the other hand, will wait for a confirmation from all in-sync-replicas, which might take a longer time (if the ISR set is larger than the quorum). This also means that any disturbance in the cluster will have larger implications on latencies in Kafka, than in RedPanda. It's worth noting that Kafka goes in the same direction with its <a href="https://www.confluent.io/blog/kafka-without-zookeeper-a-sneak-peek/">KRaft</a> implementation.</p><p>RedPanda comes with other interesting features, such as an <a href="https://vectorized.io/docs/autotune/">auto-tuner</a>, which detects the optimal settings given the hardware it's running on. Or the <a href="https://vectorized.io/docs/guide-wasm-elastic">Wasm transformations</a> supports: think of it as an in-process Kafka streams stage. Another interesting aspect is that RedPanda exposes <a href="https://vectorized.io/docs/monitoring/">Prometheus metrics</a> natively.</p><p>Let's take a look at the performance results. Our test environment goes against RedPanda's guidelines not to use networked block devices (we're using EBS's <code>gp2</code> drives), however we wanted to keep the test environment the same for all queues.</p><p>RedPanda achieved up to about <strong>15 300 msgs/s</strong> using 200 partitions, 8 sender nodes, 8 receiver nodes each running 25 threads:</p><p><a href="https://snapshot.raintank.io/dashboard/snapshot/OYGvKERHlE8ToC5lPmfyQeTen2CElzR0" target="_blank"><br /><img alt="RedPanda grafana" src="/user/pages/blog/mqperf/redpanda grafana.png?g-c73dd6a3" /><br /></a></p><p>Again, that's quite similar to what RabbitMQ achieves. Maybe that's the limit of queues which fsync each received message (or in our test scenario - a batch of up to 10 messages)? How does Kafka behave when we set <code>log.flush.interval.messages=1</code>? Turns out, it's a bit faster. We've managed to get to <strong>20 800 msgs/s</strong> using 64 partitions, 8 sender nodes (running 200 threads each) and 8 receiver nodes (running 5 threads each). However, the latencies went up to about 800ms:</p><p><a href="https://snapshot.raintank.io/dashboard/snapshot/aIl4vxmc6Vs0xCg0RQPYwvR9REJNMb3R" target="_blank"><br /><img alt="Kafka flush grafana" src="/user/pages/blog/mqperf/kafka flush grafana.png?g-c73dd6a3" /><br /></a></p><p>Finally, here are RedPanda's test results in full. Similarly to Kafka, both send and processing latencies oscillate around 47ms, though they do get slightly higher as we increase the number of senders to get the most performance:</p><table><thead><tr><th>Threads</th><th>Sender nodes</th><th>Receiver nodes</th><th>Send msgs/s</th><th>Receive msgs/s</th><th>Processing latency</th><th>Send latency</th></tr></thead><tbody><tr><td>25</td><td>1</td><td>2</td><td>4 889</td><td>4 846</td><td>47</td><td>47</td></tr><tr><td>25</td><td>1</td><td>1</td><td>8 057</td><td>8 057</td><td>48</td><td>48</td></tr><tr><td>25</td><td>2</td><td>4</td><td>14 453</td><td>14 454</td><td>48</td><td>48</td></tr><tr><td>25</td><td>2</td><td>4</td><td>14 638</td><td>14 637</td><td>48</td><td>48</td></tr><tr><td>5</td><td>8</td><td>8</td><td>14 730</td><td>14 738</td><td>47</td><td>47</td></tr><tr><td>25</td><td>8</td><td>8</td><td>15 369</td><td>15 369</td><td>141</td><td>137</td></tr></tbody></table><h1>Summary of features</h1><p>Below you can find a <a href="https://docs.google.com/spreadsheets/d/1DrklYQsYYbmegaj5j6Owu_3h7A-4xwNXanjwKXoaz8o">summary of some of the characteristics</a> of the queues that we’ve tested. Of course this list isn’t comprehensive, rather it touches on areas that we’ve mentioned above, and which are important when considering replication, message persistence and data safety. However, each system has a number of unique features, which are out of scope here.</p><p><a href="https://docs.google.com/spreadsheets/d/1DrklYQsYYbmegaj5j6Owu_3h7A-4xwNXanjwKXoaz8o" target="_blank"><br /><img alt="Summary of features" src="/user/pages/blog/mqperf/summary.png?g-c73dd6a3" /><br /></a></p><h1>Which queue to choose?</h1><p>It depends! Unfortunately, there are no easy answers to such a question :).</p><p>As always, which message queue to choose depends on specific project requirements. All of the above solutions have some good sides:</p><ul><li>SQS is an as-a-service offering, so especially if you are using the AWS cloud, it's an easy choice: good performance and no setup required. It's cheap for low to moderate workloads, but might get expensive with high load</li><li>if you are already using Mongo, PostgreSQL or EventStore, you can either use it as a message queue or easily build a message queue on top of the database, without the need to create and maintain a separate messaging cluster</li><li>if you want to have high persistence guarantees, RabbitMQ ensures replication across the cluster and on disk on message send. It's a very popular choice used in many projects, with full AMQP implementation and support for many messaging topologies</li><li>ActiveMQ Artemis is a popular, battle-tested and widely used messaging broker with wide protocol support and good performance</li><li>NATS Streaming support many useful communication patterns, and is especially popular in IoT deployments</li><li>Redis Streams offers good performance on top of a popular and familiar key-value store</li><li>RocketMQ offers a JMS-compatible interface, with great performance</li><li>Pulsar builds provides a wide feature set, with many messaging schemes available. It’s gaining popularity, due to it’s flexible nature, accommodating for a wide range of use-cases, and great performance</li><li>Kafka offers the best performance and scalability, at the cost of feature set. It is the de-facto standard for processing event streams across enterprises.</li><li>RedPanda exposes a Kafka-compatible interface, focusing on zero data loss, and providing additional data processing and observability features</li></ul><blockquote><p>Still not sure which message queue is the best fit for your problem? Let us help you in choosing a particular technology, entire tech stack or architecture, given your unique requirements and constraints. Head over to our <a href="https://softwaremill.com/services/">consulting services</a> offer or <a href="https://softwaremill.com/contact/">contact us</a> right away!</p></blockquote><p>Here’s a summary of the performance tests. First, zooming in on our database-based queues, Rabbit, NATS Streaming, Redis Streams, Artemis, RedPanda and Kafka in the flush variant, with SQS for comparison:</p><p><img alt="Summary mqs" src="/user/pages/blog/mqperf/summary1.png?g-c73dd6a3" /></p><p>And including all of the tested queues:</p><p><img alt="Summary throughput" src="/user/pages/blog/mqperf/summary2.png?g-c73dd6a3" /></p><p>Finally, the processing latency has a wider distribution across the brokers. Usually, it's below 150ms - with RocketMQ, PostgreSQL and KMQ faring worse under high load:</p><p><img alt="Summary processing latency" src="/user/pages/blog/mqperf/summary_latencies.png?g-c73dd6a3" /></p><p>There are of course many other aspects besides performance, which should be taken into account when choosing a message queue, such as administration overhead, network partition tolerance, feature set regarding routing, documentation quality, maturity etc. While there's no message-queueing silver bullet, hopefully this summary will be useful when choosing the best system for your project!</p><h1>Credits</h1><p>The following team members contributed to this work: <a href="https://twitter.com/GrzegorzKocur">Grzegorz Kocur</a>, <a href="https://stackoverflow.com/users/542270/opal">Maciej Opała</a>, <a href="https://twitter.com/marcin_kubala">Marcin Kubala</a>, <a href="https://twitter.com/kpciesielski">Krzysztof Ciesielski</a>, <a href="https://twitter.com/kkondzielski">Kasper Kondzielski</a>, Tomasz Król, <a href="https://twitter.com/adamwarski">Adam Warski</a>. <a href="https://twitter.com/clebertsuconic">Clebert Suconic</a>, <a href="https://twitter.com/itsourcery">Michael André Pearce</a>, <a href="https://twitter.com/gregyoung">Greg Young</a> and <a href="https://github.com/franz1981">Francesco Nigro</a> helped out with some configuration aspects of Artemis and EventStore. Thanks!</p><div id="jscomments"><div id="disqus_thread"></div><script type="text/javascript">;var disqus_config=function(){this.language='en';this.shortname='softwaremill';this.page.title='Evaluating\u0020persistent,\u0020replicated\u0020message\u0020queues';this.page.url='\/mqperf\u002D2020';this.page.identifier='\/mqperf\u002D2020'};(function(){var e=document.createElement('script');e.type='text/javascript';e.async=!0;e.src='//softwaremill.disqus.com/embed.js';e.setAttribute('data-timestamp',+new Date());(document.getElementsByTagName('head')[0]||document.getElementsByTagName('body')[0]).appendChild(e)})();</script><noscript>Please enable JavaScript to view the <a href="http://disqus.com/?ref_noscript" rel="nofollow noopener noreferrer">comments powered by Disqus.</a></noscript><a href="http://disqus.com" class="dsq-brlink" rel="nofollow noopener noreferrer">Blog Comments powered by <span class="logo-disqus">Disqus</span>.</a><script type="text/javascript">(function(){var e=document.createElement('script');e.async=!0;e.type='text/javascript';e.src='//softwaremill.disqus.com/count.js';(document.getElementsByTagName('HEAD')[0]||document.getElementsByTagName('BODY')[0]).appendChild(e)}());</script></div></article><aside class="post__meta"><div class="post__meta__wrapper table__of__contents"><h4>Contents</h4><div class="post__menu"></div></div></aside></div></div></section></section><footer><section id="contact-form" class="footer__section content__section section-contact"><div class="viewport"><div class="section__grid grid--two-columns"><div class="grid__item item--contact-data"><div class="block-contact"><h3 class="contact__title">Let's do things together!</h3><ul class="contact__list"><li class="list__item"><a href="tel:+48 22 188 11 33">+48 22 188 11 33 (PL)</a></li><li class="list__item"><a href="tel:+44 56 0156 3406">+44 56 0156 3406 (UK)</a></li><li class="list__item"><a href="mailto:hello@softwaremill.com">hello@softwaremill.com</a></li></ul></div></div><div class="grid__item item--form"><form class="contact-form" action="#" data-contact-form data-getform="0377d391-2b91-431f-823f-a230e8d3b971" data-thankyou="Thanks for getting in touch! We’ll respond to your inquiry within a few business days." data-error="There was an error. Message not sent."><fieldset><input type="text" name="name" placeholder="Name" required><input type="email" name="email" placeholder="E-mail" required><textarea name="message" placeholder="Message" required></textarea><div class="input"><p>Your personal data collected in this form will be used only to contact you and talk about your project. For more information, see our <a href="https://softwaremill.com/privacy-policy/" target="_blank">Privacy Policy</a>.</p></div><button type="submit">Send message</button></fieldset></form></div></div></div></section><section class="footer__section content__section section--black text--white"><div class="viewport"><div class="section__grid grid--two-columns"><div class="grid__item item--nav"><div class="section__header"><h2>See also</h2></div><div class="footer__nav"><nav id="nav-bottom" class="nav-bottom"><ul class="nav__menu menu--bottom"><li class="menu__item"><a href="/portfolio-clients" data-gtmevent="footer-menu-click" data-gtmvalue="Portfolio">Portfolio</a></li><li class="menu__item"><a href="/services" data-gtmevent="footer-menu-click" data-gtmvalue="Services">Services</a></li><li class="menu__item"><a href="/team" data-gtmevent="footer-menu-click" data-gtmvalue="Company">Company</a></li><li class="menu__item"><a href="/join-us" data-gtmevent="footer-menu-click" data-gtmvalue="Join Us">Join Us</a></li><li class="menu__item"><a href="/contact" data-gtmevent="footer-menu-click" data-gtmvalue="Hire Us">Hire Us</a></li><li class="menu__item"><a href="/blog" data-gtmevent="footer-menu-click" data-gtmvalue="Blog">Blog</a></li></ul></nav></div><div class="section__header content__section no-padding-bottom"><h2>Follow us</h2></div><div class="block-socialmedia"><ul class="socialmedia__list"><li><a target="_blank" href="https://twitter.com/softwaremill" data-gtmevent="footer-sm-click" data-gtmvalue="twitter" title="Twitter"><figure class="socialmedia__ico ui-ico ico--twitter"><svg version="1.1" class="ico-twitter" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" x="0px" y="0px" viewBox="-947 470.9 24.2 20.1" enable-background="new -947 470.9 24.2 20.1" xml:space="preserve"><path class="svg__ico" fill="#FFFFFF" d="M-923.4,471.2c-1,0.6-2.1,1-3.2,1.2c-0.9-1-2.3-1.6-3.6-1.6c-2.8,0-5,2.2-5,5c0,0,0,0,0,0.1 c0,0.4,0.1,0.8,0.2,1.2c-4-0.2-7.8-2.1-10.3-5.2c-1.3,2.3-0.6,5.3,1.6,6.8c-0.8,0-1.6-0.2-2.2-0.7v0.1c0,2.4,1.7,4.5,4.1,5 c-0.4,0.1-0.9,0.2-1.3,0.2c-0.3,0-0.6,0-0.9-0.1c0.6,2.1,2.6,3.5,4.7,3.5c-1.8,1.4-4,2.1-6.2,2.2c-0.4,0-0.8,0-1.2-0.1 c2.3,1.5,5,2.2,7.7,2.2c9.3,0,14.3-7.7,14.3-14.4V476c0.8-0.8,1.6-1.8,2.2-2.7c-0.9,0.4-1.9,0.7-2.9,0.8 C-924.6,473.4-923.8,472.4-923.4,471.2z"/></svg></figure></a></li><li><a target="_blank" data-gtmevent="footer-sm-click" data-gtmvalue="facebook" href="https://www.facebook.com/softwaremill" title="Facebook"><figure class="socialmedia__ico ui-ico ico--facebook"><svg version="1.1" class="ico-facebook" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" x="0px" y="0px" viewBox="-953 469.3 12.5 24" enable-background="new -953 469.3 12.5 24" xml:space="preserve"><path class="svg__ico" fill="#FFFFFF" d="M-949.3,493.3h4.4v-11h3.7l0.5-4.3h-4.2v-2.7c0-1.3,0.3-2,2.1-2h2.3v-3.8 c-1.1-0.1-2.2-0.2-3.3-0.2c-3.2,0-5.5,2-5.5,5.6v3.1h-3.7v4.3h3.7V493.3z"/></svg></figure></a></li><li><a target="_blank" data-gtmevent="footer-sm-click" data-gtmvalue="linkedin" href="https://www.linkedin.com/company/808422" title="LinkedIn"><figure class="socialmedia__ico ui-ico ico--linkedin"><svg version="1.1" class="ico-linkedin" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" x="0px" y="0px" viewBox="-949 471.7 20.9 19.3" enable-background="new -949 471.7 20.9 19.3" xml:space="preserve"><rect class="svg__ico" x="-948.5" y="477.9" fill="#FFFFFF" width="4.1" height="13"/><path class="svg__ico" fill="#FFFFFF" d="M-933.3,477.9c-2.3,0-3.8,1.3-4.1,2.2v-2h-4.6c0.1,1,0,13,0,13h4.6v-7.1c0-0.4,0-0.7,0.1-1.1 c0.3-1,1.2-1.6,2.2-1.6c1.6,0,2.3,1.2,2.3,2.9v6.7h4.7v-7.2C-928.1,479.7-930.4,477.9-933.3,477.9z"/><path class="svg__ico" fill="#FFFFFF" d="M-946.3,471.7c-0.1,0-0.1,0-0.2,0c-1.3-0.1-2.4,0.9-2.5,2.1c0,0,0,0.1,0,0.1c0,1.2,1,2.3,2.2,2.3 c0.1,0,0.1,0,0.2,0c1.2,0.1,2.4-0.8,2.5-2c0-0.1,0-0.2,0-0.2C-944.1,472.8-945.1,471.8-946.3,471.7z"/></svg></figure></a></li><li><a target="_blank" data-gtmevent="footer-sm-click" data-gtmvalue="github" href="https://github.com/softwaremill" title="Github"><figure class="socialmedia__ico ui-ico ico--github"><svg version="1.1" class="ico-github" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" x="0px" y="0px" viewBox="-946 469 25.9 25" enable-background="new -946 469 25.9 25" xml:space="preserve"><path class="svg__ico" fill="#FFFFFF" d="M-933.2,469c-7.1,0-12.8,5.8-12.8,12.8c0,5.5,3.6,10.4,8.8,12.1c0.7,0.1,0.9-0.3,0.9-0.6v-2.2 c-3.6,0.8-4.3-1.7-4.3-1.7c-0.2-0.8-0.7-1.5-1.4-1.9c-1.2-0.8,0.1-0.7,0.1-0.7c0.8,0.1,1.6,0.6,2,1.3c0.7,1.3,2.3,1.8,3.6,1.1 c0,0,0.1,0,0.1,0c0-0.7,0.3-1.3,0.8-1.7c-2.8-0.3-5.8-1.4-5.8-6.3c0-1.3,0.4-2.5,1.3-3.4c-0.4-1.1-0.4-2.3,0.2-3.4 c0,0,1.1-0.3,3.5,1.3c1.1-0.3,2.1-0.4,3.2-0.4c1.1,0,2.2,0.2,3.2,0.4c2.4-1.7,3.5-1.3,3.5-1.3c0.4,1.1,0.5,2.3,0.2,3.4 c0.9,0.9,1.3,2.1,1.3,3.4c0,4.9-3,6-5.8,6.3c0.6,0.6,0.9,1.5,0.8,2.4v3.5c0,0.3,0.2,0.8,0.9,0.6c5.2-1.8,8.7-6.6,8.7-12.2 C-920.3,474.7-926.1,469.1-933.2,469z"/></svg></figure></a></li><li><a target="_blank" data-gtmevent="footer-sm-click" data-gtmvalue="youtube" href="https://www.youtube.com/c/SoftwareMillCom" title="YouTube"><figure class="socialmedia__ico ui-ico ico--yt"><svg version="1.1" class="ico-yt" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" x="0px" y="0px" viewBox="-948.5 471.7 23.5 17.8" enable-background="new -948.5 471.7 23.5 17.8" xml:space="preserve"><path class="svg__ico" fill="#FFFFFF" d="M-926.6,473.5c-0.6-0.6-1.4-1-2.3-1c-3.2-0.3-7.8-0.3-7.8-0.3s-4.8,0-7.8,0.3 c-0.9,0-1.7,0.4-2.3,1c-0.5,0.7-0.8,1.5-0.9,2.4c-0.2,1.3-0.2,2.5-0.3,3.8v1.9c0,1.3,0.1,2.6,0.3,3.8c0.1,0.8,0.4,1.6,0.9,2.3 c0.7,0.6,1.6,1,2.5,1c1.8,0.2,7.7,0.2,7.7,0.2s4.8,0,7.8-0.2c0.9,0,1.7-0.4,2.3-1c0.5-0.7,0.8-1.5,0.9-2.4c0,0,0.2-1.8,0.2-3.7v-1.8 c0-1.3-0.1-2.6-0.3-3.9C-925.8,475-926.1,474.2-926.6,473.5z M-939.5,484.8v-8.4l7,4.2L-939.5,484.8z"/></svg></figure></a></li><li><a target="_blank" data-gtmevent="footer-sm-click" data-gtmvalue="instagram" href="https://instagram.com/softwaremill_vibes" title="Instagram"><figure class="socialmedia__ico ui-ico ico--instagram"><?xml version="1.0" encoding="UTF-8" standalone="no"?><svg viewBox="0 0 256 256" version="1.1" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" preserveAspectRatio="xMidYMid"><g class="svg__ico" fill="#FFFFFF"><path d="M127.999746,23.06353 C162.177385,23.06353 166.225393,23.1936027 179.722476,23.8094161 C192.20235,24.3789926 198.979853,26.4642218 203.490736,28.2166477 C209.464938,30.5386501 213.729395,33.3128586 218.208268,37.7917319 C222.687141,42.2706052 225.46135,46.5350617 227.782844,52.5092638 C229.535778,57.0201472 231.621007,63.7976504 232.190584,76.277016 C232.806397,89.7746075 232.93647,93.8226147 232.93647,128.000254 C232.93647,162.177893 232.806397,166.225901 232.190584,179.722984 C231.621007,192.202858 229.535778,198.980361 227.782844,203.491244 C225.46135,209.465446 222.687141,213.729903 218.208268,218.208776 C213.729395,222.687649 209.464938,225.461858 203.490736,227.783352 C198.979853,229.536286 192.20235,231.621516 179.722476,232.191092 C166.227425,232.806905 162.179418,232.936978 127.999746,232.936978 C93.8200742,232.936978 89.772067,232.806905 76.277016,232.191092 C63.7971424,231.621516 57.0196391,229.536286 52.5092638,227.783352 C46.5345536,225.461858 42.2700971,222.687649 37.7912238,218.208776 C33.3123505,213.729903 30.538142,209.465446 28.2166477,203.491244 C26.4637138,198.980361 24.3784845,192.202858 23.808908,179.723492 C23.1930946,166.225901 23.0630219,162.177893 23.0630219,128.000254 C23.0630219,93.8226147 23.1930946,89.7746075 23.808908,76.2775241 C24.3784845,63.7976504 26.4637138,57.0201472 28.2166477,52.5092638 C30.538142,46.5350617 33.3123505,42.2706052 37.7912238,37.7917319 C42.2700971,33.3128586 46.5345536,30.5386501 52.5092638,28.2166477 C57.0196391,26.4642218 63.7971424,24.3789926 76.2765079,23.8094161 C89.7740994,23.1936027 93.8221066,23.06353 127.999746,23.06353 M127.999746,0 C93.2367791,0 88.8783247,0.147348072 75.2257637,0.770274749 C61.601148,1.39218523 52.2968794,3.55566141 44.1546281,6.72008828 C35.7374966,9.99121548 28.5992446,14.3679613 21.4833489,21.483857 C14.3674532,28.5997527 9.99070739,35.7380046 6.71958019,44.1551362 C3.55515331,52.2973875 1.39167714,61.6016561 0.769766653,75.2262718 C0.146839975,88.8783247 0,93.2372872 0,128.000254 C0,162.763221 0.146839975,167.122183 0.769766653,180.774236 C1.39167714,194.398852 3.55515331,203.703121 6.71958019,211.845372 C9.99070739,220.261995 14.3674532,227.400755 21.4833489,234.516651 C28.5992446,241.632547 35.7374966,246.009293 44.1546281,249.28042 C52.2968794,252.444847 61.601148,254.608323 75.2257637,255.230233 C88.8783247,255.85316 93.2367791,256 127.999746,256 C162.762713,256 167.121675,255.85316 180.773728,255.230233 C194.398344,254.608323 203.702613,252.444847 211.844864,249.28042 C220.261995,246.009293 227.400247,241.632547 234.516143,234.516651 C241.632039,227.400755 246.008785,220.262503 249.279912,211.845372 C252.444339,203.703121 254.607815,194.398852 255.229725,180.774236 C255.852652,167.122183 256,162.763221 256,128.000254 C256,93.2372872 255.852652,88.8783247 255.229725,75.2262718 C254.607815,61.6016561 252.444339,52.2973875 249.279912,44.1551362 C246.008785,35.7380046 241.632039,28.5997527 234.516143,21.483857 C227.400247,14.3679613 220.261995,9.99121548 211.844864,6.72008828 C203.702613,3.55566141 194.398344,1.39218523 180.773728,0.770274749 C167.121675,0.147348072 162.762713,0 127.999746,0 Z M127.999746,62.2703115 C91.698262,62.2703115 62.2698034,91.69877 62.2698034,128.000254 C62.2698034,164.301738 91.698262,193.730197 127.999746,193.730197 C164.30123,193.730197 193.729689,164.301738 193.729689,128.000254 C193.729689,91.69877 164.30123,62.2703115 127.999746,62.2703115 Z M127.999746,170.667175 C104.435741,170.667175 85.3328252,151.564259 85.3328252,128.000254 C85.3328252,104.436249 104.435741,85.3333333 127.999746,85.3333333 C151.563751,85.3333333 170.666667,104.436249 170.666667,128.000254 C170.666667,151.564259 151.563751,170.667175 127.999746,170.667175 Z M211.686338,59.6734287 C211.686338,68.1566129 204.809755,75.0337031 196.326571,75.0337031 C187.843387,75.0337031 180.966297,68.1566129 180.966297,59.6734287 C180.966297,51.1902445 187.843387,44.3136624 196.326571,44.3136624 C204.809755,44.3136624 211.686338,51.1902445 211.686338,59.6734287 Z"></path></g></svg></figure></a></li><li><a target="_blank" data-gtmevent="footer-sm-click" data-gtmvalue="slideshare" href="http://www.slideshare.net/softwaremill" title="Slideshare"><figure class="socialmedia__ico ui-ico ico--slideshare"><svg version="1.1" class="ico-slideshare" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" x="0px" y="0px" viewBox="-944 470.1 30.9 20.9" enable-background="new -944 470.1 30.9 20.9" xml:space="preserve"><path class="svg__ico" fill="#FFFFFF" d="M-923.9,476.9c1.9,0,3.4-1.5,3.4-3.4c0,0,0-0.1,0-0.1c0-1.9-1.5-3.4-3.4-3.4c-1.9,0-3.4,1.5-3.4,3.4 c0,0,0,0,0,0C-927.3,475.4-925.8,476.9-923.9,476.9z"/><path class="svg__ico" fill="#FFFFFF" d="M-932.9,476.9C-932.9,476.9-932.8,476.9-932.9,476.9c1.9,0,3.5-1.5,3.5-3.4c0,0,0-0.1,0-0.1 c0-1.9-1.5-3.4-3.4-3.4c-1.9,0-3.4,1.5-3.4,3.4c0,0,0,0,0,0C-936.3,475.4-934.8,476.9-932.9,476.9z"/><path class="svg__ico" fill="#FFFFFF" d="M-914.6,475.8c-1,1.2-5.4,2.6-6,2.6h-4.8c-1.1,0-2.9,0.3-2.9,1v0.6c-0.1,0-0.1-0.1-0.2-0.1 c-0.7-0.9-1.9-1.3-3-1.3c-2.3,0-4.5-0.2-6.8-0.7c-2-0.4-5.3-3.3-5.6-2.5c-0.3,0.8,0.3,1.3,1.3,2.5c1.1,1.3,5.5,3,5.5,3v5.3 c0,1.6,3.2,3.9,4.8,3.9s2.9-1.1,2.9-1.9v-4.9c0.3,0.1,0.7,0.3,1,0.3v4.5c0,0.8,1.1,2.8,4.5,2.8c3.3,0,4.3-4,4.3-4.7v-4.9 c2.3-1.3,4.8-1.9,6-4.2C-912.5,475.1-913.5,474.7-914.6,475.8z"/></svg></figure></a></li><li><a target="_blank" data-gtmevent="footer-sm-click" data-gtmvalue="clutch" href="https://clutch.co/profile/softwaremill" title="Clutch"><figure class="socialmedia__ico ui-ico ico--clutch"><svg version="1.1" class="ico-clutch" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" x="0px" y="0px" viewBox="-949 469.5 20.8 23.5" enable-background="new -949 469.5 20.8 23.5" xml:space="preserve"><path class="svg__ico" fill="#FFFFFF" d="M-937.1,487.8c-3.6,0.1-6.6-2.7-6.7-6.2c0-0.1,0-0.2,0-0.3c-0.1-3.5,2.7-6.4,6.2-6.5c0.2,0,0.4,0,0.6,0 c2,0,3.9,0.8,5.2,2.3l3.7-3.7c-2.3-2.5-5.5-3.9-8.9-3.9c-7.6,0-12,5.2-12,11.6c-0.1,6.4,4.9,11.7,11.3,11.8c0.2,0,0.4,0,0.6,0 c3.4,0,6.7-1.4,8.9-3.9l-3.7-3.6C-933.2,487-935.1,487.8-937.1,487.8z"/><path class="svg__ico" fill="#FFFFFF" d="M-937.4,477.4c-2.1,0-3.9,1.7-3.9,3.9c0,0,0,0,0,0c0,2.1,1.7,3.9,3.9,3.9c2.1,0,3.9-1.7,3.9-3.9 C-933.5,479.2-935.3,477.4-937.4,477.4C-937.4,477.4-937.4,477.4-937.4,477.4z"/></svg></figure></a></li><li><a target="_blank" data-gtmevent="footer-sm-click" data-gtmvalue="medium" href="https://blog.softwaremill.com/?gi=854e7326b87a" title="Medium"><figure class="socialmedia__ico ui-ico ico--medium"><svg version="1.1" class="ico-medium" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" x="0px" y="0px" viewBox="-947 469 25 25" enable-background="new -947 469 25 25" xml:space="preserve"><path class="svg__ico" fill="#FFFFFF" d="M-934.5,469c-6.9,0-12.5,5.6-12.5,12.5c0,6.9,5.6,12.5,12.5,12.5c6.9,0,12.5-5.6,12.5-12.5c0,0,0,0,0,0 C-922,474.6-927.6,469-934.5,469z M-927.4,477.3L-927.4,477.3h-0.6c-0.3,0-0.5,0.2-0.5,0.5v7.1c0.1,0.2,0.3,0.4,0.5,0.5h0.6v1.7 h-5.2v-1.7h1.1v-7.4h-0.1l-2.5,9.1h-2l-2.5-9.1h-0.1v7.4h1.1v1.7h-4.3v-1.7h0.6c0.3,0,0.5-0.2,0.5-0.5v-7.1 c-0.1-0.3-0.3-0.5-0.5-0.5h-0.6v-1.7h5.4l1.8,6.6h0l1.8-6.6h5.4V477.3z"/></svg></figure></a></li><li><a target="_blank" data-gtmevent="footer-sm-click" data-gtmvalue="dribble" href="https://dribbble.com/softwaremill" title="Dribble"><figure class="socialmedia__ico ui-ico ico--dribble"><svg width="24" height="24" viewBox="0 0 24 24" fill="none" xmlns="http://www.w3.org/2000/svg"><path class="svg__ico" d="M12 0C5.3724 0 0 5.3724 0 12C0 18.6276 5.3724 24 12 24C18.6276 24 24 18.6276 24 12C24 5.3724 18.6276 0 12 0ZM12 1.7388C14.6142 1.7388 17.0004 2.7168 18.8124 4.326C17.481 6.0822 15.4584 7.2516 13.4316 8.043C12.2842 5.95341 10.9984 3.94292 9.5826 2.025C10.3744 1.83414 11.1861 1.73807 12.0006 1.7388H12ZM7.6344 2.7108C8.9724 4.7124 10.2684 6.5682 11.4522 8.6688C8.4582 9.4446 5.0748 9.9102 1.9494 9.918C2.6082 6.7212 4.7556 4.0668 7.6344 2.7114V2.7108ZM19.9506 5.5128C21.4334 7.32477 22.249 9.59091 22.2612 11.9322C19.8876 11.4642 17.5272 11.3418 15.1236 11.5842C14.8536 10.9104 14.526 10.2702 14.2122 9.5802C16.284 8.7444 18.4992 7.314 19.9506 5.5122V5.5128ZM12.2856 10.2564C12.5424 10.8024 12.84 11.382 13.1196 11.9742C9.7776 13.4478 6.2226 15.417 4.3776 18.8694C2.6064 16.9094 1.66248 14.3399 1.7436 11.6994C5.3226 11.6826 8.8356 11.235 12.2856 10.2564V10.2564ZM17.7084 13.0542C19.2017 13.0545 20.6888 13.2461 22.1334 13.6242C21.9107 15.0139 21.4044 16.343 20.646 17.5287C19.8876 18.7144 18.8934 19.7314 17.7252 20.5164C17.1744 18.0114 16.6494 15.6144 15.7212 13.1976C16.3791 13.1017 17.043 13.0536 17.7078 13.0536L17.7084 13.0542ZM22.1868 13.2402C22.1796 13.299 22.173 13.3566 22.1646 13.4142C22.173 13.356 22.1802 13.2984 22.1868 13.2402ZM13.8228 13.6662C14.7684 16.11 15.5106 18.816 16.0086 21.4494C14.7409 21.9873 13.3777 22.2636 12.0006 22.2618C9.71931 22.2651 7.50256 21.5047 5.7036 20.1018C7.5618 17.0874 10.44 14.8062 13.8222 13.6668L13.8228 13.6662Z" fill="white"/></svg></figure></a></li><li><a target="_blank" data-gtmevent="footer-sm-click" data-gtmvalue="rss" href="https://softwaremill.com/blog.rss" title="RSS"><figure class="socialmedia__ico ui-ico ico--rss"><svg width="17" height="16" viewBox="0 0 17 16" fill="none" xmlns="http://www.w3.org/2000/svg"><g clip-path="url(#clip0)"><path d="M13.5495 16C13.5495 8.979 7.771 3.2005 0.75 3.2005V0C9.526 0 16.75 7.224 16.75 16H13.5495ZM2.9425 11.6095C3.52512 11.6106 4.08358 11.8425 4.49555 12.2544C4.90753 12.6664 5.13944 13.2249 5.1405 13.8075C5.1405 15.016 4.1485 16 2.9375 16C1.729 16 0.75 15.018 0.75 13.8075C0.75 12.597 1.7345 11.6095 2.9425 11.6095ZM11.357 16H8.245C8.245 11.888 4.862 8.5025 0.75 8.5025V5.393C6.5675 5.393 11.357 10.182 11.357 16Z" fill="white"/></g><defs><clipPath id="clip0"><rect width="16" height="16" fill="white" transform="translate(0.75)"/></clipPath></defs></svg></figure></a></li></ul></div></div><div class="grid__item item--social"><div class="section__header"><h2>Latest on Blog</h2></div><ul class="articles__list"><li class="list__item item--article"><a href="/meeting-with-the-jvm-community-at-geecon"><div class="block-author"><div class="author__meta"><figure class="employee__image "><img alt="webp image" src="/user/webp/user/themes/softwaremill/assets/team/aUZErAviSXVp4en.webp" /></figure><div class="author__desc"><p class="name"><span>Maria Wąchal</span> | <span class="date">24 May 2022.</span><span class="time-to-read">11 minutes read</span></p></div></div></div><h3 class="article__title">Meeting with the JVM community at GeeCON</h3></a><ul class="article__tags tags__list"><li class="list__item item--tag"><a href="javascript:void(0)">conferences</a></li><li class="list__item item--tag"><a href="javascript:void(0)">Lessons Learned</a></li><li class="list__item item--tag"><a href="javascript:void(0)">Company Culture</a></li><li class="list__item item--tag"><a href="javascript:void(0)">Team</a></li></ul></li></ul></div></div><!-- /section__grid --></div><!-- /viewport --></section><section class="footer__section content__section section--black text--white section-copyrights"><div class="viewport"><div class="section__grid grid--two-columns"><div class="footer__copyrights"><p>&copy; 2022 SoftwareMill. All rights reserved. <a href="/privacy-policy">Privacy policy.</a></p></div></div></div></section></footer></div><script src="/user/themes/softwaremill/_/dist/main.50d58c14.js" type="module"></script><script>;document.getElementById('tweet-button').addEventListener('click',function(t){t.preventDefault();twitterWindow=window.open('https://twitter.com/share?text='+document.getElementById('tweet-content').textContent+'&url='+document.URL,'twitter-popup','height=350,width=600');if(twitterWindow.focus){twitterWindow.focus()}});</script><script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script></body></html>