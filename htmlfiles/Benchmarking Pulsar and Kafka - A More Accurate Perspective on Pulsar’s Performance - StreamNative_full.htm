<!DOCTYPE html>
<html data-html-server-rendered="true" lang="en" data-vue-tag="%7B%22lang%22:%7B%22ssr%22:%22en%22%7D%7D">
<head>
    <title>Benchmarking Pulsar and Kafka - A More Accurate Perspective on Pulsar’s Performance - StreamNative</title><meta name="gridsome:hash" content="9e55314d9dbdc772f0490e435929eb5016906f14"><meta data-vue-tag="ssr" charset="utf-8"><meta data-vue-tag="ssr" name="generator" content="Gridsome v0.7.23"><meta data-vue-tag="ssr" data-key="viewport" name="viewport" content="width=device-width, initial-scale=1, viewport-fit=cover"><meta data-vue-tag="ssr" data-key="format-detection" name="format-detection" content="telephone=no"><meta data-vue-tag="ssr" name="description" content="We took a closer look at Confluent’s benchmark and found some issues. In order to provide the community a more accurate picture, we decided to address these issues and repeat the test. The test result shows that Pulsar significantly outperformed Kafka in scenarios that more closely resembled real-world workloads and matched Kafka’s performance in the basic scenario Confluent used."><meta data-vue-tag="ssr" property="og:title" content="Benchmarking Pulsar and Kafka - A More Accurate Perspective on Pulsar’s Performance"><meta data-vue-tag="ssr" property="og:description" content="We took a closer look at Confluent’s benchmark and found some issues. In order to provide the community a more accurate picture, we decided to address these issues and repeat the test. The test result shows that Pulsar significantly outperformed Kafka in scenarios that more closely resembled real-world workloads and matched Kafka’s performance in the basic scenario Confluent used."><meta data-vue-tag="ssr" property="og:url" content="https://streamnative.io/blog/tech/2020-11-09-benchmark-pulsar-kafka-performance/"><meta data-vue-tag="ssr" property="og:image" content="https://streamnative.io//uploads/images/blogs/benchmark-pulsar-kafka/benchmark-pulsar-kafka-cover.jpg"><meta data-vue-tag="ssr" name="twitter:title" content="Benchmarking Pulsar and Kafka - A More Accurate Perspective on Pulsar’s Performance"><meta data-vue-tag="ssr" name="twitter:description" content="We took a closer look at Confluent’s benchmark and found some issues. In order to provide the community a more accurate picture, we decided to address these issues and repeat the test. The test result shows that Pulsar significantly outperformed Kafka in scenarios that more closely resembled real-world workloads and matched Kafka’s performance in the basic scenario Confluent used."><meta data-vue-tag="ssr" name="twitter:image" content="https://streamnative.io//uploads/images/blogs/benchmark-pulsar-kafka/benchmark-pulsar-kafka-top.jpg"><link data-vue-tag="ssr" rel="icon" href="data:,"><link data-vue-tag="ssr" rel="icon" type="image/png" sizes="16x16" href="/assets/static/favicon.ce0531f.87a1aa99fef0b33710c1e0c09830bcf8.png"><link data-vue-tag="ssr" rel="icon" type="image/png" sizes="32x32" href="/assets/static/favicon.ac8d93a.87a1aa99fef0b33710c1e0c09830bcf8.png"><link rel="preload" href="/assets/css/0.styles.208477a6.css" as="style"><link rel="preload" href="/assets/js/app.693fd7b3.js" as="script"><link rel="preload" href="/assets/js/page--src--templates--blog-vue.1817b5d1.js" as="script"><link rel="prefetch" href="/assets/js/43.2c6428d3.js"><link rel="prefetch" href="/assets/js/page--src--pages--404-vue.d98b805a.js"><link rel="prefetch" href="/assets/js/page--src--pages--about-vue.6888d8bd.js"><link rel="prefetch" href="/assets/js/page--src--pages--about-vue~page--src--pages--api--cloud-vue~page--src--pages--blog-vue~page--src--p~797c74f8.33855e68.js"><link rel="prefetch" href="/assets/js/page--src--pages--ambassador-vue.d5864cbe.js"><link rel="prefetch" href="/assets/js/page--src--pages--api--cloud-vue.5f5d33fa.js"><link rel="prefetch" href="/assets/js/page--src--pages--blog-vue.5d9f3f34.js"><link rel="prefetch" href="/assets/js/page--src--pages--blogs-vue.339a6501.js"><link rel="prefetch" href="/assets/js/page--src--pages--careers-vue.76c74a9f.js"><link rel="prefetch" href="/assets/js/page--src--pages--cloud-terms-and-conditions-vue.3e271690.js"><link rel="prefetch" href="/assets/js/page--src--pages--cloud-uptime-sla-vue.5b1f36f6.js"><link rel="prefetch" href="/assets/js/page--src--pages--cloudforkafka-vue.a92ecf53.js"><link rel="prefetch" href="/assets/js/page--src--pages--ebooks-vue.cfea3336.js"><link rel="prefetch" href="/assets/js/page--src--pages--events-vue.896f49df.js"><link rel="prefetch" href="/assets/js/page--src--pages--faq-vue.1b5f4513.js"><link rel="prefetch" href="/assets/js/page--src--pages--fundamentals-vue.0d678630.js"><link rel="prefetch" href="/assets/js/page--src--pages--history-vue.0fe9cba0.js"><link rel="prefetch" href="/assets/js/page--src--pages--index-vue.fb1ebe1c.js"><link rel="prefetch" href="/assets/js/page--src--pages--news-vue.0dccbf6a.js"><link rel="prefetch" href="/assets/js/page--src--pages--oreilly-book-vue.f8b589e3.js"><link rel="prefetch" href="/assets/js/page--src--pages--partner-vue.8ea0f6ab.js"><link rel="prefetch" href="/assets/js/page--src--pages--platform-vue.41042c71.js"><link rel="prefetch" href="/assets/js/page--src--pages--policy-vue.d9a31684.js"><link rel="prefetch" href="/assets/js/page--src--pages--pro-services-vue.4b6952d3.js"><link rel="prefetch" href="/assets/js/page--src--pages--pulsar-vue.8cfb2fc3.js"><link rel="prefetch" href="/assets/js/page--src--pages--resource-center-vue.d78f1128.js"><link rel="prefetch" href="/assets/js/page--src--pages--streamnativecloud-vue.b496ae55.js"><link rel="prefetch" href="/assets/js/page--src--pages--success-stories-vue.3f604a14.js"><link rel="prefetch" href="/assets/js/page--src--pages--terms-vue.0e232c0d.js"><link rel="prefetch" href="/assets/js/page--src--pages--training-vue.574479fd.js"><link rel="prefetch" href="/assets/js/page--src--pages--webinars-vue.cf0669ca.js"><link rel="prefetch" href="/assets/js/page--src--pages--whitepapers-vue.cd255446.js"><link rel="prefetch" href="/assets/js/page--src--templates--career-vue.8583e8ae.js"><link rel="prefetch" href="/assets/js/page--src--templates--downloadable-landing-page-vue.7e441a3c.js"><link rel="prefetch" href="/assets/js/page--src--templates--event-landing-page-vue.23e562a5.js"><link rel="prefetch" href="/assets/js/page--src--templates--general-landing-page-vue.516056b8.js"><link rel="prefetch" href="/assets/js/page--src--templates--success-story-vue.5892cec7.js"><link rel="prefetch" href="/assets/js/page--src--templates--thank-vue.0204f12b.js"><link rel="prefetch" href="/assets/js/page--src--templates--whitepaper-vue.426b4c0e.js"><link rel="prefetch" href="/assets/js/vendors~page--src--pages--careers-vue.c0bbd512.js"><link rel="prefetch" href="/assets/js/vendors~page--src--pages--index-vue~page--src--pages--success-stories-vue.e90744b7.js"><link rel="stylesheet" href="/assets/css/0.styles.208477a6.css"><noscript data-vue-tag="ssr"><style>.g-image--loading{display:none;}</style></noscript>
    <script>
      rudderanalytics=window.rudderanalytics=[];for(var methods=["load","page","track","identify","alias","group","ready","reset","getAnonymousId","setAnonymousId"],i=0;i<methods.length;i++){var method=methods[i];rudderanalytics[method]=function(a){return function(){rudderanalytics.push([a].concat(Array.prototype.slice.call(arguments)))}}(method)}rudderanalytics.load('1xbSpCxEyaf2zG6Ji36VPCvSbRL','https://hosted.rudderlabs.com'),rudderanalytics.page();
    </script>
    <script src="https://cdn.rudderlabs.com/v1/rudder-analytics.min.js"></script>
    <!-- baidu-script-placeholder -->
    <script type="text/javascript" id="hs-script-loader" async defer src="//js.hs-scripts.com/6585952.js"></script>
    <script type="text/javascript">
        _linkedin_partner_id = "3589636";
        window._linkedin_data_partner_ids = window._linkedin_data_partner_ids || [];
        window._linkedin_data_partner_ids.push(_linkedin_partner_id);
        </script><script type="text/javascript">
        (function(l) {
        if (!l){window.lintrk = function(a,b){window.lintrk.q.push([a,b])};
        window.lintrk.q=[]}
        var s = document.getElementsByTagName("script")[0];
        var b = document.createElement("script");
        b.type = "text/javascript";b.async = true;
        b.src = "https://snap.licdn.com/li.lms-analytics/insight.min.js";
        s.parentNode.insertBefore(b, s);})(window.lintrk);
    </script>
    <script type="text/javascript" src="https://www.slidestalk.com/jssdk/apiv1?uid=1027&ak=97aa773e658a8d22afddf0f47844e01f"></script>
    <noscript>
        <img height="1" width="1" style="display:none;" alt="" src="https://px.ads.linkedin.com/collect/?pid=3589636&fmt=gif" />
    </noscript>
        
</head>
<body >
<div data-server-rendered="true" id="app" data-v-4064100e data-v-124acb4b><div data-v-4064100e><div class="mx-auto font-default" data-v-4064100e><div id="nav-box" class="nav-box" data-v-4064100e><section class="banner-background flex justify-between items-center content-center py-2 px-3 md:px-20 text-white" data-v-3526bdd2 data-v-4064100e><p class="md:text-lg text-white " data-v-3526bdd2>
    Get your free copy of the *NEW* Apache Pulsar vs. Apache Kafka 2022 Benchmark
  </p><div class="md:py-3" data-v-3526bdd2><a href="https://streamnative.io/download/report-pulsar-vs-kafka-benchmark-2022/?utm_campaign=Benchmarking%20Pulsar%20vs.%20Kafka%202022&amp;utm_source=Benchmark%20Promo%20Website%20Banner%20Link%20to%20LP&amp;utm_medium=Benchmark%20Promo%20Website%20Banner%20Link%20to%20LP&amp;utm_content=Pulsar%20vs.%20Kafka%20Benchmark%20LP%20Link" target="_blank" rel="noopener" to="https://streamnative.io/download/report-pulsar-vs-kafka-benchmark-2022/?utm_campaign=Benchmarking%20Pulsar%20vs.%20Kafka%202022&amp;utm_source=Benchmark%20Promo%20Website%20Banner%20Link%20to%20LP&amp;utm_medium=Benchmark%20Promo%20Website%20Banner%20Link%20to%20LP&amp;utm_content=Pulsar%20vs.%20Kafka%20Benchmark%20LP%20Link" class="sn-button text-blue-light button-text border-white m-0 text-current sn-button text-blue-light" data-v-8f7965c6 data-v-8f7965c6 data-v-75f8c361 data-v-3526bdd2>Download Now</a><div data-v-3526bdd2><i class="md-icon md-icon-font text-current font-icon overflow-hidden absolute top-4 right-4 cursor-pointer md-theme-default" data-v-c35c051a data-v-3526bdd2>close</i></div></div></section><div class="md-toolbar-section-end px-6 md:px-12 md:py-6 flex-col items-end md:items-center md:space-y-0 md:flex-row bg-transparent" style="display:;" data-v-4064100e><h1 class="md-title flex w-full" data-v-4064100e><a href="/" to="/" class="text-3xl mx-auto md:ml-0 active text-current" data-v-8f7965c6 data-v-4064100e><img alt="StreamNative Logo" src="data:image/svg+xml,%3csvg fill='none' viewBox='0 0 543 101' xmlns='http://www.w3.org/2000/svg' xmlns:xlink='http://www.w3.org/1999/xlink'%3e%3cdefs%3e%3cfilter id='__svg-blur-bc72205a12167a70bff41472aa51bb7a'%3e%3cfeGaussianBlur in='SourceGraphic' stdDeviation='40'/%3e%3c/filter%3e%3c/defs%3e%3cimage x='0' y='0' filter='url(%23__svg-blur-bc72205a12167a70bff41472aa51bb7a)' width='543' height='101' xlink:href='data:image/png%3bbase64%2ciVBORw0KGgoAAAANSUhEUgAAAEAAAAAMCAYAAADS87vJAAAACXBIWXMAABfWAAAX1gFCcJy6AAAEdUlEQVRIx62We4xcUxjAz53ZrmJ3PVtCNd7bnXM7Y5e1BFniUYmooIiEFEmDJt5SBLVShFB6p4%2bklSoqaKRWCJVQqo2lGxErjXonVkLq3aqs6s4cv3PONzNnru3aP3qTX853z/N7nYdSi02zKpoelZi3YR2s5b9PLTRtyn6LTKRUDkELSsopavd/MRwbrBGumUvJ4dcU6hZ5KnO0/c%2baSXmjetIYHGEw1jg5MX%2brReUJrv269RkmygaTZ0RZ5DhTU1zvBgfk4SBVr3yOdQqyRixtUwOHhXqFOoxVn%2bVifBEWOuOHVbF8tWubO5gdeZAO6t3CFQVEjiv12SAakfxngugGY6tj4IDUelNSWRLOXQmI/Tps24FwSE230EEj6bXEGl16AEd04oBpKhn2OTNjlXSIG%2bj8EHwE6%2bB0qUfLOD82L4dK2u/osYx5ED6DWfL/PJy2i60zCU6WfvfB0yOvfVR6DWxMSg/LX0O1ft6WrGrprqT9FWCAkOk74H1ScC%2b/iP4ecJg%2bFFrhLJANqi%2bHq1CsRf4neWP0dPknUjG5rE/ydflGyovhBGlfDz9BH5GNRJ4hbTPhdll3b3gVvgM7XxdMA8KtO6Q/B4s%2bReSL4C6vt/36DZuuqVVlCttgaeCeSuqeCjvhBTgX4/dDceuML%2bEvZLaLng1/wntwKayCl2AZrKXPeMqXYT58CD1wNgzDc7BDjLDjt7MG2aXfkv4fe%2bX1gBh2JbwCj8Im5j6T8hP4Ay6DxyRb5sBXYsMaeArmwgdwK3wDksGNnXgtb1S20Ov%2bHx/qZmvsGaTKceKAbfCu1N0CG0S%2bAX4U%2bQjJGGvknWJcJ1wA18Nrfpw%2bD36WMb3eaU62hpDO%2bh0OwBspnxGj%2bv0cMXms74G7fWDiwyhv9g5z4xN4UTLuV9onU26GS7zD9GoJmM2YFUrN2iCRVv7UNybDzfC5emTr8e4/U7Bpv1Im73CO8mk/x%2b/RqjMGRG6VyM6WiNl0vRC2wBkSiT5xyGDggKLIv6F0l98CuZsoz4dv4Wu/VVwG2eif4x0dHyPOHggcsEbkAcnCT8mqfX1G6MU%2b8vra2rZIdubUm2YyV2A7xr/hrsL5Q/5QGd81VdLFeu8Lr6ybvFsiPQ%2bu8RGqZkzRp77bBkVZcFCUe1bSfbqfz/W32fWEyD9g1ImS5jigME7WH5KtsBw2ShZskrPJZkwJ7pesWy1z3Sv1SXCe9UuGvA4HK66/XowuqQWl7WoB5VJ7K5R/ZwtMDE7ZBn846Th1itr0O5z2PSj3rz/dnWL2gGuUf3tgkVXa9m2RUu67eB/kJnnkcCbF1uhmkG3o5Am1d4ebm/6xPYzHSR3tuYkyb3OgN3VxY6CXvSbba3OvcHd/7R2wzMrl21zbSrZDQ3tUb/SRcofnRnnNtUWjX4Pp/uFD6D/X4RiuzFw0%2bryVx1NaD3sNFs0/8AtsxRGbKWe6th4yJ9kRPksrj5awLqrV6Sj1WEm9zur6qvoxdU/eqPay3OXY1Dz5EepUqm%2bdXtW6fwFLNWlCtpnb4wAAAABJRU5ErkJggg==' /%3e%3c/svg%3e" width="543" data-src="/assets/static/sn-logo-vertical-dark.c516648.a34f97839dee38e7499aa0c21d0b2255.png" data-srcset="/assets/static/sn-logo-vertical-dark.c516648.a34f97839dee38e7499aa0c21d0b2255.png 543w" data-sizes="(max-width: 543px) 100vw, 543px" class="w-56 mt-4 md:mt-0 g-image g-image--lazy g-image--loading" data-v-4064100e><noscript data-v-4064100e><img src="/assets/static/sn-logo-vertical-dark.c516648.a34f97839dee38e7499aa0c21d0b2255.png" class="w-56 mt-4 md:mt-0 g-image g-image--loaded" width="543" alt="StreamNative Logo"></noscript></a></h1><div class="md-menu" data-v-4064100e><button type="button" md-menu-trigger="" class="md-button nav-button md-theme-default" data-v-4064100e><div class="md-ripple"><div class="md-button-content"><span data-v-4064100e>Products<i class="md-icon md-icon-font text-blue-light md-theme-default" data-v-4064100e>expand_more</i></span></div> </div></button><!----></div><div class="md-menu" data-v-4064100e><button type="button" md-menu-trigger="" class="md-button nav-button md-theme-default" data-v-4064100e><div class="md-ripple"><div class="md-button-content"><span data-v-4064100e>Open Source<i class="md-icon md-icon-font text-blue-light md-theme-default" data-v-4064100e>expand_more</i></span></div> </div></button><!----></div><div class="md-menu" data-v-4064100e><button type="button" md-menu-trigger="" class="md-button nav-button md-theme-default" data-v-4064100e><div class="md-ripple"><div class="md-button-content"><span data-v-4064100e>Resources<i class="md-icon md-icon-font text-blue-light md-theme-default" data-v-4064100e>expand_more</i></span></div> </div></button><!----></div><!----><a href="/contact/" class="md-button nav-button my-0 mr-5 md:mr-0 md-theme-default" data-v-4064100e><div class="md-ripple"><div class="md-button-content">Contact
          </div> </div></a><div class="z-10" data-v-1ca14dfe data-v-4064100e><!----></div><a filled="" target="_blank" href="https://console.streamnative.cloud/?defaultMethod=login" rel="noopener" class="sn-button text-blue-light md-raised mr-0 md:ml-5 text-current bg-gradient-to-r from-blue-light to-blue-lightest text-white border-transparent sn-button-fill" data-v-8f7965c6 data-v-8f7965c6 data-v-75f8c361 data-v-4064100e>Login
          </a></div></div></div><div style="padding-top:180px;" data-v-4064100e><div data-v-4064100e data-v-124acb4b><div class="article-share-icon" data-v-4064100e data-v-124acb4b><span data-v-4064100e data-v-124acb4b>share</span><a href="https://twitter.com/share?text=Benchmarking Pulsar and Kafka - A More Accurate Perspective on Pulsar’s Performance&amp;url=" data-v-4064100e data-v-124acb4b><img src="/uploads/images/twitter-icon.svg" alt="twitter" data-v-4064100e data-v-124acb4b></a><a href="https://www.linkedin.com/shareArticle?mini=true&amp;url=&amp;title=Benchmarking Pulsar and Kafka - A More Accurate Perspective on Pulsar’s Performance&amp;summary=This post presents StreamNative’s response to Confluent’s recent article “Benchmarking Apache Kafka, Apache Pulsar, and RabbitMQ: Which is the Fastest?”.&amp;source=streamnative" data-v-4064100e data-v-124acb4b><img src="/uploads/images/linkedin-icon.svg" alt="linkedIn" data-v-4064100e data-v-124acb4b></a></div><div class="container-main" data-v-4064100e data-v-124acb4b><ul class="breadcrumb mb-3" data-v-4064100e data-v-124acb4b><li data-v-4064100e data-v-124acb4b><a class="to-left" data-v-4064100e data-v-124acb4b></a></li><li class="ml-1" data-v-4064100e data-v-124acb4b><a href="/blogs/" to="/blogs/" class="all-articles text-blue-light text-current" data-v-8f7965c6 data-v-124acb4b>All articles ...
          </a></li></ul><div class="title" data-v-4064100e data-v-124acb4b><h2 class="text-3xl mb-1" data-v-4064100e data-v-124acb4b>Benchmarking Pulsar and Kafka - A More Accurate Perspective on Pulsar’s Performance</h2><h6 class="text-sm text-gray mb-4" data-v-4064100e data-v-124acb4b>November 9, 2020</h6></div><div class="author-list" data-v-4064100e data-v-124acb4b><div class="article-author mr-6" data-v-4064100e data-v-124acb4b><div class="author-img" data-v-4064100e data-v-124acb4b><img alt="head img" class="img-thumbnail article-head-img" data-v-4064100e data-v-124acb4b></div><div class="author-info" data-v-4064100e data-v-124acb4b><span data-v-4064100e data-v-124acb4b></span><!----><a href="" target="_blank" style="display:none;" data-v-4064100e data-v-124acb4b><img src="/uploads/images/linkedin-icon.svg" alt="linkedIn" class="article-social opacity-50" data-v-4064100e data-v-124acb4b></a></div></div></div><img src="/uploads/images/blogs/benchmark-pulsar-kafka/benchmark-pulsar-kafka-top.jpg" alt="head img" data-v-4064100e data-v-124acb4b><div class="markdown-body markdown font-text" data-v-4064100e data-v-124acb4b><div data-v-4064100e data-v-124acb4b><blockquote>
<p><strong>Note</strong>: This post presents StreamNative’s response to Confluent’s recent article <a href="https://www.confluent.io/blog/kafka-fastest-messaging-system/#benchmarking-framework" target="_blank" rel="nofollow noopener noreferrer">“Benchmarking Apache Kafka, Apache Pulsar, and RabbitMQ: Which is the Fastest?”</a>. For a brief overview of these systems, see our review of Pulsar vs. Kafka (<a href="https://streamnative.io/blog/tech/2020-07-08-pulsar-vs-kafka-part-1" target="_blank" rel="nofollow noopener noreferrer">part 1</a>, <a href="https://streamnative.io/blog/tech/2020-07-22-pulsar-vs-kafka-part-2" target="_blank" rel="nofollow noopener noreferrer">part 2</a>).</p>
</blockquote>
<h2 id="executive-summary"><a href="#executive-summary" aria-hidden="true"><span class="icon icon-link"></span></a>Executive Summary</h2>
<p>Today, many companies are looking at real-time data streaming applications to develop new products and services. Organizations must first understand the advantages and differentiators of the different event streaming systems before they can select the technology best-suited to meet their business needs. </p>
<p>Benchmarks are one method organizations use to compare and measure the performance of different technologies. In order for these benchmarks to be meaningful, they must be done correctly and provide accurate information.  Unfortunately, it is all too easy for benchmarks to fail to provide accurate insights due to any number of issues. </p>
<p>Confluent recently ran a benchmark to evaluate how Kafka, Pulsar, and RabbitMQ compare in terms of throughput and latency. According to Confluent’s blog, Kakfa was able to achieve the “best throughput” with “low latency” and RabbitMQ was able to provide “low latency” at “lower throughputs”. Overall, their benchmark declared Kafka the clear winner in terms of “speed”.</p>
<p>While Kafka is an established  technology, Pulsar is the top streaming technology of choice for many companies today, from global corporations to innovative start-ups. In fact, at the recent Splunk summit, conf20, Sendur Sellakumar, Splunk’s Chief Product Officer, discussed their decision to adopt Pulsar over Kafka:</p>
<blockquote>
<p>   "... we've shifted to Apache Pulsar as our underlying streaming. It is our bet on the long term architecture for enterprise-grade multi-tenant streaming."    </p>
<pre><code>    - Sendur Sellakumar, CPO, Splunk 
</code></pre>
</blockquote>
<p>This is just one of many examples of companies adopting Pulsar. These companies choose Pulsar because it provides the ability to horizontally and cost effectively scale to massive data volumes, with no single point of failure, in modern elastic cloud environments, like Kubernetes. At the same time, built-in features like automatic data rebalancing, multi-tenancy, geo-replication, and tiered storage with infinite retention, simplify operations and make it easier for teams to focus on business goals.</p>
<p>Ultimately, developers are adopting Pulsar for its features, performance, and because all of the unique aspects of Pulsar, mentioned above, make it well suited to be the backbone for streaming data.</p>
<p>Knowing what we know, we had to take a closer look at Confluent’s benchmark to try to understand their results. We found two issues that were highly problematic. First, and the largest source of inaccuracy, is Confluent’s limited knowledge of Pulsar. Without understanding the technology, they were not able to set-up the test in a way that could accurately measure Pulsar’s performance. </p>
<p>Second, their performance measurements were based on a narrow set of test parameters. This limited the applicability of the results and failed to provide readers with an accurate picture of the technologies’ capabilities across different workloads and real-world use cases. </p>
<p>In order to provide the community a more accurate picture, we decided to address these issues and repeat the test. Key updates included:</p>
<ol>
<li>We updated the benchmark setup to include all of the durability levels supported by Pulsar and Kafka. This allowed us to compare throughput and latency at the same level of durability. </li>
<li>We fixed the OpenMessaging Benchmark (OMB) framework to eliminate the variants introduced by using different instances, and corrected configuration errors in their OMB Pulsar driver. </li>
<li>Finally, we measured additional performance factors and conditions, such as varying numbers of partitions and mixed workloads that contain writes, tailing-reads, and catch-up reads to provide a more comprehensive view of performance. </li>
</ol>
<p>With these updates made, we repeated the test. The result - Pulsar significantly outperformed Kafka in scenarios that more closely resembled real-world workloads and matched Kafka’s performance in the basic scenario Confluent used. </p>
<p>The following section highlights the most important findings. A more comprehensive performance report in the section <a href="#streamnative-benchmark-results">StreamNative Benchmark Results</a> also gives detail of our test setup and additional commentary.</p>
<h3 id="streamnative-benchmark-result-highlights"><a href="#streamnative-benchmark-result-highlights" aria-hidden="true"><span class="icon icon-link"></span></a>StreamNative Benchmark Result Highlights</h3>
<h4 id="1-with-the-same-durability-guarantee-as-kafka-pulsar-achieves-605-mbs-publish-and-end-to-end-throughput-same-as-kafka-and-35-gbs-catch-up-read-throughput-35-times-higher-than-kafka-increasing-the-number-of-partitions-and-changing-durability-levels-have-no-impact-on-pulsars-throughput-however-the-kafkas-throughput-was-severely-impacted-when-changing-the-number-of-partitions-or-changing-durability-levels"><a href="#1-with-the-same-durability-guarantee-as-kafka-pulsar-achieves-605-mbs-publish-and-end-to-end-throughput-same-as-kafka-and-35-gbs-catch-up-read-throughput-35-times-higher-than-kafka-increasing-the-number-of-partitions-and-changing-durability-levels-have-no-impact-on-pulsars-throughput-however-the-kafkas-throughput-was-severely-impacted-when-changing-the-number-of-partitions-or-changing-durability-levels" aria-hidden="true"><span class="icon icon-link"></span></a>#1 With the same durability guarantee as Kafka, Pulsar achieves 605 MB/s publish and end-to-end throughput (same as Kafka), and 3.5 GB/s catch-up read throughput (3.5 times higher than Kafka). Increasing the number of partitions and changing durability levels have no impact on Pulsar's throughput. However, the Kafka's throughput was severely impacted when changing the number of partitions or changing durability levels.</h4>
<p>Table 1: Throughput differences between Pulsar and Kafka under different workloads with different durability guarantees</p>
<table>
    <thead>
        <tr>
            <th></th>
            <th>Durability Levels</th>
            <th>Partitions</th>
            <th>Pulsar</th>
            <th>Kafka</th>
        </tr>
    </thead>
    <tbody>
        <tr>
            <td rowspan=6>Peak Publish + Tailing Reads Throughput (MB/s)</td>
            <td rowspan=3>Level-1 Durability</td>
            <td>1</td>
            <td>300 MB/s</td>
            <td>160 MB/s</td>
        </tr>
        <tr>
            <td>100</td>
            <td>300 MB/s</td>
            <td>420 MB/s</td>
        </tr>
        <tr>
            <td>2000</td>
            <td>300 MB/s</td>
            <td>300 MB/s</td>
        </tr>
        <tr>
            <td rowspan=3>Level-2 Durability</td>
            <td>1</td>
            <td>300 MB/s</td>
            <td>180 MB/s</td>
        </tr>
        <tr>
            <td>100</td>
            <td>605 MB/s</td>
            <td>605 MB/s</td>
        </tr>
        <tr>
            <td>2000</td>
            <td>605 MB/s</td>
            <td>300 MB/s</td>
        </tr>
        <tr>
            <td rowspan=2>Peak Catch-up Reads Throughput (MB/s)</td>
            <td>Level-1 Durability</td>
            <td>100</td>
            <td>1.7 GB/s</td>
            <td>1 GB/s</td>
        </tr>
        <tr>
            <td>Level-2 Durability</td>
            <td>100</td>
            <td>3.5 GB/s</td>
            <td>1 GB/s</td>
        </tr>
    </tbody>
</table>
<blockquote>
<p>For details on "Level-1 Durability", see <a href="#an-overview-of-durability-in-distributed-systems">An Overview of Durability in Distributed Systems</a> section for detailed discussion on durability differences between Pulsar and Kafka.</p>
</blockquote>
<h4 id="2-pulsar-delivers-significantly-better-latency-than-kafka-in-each-of-the-different-test-cases-including-different-number-of-subscriptions-different-number-of-topics-and-different-durability-guarantees"><a href="#2-pulsar-delivers-significantly-better-latency-than-kafka-in-each-of-the-different-test-cases-including-different-number-of-subscriptions-different-number-of-topics-and-different-durability-guarantees" aria-hidden="true"><span class="icon icon-link"></span></a>#2: Pulsar delivers significantly better latency than Kafka in each of the different test cases (including different number of subscriptions, different number of topics, and different durability guarantees).</h4>
<p>Pulsar’s 99th percentile latency is within the range of 5 and 15 milliseconds.
Kafka’s 99th percentile latency can go up to seconds and is hugely impacted by the number of topics, subscriptions and different durability guarantees.</p>
<p>Table 2: End-to-End P99 Latency between Pulsar and Kafka of different number of subscriptions with different durability guarantees</p>
<table>
    <thead>
        <tr>
            <th></th>
            <th>Partitions & Subscriptions</th>
            <th>Local Durability</th>
            <th>Replication Durability</th>
            <th>Pulsar</th>
            <th>Kafka</th>
        </tr>
    </thead>
    <tbody>
        <tr>
            <td rowspan=8>End-to-End P99 Latency (ms)<br/>(Publish + Tailing Reads)</td>
            <td rowspan=4>100 Partitions, 1 Subscription</td>
            <td rowspan=2>Sync</td>
            <td>Ack-1</td>
            <td>5.86</td>
            <td>18.75</td>
        </tr>
        <tr>
            <td>Ack-2</td>
            <td>11.64</td>
            <td>64.62</td>
        </tr>
        <tr>
            <td rowspan=2>Async</td>
            <td>Ack-1</td>
            <td>5.33</td>
            <td>6.94</td>
        </tr>
        <tr>
            <td>Ack-2</td>
            <td>5.55</td>
            <td>10.43</td>
        </tr>
        <tr>
            <td rowspan=4>100 Partitions, 10 Subscriptions</td>
            <td rowspan=2>Sync</td>
            <td>Ack-1</td>
            <td>7.12</td>
            <td>145.10</td>
        </tr>
        <tr>
            <td>Ack-2</td>
            <td>14.65</td>
            <td>1599.79</td>
        </tr>
        <tr>
            <td rowspan=2>Async</td>
            <td>Ack-1</td>
            <td>6.84</td>
            <td>89.80</td>
        </tr>
        <tr>
            <td>Ack-2</td>
            <td>6.94</td>
            <td>1295.78</td>
        </tr>
    </tbody>
</table>
<p>Table 3: End-to-End P99 Latency between Pulsar and Kafka of different number of topics with different durability guarantees</p>
<table>
    <thead>
        <tr>
            <th></th>
            <th>Local Durability</th>
            <th>Replication Durability</th>
            <th>Partitions</th>
            <th>Pulsar</th>
            <th>Kafka</th>
        </tr>
    </thead>
    <tbody>
        <tr>
            <td rowspan=12>End-to-End P99 Latency (ms)<br/>(Publish + Tailing Reads)</td>
            <td rowspan=6>Sync</td>
            <td rowspan=3>Ack-1</td>
            <td>100</td>
            <td>5.86</td>
            <td>18.75</td>
        </tr>
        <tr>
            <td>5000</td>
            <td>6.26</td>
            <td>79236</td>
        </tr>
        <tr>
            <td>10000</td>
            <td>6.67</td>
            <td>187840</td>
        </tr>
        <tr>
            <td rowspan=3>Ack-2</td>
            <td>100</td>
            <td>11.64</td>
            <td>64.62</td>
        </tr>
        <tr>
            <td>5000</td>
            <td>14.38</td>
            <td>157960</td>
        </tr>
        <tr>
            <td>10000</td>
            <td>15.78</td>
            <td>197140</td>
        </tr>
        <tr>
            <td rowspan=6>Async</td>
            <td rowspan=3>Ack-1</td>
            <td>100</td>
            <td>5.33</td>
            <td>6.94</td>
        </tr>
        <tr>
            <td>5000</td>
            <td>5.75</td>
            <td>86641</td>
        </tr>
        <tr>
            <td>10000</td>
            <td>6.64</td>
            <td>184513</td>
        </tr>
        <tr>
            <td rowspan=3>Ack-2</td>
            <td>100</td>
            <td>5.55</td>
            <td>10.43</td>
        </tr>
        <tr>
            <td>5000</td>
            <td>6.20</td>
            <td>116028</td>
        </tr>
        <tr>
            <td>10000</td>
            <td>7.50</td>
            <td>200793</td>
        </tr>
    </tbody>
</table>
<h4 id="3-pulsar-provides-significantly-better-io-isolation-than-kafka-pulsars-99th-percentile-publish-latency-remains-around-5-milliseconds-when-there-are-consumers-catching-up-on-reading-historic-data-in-contrast-kafkas-latency-is-severely-impacted-by-catchup-reads-kafkas-99th-percentile-publish-latency-can-increase-from-milliseconds-to-multiple-seconds"><a href="#3-pulsar-provides-significantly-better-io-isolation-than-kafka-pulsars-99th-percentile-publish-latency-remains-around-5-milliseconds-when-there-are-consumers-catching-up-on-reading-historic-data-in-contrast-kafkas-latency-is-severely-impacted-by-catchup-reads-kafkas-99th-percentile-publish-latency-can-increase-from-milliseconds-to-multiple-seconds" aria-hidden="true"><span class="icon icon-link"></span></a>#3: Pulsar provides significantly better I/O isolation than Kafka. Pulsar’s 99th percentile publish latency remains around 5 milliseconds when there are consumers catching up on reading historic data. In contrast, Kafka’s latency is severely impacted by catchup reads. Kafka’s 99th percentile publish latency can increase from milliseconds to multiple seconds.</h4>
<p>Table 4: Publish P99 Latency between Pulsar and Kafka with catching up reads</p>
<table>
    <thead>
        <tr>
            <th></th>
            <th>Local Durability</th>
            <th>Replication Durability</th>
            <th>Pulsar</th>
            <th>Kafka</th>
        </tr>
    </thead>
    <tbody>
        <tr>
            <td rowspan=4>Publish  P99 Latency (ms)<br/>(Mixed Workload)</td>
            <td rowspan=2>Sync</td>
            <td>Ack-1</td>
            <td>5.89</td>
            <td>13.48</td>
        </tr>
        <tr>
            <td>Ack-2</td>
            <td>15.39</td>
            <td>2091.31</td>
        </tr>
        <tr>
            <td rowspan=2>Async</td>
            <td>Ack-1</td>
            <td>10.44</td>
            <td>9.51</td>
        </tr>
        <tr>
            <td>Ack-2</td>
            <td>35.51</td>
            <td>1014.95</td>
        </tr>
    </tbody>
</table>
<p>All of our benchmarks are <a href="https://github.com/streamnative/openmessaging-benchmark" target="_blank" rel="nofollow noopener noreferrer">open source</a>, so curious readers can repeat the test for themselves. Additionally, you can dig deeper into the results and metrics, which are available in the repository. </p>
<p>Although our benchmark is more accurate and more comprehensive than Confluent’s, it doesn’t cover every scenario. Ultimately, no benchmark can replace testing done on your own hardware with your own workloads. We encourage you to evaluate additional variables and scenarios and to test using your own setups and environments. </p>
<h2 id="content"><a href="#content" aria-hidden="true"><span class="icon icon-link"></span></a>CONTENT</h2>
<ul>
<li>
<p><a href="#a-deeper-look-confluent-benchmark">A Deeper Look Confluent Benchmark</a>   </p>
<ul>
<li><a href="#issues-with-confluent-setup">Issues with Confluent Setup</a></li>
<li><a href="#issues-with-omb-framework">Issues with OMB Framework</a></li>
<li><a href="#issues-with-confluent-methodology">Issues with Confluent Methodology</a></li>
</ul>
</li>
<li>
<p><a href="#an-overview-of-durability-in-distributed-systems">An Overview of Durability in Distributed Systems</a></p>
<ul>
<li><a href="#replication-durability-and-local-durability">Replication Durability and Local Durability</a></li>
<li><a href="#durability-modes-sync-vs-async">Durability Modes: Sync vs. Async</a></li>
<li><a href="#durability-levels-measuring-durability-guarantees">Durability Levels: Measuring durability guarantees</a></li>
<li><a href="#durability-in-pulsar">Durability in Pulsar</a></li>
<li><a href="#durability-in-kafka">Durability in Kafka</a></li>
<li><a href="#durability-differences-between-pulsar-and-kafka">Durability Differences Between Pulsar and Kafka</a></li>
</ul>
</li>
<li>
<p><a href="#streamnative-benchmark">StreamNative Benchmark</a></p>
<ul>
<li><a href="#streamnative-setup">StreamNative Setup</a></li>
<li><a href="#streamnative-framework">StreamNative Framework</a></li>
<li><a href="#streamnative-methodology">StreamNative Methodology</a></li>
</ul>
</li>
<li>
<p><a href="#testbed">Testbed</a></p>
<ul>
<li><a href="#disk-throughput">Disk Throughput</a></li>
<li><a href="#disk-data-sync-latency">Disk Data Sync Latency</a></li>
</ul>
</li>
<li>
<p><a href="#streamnative-benchmark-results">StreamNative Benchmark Results</a></p>
<ul>
<li><a href="#maximum-throughput-test">Maximum Throughput Test</a></li>
<li><a href="#publish-and-end-to-end-latency-test">Publish and End-to-End Latency Test</a></li>
<li><a href="#catch-up-read-test">Catch-Up Read Test</a></li>
<li><a href="#mixed-workload-test">Mixed Workload Test</a></li>
</ul>
</li>
<li><a href="#conclusion">Conclusion</a></li>
</ul>
<h2 id="a-deeper-look-at-confluent-benchmark"><a href="#a-deeper-look-at-confluent-benchmark" aria-hidden="true"><span class="icon icon-link"></span></a>A Deeper Look at Confluent Benchmark</h2>
<p>Confluent used the <a href="http://openmessaging.cloud/docs/benchmarks/" target="_blank" rel="nofollow noopener noreferrer">OpenMessaging Benchmark (OMB) Framework</a> as the basis for their benchmark with a few modifications. In this section, we describe the issues we found in Confluent’s benchmark and explain how they impacted Confluent’s test results and led to erroneous conclusions.</p>
<h3 id="issues-with-confluent-setup"><a href="#issues-with-confluent-setup" aria-hidden="true"><span class="icon icon-link"></span></a>Issues with Confluent Setup</h3>
<p>A fundamental problem with Confluent’s benchmark is that Pulsar was not set up properly. (We will talk more about this in the section on the StreamNative Benchmark). In addition to the issues tuning Pulsar, Pulsar and Kafka were set up with different durability guarantees. Because the level of durability impacts performance, the durability settings on both systems must be equivalent for a comparison to be meaningful. </p>
<p>Confluent’s engineers used the default durability guarantee for Pulsar, which is a much stronger guarantee than the configuration which was used for Kafka. Because increasing durability negatively impacts latency and throughput, Confluent’s test placed a much higher demand on Pulsar than it did on Kafka. In the version of Pulsar used by Confluent, there was not yet support for reducing the durability down to a level to match Kafka, but such a future will be released as part of Pulsar in an upcoming release and was used in this test. Had their engineers used this new equivalent durability setting on both systems, the test results would have allowed for an accurate comparison. We certainly don’t fault Confluent’s engineers for not using a not-yet-released feature, however, the writeup failed to provide the necessary context for these results and treated that as though they were equivalent, that additional context which will be provided here.</p>
<h3 id="issues-with-omb-framework"><a href="#issues-with-omb-framework" aria-hidden="true"><span class="icon icon-link"></span></a>Issues with OMB Framework</h3>
<p>Confluent’s benchmark followed OMB Framework guidelines, which recommend using the same instance type across multiple event streaming systems. However, in our testing we found large amounts of variance among different instances of the same type, particularly when it came to disk IO. In order to minimize this variance, we used the same instances from run to run for both Pulsar and Kafka, which we found significantly helped to increase the accuracy of the results, as even small variations in disk IO performance can result in much larger variance in overall system performance. We would suggest the OMB framework guidelines be updated to include this recommendation in the future.</p>
<h3 id="issues-with-confluent-methodology"><a href="#issues-with-confluent-methodology" aria-hidden="true"><span class="icon icon-link"></span></a>Issues with Confluent Methodology</h3>
<p>Confluent’s benchmark measured only a few, limited scenarios. For example, real-world workloads consist of writes, tailing reads, and catch-up reads. Tailing-reads occur when a consumer is reading recent messages near the “tail” of the log, which was the only scenario tested by Confluent. In contrast, a catch-up read is when a consumer has a large amount of backlog it must consume to “catch-up” to the tail of the log, which is a common and critical task in a real-world system.  Catch-up reads, when not taken into account, can severely impact the latency of writes and tailing reads. As Confluent’s benchmark focused only on throughput and end-to-end latency, it fails to give a complete picture of expected behavior across a variety of workloads. Likewise to further give a result closer to real-world use cases, we also considered it important  to run the benchmark with varying numbers of subscriptions and partitions. Very few organizations only care about a few topics with a handful of partitions and consumers, they need the ability to have large numbers of different consumers with a large number of distinct topics/partitions to map to their business use cases</p>
<p>To summarize, we have outlined specific issues with Confluent’s methodology in the following table:</p>
<p>Table 5: Issues with Confluent’s benchmark methodology</p>
<table>
<thead>
<tr>
<th>Parameters Tested</th>
<th>Exclusions</th>
<th>Limitations</th>
</tr>
</thead>
<tbody>
<tr>
<td>Writes and tailing reads</td>
<td>Catch-up reads</td>
<td>While maximum throughput and end-to-end latency are useful to illustrate the basic performance characteristics of an event streaming system, limiting the study to two parameters provides only a partial view of system performance.</td>
</tr>
<tr>
<td>1 subscription</td>
<td>Varying numbers of subscriptions / consumer groups</td>
<td>Did not show how the number of subscriptions impacts throughput and latency.</td>
</tr>
<tr>
<td>100 partitions</td>
<td>Varying numbers of partitions</td>
<td>Did not show how the number of partitions impacts throughput and latency.</td>
</tr>
</tbody>
</table>
<p>Many of the issues with Confluent’s benchmark stem from a limited understanding of Pulsar. To help others avoid these problems when running benchmarks in the future, we’ll provide some insights on the technology.</p>
<p>Understanding Pulsar’s durability guarantees is required in order to run an accurate benchmark, so we will begin our discussion there. We’ll start with a general overview of durability in distributed systems, and then explain the differences between the durability guarantees offered by Pulsar and Kafka. </p>
<h2 id="an-overview-of-durability-in-distributed-systems"><a href="#an-overview-of-durability-in-distributed-systems" aria-hidden="true"><span class="icon icon-link"></span></a>An Overview of Durability in Distributed Systems</h2>
<p>Durability refers to maintaining system consistency and availability in the face of external problems, such as a hardware or operating system failure. Single-node storage systems (such as RDBMS) will “fsync” writes to disk to ensure maximum durability. Operating systems will typically buffer writes, which can be lost in the event of failure, but an fsync will ensure these data is written to physical storage. In distributed systems, durability typically comes from replication, with multiple copies of the data being distributed to different nodes that can fail independently. However, it is important not to conflate local durability (fsyncing data) with replication durability, as they both have a distinct purpose. In the following sections, we explain some key differences between these features and why both are important. </p>
<h3 id="replication-durability-and-local-durability"><a href="#replication-durability-and-local-durability" aria-hidden="true"><span class="icon icon-link"></span></a>Replication durability and local durability</h3>
<p>Distributed systems typically provide both replication durability and local durability. Separate mechanisms control each type of durability. You can use these mechanisms in various combinations to set the desired level of durability.</p>
<p>Replication durability is achieved by using an algorithm to create multiple copies of data so the same data can be stored in several locations to improve availability and accessibility. The number of replicas N, determines the system’s failure tolerance, with many systems requiring a “quorum”, or N/2 + 1 nodes, to acknowledge a write. Some systems offer the ability to continue to serve existing data with any single replica still available.  This replication mechanism is key to handling the total loss of an instance, with a new instance able to re-replicate data from the existing replicas, while also being critical to availability and consensus (which is beyond the scope of this discussion).</p>
<p>By contrast, local durability determines what an acknowledgement means at the individual node level.  This requires fsyncing data to a persistent medium to ensure no data is lost, even if a power failure or hardware failure occurs. An fsync of data ensures that in the event of transient failure, where the machine can recover, the node has all the data for it’s previous acknowledgements.</p>
<h3 id="durability-modes-sync-vs-async"><a href="#durability-modes-sync-vs-async" aria-hidden="true"><span class="icon icon-link"></span></a>Durability Modes: Sync vs. Async</h3>
<p>Different types of systems offer varying levels of durability guarantees. In general, the level of overall durability any given system can provide depends on the following:</p>
<ul>
<li>Whether the system fsyncs data to local disks</li>
<li>Whether the system replicates data to multiple locations</li>
<li>When the system acknowledges replication to a peer</li>
<li>When the system acknowledges writes to the client</li>
</ul>
<p>Among different systems, these choices vary widely and not all systems give users the option to control these values, but in general,  systems that lack some of these  mechanisms  (such as replication in non-distributed systems) offer less durability. </p>
<p>To discuss this more concretely, we can define two durability modes which control when a system acknowledges writes, both internally for replication and to the client. These are “sync”
and “async”. These modes operate as described below.</p>
<ul>
<li><b>Sync Durability</b>: The system returns a write response to the peer/client ONLY AFTER the data has been successfully f-synced to local disks (local durability) or replicated to multiple locations (replication durability).</li>
<li><b>Async Durability</b>: The system returns a write response to the peer/client BEFORE the data has been successfully f-synced to local disks (local durability) or replicated to multiple locations (replication durability).</li>
</ul>
<h3 id="durability-levels-measuring-durability-guarantees"><a href="#durability-levels-measuring-durability-guarantees" aria-hidden="true"><span class="icon icon-link"></span></a>Durability Levels: Measuring durability guarantees</h3>
<p>Durability guarantees can take many forms and depend on the following variables:</p>
<ul>
<li>Whether data is stored locally, replicated in multiple locations, or both</li>
<li>When writes are acknowledged (sync vs. async)</li>
</ul>
<p>Like with durability mode, we define some durability “levels” which we can use to differentiate between different distributed systems. We define  four levels. Table 6 describes each, from the highest level of durability to the lowest.</p>
<p>Table 6: Durability Levels of Distributed Systems</p>
<table>
<thead>
<tr>
<th>Level</th>
<th>Replication</th>
<th>Local</th>
<th>Operation</th>
</tr>
</thead>
<tbody>
<tr>
<td>1</td>
<td>Sync</td>
<td>Sync</td>
<td>The system returns a write response to the client ONLY AFTER the data has been replicated to multiple (at least the majority of) locations AND each replica has been successfully fsync-ed to local disks.</td>
</tr>
<tr>
<td>2</td>
<td>Sync</td>
<td>Async</td>
<td>The system returns a write response to the client ONLY AFTER the data has been replicated to multiple (at least the majority of) locations.There is no guarantee that each replica has successfully fsync-ed to local disks.</td>
</tr>
<tr>
<td>3</td>
<td>Async</td>
<td>Sync</td>
<td>The system returns a write response to the client when one replica has been successfully fsync-ed to a local disk. There is no guarantee that data is replicated to the other locations.</td>
</tr>
<tr>
<td>4</td>
<td>Async</td>
<td>Async</td>
<td>The system returns a write response to the client immediately after the data has been replicated to multiple locations. There are no replication or local durability guarantees.</td>
</tr>
</tbody>
</table>
<p>Most distributed relational database management systems (such as NewSQL databases) guarantee the highest level of durability; therefore, they would be categorized as Level 1.</p>
<p>Much like a database, Pulsar is a Level 1 system that provides the highest level of durability by default. In addition, Pulsar allows the option to customize the desired durability level for each application individually. By contrast, most of Kafka production deployments are configured to operate as either a Level 2 or Level 4 system. Based on our limited knowledge on Kafka, Kafka can be configured to operate as a Level 1 system by setting <code>flush.messages</code> to <code>1</code> and <code>flush.ms</code> to <code>0</code>.
But configuring those 2 settings has a severe impact on both throughput and latency. We will discuss it more in our benchmark results.</p>
<p>We’ll look at the durability capabilities of each in detail, beginning with Pulsar.</p>
<h3 id="durability-in-pulsar"><a href="#durability-in-pulsar" aria-hidden="true"><span class="icon icon-link"></span></a>Durability in Pulsar</h3>
<p>Pulsar offers durability guarantees at all levels. It can replicate data to multiple locations and fsync data to local disks. Pulsar has two durability modes (sync and async described earlier). Each option is individually configurable. You can use them in various combinations to customize settings for individual use cases.</p>
<p>Pulsar controls replication durability using a raft-equivalent, quorum-based replication protocol. You can tune the durability mode for replication durability by adjusting the <code>ack-quorum-size</code> and <code>write-quorum-size</code> parameters. The settings for these parameters are described in Table 7 below. The durability levels supported by Pulsar are described in Table 8 below. (A detailed discussion of Pulsar’s replication protocol and consensus algorithm are beyond the scope of this article; however, we will explore these areas in depth in a future blog post.)</p>
<p>Table 7: Durability Configuration Settings in Pulsar</p>
<table>
    <thead>
        <tr>
            <th></th>
            <th>Configuration Settings</th>
            <th>Durability Mode</th>
        </tr>
    </thead>
    <tbody>
        <tr>
            <td rowspan=2>Replication</td>
            <td>ackQuorumSize = 1</td>
            <td>Async</td>
        </tr>
        <tr>
            <td>ackQuorumSize  ≥ writeQuorumSize / 2 + 1</td>
            <td>Sync</td>
        </tr>
        <tr>
            <td rowspan=3>Local</td>
            <td>(default)<br/>journalWriteData = true<br/>journalSyncData = true</td>
            <td>Sync</td>
        </tr>
        <tr>
            <td>journalWriteData = true<br/>journalSyncData = false</td>
            <td>Async</td>
        </tr>
        <tr>
            <td>journalWriteData = false<br/>journalSyncData = false</td>
            <td>Async</td>
        </tr>
    </tbody>
</table>
<p>Table 8: Durability Levels in Pulsar</p>
<table>
    <thead>
        <tr>
            <th>Durability Level</th>
            <th>Replication Durability</th>
            <th>Local Durability</th>
        </tr>
    </thead>
    <tbody>
        <tr>
            <td>Level 1</td>
            <td>Sync:<br/>ackQuorumSize  ≥ writeQuorumSize / 2 + 1</td>
            <td>Sync:<br/>journalWriteData = true<br/>journalSyncData = true</td>
        </tr>
        <tr>
            <td>Level 3</td>
            <td>Async:<br/>ackQuorumSize = 1</td>
            <td>Sync:<br/>journalWriteData = true<br/>journalSyncData = true</td>
        </tr>
        <tr>
            <td>Level 2</td>
            <td>Sync:<br/>ackQuorumSize  ≥ writeQuorumSize / 2 + 1</td>
            <td>Async:<br/>journalWriteData = true<br/>journalSyncData = false</td>
        </tr>
        <tr>
            <td>Level 4</td>
            <td>Async:<br/>ackQuorumSize = 1</td>
            <td>Async:<br/>journalWriteData = true<br/>journalSyncData = false</td>
        </tr>
        <tr>
            <td>Level 2</td>
            <td>Sync:<br/>ackQuorumSize  ≥ writeQuorumSize / 2 + 1</td>
            <td>Async:<br/>journalWriteData = false<br/>journalSyncData = false</td>
        </tr>
        <tr>
            <td>Level 4</td>
            <td>Async:<br/>ackQuorumSize = 1</td>
            <td>Async:<br/>journalWriteData = false<br/>journalSyncData = false</td>
        </tr>
    </tbody>
</table>
<p>Pulsar controls local durability by writing and/or fsyncing data to a journal disk(s). Pulsar also provides options for tuning the local durability mode using the configuration parameters in Table 9:</p>
<p>Table 9: Pulsar’s Local Durability Mode Parameters</p>
<table>
<thead>
<tr>
<th>Parameter</th>
<th>Description</th>
<th>Values</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>journalWriteData</code></td>
<td>Controls whether a bookie writes data to its journal disks before persisting data to the ledger disks</td>
<td><code>true</code> = enable journaling<br/><code>false</code>= disable journaling</td>
</tr>
<tr>
<td><code>journalSyncData</code></td>
<td>Controls whether a bookie fsyncs data to journal disks before returning a write acknowledgement to brokers</td>
<td><code>true</code> = enable fsync<br/><code>false</code>= disable fsync</td>
</tr>
</tbody>
</table>
<h3 id="durability-in-kafka"><a href="#durability-in-kafka" aria-hidden="true"><span class="icon icon-link"></span></a>Durability in Kafka</h3>
<p>Kafka offers three durability levels: Level 1, Level 2 and Level 4. Kafka can provide replication durability at Level 2 (default settings), but offers no durability guarantees at Level 4 because it lacks the ability to fsync data to disks before acknowledging writes. Kafka can be configured to operate as a Level 1 system by setting <code>flush.messages</code> to <code>1</code> and <code>flush.ms</code> to <code>0</code>. However such setup is rarely seen in Kafka production deployments.</p>
<p>Kafka’s ISR replication protocol controls replication durability. You can tune Kafka’s replication durability mode by adjusting the <code>acks</code> and <code>min.insync.replicas</code> parameters associated with this protocol. The settings for these parameters are described in Table 10 below. The durability levels supported by Kafka are described in Table 11 below. (A detailed explanation of Kafka’s  replication protocol is beyond the scope of this article; however, we will explore how Kafka’s protocol differs from Pulsar’s in a future blog post.)</p>
<p>Table 10: Durability Configuration Settings in Kafka</p>
<table>
    <thead>
        <tr>
            <th></th>
            <th>Configuration Settings</th>
            <th>Durability Mode</th>
        </tr>
    </thead>
    <tbody>
        <tr>
            <td rowspan=2>Replication</td>
            <td>acks = 1</td>
            <td>Async</td>
        </tr>
        <tr>
            <td>acks = all</td>
            <td>Sync</td>
        </tr>
        <tr>
            <td rowspan=2>Local</td>
            <td>Default fsync settings</td>
            <td>Async</td>
        </tr>
        <tr>
            <td>flush.messages = 1<br/>flush.ms = 0</td>
            <td>Sync</td>
        </tr>
    </tbody>
</table>
<p>Table 11: Durability Levels in Kafka</p>
<table>
    <thead>
        <tr>
            <th>Durability Level</th>
            <th>Replication Durability</th>
            <th>Local Durability</th>
        </tr>
    </thead>
    <tbody>
        <tr>
            <td>Level 2</td>
            <td>Sync:<br/>acks = all</td>
            <td>Async:<br/>Default fsync settings</td>
        </tr>
        <tr>
            <td>Level 4</td>
            <td>Async:<br/>acks = 1</td>
            <td>Async:<br/>Default fsync settings</td>
        </tr>
        <tr>
            <td>Level 1</td>
            <td>Sync:<br/>acks = all</td>
            <td>Sync:<br/>flush.messages = 1<br/>flush.ms = 0</td>
        </tr>
        <tr>
            <td>Level 4</td>
            <td>Async:<br/>acks = 1</td>
            <td>Sync:<br/>flush.messages = 1<br/>flush.ms = 0</td>
        </tr>
    </tbody>
</table>
<p>Unlike Pulsar, Kafka does not write data to a separate journal disk(s). Instead, Kafka acknowledges writes before fsyncing data to disks. This operation minimizes I/O contention between writes and reads, and prevents performance degradation. </p>
<p>Kafka’s does offer the ability to fsync after every message, with the above <code>flush.messages = 1</code> and <code>flush.ms = 0</code>, and while this can be used to greatly reduce the likelihood of message loss, however it severely impacts the throughput and latency, which ultimately means such settings is rarely used in production deployments.</p>
<p>Kafka’s inability to journal data makes it vulnerable to data loss in the event of a machine failure or power outage. This is a significant weakness, and one of the main reasons why <a href="https://streamnative.io/whitepaper/case-study-apache-pulsar-tencent-billing" target="_blank" rel="nofollow noopener noreferrer">Tencent chose Pulsar for their new billing system</a>.</p>
<h3 id="durability-differences-between-pulsar-and-kafka"><a href="#durability-differences-between-pulsar-and-kafka" aria-hidden="true"><span class="icon icon-link"></span></a>Durability Differences Between Pulsar and Kafka</h3>
<p>Pulsar’s durability settings are highly configurable and allow users to optimize durability settings to meet the requirements of an individual application, use case, or hardware configuration. </p>
<p>Because Kafka offers less flexibility, depending on the scenario, it is not always possible to establish equivalent durability settings in both systems. This makes benchmarking difficult. To address this, the OMB Framework recommends using the closest settings available. </p>
<p>With this background, we can now describe the gaps in Confluent’s benchmark. Confluent attempted to simulate Pulsar’s fsyncing behavior. In Kafka, the settings Confluent chose provide async durability. However, the settings they chose for Pulsar provide sync durability. This discrepancy produced flawed test results that inaccurately portrayed Pulsar’s performance as inferior. As you will see when we review the results of our own benchmark later, Pulsar performs as well as or better than Kafka, while offering stronger durability guarantees. </p>
<h2 id="streamnative-benchmark"><a href="#streamnative-benchmark" aria-hidden="true"><span class="icon icon-link"></span></a>StreamNative Benchmark</h2>
<p>To get a more accurate picture of Pulsar’s performance, we needed to address the issues with the Confluent benchmark. We focused on tuning Pulsar’s configuration, ensuring the durability settings on both systems were equivalent, and including additional performance factors and conditions, such as varying numbers of partitions and mixed workloads, to enable us to measure performance across different use cases. The following sections explain the changes we made in detail. </p>
<h3 id="streamnative-setup"><a href="#streamnative-setup" aria-hidden="true"><span class="icon icon-link"></span></a>StreamNative Setup</h3>
<p>Our benchmarking setup included all the durability levels supported by Pulsar and Kafka. This allowed us to compare throughput and latency at the same level of durability. The durability settings we used are described below.</p>
<h4 id="replication-durability-setup"><a href="#replication-durability-setup" aria-hidden="true"><span class="icon icon-link"></span></a>Replication Durability Setup</h4>
<p>Our replication durability setup was identical to Confluent’s. Although we made no changes, we are sharing the specific settings we used in Table 12 for completeness.</p>
<p>Table 12: Replication Durability Setup Settings</p>
<table>
    <thead>
        <tr>
            <th></th>
            <th>Durability Mode</th>
            <th>Configurations</th>
        </tr>
    </thead>
    <tbody>
        <tr>
            <td rowspan=2>Pulsar</td>
            <td>Sync</td>
            <td>ensemble-size=3<br/>write-quorum-size=3<br/>ack-quorum-size=2</td>
        </tr>
        <tr>
            <td>Async</td>
            <td>ensemble-size=3<br/>write-quorum-size=3<br/>ack-quorum-size=1</td>
        </tr>
        <tr>
            <td rowspan=2>Kafka</td>
            <td>Sync</td>
            <td>replicas=3<br/>acks=all<br/>min.insync.replicas=2</td>
        </tr>
        <tr>
            <td>Async</td>
            <td>replicas=3<br/>acks=1<br/>min.insync.replicas=2</td>
        </tr>
    </tbody>
</table>
<p>A new Pulsar <a href="https://github.com/apache/bookkeeper/pull/2401" target="_blank" rel="nofollow noopener noreferrer">feature</a> gives applications the option to skip journaling, which relaxes the local durability guarantee, avoids write amplification, and improves write throughput. (This feature will be available in the next release of Apache BookKeeper). However, this feature will not be made the default, nor do we recommend it for most scenarios, as it still introduces the potential for message loss. </p>
<p>We used this feature in our benchmark to ensure an accurate performance comparison between the two systems. Bypassing journaling on Pulsar provides the same local durability guarantee as Kafka’s default fsync settings. </p>
<p>Pulsar’s new feature includes a new local durability mode (<code>Async - Bypass journal</code>).  We used this mode to configure Pulsar to match Kafka’s default level of local durability. Table 13 shows the specific settings for our benchmark.</p>
<p>Table 13: Local Durability Setup Settings for StreamNative’s Benchmark</p>
<table>
    <thead>
        <tr>
            <th></th>
            <th>Durability Mode</th>
            <th>Configurations</th>
        </tr>
    </thead>
    <tbody>
        <tr>
            <td rowspan=3>Pulsar</td>
            <td>Sync (default)</td>
            <td>journalWriteData=true<br/>journalSyncData=true<br/>journalMaxGroupWaitMSec=1</td>
        </tr>
        <tr>
            <td>Async<br/>(write to journal)</td>
            <td>journalWriteData=true<br/>journalSyncData=false<br/>journalMaxGroupWaitMSec=1<br/>journalPageCacheFlushIntervalMSec=1000</td>
        </tr>
        <tr>
            <td>Async<br/>(bypass journaling)</td>
            <td>journalWriteData=false<br/>journalSyncData=false</td>
        </tr>
        <tr>
            <td rowspan=2>Kafka</td>
            <td>Sync</td>
            <td>flush.messages=1<br/>flush.ms=0</td>
        </tr>
        <tr>
            <td>Async (default)</td>
            <td>flush.messages=10000 (default)<br/>flush.ms=1000 (default)</td>
        </tr>
    </tbody>
</table>
<h2 id="streamnative-framework"><a href="#streamnative-framework" aria-hidden="true"><span class="icon icon-link"></span></a>StreamNative Framework</h2>
<p>We fixed some issues in <a href="https://github.com/confluentinc/openmessaging-benchmark" target="_blank" rel="nofollow noopener noreferrer">Confluent’s OMB Framework fork</a> and corrected configuration errors in their OMB Pulsar driver. The new benchmarking code we developed, including the fixes described below, is available as <a href="https://github.com/streamnative/openmessaging-benchmark/tree/blog" target="_blank" rel="nofollow noopener noreferrer">open source</a>.</p>
<h3 id="fixes-in-the-omb-framework"><a href="#fixes-in-the-omb-framework" aria-hidden="true"><span class="icon icon-link"></span></a>Fixes in the OMB Framework</h3>
<p>Confluent followed the OMB Framework’s recommendation to use two sets of instances—one for Kafka and another for Pulsar. For our benchmark, we allocated one set of three instances to eliminate variations. In our first test, we deployed all three instances on Pulsar. Then, we repeated the test on Kafka using the same set of instances.</p>
<p>Because we used the same machines for benchmarking different systems, we cleared the filesystem pagecache before each run. This ensured the current test would not be impacted by previous activity.</p>
<h3 id="fixes-in-the-omb-pulsar-driver-configuration"><a href="#fixes-in-the-omb-pulsar-driver-configuration" aria-hidden="true"><span class="icon icon-link"></span></a>Fixes in the OMB Pulsar Driver Configuration</h3>
<p>We fixed a number of errors in Confluent’s OMB Pulsar driver configuration. The following sections explain the specific changes we made to the broker, bookie, producer, consumer, and Pulsar image.</p>
<h4 id="broker-changes"><a href="#broker-changes" aria-hidden="true"><span class="icon icon-link"></span></a>Broker Changes</h4>
<p>Pulsar brokers use the <code>managedLedgerNewEntriesCheckDelayInMillis</code> parameter to determine the length of time (in milliseconds) a catch-up subscription must wait before dispatching messages to its consumers. In the OMB Framework, the value for this parameter was set to <code>10</code>. This was the main reason why Confluent’s benchmark inaccurately showed Pulsar to have higher latency than Kafka. We changed the value to <code>0</code> to emulate Kafka’s latency behavior on Pulsar. After making this change, Pulsar showed significantly better latency than Kafka in all test cases.</p>
<p>Additionally, to optimize performance, we increased the value of the <code>bookkeeperNumberOfChannelsPerBookie</code>parameter from <code>16</code> to <code>64</code> to prevent any single Netty channel between a broker and a bookie from becoming a bottleneck. Such bottlenecks cause high latency when large volumes of messages accumulate in a Netty IO queue.</p>
<p>We intend on providing this guidance more clearly in the Pulsar documentation to help users who are looking to optimize entirely for end-to-end latency.</p>
<h4 id="bookie-changes"><a href="#bookie-changes" aria-hidden="true"><span class="icon icon-link"></span></a>Bookie Changes</h4>
<p>We added a new bookie configuration to test Pulsar’s performance when bypassing journaling. See the Durability section for a discussion on this and recall that with this feature, we more closely match Kafka’s durability guarantees. </p>
<p>To test the performance of this feature, we built a customized image based on the official Pulsar 2.6.1 release to include this change. (For more details, see <a href="https://github.com/streamnative/pulsar/releases/download/v2.6.1-sn-16/apache-pulsar-2.6.1-sn-16-bin.tar.gz" target="_blank" rel="nofollow noopener noreferrer">Pulsar Image</a>.)</p>
<p>We configured the following settings manually to bypass journaling in Pulsar. </p>
<pre><code>journalWriteData=false
journalSyncData=false
</code></pre>
<p>Additionally, we changed the value of the <code>journalPageCacheFlushIntervalMSec</code> parameter from <code>1</code> to <code>1000</code> to benchmark async local durability (<code>journalSyncData=false</code>) in Pulsar. Increasing the value enabled Pulsar to simulate Kafka’s flushing behavior as described below.</p>
<p>Kafka ensures local durability by flushing dirty pages in the filesystem page cache to disks. Data is flushed by a set of background threads called <a href="https://lwn.net/Articles/326552/" target="_blank" rel="nofollow noopener noreferrer">pdflush</a>. <code>Pdflush</code> is configurable and the wait time between flushes is typically set to 5 seconds. Setting Pulsar’s <code>journalPageCacheFlushIntervalMSec</code> parameter to <code>1000</code>  is equivalent to a 5-second pdflush interval on Kafka. Making this change enabled us to benchmark async local durability more precisely and achieve a more accurate comparison between Pulsar and Kafka.</p>
<h4 id="producer-changes"><a href="#producer-changes" aria-hidden="true"><span class="icon icon-link"></span></a>Producer Changes</h4>
<p>Our batching configuration was identical to Confluent’s with one exception: We increased the switch interval to make it longer than the batch interval. Specifically, we changed the value of the <code>batchingPartitionSwitchFrequencyByPublishDelay</code> parameter from <code>1</code> to <code>2</code>. This change ensured Pulsar’s producer would focus on only one partition during each batching period. </p>
<p>Setting the switch interval and the batch interval to the same value can cause Pulsar to switch partitions more often than necessary, which generates too many small batches and can potentially impact throughput. Making the switch interval larger than the batch interval minimizes this risk.</p>
<h4 id="consumer-changes"><a href="#consumer-changes" aria-hidden="true"><span class="icon icon-link"></span></a>Consumer Changes</h4>
<p>Pulsar clients use receiver queues to apply back pressure when applications are unable to process incoming messages fast enough. The size of the consumer receiver queue can affect end-to-end latency. A larger queue can pre-fetch and buffer more messages than a smaller one.</p>
<p>Two parameters determine the size of the receiver queue: <code>receiverQueueSize</code> and <code>maxTotalReceiverQueueSizeAcrossPartitions</code>. Pulsar calculates the receiver queue size as follows:</p>
<pre><code>Math.min(receiverQueueSize, maxTotalReceiverQueueSizeAcrossPartitions / number of partitions)
</code></pre>
<p>For example, if <code>maxTotalReceiverQueueSizeAcrossPartitions</code> is set to 50000 and you have 100 partitions, the Pulsar client sets the consumer’s receiver queue size to 500 on each partition. </p>
<p>For our benchmark, we increased <code>maxTotalReceiverQueueSizeAcrossPartitions</code> from <code>50000</code> to <code>5000000</code>. This tuning optimization ensured consumers would not apply back pressure. </p>
<h4 id="pulsar-image"><a href="#pulsar-image" aria-hidden="true"><span class="icon icon-link"></span></a>Pulsar Image</h4>
<p>We built a customized Pulsar release (v. 2.6.1-sn-16) to include the Pulsar and BookKeeper fixes described above. Version 2.6.1-sn-16 is based on the official Pulsar 2.6.1 release and available to download at <a href="https://github.com/streamnative/pulsar/releases/download/v2.6.1-sn-16/apache-pulsar-2.6.1-sn-16-bin.tar.gz" target="_blank" rel="nofollow noopener noreferrer">here</a>.</p>
<h3 id="streamnative-methodology"><a href="#streamnative-methodology" aria-hidden="true"><span class="icon icon-link"></span></a>StreamNative Methodology</h3>
<p>We updated Confluent’s benchmarking methodology to get a more comprehensive view of performance using real-world workloads. Specifically, we made the following changes for our test:</p>
<ul>
<li>Added catch-up reads to evaluate the following:</li>
    <ul>
    <li>The maximum level of throughput each system can achieve when processing catch-up reads</li>
    <li>How reads impact publish and end-to-end latency</li>
    </ul>
<li>Varied the number of partitions to see how each change impacted throughput and latency</li>
<li>Varied the number of subscriptions to see how each change impacted throughput and latency</li>
</ul>
<p>Our benchmark scenarios measured the following types of workloads:</p>
<ul>
<li><b>Maximum Throughput</b>: What is the maximum throughput each system can achieve?</li>
<li><b>Publish and Tailing Read Latency</b>: What are the minimum publish and end-to-end tailing latency levels each system can achieve for a given throughput?</li>
<li><b>Catch-up Reads</b>: What is the maximum throughput each system can achieve when reading messages from a large backlog?</li>
<li><b>Mixed Workload</b>: What are the minimum publish and end-to-end tailing latency levels each system can achieve while consumers are catching up? How do catch-up reads impact publish latency and end-to-end tailing latency?</li>
</ul>
<h2 id="testbed"><a href="#testbed" aria-hidden="true"><span class="icon icon-link"></span></a>Testbed</h2>
<p>The OMB Framework recommends specific testbed definitions (for instance types and JVM configurations) and workload driver configurations (for the producer, consumer, and server side). Our benchmark used the same testbed definitions as Confluent’s. These testbed definitions can be found in <a href="https://github.com/streamnative/openmessaging-benchmark/tree/blog" target="_blank" rel="nofollow noopener noreferrer">our fork</a> within Confluent’s OMB repository. </p>
<p>Below, we highlight the disk throughput and disk fsync latency we observed. These hardware metrics are important to consider when interpreting benchmark results.</p>
<h3 id="disk-throughput"><a href="#disk-throughput" aria-hidden="true"><span class="icon icon-link"></span></a>Disk Throughput</h3>
<p>Our benchmark used the same instance type as Confluent’s—specifically,<code>i3en.2xlarge</code> (with 8 vCores, 64 GB RAM, 2 x 2, 500 GB NVMe SSDs). We confirmed that <code>i3en.2xlarge</code> instances can support up to ~655 MB/s of write throughput across two disks. See the <a href="https://wiki.archlinux.org/index.php/Dd" target="_blank" rel="nofollow noopener noreferrer"><code>dd</code></a> result below.</p>
<pre><code>Disk 1
dd if=/dev/zero of=/mnt/data-1/test bs=1M count=65536 oflag=direct
65536+0 records in
65536+0 records out
68719476736 bytes (69 GB) copied, 210.08 s, 327 MB/s

Disk 2
dd if=/dev/zero of=/mnt/data-2/test bs=1M count=65536 oflag=direct
65536+0 records in
65536+0 records out
68719476736 bytes (69 GB) copied, 209.635 s, 328 MB/s
</code></pre>
<h3 id="disk-data-sync-latency"><a href="#disk-data-sync-latency" aria-hidden="true"><span class="icon icon-link"></span></a>Disk data sync latency</h3>
<p>It is critical to capture the fsync latency on NVMe SSDs when running latency-related tests. We observed that the 99th percentile fsync latency on these 3 instances varies from 1 millisecond to 6 milliseconds as shown in the following diagram. As was mentioned earlier, we saw large amounts of variance of disks from different instances. That was primarily manifested in this latency and we found a set of instances that exhibited consistent latency.</p>
<p><img src="/uploads/images/blogs/benchmark-pulsar-kafka/figure14.png">
Figure 14: 99th percentile fsync latency on 3 different instances</p>
<h2 id="streamnative-benchmark-results"><a href="#streamnative-benchmark-results" aria-hidden="true"><span class="icon icon-link"></span></a>StreamNative Benchmark Results</h2>
<p>We have summarized our benchmark results below. You can find our <a href="https://streamnative.io/blog/tech/2020-11-09-benchmark-pulsar-kafka-performance-report" target="_blank" rel="nofollow noopener noreferrer">complete benchmark report</a>.  </p>
<h3 id="maximum-throughput-test"><a href="#maximum-throughput-test" aria-hidden="true"><span class="icon icon-link"></span></a>Maximum Throughput Test</h3>
<blockquote>
<p>See the full report of “Maximum Throughput Test” <a href="https://streamnative.io/blog/tech/2020-11-09-benchmark-pulsar-kafka-performance-report#maximum-throughput-test" target="_blank" rel="nofollow noopener noreferrer">here</a>.</p>
</blockquote>
<p>The Maximum Throughput Test was designed to determine the maximum throughput each system can achieve when processing workloads that include publish and tailing-reads under different durability guarantees. We also varied the number of topic partitions to see how each change impacted the maximum throughput.</p>
<p>We found that:</p>
<ol>
<li> When configured to provide level-1 durability (sync replication durability and sync local durability), Pulsar achieved a throughput of ~300 MB/s, which reached the physical limit of the journal disk’s bandwidth. Pulsar is implemented on top of a scalable and durable log storage (Apache BookKeeper) to make maximum use of disk bandwidth without sacrificing durability guarantees. Kafka was able to achieve ~420 MB/s with 100 partitions. It should be noted that when providing level-1 durability, Pulsar was configured to use one disk as journal disk for writes and the other disk as ledger disk for reads, comparing to Kafka use both disks for writes and reads. While Pulsar's setup is able to provide better I/O isolation, its throughput was also limited by the maximum bandwidth of a single disk (~300 MB/s). Alternative disk configurations can be beneficial to Pulsar and allow for more cost effective operation, which will be discussed in a later blog post. </li>
<li> When configured to provide level-2 durability (sync replication durability and async local durability), Pulsar and Kafka each achieved a max throughput of ~600 MB/s. Both systems reached the physical limit of disk bandwidth. </li>
<li> The maximum throughput of Kafka on one partition is only ½ of the max throughput of Pulsar. </li>
<li> Varying the number of partitions had no effect on Pulsar’s throughput, but it did affect Kafka’s.
    <ul>
    <li> Pulsar sustained maximum throughput (~300 MB/s under a level-1 durability guarantee and ~600 MB/s under a level-2 durability guarantee) as the number of partitions was increased from 100 to 2000.</li>
    <li> Kafka’s throughput decreased by half as the number of partitions was increased from 100 to 2000.</li>
    </ul>
</li>
</ol>
<h3 id="publish-and-end-to-end-latency-test"><a href="#publish-and-end-to-end-latency-test" aria-hidden="true"><span class="icon icon-link"></span></a>Publish and End-to-End Latency Test</h3>
<blockquote>
<p>See the full report of “Publish and End-to-End Latency Test” <a href="https://streamnative.io/blog/tech/2020-11-09-benchmark-pulsar-kafka-performance-report#publish-and-end-to-end-latency-test" target="_blank" rel="nofollow noopener noreferrer">here</a>.</p>
</blockquote>
<p>The Publish and End-to-End Latency Test was designed to determine the lowest latency each system can achieve when processing workloads that consist of publish and tailing-reads under different durability guarantees. We varied the number of subscriptions and the number of partitions to see how each change impacted both publish and end-to-end latency.</p>
<p>We found that</p>
<ol>
<li> Pulsar’s publish and end-to-end latency were significantly (up to hundreds of times) lower than Kafka’s in all test cases, which evaluated various durability guarantees and varying numbers of partitions and subscriptions. Pulsar’s 99th percentile publish latency and end-to-end latency stayed within 10 milliseconds, even as the number of partitions was increased from 100 to 10000 or as the number of subscriptions was increased from 1 to 10.</li>
<li> Kafka’s publish and end-to-end latency was greatly affected by variations in the numbers of subscriptions and partitions.
    <ul>
    <li> Both publish and end-to-end latency increased from ~5 milliseconds to ~13 seconds as the number of subscriptions was increased from 1 to 10.</li>
    <li> Both publish and end-to-end latency increased from ~5 milliseconds to ~200 seconds as the number of topic partitions was increased from 100 to 10000.</li>
    </ul>
</li>
</ol>
<h3 id="catch-up-read-test"><a href="#catch-up-read-test" aria-hidden="true"><span class="icon icon-link"></span></a>Catch-up Read Test</h3>
<blockquote>
<p>See the full report of “Catch-up Read Test” <a href="https://streamnative.io/blog/tech/2020-11-09-benchmark-pulsar-kafka-performance-report#catch-up-read-test" target="_blank" rel="nofollow noopener noreferrer">here</a>.</p>
</blockquote>
<p>The Catch-up Read Test was designed to determine the maximum throughput each system can achieve when processing workloads that contain catch-up reads only. At the beginning of the test, a producer sent messages at a fixed rate of 200K per second. When the producer had sent 512GB of data, consumers began to read the messages that had been received. The consumers processed the accumulated messages and had no difficulty keeping up with the producer, which continued to send new messages at the same speed.</p>
<p>When processing catch-up reads, Pulsar’s maximum throughput was 3.5 times faster than Kafka’s. Pulsar achieved a maximum throughput of 3.5 GB/s (3.5 million messages/second) while Kafka achieved a throughput of only 1 GB/s (1 million messages/second).</p>
<h3 id="mixed-workload-test"><a href="#mixed-workload-test" aria-hidden="true"><span class="icon icon-link"></span></a>Mixed Workload Test</h3>
<blockquote>
<p>See the full report of “Mixed Workload Test” <a href="https://streamnative.io/blog/tech/2020-11-09-benchmark-pulsar-kafka-performance-report#mixed-workload-test" target="_blank" rel="nofollow noopener noreferrer">here</a>.</p>
</blockquote>
<p>This Mixed Workload Test was designed to determine the impact of catch-up reads on publish and tailing reads in mixed workloads. At the beginning of the test, producers sent messages at a fixed rate of 200K per second and consumers consume messages in tailing mode. After the producer produces 512GB of messages, it will start a new set of catch-up consumers to read all the messages from the beginning. At the same time, producers and existing tailing-read consumers continued to publish and consume messages at the same speed.</p>
<p>We tested Kafka and Pulsar using different durability settings and found that catch-up reads seriously affected Kafka’s publish latency, but had little impact on Pulsar. Kafka’s 99th percentile publish latency increased from 5 milliseconds to 1-3 seconds. However, Pulsar maintained a 99th percentile publish latency ranging from several milliseconds to tens of milliseconds. </p>
<p>The links below provide convenient access to individual sections of our benchmark report. </p>
<ul>
<li>
<p><a href="https://streamnative.io/blog/tech/2020-11-09-benchmark-pulsar-kafka-performance-report#maximum-throughput-test" target="_blank" rel="nofollow noopener noreferrer">Max Throughput Test</a></p>
<ul>
<li><a href="https://streamnative.io/blog/tech/2020-11-09-benchmark-pulsar-kafka-performance-report#1-100-partitions-1-subscription-2-producers-and-2-consumers" target="_blank" rel="nofollow noopener noreferrer">100 partitions, 1 subscription, 2 producers / 2 consumers</a></li>
<li><a href="https://streamnative.io/blog/tech/2020-11-09-benchmark-pulsar-kafka-performance-report#2-2000-partitions-1-subscription-2-producers-and-2-consumers" target="_blank" rel="nofollow noopener noreferrer">2000 partitions, 1 subscription, 2 producers / 2 consumers</a></li>
<li><a href="https://streamnative.io/blog/tech/2020-11-09-benchmark-pulsar-kafka-performance-report#3-1-partition-1-subscription-2-producers-and-2-consumers" target="_blank" rel="nofollow noopener noreferrer">1 partition, 1 subscription, 2 producers / 2 consumers</a></li>
<li><a href="https://streamnative.io/blog/tech/2020-11-09-benchmark-pulsar-kafka-performance-report#4-1-partition-1-subscription-1-producer-and-1-consumer" target="_blank" rel="nofollow noopener noreferrer">1 partition, 1 subscription, 1 producer / 1 consumer</a></li>
</ul>
</li>
<li>
<p><a href="https://streamnative.io/blog/tech/2020-11-09-benchmark-pulsar-kafka-performance-report#publish-and-end-to-end-latency-test" target="_blank" rel="nofollow noopener noreferrer">Publish and End-to-End Latency Test</a></p>
<ul>
<li><a href="https://streamnative.io/blog/tech/2020-11-09-benchmark-pulsar-kafka-performance-report#1-100-partitions-1-subscription" target="_blank" rel="nofollow noopener noreferrer">100 partitions, 1 subscription</a></li>
<li><a href="https://streamnative.io/blog/tech/2020-11-09-benchmark-pulsar-kafka-performance-report#2-100-partitions-10-subscriptions" target="_blank" rel="nofollow noopener noreferrer">100 partitions, 10 subscriptions</a></li>
<li><a href="https://streamnative.io/blog/tech/2020-11-09-benchmark-pulsar-kafka-performance-report#3-100-5000-8000-10000-partitions" target="_blank" rel="nofollow noopener noreferrer">Different partitions: 100, 1000, 2000, 5000, 8000, 10000</a></li>
</ul>
</li>
<li><a href="https://streamnative.io/blog/tech/2020-11-09-benchmark-pulsar-kafka-performance-report#catch-up-read-test" target="_blank" rel="nofollow noopener noreferrer">Catchup Read Throughput Test</a></li>
<li><a href="https://streamnative.io/blog/tech/2020-11-09-benchmark-pulsar-kafka-performance-report#mixed-workload-test" target="_blank" rel="nofollow noopener noreferrer">Mixed Workload Test</a></li>
</ul>
<p>All the raw data of the benchmark results are also available at <a href="https://github.com/streamnative/openmessaging-benchmark/tree/blog/results" target="_blank" rel="nofollow noopener noreferrer">here</a>. </p>
<h2 id="conclusion"><a href="#conclusion" aria-hidden="true"><span class="icon icon-link"></span></a>Conclusion</h2>
<p>A tricky aspect of benchmarks is that they often represent only a narrow combination of business logic and configuration options, which may or may not reflect real-world use cases or best practices. Benchmarks can further be compromised by issues in their framework, set-up, and methodology. We noted all of these issues in the recent Confluent benchmark.</p>
<p>At the community’s request, the team at StreamNative set out to run this benchmark in order to provide knowledge, insights, and transparency into Pulsar’s true performance capabilities.  In order to run a more accurate benchmark, we identified and fixed the issues with the Confluent benchmark, and also added new test parameters that would provide insights into how the technologies compared in more real-world use cases.</p>
<p>The results to our benchmark showed that, with the same durability guarantee as Kafka, Pulsar is able to outperform Kafka in workloads resembling real-world use cases and to achieve the same end-to-end through as Kafka in Confluent’s limited use case. Furthermore, Pulsar delivers significantly better latency than Kafka in each of the different test cases, including varying subscriptions, topics, and durability guarantees, and better I/O isolation than Kafka. </p>
<p>As noted, no benchmark can replace testing done on your own hardware with your own workloads. We encourage you to test Pulsar and Kafka using your own setups and workloads in order to understand how each system performs in your particular production environment. If you have any questions on Pulsar best practices as you go through, please reach out to <a href="https://streamnative.io/contact" target="_blank" rel="nofollow noopener noreferrer">us directly</a>, or feel free to join the Pulsar Slack channel.</p>
<p>In the next few months we will publish a series of blog posts to help the community better understand and leverage Pulsar to meet their business needs. Specifically, we will show the performance of Pulsar in different workloads and setups, how to select and size your hardware across different cloud providers and on-prem environments, and show how you can use Pulsar to build the most cost effective streaming platform.</p>
<p>If you have any questions about Pulsar’s storage architecture, its performance characteristics, or the results of this benchmark, we encourage you to join the <a href="https://apache-pulsar.herokuapp.com/" target="_blank" rel="nofollow noopener noreferrer">Pulsar Slack channel</a> to discuss. </p>
</div></div><div class="article-author-info" data-v-4064100e data-v-124acb4b><div class="article-author-img" data-v-4064100e data-v-124acb4b><img alt="head img" class="img-thumbnail article-head-img" data-v-4064100e data-v-124acb4b></div><p data-v-4064100e data-v-124acb4b>
          
          <!----></p></div></div></div></div><section class="bg-blue-darkest p-8 md:p-12 text-gray font" data-v-dd00c750 data-v-4064100e><div class="flex flex-col lg:grid lg:grid-cols-5" data-v-dd00c750><div class="flex flex-col md:grid md:grid-cols-4 lg:col-span-4" data-v-dd00c750><div data-v-dd00c750><a href="/" to="/" class="active text-current" data-v-8f7965c6 data-v-dd00c750><img alt="StreamNative Logo" src="data:image/svg+xml,%3csvg fill='none' viewBox='0 0 1400 545' xmlns='http://www.w3.org/2000/svg' xmlns:xlink='http://www.w3.org/1999/xlink'%3e%3cdefs%3e%3cfilter id='__svg-blur-47c20af6bc4301035393da067e63ff81'%3e%3cfeGaussianBlur in='SourceGraphic' stdDeviation='40'/%3e%3c/filter%3e%3c/defs%3e%3cimage x='0' y='0' filter='url(%23__svg-blur-47c20af6bc4301035393da067e63ff81)' width='1400' height='545' xlink:href='data:image/png%3bbase64%2ciVBORw0KGgoAAAANSUhEUgAAAEAAAAAZCAYAAACB6CjhAAAACXBIWXMAABfoAAAX6AE9xeEaAAAGm0lEQVRYw82YeYjVVRTH5703MzpupaOmZTihEaUoZqtL2aYJIqSJZWlGoZYGhliQEWWhjktqJiMVaYaOaWFZRCppVhqVkbbYJqGS0YJToeXam75n%2bFw7Xn%2b/eTN/1YUvd7/33HPPdm9RbW1tkcFSPp%2b3cq6ogSnMS2oL63qkzflPkx0awjKuraPqtymfLswSZqoeMEOYL4xjbCY%2bNO1ZY6aQVbkuD2Ng9P%2bHKeHwEDVd%2bKO2cHqbObmEW840YJ/4AoqSGBlLk2dizNB4vbS5pzDeEWU39qY74AnheAL%2bov/%2bwIBIosJ6PYUq1TcqXyx0cwzLBYaovxiigsRkQu7oyjmcwtCoL%2bPai6P%2bbFTPhEWyEL6Qgx0V/hby5KGchwGWDmp8J7dZ4GwQ80sZVyO8IfxO/UbHqG2qVxaQmFya7UmbY6rXWMm3QjcOWkt%2bHAlIS%2bNjAiEq3OyjjBtMvbXwvTBXBJZjSyx9J0xRWzNjjjBaqDDJEfozt5f6n1ReLUwWytye5wpPqH%2bV8mnK29J%2bnvCg6p1tjvIlynsIzYVZwhyhs%2bfEwxB0zDHC0iEQVGK3MCa%2b%2bQQGjGTOPuEhoavbq58I%2bor1fhM%2bFowBa5nzAfnNwpWUPxEWMGcT63Sk/pMw26RS%2bBwpGMK8j4QvKP8gvC7sob7FM6CaxjoR1wI20BbpYsQLfYWLhRJ/%2bNiCe2OkfJLwo2Pme0Jv%2blpC/GpHw/OMG%2bXatnGwc6hPZkx/dHy4SQx7z4L27souY9wS%2bhZRn8A67wuHhTPDRq84QqcW0JtcqkX9d8zZ2rQFhmeA8Axr74YgU4MTyl92c1ZiZ8oZU4rEHeImd6nNJOGA8hHMmSvshFG72ONyx4CxkYR3p75aOGKqGTZfwIBF4ZDBncQHj314kmFS/poRrrGto9u0VGbtHNYzYAW30sG12YFrNP4saDL7MIC%2bGax3LfXHqfd2DLiLvkeo96K%2bBsaelICbGFDhNjcxfQDjUp7mxyNpCB5lqPMCq9BzS9WMbSrsDfGE0MSkgXpHR8MttJknGY8%2bf4MKTqNvHuWwRz%2bhD%2bVJrFNJ/RLqG1CXNv6wi4OO07Yu6IQGbvaHTwo4EqTA9HS58I7wqjDRbt8xzIh8wQ6OFxiBdW7h3bPy601SsCGmSj1ob44UbDVPgJU3Xe%2bMd3jO1AFaB%2bJZgi25A5tR5m%2bwpdu0LR7hGGJpqYtThTLPhELvg1T/Wzg8T5vfGF%2bfLbh3ilF7yxnGrc7FZbmptgmPnnD7A7ErFlwFg3WG8JgwjLpZ8VIdtgSmlkSRYAljmjLe3OR%2bUxf2OjmeaNLqJeFBx7hi6M2GiDOKLouSdDkcoo0ZFkTFG6bWuMvRCcYxMGmhY94%2b2sqpr0m7RXs0OaZ%2bKdzn9p2o/nmFpCms0dBXatpDJJewQGlkUZf6aBAmhLJJyJ%2b8Gs2GWGhcikotc2uasVym/qUWd9B2gWOgeYF7MJLXYCfspseix0Flu2Ksw3ujLzbN4pu7A41JKhsbsVwBfRrjIsVNTpziSHA2YwaRz0S0zfWt8L5ZRFXjly3dLlxN1GZS9ouwnj1ChFhEm83tErnxbgRHljarv4pxL8YBXL3GwjiqST0JN9ubRVd9eXAK5Bvcuz9WgeB2zCJvJqBpw0MrEHMFDMqyhz2YPqWvAsIrHU1mk2ooD2P9kdS/tkCI8h72a%2baCJUsXphpQZ/0HI3bH3VvgoNPnPGJsaX6sAgkMaK9DTKB8A7H/SsbYTa9Xv0Vw29lzp1ODOh/vaNwIk8zmtKO/CptkzJqBetiYA8ZM4VvhM%2bFX4apEBjiih9Xz%2bgsvxLx7JfaNVSDYAIipxR93gsCnhf3E/EEdtgf7AnN2MP%2biBAas5yDNXWRphxzF2D60/0xY3Ix1w1umRaprVWMrXEx4EeZTcCTobcJfgGfmU0Enqe9wzAwSUIOO3wtTjMl76WvnJG8ta2%2bl3ooxU6kf4NAhNpkSok7zIrxItzgjnsiAsUw6nPADdMyJvaUPHTczKVHgUMSzA/UhZpDArS5SXIdoXyfcaYbRrTdIYy1mX4bYjyPya0J/J/Wb8XvW/i89PWofztrv4g0q6g3A1PFSA/4Aj2JVy6KfpEJ%2bOduYSM4/qRsTSZ7m2%2bv5j0yTgMXafA6Pi3kWdFCuxBefn2A00z41s0Rh/oe4OERmPhoLP8b%2brzBaI3y65qI16yJAIrzTfqbcP2Cxk4zTGdCYL2kOkkn6uW3MN3zaf0LSd3naT3E9f4WnlAu9K/4Bo2EBDOh3kIQAAAAASUVORK5CYII=' /%3e%3c/svg%3e" width="1400" data-src="/assets/static/streamnative-logo-white.be54052.8284ad3d0684b71ef5e98f89f4fc88d1.png" data-srcset="/assets/static/streamnative-logo-white.82a2fbd.8284ad3d0684b71ef5e98f89f4fc88d1.png 480w, /assets/static/streamnative-logo-white.cbab2cf.8284ad3d0684b71ef5e98f89f4fc88d1.png 1024w, /assets/static/streamnative-logo-white.be54052.8284ad3d0684b71ef5e98f89f4fc88d1.png 1400w" data-sizes="(max-width: 1400px) 100vw, 1400px" class="w-40 g-image g-image--lazy g-image--loading" data-v-dd00c750><noscript data-v-dd00c750><img src="/assets/static/streamnative-logo-white.be54052.8284ad3d0684b71ef5e98f89f4fc88d1.png" class="w-40 g-image g-image--loaded" width="1400" alt="StreamNative Logo"></noscript></a></div><div data-v-dd00c750><ol class="mt-6 md:mt-0" data-v-dd00c750><h5 class="uppercase" data-v-dd00c750>Company</h5><li data-v-dd00c750><a href="/success-stories/" to="/success-stories/" class="text-current" data-v-8f7965c6 data-v-dd00c750>Success Stories</a></li><li data-v-dd00c750><a href="/about/" to="/about/" class="text-current" data-v-8f7965c6 data-v-dd00c750>About</a></li><li data-v-dd00c750><a href="/careers/" to="/careers/" class="text-current" data-v-8f7965c6 data-v-dd00c750>Careers</a></li><li data-v-dd00c750><a href="/contact/" to="/contact/" class="text-current" data-v-8f7965c6 data-v-dd00c750>Contact</a></li><li data-v-dd00c750><a href="/news/" to="/news/" class="text-current" data-v-8f7965c6 data-v-dd00c750>News</a></li></ol></div><ol class="mt-6 md:mt-0" data-v-dd00c750><h5 class="uppercase" data-v-dd00c750>Developers</h5><li :key="Pulsar Summit" data-v-dd00c750><a href="https://pulsar-summit.org/" target="_blank" rel="noopener" to="https://pulsar-summit.org/" class="text-current" data-v-8f7965c6 data-v-8f7965c6 data-v-dd00c750>Pulsar Summit</a></li><li :key="Events" data-v-dd00c750><a href="/events" to="/events" class="text-current" data-v-8f7965c6 data-v-dd00c750>Events</a></li><li :key="Pulsar Weekly" data-v-dd00c750><a href="https://weekly.streamnative.io/" target="_blank" rel="noopener" to="https://weekly.streamnative.io/" class="text-current" data-v-8f7965c6 data-v-8f7965c6 data-v-dd00c750>Pulsar Weekly</a></li></ol><ol class="mt-6 md:mt-0" data-v-dd00c750><h5 class="uppercase" data-v-dd00c750>Connect</h5><li data-v-dd00c750><a href="https://github.com/streamnative/" target="_blank" rel="noopener" to="https://github.com/streamnative/" class="text-current" data-v-8f7965c6 data-v-8f7965c6 data-v-dd00c750>Github</a></li><li data-v-dd00c750><a href="https://twitter.com/streamnativeio/" target="_blank" rel="noopener" to="https://twitter.com/streamnativeio/" class="text-current" data-v-8f7965c6 data-v-8f7965c6 data-v-dd00c750>Twitter</a></li><li data-v-dd00c750><a href="https://medium.com/streamnative/" target="_blank" rel="noopener" to="https://medium.com/streamnative/" class="text-current" data-v-8f7965c6 data-v-8f7965c6 data-v-dd00c750>Medium</a></li><li data-v-dd00c750><a href="https://www.linkedin.com/company/streamnative/" target="_blank" rel="noopener" to="https://www.linkedin.com/company/streamnative/" class="text-current" data-v-8f7965c6 data-v-8f7965c6 data-v-dd00c750>LinkedIn</a></li><li data-v-dd00c750><a href="https://www.slideshare.net/streamnative" target="_blank" rel="noopener" to="https://www.slideshare.net/streamnative" class="text-current" data-v-8f7965c6 data-v-8f7965c6 data-v-dd00c750>SlideShare</a></li><li data-v-dd00c750><a href="https://www.youtube.com/channel/UCywxUI5HlIyc0VEKYR4X9Pg" target="_blank" rel="noopener" to="https://www.youtube.com/channel/UCywxUI5HlIyc0VEKYR4X9Pg" class="text-current" data-v-8f7965c6 data-v-8f7965c6 data-v-dd00c750>YouTube</a></li></ol></div><div class="mt-6 lg:mt-0" data-v-dd00c750><h5 class="uppercase" data-v-dd00c750>Stay Updated</h5><!----><!----></div></div><div class="flex flex-col lg:flex-row justify-between mt-16 text-xs" data-v-dd00c750><span class="mb-2" data-v-dd00c750>&copy; StreamNative, Inc. 2022</span><!----><span class="mb-2" data-v-dd00c750>Apache, Apache Pulsar, Apache BookKeeper, Apache Flink, and associated open source project names are trademarks of the Apache Software Foundation.</span><span class="underline mb-2" data-v-dd00c750><a href="/terms/" class="mr-3 text-gray" data-v-dd00c750>Terms</a><a href="/policy/" class="text-gray" data-v-dd00c750>Privacy</a></span></div></section></div><!----></div>
<script src="/assets/js/app.693fd7b3.js" defer></script><script src="/assets/js/page--src--templates--blog-vue.1817b5d1.js" defer></script>
</body>
</html>
