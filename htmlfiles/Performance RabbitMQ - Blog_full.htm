<!doctype html><html><head><script>(function(t,s,o,e,a){t[e]=t[e]||[],t[e].push({'gtm.start':(new Date).getTime(),event:"gtm.js"});var i=s.getElementsByTagName(o)[0],n=s.createElement(o),r=e!="dataLayer"?"&amp;l="+e:'';n.async=!0,n.src="https://www.googletagmanager.com/gtm.js?id="+a+r,i.parentNode.insertBefore(n,i)})(window,document,"script","dataLayer","GTM-NSPM4RC")</script><meta xmlns=http://www.w3.org/1999/xhtml name=googlebot content="NOODP"></meta><meta xmlns=http://www.w3.org/1999/xhtml name=google-site-verification content="nSYeDgyKM9mw5CWcZuD0xu7iSWXlJijAlg9rcxVOYf4"></meta><meta xmlns=http://www.w3.org/1999/xhtml name=google-site-verification content="6UEaC3SWhpGQvqRnSJIEm2swxXpM5Adn4dxZhFsNdw0"></meta><meta charset=utf-8><meta content="width=device-width,initial-scale=1,maximum-scale=1,minimum-scale=1,user-scalable=no" id=viewport name=viewport><title>Performance | RabbitMQ - Blog</title><meta name=description content><link xmlns=http://www.w3.org/1999/xhtml rel=icon type=/image/vnd.microsoft.icon href=https://www.rabbitmq.com/favicon.ico></link>
<link rel=alternate type=application/rss+xml href=https://blog.rabbitmq.com/categories/performance/index.xml title="RabbitMQ - Blog"><link href="https://fonts.googleapis.com/css?family=Raleway:400,500,600,700" rel=stylesheet><link rel=stylesheet href=/assets/css/syntax.css type=text/css><link xmlns=http://www.w3.org/1999/xhtml rel=stylesheet rev="stylesheet" href=https://www.rabbitmq.com/css/rabbit.css type=text/css></link>
<link xmlns=http://www.w3.org/1999/xhtml rel=icon type=/image/vnd.microsoft.icon href=https://www.rabbitmq.com/favicon.ico></link>
<link rel=stylesheet href=/assets/css/rabbitmq-blog.css type=text/css><script>window.twttr=function(n,s,o){var t,i=n.getElementsByTagName(s)[0],e=window.twttr||{};return n.getElementById(o)?e:(t=n.createElement(s),t.id=o,t.src="https://platform.twitter.com/widgets.js",i.parentNode.insertBefore(t,i),e._e=[],e.ready=function(t){e._e.push(t)},e)}(document,"script","twitter-wjs")</script></head><body><noscript><iframe src="https://www.googletagmanager.com/ns.html?id=GTM-NSPM4RC" height=0 width=0 style=display:none;visibility:hidden></iframe></noscript><div xmlns=http://www.w3.org/1999/xhtml id=outerContainer><div class=container><div class=rabbit-logo><a href=https://www.rabbitmq.com/><img src=https://www.rabbitmq.com/img/logo-rabbitmq.svg alt=RabbitMQ></a></div><a class="btn menubtn" onclick=showHide()>Menu <img src=https://www.rabbitmq.com/img/carrot-down-white.svg></a><div class=mobilemenuicon onclick=showHide()><img src=https://www.rabbitmq.com/img/mobile-menu-icon.svg></div><div id=nav><ul id=mainNav><li><a href=https://www.rabbitmq.com/#features>Features</a></li><li><a href=https://www.rabbitmq.com/#getstarted>Get Started</a></li><li><a href=https://www.rabbitmq.com/#support>Support</a></li><li><a href=https://www.rabbitmq.com/#community>Community</a></li><li><a href=https://www.rabbitmq.com/documentation.html>Docs</a></li><li><a href=https://blog.rabbitmq.com class=selected>Blog</a></li></ul></div></div><div class=nav-separator></div><div id=innerContainer class=container><div id=left-content><h2>Archive for the 'Performance' Category</h2><h3><a href=https://blog.rabbitmq.com/posts/2022/05/rabbitmq-3.10-performance-improvements/ rel=bookmark title="RabbitMQ 3.10 Performance Improvements">RabbitMQ 3.10 Performance Improvements</a></h3><small>May 16, 2022
by
Michał Kuratczyk</small><div class=entry><p>RabbitMQ 3.10 was released on the 3rd of May 2022, with <a href=/posts/2022/05/rabbitmq-3.10-release-overview>many new features and improvements</a>.
This blog post gives an overview of the performance improvements
in that release. Long story short, you can expect higher throughput, lower latency and faster node startups,
especially with large definitions files imported on startup.</p></div><div><a href=/posts/2022/05/rabbitmq-3.10-performance-improvements/>Read More...</a></div><hr><h3><a href=https://blog.rabbitmq.com/posts/2021/03/erlang-24-support-roadmap/ rel=bookmark title="Erlang 24 Support Roadmap">Erlang 24 Support Roadmap</a></h3><small>March 23, 2021
by
Michael Klishin</small><div class=entry><h2 id=tldr>TL;DR</h2><ul><li>Erlang 24 will ship in May and it offers significant performance gains to RabbitMQ users</li><li>Supporting Erlang 24 and 22 at the same time is not feasible, so in early May 2021, Erlang 22 support will be dropped</li><li>If you run on Erlang 22, <a href>upgrade to 23.2</a> today: it should be a drop-in replacement</li><li>Users of the <a href=https://github.com/rabbitmq/cluster-operator>RabbitMQ Kubernetes Operator</a>, the <a href=https://github.com/docker-library/rabbitmq>Docker community image</a> and modern releases of <a href="https://docs.pivotal.io/rabbitmq-cf/1-21/index.html#:~:text=RabbitMQ%20for%20VMs.-,About%20VMware%20Tanzu%20RabbitMQ%20for%20VMs,and%20a%20pre%2Dprovisioned%20service.&text=Dedicated%20VM%20that%20serves%20a%20single%20service%20instance.">VMware Tanzu RabbitMQ for VMs</a> are not affected as those projects all use Erlang 23 today</li></ul></div><div><a href=/posts/2021/03/erlang-24-support-roadmap/>Read More...</a></div><hr><h3><a href=https://blog.rabbitmq.com/posts/2020/06/cluster-sizing-case-study-quorum-queues-part-2/ rel=bookmark title="Cluster Sizing Case Study – Quorum Queues Part 2">Cluster Sizing Case Study – Quorum Queues Part 2</a></h3><small>June 22, 2020
by
Jack Vanlightly</small><div class=entry><p>In the <a href=/posts/2020/06/cluster-sizing-case-study-quorum-queues-part-1>last post</a> we started a sizing analysis of our <a href=/posts/2020/06/cluster-sizing-and-other-considerations>workload</a> using quorum queues. We focused on the happy scenario that consumers are keeping up meaning that there are no queue backlogs and all brokers in the cluster are operating normally. By running a series of benchmarks modelling our workload at different intensities we identified the top 5 cluster size and storage volume combinations in terms of cost per 1000 msg/s per month.</p><ol><li>Cluster: 7 nodes, 8 vCPUs (c5.2xlarge), gp2 SDD. Cost: $54</li><li>Cluster: 9 nodes, 8 vCPUs (c5.2xlarge), gp2 SDD. Cost: $69</li><li>Cluster: 5 nodes, 8 vCPUs (c5.2xlarge), st1 HDD. Cost: $93</li><li>Cluster: 5 nodes, 16 vCPUs (c5.4xlarge), gp2 SDD. Cost: $98</li><li>Cluster: 7 nodes, 16 vCPUs (c5.4xlarge), gp2 SDD. Cost: $107</li></ol><p>There are more tests to run to ensure these clusters can handle things like brokers failing and large backlogs accumulating during things like outages or system slowdowns.</p><p>All quorum queues are declared with the following properties:</p><ul><li>x-quorum-initial-group-size=3</li><li>x-max-in-memory-length=0</li></ul><p>The <em>x-max-in-memory-length</em> property forces the quorum queue to remove message bodies from memory as soon as it is safe to do. You can set it to a longer limit, this is the most aggressive - designed to avoid large memory growth at the cost of more disk reads when consumers do not keep up. Without this property message bodies are kept in memory at all times which can place memory growth to the point of memory alarms setting off which severely impacts the publish rate - something we want to avoid in this workload case study.</p></div><div><a href=/posts/2020/06/cluster-sizing-case-study-quorum-queues-part-2/>Read More...</a></div><hr><h3><a href=https://blog.rabbitmq.com/posts/2020/06/cluster-sizing-case-study-quorum-queues-part-1/ rel=bookmark title="Cluster Sizing Case Study – Quorum Queues Part 1">Cluster Sizing Case Study – Quorum Queues Part 1</a></h3><small>June 21, 2020
by
Jack Vanlightly</small><div class=entry><p>In a <a href=/posts/2020/06/cluster-sizing-and-other-considerations>first post</a> in this sizing series we covered the workload, the tests, and the cluster and storage volume configurations on AWS ec2. In this post we’ll run a sizing analysis with quorum queues. We also ran a <a href=/posts/2020/06/cluster-sizing-case-study-mirrored-queues-part-1>sizing analysis on mirrored queues</a>.</p><p>In this post we&rsquo;ll run the increasing intensity tests that will measure our candidate cluster sizes at varying publish rates, under ideal conditions. In the next post we&rsquo;ll run resiliency tests that measure whether our clusters can handle our target peak load under adverse conditions.</p><p>All quorum queues are declared with the following properties:</p><ul><li>x-quorum-initial-group-size=3 (replication factor)</li><li>x-max-in-memory-length=0</li></ul><p>The <em>x-max-in-memory-length</em> property forces the quorum queue to remove message bodies from memory as soon as it is safe to do. You can set it to a longer limit, this is the most aggressive - designed to avoid large memory growth at the cost of more disk reads when consumers do not keep up. Without this property message bodies are kept in memory at all times which can place memory growth to the point of memory alarms setting off which severely impacts the publish rate - something we want to avoid in this workload case study.</p></div><div><a href=/posts/2020/06/cluster-sizing-case-study-quorum-queues-part-1/>Read More...</a></div><hr><h3><a href=https://blog.rabbitmq.com/posts/2020/06/cluster-sizing-case-study-mirrored-queues-part-2/ rel=bookmark title="Cluster Sizing Case Study – Mirrored Queues Part 2">Cluster Sizing Case Study – Mirrored Queues Part 2</a></h3><small>June 20, 2020
by
Jack Vanlightly</small><div class=entry><p>In the <a href=/posts/2020/06/cluster-sizing-case-study-mirrored-queues-part-1>last post</a> we started a sizing analysis of our <a href=/posts/2020/06/cluster-sizing-and-other-considerations>workload</a> using mirrored queues. We focused on the happy scenario that consumers are keeping up meaning that there are no queue backlogs and all brokers in the cluster are operating normally. By running a series of benchmarks modelling our workload at different intensities we identified the top 5 cluster size and storage volume combinations in terms of cost per 1000 msg/s per month.</p><ol><li>Cluster: 5 nodes, 8 vCPUs, gp2 SDD. Cost: $58</li><li>Cluster: 7 nodes, 8 vCPUs, gp2 SDD. Cost: $81</li><li>Cluster: 5 nodes, 8 vCPUs, st1 HDD. Cost: $93</li><li>Cluster: 5 nodes, 16 vCPUs, gp2 SDD. Cost: $98</li><li>Cluster: 9 nodes, 8 vCPUs, gp2 SDD. Cost: $104</li></ol><p>There are more tests to run to ensure these clusters can handle things like brokers failing and large backlogs accumulating during things like outages or system slowdowns.</p></div><div><a href=/posts/2020/06/cluster-sizing-case-study-mirrored-queues-part-2/>Read More...</a></div><hr><h3><a href=https://blog.rabbitmq.com/posts/2020/06/cluster-sizing-case-study-mirrored-queues-part-1/ rel=bookmark title="Cluster Sizing Case Study - Mirrored Queues Part 1">Cluster Sizing Case Study - Mirrored Queues Part 1</a></h3><small>June 19, 2020
by
Jack Vanlightly</small><div class=entry><p>In a <a href=/posts/2020/06/cluster-sizing-and-other-considerations>first post</a> in this sizing series we covered the workload, cluster and storage volume configurations on AWS ec2. In this post we’ll run a sizing analysis with mirrored queues.</p><p>The first phase of our sizing analysis will be assessing what intensities each of our clusters and storage volumes can handle easily and which are too much.</p><p>All tests use the following policy:</p><ul><li>ha-mode: exactly</li><li>ha-params: 2</li><li>ha-sync-mode: manual</li></ul></div><div><a href=/posts/2020/06/cluster-sizing-case-study-mirrored-queues-part-1/>Read More...</a></div><hr><h3><a href=https://blog.rabbitmq.com/posts/2020/06/cluster-sizing-and-other-considerations/ rel=bookmark title="Cluster Sizing and Other Considerations">Cluster Sizing and Other Considerations</a></h3><small>June 18, 2020
by
Jack Vanlightly</small><div class=entry><p>This is the start of a short series where we look at sizing your RabbitMQ clusters. The actual sizing wholly depends on your hardware and workload, so rather than tell you how many CPUs and how much RAM you should provision, we’ll create some general guidelines and use a case study to show what things you should consider.</p></div><div><a href=/posts/2020/06/cluster-sizing-and-other-considerations/>Read More...</a></div><hr><h3><a href=https://blog.rabbitmq.com/posts/2020/06/how-to-run-benchmarks/ rel=bookmark title="How to Run Benchmarks">How to Run Benchmarks</a></h3><small>June 4, 2020
by
Jack Vanlightly</small><div class=entry><p>There can be many reasons to do benchmarking:</p><ul><li>Sizing and capacity planning</li><li>Product assessment (can RabbitMQ handle my load?)</li><li>Discover best configuration for your workload</li></ul><p>In this post we’ll take a look at the various options for running RabbitMQ benchmarks. But before we do, you’ll need a way to see the results and look at system metrics.</p></div><div><a href=/posts/2020/06/how-to-run-benchmarks/>Read More...</a></div><hr><h3><a href=https://blog.rabbitmq.com/posts/2020/05/quorum-queues-and-flow-control-stress-tests/ rel=bookmark title="Quorum Queues and Flow Control - Stress Tests">Quorum Queues and Flow Control - Stress Tests</a></h3><small>May 15, 2020
by
Jack Vanlightly</small><div class=entry><p>In the <a href=/posts/2020/05/quorum-queues-and-flow-control-single-queue-benchmarks>last post</a> we ran some simple benchmarks on a single queue to see what effect pipelining publisher confirms and consumer acknowledgements had on flow control. </p><p>Specifically we looked at:</p><ul><li>Publishers: Restricting the number of in-flight messages (messages sent but pending a confirm).</li><li>Consumers: Prefetch (the number in-flight messages the broker will allow on the channel)</li><li>Consumers: Ack Interval (multiple flag usage)</li></ul><p>Unsurprisingly, we saw when we restricted publishers and the brokers to a small number of in-flight messages at a time, that throughput was low. When we increased that limit, throughput increased, but only to a point, after which we saw no more throughput gains but instead just latency increases. We also saw that allowing consumers to use the multiple flag was beneficial to throughput.</p><p>In this post we’re going to look at those same three settings, but with many clients, many queues and different amounts of load, including stress tests. We’ll see that publisher confirms and consumer acknowledgements play a role in flow control to help prevent overload of a broker. </p></div><div><a href=/posts/2020/05/quorum-queues-and-flow-control-stress-tests/>Read More...</a></div><hr><h3><a href=https://blog.rabbitmq.com/posts/2020/05/quorum-queues-and-flow-control-single-queue-benchmarks/ rel=bookmark title="Quorum Queues and Flow Control - Single Queue Benchmarks">Quorum Queues and Flow Control - Single Queue Benchmarks</a></h3><small>May 14, 2020
by
Jack Vanlightly</small><div class=entry><p>In the last post we covered what flow control is, both as a general concept and the various flow control mechanisms available in RabbitMQ. We saw that publisher confirms and consumer acknowledgements are not just data safety measures, but also play a role in flow control. </p><p>In this post we’re going to look at how application developers can use publisher confirms and consumer acknowledgements to get a balance of safety and high performance, in the context of a single queue. </p><p>Flow control becomes especially important when a broker is being overloaded. A single queue is unlikely to overload your broker. If you send large messages then sure, you can saturate your network, or if you only have a single CPU core, then one queue could max it out. But most of us are on 8, 16 or 30+ core machines. But it’s interesting to break down the effects of confirms and acks on a single queue. From there we can take our learnings and see if they apply to larger deployments (the next post).</p></div><div><a href=/posts/2020/05/quorum-queues-and-flow-control-single-queue-benchmarks/>Read More...</a></div><hr><h3><a href=https://blog.rabbitmq.com/posts/2020/05/quorum-queues-and-flow-control-the-concepts/ rel=bookmark title="Quorum Queues and Flow Control - The Concepts">Quorum Queues and Flow Control - The Concepts</a></h3><small>May 4, 2020
by
Jack Vanlightly</small><div class=entry><p>As part of our quorum queue series we’re taking a look at flow control, how it protects RabbitMQ from being overloaded and how that relates to quorum queues.</p><h2 id=what-is-flow-control>What is Flow Control?</h2><p>Flow control is a concept that has been in computer networking and networked software for decades. Essentially it is a mechanism for applying back pressure to senders to avoid overloading receivers. Receivers typically buffer incoming packets/messages as a way of dealing with a send rate that exceeds its processing rate. But receiver buffers cannot grow forever so either the send rate should only transiently exceed receiver processing capacity (bursty traffic) or the sender must be slowed down (back pressure).</p><p>Flow control is a way of applying this back pressure on the sender, slowing them down so that the receiver’s buffers do not overflow and latencies do not grow too large. In a chain of sender/receivers, this back pressure can propagate up the chain to the origin of the traffic. In more complex graphs of connected components, flow control can balance incoming traffic between fast and slow senders, avoiding overload but allowing the system to reach full utilisation despite different numbers of senders, different rates and different load patterns (steady or bursty).</p></div><div><a href=/posts/2020/05/quorum-queues-and-flow-control-the-concepts/>Read More...</a></div><hr><h3><a href=https://blog.rabbitmq.com/posts/2020/04/quorum-queues-and-why-disks-matter/ rel=bookmark title="Quorum queues and why disks matter">Quorum queues and why disks matter</a></h3><small>April 21, 2020
by
Jack Vanlightly</small><div class=entry><p>Quorum queues are still relatively new to RabbitMQ and many people have still not made the jump from classic mirrored queues. Before you migrate to this new queue type you need to make sure that your hardware can support your workload and a big factor in that is what storage drives you use.</p><p>In this blog post we’re going to take a closer look at quorum queues and their performance characteristics on different storage configurations.</p><h2 id=hdd-or-ssd-one-drive-or-multiple-drives>HDD or SSD? One drive or multiple drives?</h2><p>The TL;DR is that we highly recommend SSDs when using quorum queues. The reason for this is that quorum queues are sensitive to IO latency and SSDs deliver lower latency IO than HDDs. With higher IO latency, you&rsquo;ll see lower throughput, higher end-to-end latency and some other undesirable effects.</p><p>Further down in this post we’ll demonstrate why we recommend this, using various benchmarks with different SSD and HDD configurations.</p></div><div><a href=/posts/2020/04/quorum-queues-and-why-disks-matter/>Read More...</a></div><hr><h3><a href=https://blog.rabbitmq.com/posts/2018/04/rabbitmq-java-client-metrics-with-micrometer-and-datadog/ rel=bookmark title="RabbitMQ Java Client Metrics with Micrometer and Datadog">RabbitMQ Java Client Metrics with Micrometer and Datadog</a></h3><small>April 10, 2018
by
Arnaud Cogoluègnes</small><div class=entry><p>In this post we&rsquo;ll cover how the RabbitMQ Java client library gathers runtime metrics and sends them to monitoring systems like JMX and Datadog.</p></div><div><a href=/posts/2018/04/rabbitmq-java-client-metrics-with-micrometer-and-datadog/>Read More...</a></div><hr><h3><a href=https://blog.rabbitmq.com/posts/2017/10/new-reactive-client-for-rabbitmq-http-api/ rel=bookmark title="New Reactive Client for RabbitMQ HTTP API">New Reactive Client for RabbitMQ HTTP API</a></h3><small>October 18, 2017
by
Arnaud Cogoluègnes</small><div class=entry><p>The RabbitMQ team is happy to announce the release of version 2.0 of <a href=https://github.com/rabbitmq/hop>HOP</a>, RabbitMQ HTTP API client for Java and other JVM languages. This new release introduce a new reactive client based on <a href=https://docs.spring.io/spring/docs/5.0.0.RELEASE/spring-framework-reference/web-reactive.html#webflux-client>Spring Framework 5.0 WebFlux</a>.</p></div><div><a href=/posts/2017/10/new-reactive-client-for-rabbitmq-http-api/>Read More...</a></div><hr><h3><a href=https://blog.rabbitmq.com/posts/2016/11/metrics-support-in-rabbitmq-java-client-4-0/ rel=bookmark title="Metrics support in RabbitMQ Java Client 4.0">Metrics support in RabbitMQ Java Client 4.0</a></h3><small>November 30, 2016
by
Arnaud Cogoluègnes</small><div class=entry><p><a href=/posts/2016/11/rabbitmq-java-client-4-0-is-released/>Version 4.0 of the RabbitMQ Java Client</a> brings support for runtime metrics. This can be especially useful to know how a client application is behaving. Let&rsquo;s see how to enable metrics collection and how to monitor those metrics on JMX or even inside a Spring Boot application.</p></div><div><a href=/posts/2016/11/metrics-support-in-rabbitmq-java-client-4-0/>Read More...</a></div><hr><h3><a href=https://blog.rabbitmq.com/posts/2015/10/new-credit-flow-settings-on-rabbitmq-3-5-5/ rel=bookmark title="New Credit Flow Settings on RabbitMQ 3.5.5">New Credit Flow Settings on RabbitMQ 3.5.5</a></h3><small>October 6, 2015
by
Alvaro Videla</small><div class=entry><p>In order to prevent fast publishers from overflowing the broker with
more messages than it can handle at any particular moment, RabbitMQ
implements an internal mechanism called <em>credit flow</em> that will be
used by the various systems inside RabbitMQ to throttle down
publishers, while allowing the message consumers to catch up. In this
blog post we are going to see how <em>credit flow</em> works, and what we can
do to tune its configuration for an optimal behaviour.</p></div><div><a href=/posts/2015/10/new-credit-flow-settings-on-rabbitmq-3-5-5/>Read More...</a></div><hr><h3><a href=https://blog.rabbitmq.com/posts/2014/04/finding-bottlenecks-with-rabbitmq-3-3/ rel=bookmark title="Finding bottlenecks with RabbitMQ 3.3">Finding bottlenecks with RabbitMQ 3.3</a></h3><small>April 14, 2014
by
Simon MacMullen</small><div class=entry><p>One of the goals for RabbitMQ 3.3 was that you should be able to find bottlenecks in running systems more easily. Older versions of RabbitMQ let you see that you were rate-limited but didn&rsquo;t easily let you see why. In this blog post we&rsquo;ll talk through some of the new performance indicators in version 3.3.</p></div><div><a href=/posts/2014/04/finding-bottlenecks-with-rabbitmq-3-3/>Read More...</a></div><hr><h3><a href=https://blog.rabbitmq.com/posts/2014/04/consumer-bias-in-rabbitmq-3-3/ rel=bookmark title="Consumer Bias in RabbitMQ 3.3">Consumer Bias in RabbitMQ 3.3</a></h3><small>April 10, 2014
by
Simon MacMullen</small><div class=entry><p>I warn you before we start: this is another wordy blog post about performance-ish changes in RabbitMQ 3.3. Still with us? Good.</p><p>So in the <a href=/posts/2014/04/an-end-to-synchrony-performance-improvements-in-3-3/>previous post</a> I mentioned &ldquo;a new feature which I&rsquo;ll talk about in a future blog post&rdquo;. That feature is consumer bias.</p></div><div><a href=/posts/2014/04/consumer-bias-in-rabbitmq-3-3/>Read More...</a></div><hr><h3><a href=https://blog.rabbitmq.com/posts/2014/04/an-end-to-synchrony-performance-improvements-in-3-3/ rel=bookmark title="An end to synchrony: performance improvements in 3.3">An end to synchrony: performance improvements in 3.3</a></h3><small>April 3, 2014
by
Simon MacMullen</small><div class=entry><p>Well, we got the <a href=/posts/2014/04/breaking-things-with-rabbitmq-3-3>bad news</a> out of the way yesterday, so today let&rsquo;s talk about (some of) the good news: some types of publishing and consuming are now a great deal faster, especially in clusters.</p></div><div><a href=/posts/2014/04/an-end-to-synchrony-performance-improvements-in-3-3/>Read More...</a></div><hr><h3><a href=https://blog.rabbitmq.com/posts/2012/04/rabbitmq-performance-measurements-part-2/ rel=bookmark title="RabbitMQ Performance Measurements, part 2">RabbitMQ Performance Measurements, part 2</a></h3><small>April 25, 2012
by
Simon MacMullen</small><div class=entry><p>Welcome back! <a href=/posts/2012/04/rabbitmq-performance-measurements-part-1>Last time</a> we talked about flow control and
latency; today let&rsquo;s talk about how different features affect
the performance we see. Here are some simple scenarios. As
before, they&rsquo;re all variations on the theme of one publisher and
one consumer publishing as fast as they can.</p></div><div><a href=/posts/2012/04/rabbitmq-performance-measurements-part-2/>Read More...</a></div><hr><h3><a href=https://blog.rabbitmq.com/posts/2012/04/rabbitmq-performance-measurements-part-1/ rel=bookmark title="RabbitMQ Performance Measurements, part 1">RabbitMQ Performance Measurements, part 1</a></h3><small>April 16, 2012
by
Simon MacMullen</small><div class=entry><p>So today I would like to talk about some aspects of RabbitMQ&rsquo;s
performance. There are a huge number of variables that feed into
the overall level of performance you can get from a RabbitMQ
server, and today we&rsquo;re going to try tweaking some of them and
seeing what we can see.</p></div><div><a href=/posts/2012/04/rabbitmq-performance-measurements-part-1/>Read More...</a></div><hr></div><div id=right-nav><ul><li><a class=twitter-follow-button href=https://twitter.com/RabbitMQ data-show-count=false data-lang=en>Follow @RabbitMQ</a><li><form action=https://blog.rabbitmq.com/search method=get><input type=submit value=Search>
<input id=search-query type=text name=s size=10></form></li><li><h2>Archives</h2><ul><li><a href=https://blog.rabbitmq.com/year/2022/>2022</a></li><li><a href=https://blog.rabbitmq.com/year/2021/>2021</a></li><li><a href=https://blog.rabbitmq.com/year/2020/>2020</a></li><li><a href=https://blog.rabbitmq.com/year/2019/>2019</a></li><li><a href=https://blog.rabbitmq.com/year/2018/>2018</a></li><li><a href=https://blog.rabbitmq.com/year/2017/>2017</a></li><li><a href=https://blog.rabbitmq.com/year/2016/>2016</a></li><li><a href=https://blog.rabbitmq.com/year/2015/>2015</a></li><li><a href=https://blog.rabbitmq.com/year/2014/>2014</a></li><li><a href=https://blog.rabbitmq.com/year/2013/>2013</a></li><li><a href=https://blog.rabbitmq.com/year/2012/>2012</a></li><li><a href=https://blog.rabbitmq.com/year/2011/>2011</a></li><li><a href=https://blog.rabbitmq.com/year/2010/>2010</a></li></ul></li><li><h2>Categories</h2><ul><li><a href=https://blog.rabbitmq.com/categories/announcement/>Announcement</a></li><li><a href=https://blog.rabbitmq.com/categories/announcements/>Announcements</a></li><li><a href=https://blog.rabbitmq.com/categories/blueprints/>Blueprints</a></li><li><a href=https://blog.rabbitmq.com/categories/case-studies/>Case Studies</a></li><li><a href=https://blog.rabbitmq.com/categories/cloud/>Cloud</a></li><li><a href=https://blog.rabbitmq.com/categories/erlang/>Erlang</a></li><li><a href=https://blog.rabbitmq.com/categories/hasenwerkstatt/>Hasenwerkstatt</a></li><li><a href=https://blog.rabbitmq.com/categories/howto/>HowTo</a></li><li><a href=https://blog.rabbitmq.com/categories/howto-new-features/>HowTo New Features</a></li><li><a href=https://blog.rabbitmq.com/categories/introductory/>Introductory</a></li><li><a href=https://blog.rabbitmq.com/categories/kubernetes/>Kubernetes</a></li><li><a href=https://blog.rabbitmq.com/categories/new-features/>New Features</a></li><li><a href=https://blog.rabbitmq.com/categories/performance/>Performance</a></li><li><a href=https://blog.rabbitmq.com/categories/programming-languages/>Programming Languages</a></li><li><a href=https://blog.rabbitmq.com/categories/resiliency/>Resiliency</a></li><li><a href=https://blog.rabbitmq.com/categories/streams/>Streams</a></li><li><a href=https://blog.rabbitmq.com/categories/talks-and-conferences/>Talks and Conferences</a></li><li><a href=https://blog.rabbitmq.com/categories/technical-deep-dive/>Technical Deep Dive</a></li><li><a href=https://blog.rabbitmq.com/categories/updates/>Updates</a></li><li><a href=https://blog.rabbitmq.com/categories/web-messaging/>Web Messaging</a></li></ul></li><li><a href=https://blog.rabbitmq.com/categories/performance/index.xml>Atom feed</a></li></ul></div></div><div class=clear></div><div class=pageFooter><div class=container><div class=rabbit-logo><a href=https://www.rabbitmq.com/><img src=https://www.rabbitmq.com/img/logo-rabbitmq-white.svg alt=RabbitMQ></a></div><ul class=footerNav><li><a href=https://www.rabbitmq.com/#features>Features</a></li><li><a href=https://www.rabbitmq.com/#getstarted>Get Started</a></li><li><a href=https://www.rabbitmq.com/#support>Support</a></li><li><a href=https://www.rabbitmq.com/#community>Community</a></li><li><a href=https://www.rabbitmq.com/documentation.html>Docs</a></li><li><a href=https://blog.rabbitmq.com>Blog</a></li></ul><p id=copyright>Copyright &#169; 2007-2021 <a href=https://tanzu.vmware.com/>VMware</a>, Inc. or its affiliates. All rights reserved.
<a href=https://pivotal.io/terms-of-use>Terms of Use</a>,
<a href=https://pivotal.io/privacy-policy>Privacy</a> and
<a href=https://www.rabbitmq.com/trademark-guidelines.html>Trademark Guidelines</a></p><p><small>The postings on this site are by individual members of the
RabbitMQ team, and do not represent VMware’s positions, strategies
or opinions.</small></p></div></div></div></body></html>