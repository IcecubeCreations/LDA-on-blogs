








We released simdjson 0.3: the fastest JSON parser in the world is even better! – Daniel Lemire's blog






















































Skip to content



Daniel Lemire's blog
Daniel Lemire is a computer science professor at the University of Quebec (TELUQ) in Montreal. His research is focused on software performance and data engineering. He is a techno-optimist and a free-speech advocate.
Menu and widgets




My home page
My papers
My software
 

SubscribeJoin 12,500 subscribers:





Email Address














You can also follow this blog on telegram.


Search for:



Support my work!I do not accept any advertisement. However, you can support the blog with donations through paypal. Please consider getting in touch if you are a supporter so that I can thank you.
You can also support my work on GitHub.

Recent Posts


Parsing JSON faster with Intel AVX-512


Avoid exception throwing in performance-sensitive code


Faster bitset decoding using Intel AVX-512


Fast bitset decoding using Intel AVX-512


Removing characters from strings faster with AVX-512


Recent Commentsme on Avoid exception throwing in performance-sensitive codeDaniel Lemire on Avoid exception throwing in performance-sensitive codeJoern Engel on Avoid exception throwing in performance-sensitive codegrid on Are your strings immutable?krytyczna on Should computer scientists keep the Lena picture?Pages

A short history of technology
About me
Book recommendations
Cognitive biases
Interviews and talks
My bets
My favorite articles
My favorite quotes
My readers
My sayings
Predictions
Recommended video games
Terms of use
Write good papers

Archives Archives

Select Month
 May 2022  (4)
 April 2022  (4)
 March 2022  (2)
 February 2022  (4)
 January 2022  (3)
 December 2021  (2)
 November 2021  (7)
 October 2021  (12)
 September 2021  (5)
 August 2021  (2)
 July 2021  (4)
 June 2021  (5)
 May 2021  (8)
 April 2021  (6)
 March 2021  (5)
 February 2021  (4)
 January 2021  (6)
 December 2020  (11)
 November 2020  (10)
 October 2020  (6)
 September 2020  (6)
 August 2020  (4)
 July 2020  (6)
 June 2020  (7)
 May 2020  (6)
 April 2020  (7)
 March 2020  (8)
 February 2020  (7)
 January 2020  (7)
 December 2019  (10)
 November 2019  (6)
 October 2019  (7)
 September 2019  (9)
 August 2019  (9)
 July 2019  (10)
 June 2019  (9)
 May 2019  (10)
 April 2019  (8)
 March 2019  (15)
 February 2019  (9)
 January 2019  (10)
 December 2018  (9)
 November 2018  (8)
 October 2018  (10)
 September 2018  (9)
 August 2018  (10)
 July 2018  (14)
 June 2018  (9)
 May 2018  (11)
 April 2018  (11)
 March 2018  (10)
 February 2018  (7)
 January 2018  (15)
 December 2017  (9)
 November 2017  (16)
 October 2017  (13)
 September 2017  (20)
 August 2017  (12)
 July 2017  (8)
 June 2017  (9)
 May 2017  (10)
 April 2017  (11)
 March 2017  (11)
 February 2017  (6)
 January 2017  (8)
 December 2016  (8)
 November 2016  (4)
 October 2016  (6)
 September 2016  (10)
 August 2016  (6)
 July 2016  (4)
 June 2016  (6)
 May 2016  (5)
 April 2016  (10)
 March 2016  (9)
 February 2016  (8)
 January 2016  (5)
 December 2015  (8)
 November 2015  (4)
 October 2015  (8)
 September 2015  (5)
 August 2015  (6)
 July 2015  (5)
 June 2015  (2)
 May 2015  (4)
 April 2015  (4)
 March 2015  (5)
 February 2015  (5)
 January 2015  (3)
 December 2014  (6)
 November 2014  (4)
 October 2014  (3)
 September 2014  (5)
 August 2014  (5)
 July 2014  (4)
 June 2014  (2)
 May 2014  (6)
 April 2014  (7)
 March 2014  (3)
 February 2014  (5)
 January 2014  (6)
 December 2013  (8)
 November 2013  (5)
 October 2013  (5)
 September 2013  (5)
 August 2013  (3)
 July 2013  (4)
 June 2013  (4)
 May 2013  (3)
 April 2013  (7)
 March 2013  (6)
 February 2013  (6)
 January 2013  (8)
 December 2012  (2)
 November 2012  (5)
 October 2012  (4)
 September 2012  (6)
 August 2012  (4)
 July 2012  (4)
 June 2012  (3)
 May 2012  (3)
 April 2012  (6)
 March 2012  (5)
 February 2012  (3)
 January 2012  (9)
 December 2011  (3)
 November 2011  (5)
 October 2011  (5)
 September 2011  (4)
 August 2011  (8)
 July 2011  (3)
 June 2011  (5)
 May 2011  (6)
 April 2011  (6)
 March 2011  (5)
 February 2011  (4)
 January 2011  (10)
 December 2010  (7)
 November 2010  (6)
 October 2010  (3)
 September 2010  (3)
 August 2010  (5)
 July 2010  (4)
 June 2010  (7)
 May 2010  (5)
 April 2010  (7)
 March 2010  (8)
 February 2010  (5)
 January 2010  (7)
 December 2009  (4)
 November 2009  (6)
 October 2009  (10)
 September 2009  (8)
 August 2009  (11)
 July 2009  (9)
 June 2009  (7)
 May 2009  (7)
 April 2009  (7)
 March 2009  (7)
 February 2009  (14)
 January 2009  (14)
 December 2008  (16)
 November 2008  (25)
 October 2008  (13)
 September 2008  (15)
 August 2008  (14)
 July 2008  (15)
 June 2008  (14)
 May 2008  (15)
 April 2008  (20)
 March 2008  (18)
 February 2008  (12)
 January 2008  (19)
 December 2007  (24)
 November 2007  (23)
 October 2007  (19)
 September 2007  (13)
 August 2007  (23)
 July 2007  (18)
 June 2007  (15)
 May 2007  (19)
 April 2007  (9)
 March 2007  (7)
 February 2007  (27)
 January 2007  (20)
 December 2006  (20)
 November 2006  (18)
 October 2006  (9)
 September 2006  (11)
 August 2006  (25)
 July 2006  (10)
 June 2006  (18)
 May 2006  (27)
 April 2006  (25)
 March 2006  (11)
 February 2006  (11)
 January 2006  (39)
 December 2005  (23)
 November 2005  (25)
 October 2005  (20)
 September 2005  (26)
 August 2005  (39)
 July 2005  (17)
 June 2005  (16)
 May 2005  (9)
 April 2005  (13)
 March 2005  (30)
 February 2005  (20)
 January 2005  (30)
 December 2004  (11)
 November 2004  (19)
 October 2004  (14)
 September 2004  (17)
 August 2004  (13)
 July 2004  (16)
 June 2004  (16)
 May 2004  (12)


Boring stuff

Log in
Entries feed
Comments feed
WordPress.org

 







We released simdjson 0.3: the fastest JSON parser in the world is even better! 

Last year (2019), we released the simjson library. It is a C++ library available under a liberal license (Apache) that can parse JSON documents very fast. How fast? We reach and exceed 3 gigabytes per second in many instances. It can also parse millions of small JSON documents per second.
The new version is much faster. How much faster? Last year, we could parse a file like simdjson at a speed of 2.0 GB/s, and then we reached 2.2 GB/s. We are now reaching 2.5 GB/s. Why go so fast? In comparison, a fast disk can reach  5 GB/s and the best network adapters are even faster.
The following plot presents the 2020 simdjson library (version 0.3) compared with the fastest standard compliant C++ JSON parsers (RapidJSON and sajson). It ran on a single Intel Skylake core, and the code was compiled with the GNU GCC 9 compiler. All tests are reproducible using Docker containers.

In this plot, RapidJSON and simjson have exact number parsing, while RapidJSON (fast float) and sajson use approximate number parsing. Furthermore, sajson has only partial unicode validation whereas other parsers offer exact encoding (UTF8) validation.
If we only improved the performance, it would already be amazing. But our new release pack a whole lot of improvements:

Multi-Document Parsing: Read a bundle of JSON documents (ndjson) 2-4x faster than doing it individually.
Simplified API: The API has been completely revamped for ease of use, including a new JSON navigation API and fluent support for error code and exception styles of error handling with a single API. In the past, using simdjson was a bit of a chore, the new approach is definitively modern, see for yourself:
auto cars_json = R"( [

  { "make": "Toyota", "model": "Camry",  "year": 2018, 

       "tire_pressure": [ 40.1, 39.9 ] },

  { "make": "Kia",    "model": "Soul",   "year": 2012, 

       "tire_pressure": [ 30.1, 31.0 ] },

  { "make": "Toyota", "model": "Tercel", "year": 1999, 

       "tire_pressure": [ 29.8, 30.0 ] }

] )"_padded;

dom::parser parser;

dom::array cars = parser.parse(cars_json).get<dom::array>();



// Iterating through an array of objects

for (dom::object car : cars) {

  // Accessing a field by name

  cout << "Make/Model: " << car["make"] 

           << "/" << car["model"] << endl;



  // Casting a JSON element to an integer

  uint64_t year = car["year"];

  cout << "- This car is " << 2020 - year 

           << "years old." << endl;



  // Iterating through an array of floats

  double total_tire_pressure = 0;

  for (double tire_pressure : car["tire_pressure"]) {

    total_tire_pressure += tire_pressure;

  }

  cout << "- Average tire pressure: " 

      << (total_tire_pressure / 2) << endl;



  // Writing out all the information about the car

  for (auto [key, value] : car) {

    cout << "- " << key << ": " << value << endl;

  }

}



Exact Float Parsing: simdjson parses floats flawlessly at high speed.
Fallback implementation: simdjson now has a non-SIMD fallback implementation, and can run even on very old 64-bit machines. This means that you no longer need to check whether the system supports simdjson.
Automatic allocation: as part of API simplification, the parser no longer has to be preallocated: it will adjust automatically when it encounters larger files.
Runtime selection API: We have exposed simdjson’s runtime CPU detection and implementation selection as an API, so you can tell what implementation we detected and test with other implementations.
Error handling your way: Whether you use exceptions or check error codes, simdjson lets you handle errors in your style. APIs that can fail return simdjson_result, letting you check the error code before using the result. But if you are more comfortable with exceptions, skip the error code
and cast straight to the value you need, and exceptions will be thrown automatically if an error happens. Use the same API either way!
Error chaining: We also worked to keep non-exception error-handling short and sweet. Instead of having to check the error code after every single operation, now you can chain JSON navigation calls like looking up an object field or array element, or casting to a string, so that you only have to check the error code once at the very end.
We now have a dedicated web site (https://simdjson.org) in addition to the GitHub site (https://github.com/simdjson/simdjson).

Credit: many people contributed to simdjson, but John Keiser played a substantial role worthy of mention.


Published by

 

Daniel Lemire

A computer science professor at the University of Quebec (TELUQ). 
View all posts by Daniel Lemire 




Posted on March 31, 2020April 1, 2020Author Daniel LemireCategories  



30 thoughts on “We released simdjson 0.3: the fastest JSON parser in the world is even better!” 





 Claude says: 

April 1, 2020 at 8:10 am 


Congratulations is de rigueur here.
I guess the next challenge will be an API to speed up YAML parsing. YAML files are an important part of deploying PyTorch on most platforms, it will be worth seeing if you can easily adapt this library to this type of parsing.

Reply 





 Michal Lazo says: 

April 1, 2020 at 9:20 am 


Are there any SIMD accelerated XML parser?

Reply 





 Daniel Lemire says: 

April 1, 2020 at 12:47 pm 


There has been some XML parsers, at least at the prototype level, that have used SIMD instructions deliberately. However, I do not think that there has ever been something like simdjson for XML.

Reply 





 José Duarte says: 

June 11, 2020 at 2:38 am 


The Parabix XML project.

Reply 





 Daniel Lemire says: 

June 11, 2020 at 1:35 pm 



The Parabix XML project.

Yes, we know of parabix, but no, it is nothing like simdjson for XML.

Reply 





 José Duarte says: 

June 11, 2020 at 2:12 pm 


And? How does it compare? It looks innovative. Is simdjson’s approach applicable to XML too?

Reply 





 Daniel Lemire says: 

June 11, 2020 at 3:41 pm 


Please see the paper where it is discussed in details. If you have questions after reading the paper, I will be happy to answer them.

Reply 





 Joe Duarte says: 

June 14, 2020 at 7:43 pm 


Okay, I read it. Very nice work.
Q1: Why do you use 8 bytes to encode things like null, true, false, etc.? Couldn’t you just use one byte, or even a few bits? After all, there’s a null codepoint in ASCII / UTF-8 — it’s the first one, the binary zero byte 0000 0000. Do you need everything to be eight bytes for some reason?
Q2: Why are you focused only on huge files, over 50 KB? For JSON that’s huge. The most common use of JSON is slinging around requests and responses on the web, with small payloads. For example, a REST API for payments might involve JSON payloads that are about 1 to 3 KB each. (GraphQL, like REST, also uses JSON.) See PayPal’s API, or here’s an example of a typical request payload: https://doc.gopay.com/en/?lang=shell#standard-payment
Q3: What do you do if you can’t use tzcnt to count trailing zeros? That instruction is part of BMI, which came out in Haswell. Ivy Bridge and Sandy Bridge won’t have it, and there are still a lot of servers running on those families. How far back do you go on SIMD? Is something like Westmere or Nehalem you’re floor? They would have SSE4.2, carryless multiplication, and I think AES.
You might be understating simdjson performance with all those number-heavy files, since number parsing should be your slowest.
FYI, I opened an issue on GitHub asking about CPU and memory overhead. That’s an important dimension that the paper and the website don’t address. It’s also important to know if it causes cores to throttle down when you use AVX2 or whatever. I think Skylake and Cascade Lake might be okay on that front, but there might be an issue using AVX or AVX2 on earlier families. If so, using simdjson would slow down all the other applications and workloads on the server. I know that AVX512 throttles cores, but I don’t remember about AVX2.

Reply 





 Daniel Lemire says: 

June 14, 2020 at 9:59 pm 



Why do you use 8 bytes to encode things like null, true, false, etc.? Couldn’t you just use one byte, or even a few bits?

The tape uses a flat 8-byte per element, with some exceptions (numbers use two 8-byte entries).

Why are you focused only on huge files, over 50 KB? For JSON that’s huge.

That is what the paper benchmarks. But you can find other results on GitHub, including on tiny files.

What do you do if you can’t use tzcnt to count trailing zeros? That instruction is part of BMI, which came out in Haswell. Ivy Bridge and Sandy Bridge won’t have it, and there are still a lot of servers running on those families. How far back do you go on SIMD? Is something like Westmere or Nehalem you’re floor? They would have SSE4.2, carryless multiplication, and I think AES.

The simdjson relies on runtime dispatching. It runs on every x64 processing under a 64-bit system. It is open source.

FYI, I opened an issue on GitHub asking about CPU and memory overhead. That’s an important dimension that the paper and the website don’t address. It’s also important to know if it causes cores to throttle down when you use AVX2 or whatever. I think Skylake and Cascade Lake might be okay on that front, but there might be an issue using AVX or AVX2 on earlier families. If so, using simdjson would slow down all the other applications and workloads on the server. I know that AVX512 throttles cores, but I don’t remember about AVX2.

We do not support AVX-512. No downclocking is expected: we do not use AVX2 instructions requiring it (e.g., FMA). But, in any case, as the user, you are in charge of kernel that runs, so you can select SSSE3 is you prefer, even when your system supports AVX2. The simdjson has a non-allocation policy for parsing, so you can parse terabytes of data without allocating memory.

Reply 





 Joe Duarte says: 

June 15, 2020 at 8:53 am 


Okay, so on the issue of CPU overhead you said on GitHub that speed is CPU overhead or something. That’s not quite right. The equation is:
Overhead = (JSON GB / Parsing speed) × CPU usage
Where CPU usage is the percentage of CPU. There could also be a form that uses CPU clock cycles per byte or something. It’s not enough to know how fast some software is – we normally have to know its cost in resources like CPU and memory. It looks like you’re good on memory since you don’t allocate, but I’m surprised that you’re unwilling to report CPU overhead.
Another suggestions.
It would be great to know some things about simdjson’s security properties, to have some basic assurances. This is a strange era for computing given how insecure and primitive our programming languages and tools are. C++ is an unsafe language where exploitable memory bugs are inevitable on medium to large projects. One light assurance would be if you follow the C++ Core Guidelines. Much stronger assurance would be to pass something Coverity Scan. It’s free for open source projects.
A JSON parser might parse untrusted input, which can be malformed or not JSON at all. Ideally a parser would be formally verified, but hardly anyone does that since popular programming languages like C++ aren’t designed to facilitate verification and the tooling sucks. So Coverity is about as good as it gets. Address Sanitizer and Memory Sanitizer in the LLVM project are interesting too. The Software Engineering Institute at Carnegie Mellon has a Secure C++ Coding Guidelines too: https://insights.sei.cmu.edu/sei_blog/2017/04/cert-c-secure-coding-guidelines.html
If you had some kind of formal assurances like those it would be pretty distinctive.

Reply 





 Daniel Lemire says: 

June 15, 2020 at 12:24 pm 


I’m surprised that you’re unwilling to report CPU overhead.
If you have interesting performance metrics you would like to propose, we are always inviting new pull requests. The simdjson library is a community-based project. Please write up some code, and we shall be glad to discuss it.

Reply 





















 Marcel Weiher says: 

April 1, 2020 at 9:53 am 


Awesome work! When I looked at integrating the previous version into a higher level parser, it didn’t look like it handled streaming. Was that impression correct and if so, has that changed? Thanks!

Reply 





 Daniel Lemire says: 

April 1, 2020 at 12:45 pm 


We do handle long inputs containing multiple JSON documents (e.g., line separated). We even have a nifty API for it (see “parse_many”).
If you mean streaming as in “reading from a C++ istream”, then, no, we do not support this and won’t. It is too slow. We are faster than getline applied to an in-memory istream.

Reply 





 Marcel Weiher says: 

April 1, 2020 at 12:54 pm 


Don’t care about C++ istream. In order to stream, the parser must be able to deal with partial/incomplete inputs and with resuming such an incomplete parse.
Feeding it is then Somebody Else’s Problem.
One of the things I learned early on in building high-perf components is that having the component itself be fast is (at most) half the bette. The crucial bit is that it must be possible, preferably easy/straightforward, to use it in such a way the the whole ensemble is fast.
A lot of the “fast” XML parsers tended to fall flat in that regard.

Reply 





 Marcel Weiher says: 

April 1, 2020 at 12:55 pm 


battle, of course. I blame autocorrect…

Reply 





 Daniel Lemire says: 

April 1, 2020 at 1:13 pm 


The way simdjson is currently designed is that it won’t let you access a document (at all) unless it has been fully validated. The rationale behind this is that many people do not want to start ingesting documents that are incorrect. And, of course, you can only know that a document is valid if you have seen all of it.
For line-separated JSON documents, it is not an issue because you get to see the whole JSON document before returning it to the user, it is just that you have a long stream of them.
We plan to offer more options in future releases.

Reply 





 Pawel Terlecki says: 

October 29, 2020 at 11:32 pm 


The parsing speed is impressive, great work.
I second Marcel’s point. The current interface works well if a processing pipeline starts with a file. However, the parser cannot be used in the middle of a pipeline in a larger system. Without supporting streaming input, materializing large intermediate result clogs the flow. Downloading a file from cloud storage or user-defined document transformations are common scenarios here.
The parser would not have to output incorrect or incomplete documents. It would wait for another chunk of input to continue parsing a document that is in-flight.

Reply 





 Daniel Lemire says: 

October 29, 2020 at 11:59 pm 


You write “materializing large intermediate”, and with that constraint, I agree. But be mindful that large means “out of cache”, and we have megabytes of cache on current processor cores. For small to medium files, querying cache lines through an interface is an anti-design.
Note that we have since released version 0.6 which introduces a new API that we call On Demand API. So this blog post is somewhat obsolete at this point.

Reply 















 eb says: 

April 1, 2020 at 11:03 am 


Minor inconsistency in the example: the average tire pressure of the cars will not be what one would expect (only half of it)!

Reply 





 Alex Mikhalev says: 

April 1, 2020 at 4:05 pm 


Any plans for Rust bindings?

Reply 





 Daniel Lemire says: 

April 1, 2020 at 4:36 pm 


There are Rust bindings but help is needed to get it updated:
https://github.com/SunDoge/simdjson-rust

Reply 







 Catherine says: 

May 22, 2020 at 8:11 pm 


Congrats !
What about a mooc/levure on parsing with C++ ?

Reply 





 Daniel Lemire says: 

May 22, 2020 at 8:15 pm 


@Catherine
I have a talk on YouTube, does that count?
https://www.youtube.com/watch?v=wlvKAT7SZIQ

Reply 





 Catherine says: 

May 22, 2020 at 10:28 pm 


Thanks. Great talk and aha moments.

Reply 









 José Duarte says: 

June 11, 2020 at 2:47 am 


By the way, it would be neat to have an ultrafast SIMD JSON minifier, something very light in terms of CPU and memory use.
This would presumably be much simpler than a parser, since all it would have to do is strip spaces, tabs, newlines, and carriage returns. Well, it would have to know not to touch the contents of quoted strings.
There’s an enormous amount of waste with all the unminified JSON people are slinging around. You can save 10% most of the time by minifying, but there aren’t any good minifiers out there.

Reply 





 Daniel Lemire says: 

June 11, 2020 at 1:33 pm 



By the way, it would be neat to have an ultrafast SIMD JSON minifier,
something very light in terms of CPU and memory use.

But we do have that!!!! It is part of simdjson.

Reply 







 José Duarte says: 

June 11, 2020 at 2:09 pm 


Oh nice! Does it minify by default, or is it a flag?

Reply 





 Daniel Lemire says: 

June 11, 2020 at 2:46 pm 



Oh nice! Does it minify by default, or is it a flag?

It is a function that you may call on JSON string. It does not parse. It is highly optimized.
It is not currently very well exposed or documented, since it has been updated to be multiplatform only recently.

Reply 







 Daniel Ryan says: 

December 8, 2020 at 12:49 am 


How’s the performance for mobile? E.g Android and iOS devices.
I’m currently using rapidjson for a library that’s used for mobile devices and wondering if I should move over to simjson, if it’s faster and easier to use.

Reply 





 Daniel Lemire says: 

December 8, 2020 at 1:05 am 


We support 64-bit ARM platforms with accelerated kernels. See https://lemire.me/blog/2019/08/01/a-new-release-of-simdjson-runtime-dispatching-64-bit-arm-support-and-more/

Reply 





Leave a Reply Cancel replyYour email address will not be published. The comment form expects plain text. If you need to format your text, you can use HTML elements such strong, blockquote, cite, code and em. For formatting code as HTML automatically, I recommend tohtml.com.Comment * Name * 
Email * 
Website 
 Save my name, email, and website in this browser for the next time I comment.






 Receive Email Notifications?


no, do not subscribe
yes, replies to my comment
yes, all comments/replies


instantly
hourly digest
daily digest
weekly digest


Or, you can subscribe without commenting.


 

Δ 
You may subscribe to this blog by email.


Post navigation
Previous Previous post: Science and Technology links (March 28th 2020)Next Next post: Science and Technology links (April 4th 2020)






Terms of use 
Proudly powered by WordPress 
















