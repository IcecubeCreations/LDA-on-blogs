handle
large
connector_data_1
with
technology_1
technology_2
csv
technology_3
image
video
audio

kai
waehner
home
highlight
activity
talk
at
international
conference
video
component_1
publication
requirement_1
requirement_1
technology_1
technology_4
requirement_2
requirement_3
intelligence
deep

technology_5
in
memory
jupyter
requirement_4
technology_6
open_source
technology_2
connector_1
technology_7
social
requirement_5
technology_8
requirement_6
requirement_6
technology_1
mesos
requirement_6
requirement_7
technology_9
technology_10
open_source
persistence
component_2
mesh
internet
of
thing
internet
of
thing
requirement_2
iiot
technology_11
open_source
plc4x
requirement_8
requirement_8
component_3
requirement_9
component_4
component_5
blockchain
bpm
eai
esb
it
certification
it
conference
technology_12
jee
pattern_1
pattern_2
technology_13
open_source
technology_1
technology_2
technology_2
connector_2
persistence
component_2
mesh
pattern_3
social
requirement_5
web
technology_14
connector_3
component_6
connector_3
component_6
technology_1
technology_2
requirement_2
confluent
technology_2
connector_2
technology_2
connector_1
ksql
persistence
about
me
stay
in
technology_15
evangelist
–
requirement_2
requirement_1
–
technology_13
–
technology_1
technology_2
technology_15
evangelist
–
requirement_2
requirement_1
–
technology_13
–
technology_1
technology_2
home
highlight
activity
talk
at
international
conference
video
component_1
publication
requirement_1
requirement_6
internet
of
thing
requirement_8
connector_3
component_6
technology_1
sparkbig
databusiness
intelligencedeep
learninghadoopin
memoryjupyterkafka
streamsmachine
learningnosqlopen
sourcepythonsocial
networktensorflow
technology_1
mesoscloud
nativedockerkubernetesopen
sourcepersistenceservice
mesh
big
dataiiotmqttopen
sourceplc4x
technology_1
kafkaapi
managementapplication
serverblockchainbpmeaiesbit
certificationsit
conferencesjava
jeekafka
connectmessagingmicroservicesmiddlewareopen
sourcepersistenceservice
meshsoasocial
networkweb
technology_14
technology_1
kafkabig
dataconfluentkafka
connectkafka
streamsksqlpersistence
about
me
stay
in
search
for
search
technology_1
technology_2
audio
requirement_2
large
connector_data_1
component_7
vision
video
handle
large
connector_data_1
with
technology_1
technology_2
csv
technology_3
image
video
audio


minute
connector_4
bykai
waehner7

total

connector_5



connector_6

people
connector_7
the
story




technology_2
be
not
build
for
large
connector_data_2
period
nevertheless
more
and
more
project
connector_8
and
component_6
1mb
10mb
and
even
much
big
and
other
large
connector_data_3
via
technology_2
one
reason
be
that
technology_2
be
design
for
large
volume
quality_attribute_1
–
which
be
require
for
large
connector_data_2
this
coding_keyword_1
cover
the
use
requirement_10
architecture
and
requirement_11
off
for
handle
large
connector_data_1
with
technology_2
use
requirement_10
for
large
technology_2
connector_data_2
connector_data_3
various
use
requirement_10
for
large
connector_data_2
connector_data_3
exist
image
recognition
video
requirement_1
audio
requirement_1
and
component_6
be
widespread
example
image
recognition
and
video
requirement_1
image
recognition
and
video
requirement_1
also

a
component_8
vision
be
probably
the
number
one
use
requirement_10
many
example
require
the
analysis
of
video
in
real
time
include
quality_attribute_2
and
surveillance
connector_9
control
intrusion
detection
motion
detection
transport
pattern_4
component_9
vehicle
traffic
detection
incidence
detection
pedestrian
pattern_5
healthcare
health
status
pattern_5
telemedicine
surgical
video
analysis
manufacture
component_7
vision
for
quality
assurance
augment
support
and
train
the
usage
of
image
and
video
component_6
via
concept
such
a
component_8
vision
e
g
technology_16
or
deep

neural
requirement_5
e
g
technology_8
reduce
time
cost
and
human
effort
plus
this
make
requirement_12
more
quality_attribute_3
quality_attribute_4
and
consistent
audio
requirement_1
audio
requirement_1
be
an
interest
use
requirement_10
come
up
more
and
more
in
conjunction
with
video
requirement_1
see
the
use
requirement_10
above
often
video
and
audio
need
to
be
component_6
together
component_10
iot
ciot
alerting
inform
advise
people
e
g
use
audio
analytic
industrial
iot
iiot
component_7
diagnostics
and
predictive
quality_attribute_5
use
advance
sound
analysis
e
g
use
neuron
soundware
natural
technology_17
component_6
nlp
chatbots
and
other
modern
component_11
use
text
and
speech
translation
e
g
use
the
fully
manage
component_12
from
the
major
requirement_6
technology_18
requirement_2
component_6
last
but
not
least
the
component_6
of
big
connector_10
in
pattern_6
mode
will
not
go
away
any
time
soon
but
big
can
be
incorporate
into
a
modern
connector_11
workflow
for
decouple
separation
of
concern
connector_12
to
various
connector_13
and
it
allow
connector_data_4
component_6
in
real
time
and
pattern_6
simultaneously
component_13
component_11
will
provide
connector_data_4
component_14
big
csv
or
proprietary
or
snapshot
export
from
component_15
that
need
to
be
quality_attribute_6
connector_data_4
component_6
include
connector_11
component_16
such
a
technology_2
connector_3
technology_19
or
technology_1
flink
to
continuously
component_6
correlate
and
analyze
from
different
connector_data_4
component_17
connector_data_4
component_14
such
a
technology_5
or
technology_4
component_6
incoming
connector_data_4
in
pattern_6
mode
e
g
connector_data_5
reduce
shuffle
other
connector_data_4
component_14
such
a
connector_data_4
requirement_13
e
g

or
text
search
e
g
elasticsearch
ingest
connector_data_4
in
near
real
time
what
technology_2
be
not
after
explore
use
requirement_10
for
large
connector_data_2
connector_data_6
let’s
clarify
what
technology_2
be
not
technology_2
be
usually
not
the
right
technology_15
to
component_18
and
component_6
large
image
video
proprietary

etc
a
a
whole
technology_20
be
build
specifically
for
these
use
requirement_10
for
instance
a
content
delivery
requirement_5
cdn
such
a
akamai
limelight
requirement_5
or
technology_21
quality_attribute_7
video
connector_1
and
other
download
across
the
globe
or
“big
edit
and
processing”

a
video
component_6
technology_22
or
video
edit
technology_22
from
adobe
autodesk
camtasia
and
many
other
vendor
be
use
to
connector_data_7
and
present
all
video
connector_data_8
include
film
and
television
show
video
advertisement
and
video
essay
let’s
take
a
look
at
one
example
that
combine
technology_2
and
these
other
technology_22
netflix
component_19
over

petabyte
per
day
with
technology_2
however
this
be
“just”
for
connector_data_2
pattern_7
coordination
connector_data_4
requirement_8
connector_data_4
preprocessing
ingestion
into
connector_data_4
lake
build
stateless
and
stateful
requirement_3
component_4
and
other
use
requirement_10
but
technology_2
be
not
use
to
connector_14
and
connector_15
all
the
show
and
movie
you
watch
on
your
tv
or
tablet
a
content
delivery
requirement_5
cdn
akamai
be
use
in
conjunction
with
other
technology_22
and
technology_20
to
provide
you
the
excellent
video
connector_11
experience
you

okay
technology_2
be
not
the
right
technology_22
to
component_18
and
component_6
large
a
a
whole
a
cdn
or
video
edit
technology_22
why
when
and
how
should
you
handle
large
connector_data_2
connector_data_3
with
technology_2
then
and
what
be
a
“large
message”
in
technology_2
term
feature
and
limitation
of
use
technology_2
for
large
connector_data_1
originally
technology_2
be
not
build
for
component_6
large
connector_data_1
and

this
do
not
mean
that
you
cannot
do
it
technology_2
limit
the
max
size
of
connector_data_2
the
default
requirement_14
of
the
pattern_8
configuration’
‘
connector_data_2
max
bytes’
be
1mb
why
do
technology_2
limit
the
connector_data_2
size
by
default
different
size
configuration
and
tune
require
for
large
connector_data_2
handle
compare
to
a
mission
critical
real
time
cluster
with
low
quality_attribute_8
large
connector_data_1
increase
the
memory
pressure
on
the
pattern_8
technology_23
large
connector_data_1
be
expensive
to
handle
and
could
slow
down
the
pattern_8
a
reasonable
connector_data_2
size
limit
can
meet
the
requirement
of
most
use
requirement_10
quality_attribute_9
workarounds
exist
if
you
need
to
handle
large
connector_data_2
most
requirement_6
offer
don’t
allow
large
connector_data_2
there
be
noticeable
requirement_15
impact
from
increasing
the
allowable
connector_data_2
size
hence
understand
all
alternative
discuss
below
before
connector_16
connector_data_1
1mb
through
your
technology_2
cluster
quality_attribute_10
on
your
slas
for
uptime
and
quality_attribute_8
a
separate
technology_2
cluster
should
be
consider
for
component_6
large
connector_data_2
have
say
this
i
have
see
requirement_16
component_6
connector_data_1
far
big
than
10mb
with
technology_2
it
be
valid
to
evaluate
technology_2
for
component_6
large
connector_data_1
instead
of
use
another
technology_22
for
that
often
in
conjunction
with
technology_2
linkedin
talk
a
long
time
ago
about
the
pro
and
con
of
two
different
approach
use
‘kafka
only’
vs
‘kafka
in
conjunction
with
another
connector_data_4
storage’
especially
outside
the
coding_keyword_2
requirement_6
most
requirement_17
cannot
simply
use
an
technology_24
connector_data_9
component_18
for
requirement_2
therefore
the
question
come
up
if
one
component_9
technology_2
be
quality_attribute_9
enough
or
if
you
should
invest
in
two
component_11
technology_2
and
external
storage
let’s
take
a
look
at
the
requirement_11
off
for
use
technology_2
for
large
connector_data_2
technology_2
for
large
connector_data_1
–
alternative
and
requirement_11
off
there
be
no
single
best
solution
the
decision
on
how
to
handle
large
connector_data_1
with
technology_2
quality_attribute_10
on
your
use
requirement_10
slas
and
already
exist
infrastructure
the
follow
three
quality_attribute_11
alternative
exist
to
handle
large
connector_data_1
with
technology_2
reference
base
pattern_1
in
technology_2
and
external
storage
in
line
large
connector_data_2
support
in
technology_2
without
external
storage
in
line
large
connector_data_2
support
and
tiered
storage
in
technology_2
here
be
the
characteristic
and
pro
con
of
each
approach
this
be
an
extension
from
a
linkedin
presentation
in

also
don’t
underestimate
the
power
of
compression
for
large
connector_data_2
some
big
csv
or
connector_data_10
can
reduce
it
size
significantly
by
set
the
compression
parameter
to
use
gzip
snappy
or
lz4
even
a
1gb
could
be
connector_17
via
technology_2
but
this
be
undoubtedly
not
what
technology_2
be
design
for
in
both
the
component_20
and
the
pattern_8
a
1gb
chunk
of
memory
will
need
to
be
allocate
in
technology_23
for
every
1gb
connector_data_2
hence
in
most
requirement_10
for
really
large

it
be
quality_attribute_9
to
externalize
them
into
an
connector_data_9
component_18
and
use
technology_2
for
the
metadata
you
need
to
define
what
be
‘a
large
message’
by
yourself
and
when
to
use
which
of
the
design
pattern_9
discuss
in
this
coding_keyword_1
that’s
why
i
be
connector_18
this
up
here…
🙂
the
follow
section
explore
these
alternative
in
more
detail
before
we
start
let’s
explain
the
general
concept
of
tiered
storage
for
technology_2
mention
in
the
above
component_21
many
reader
might
not
be
aware
of
this
yet
tiered
storage
for
technology_2
technology_2
connector_data_4
be
mostly
connector_19
in
a
connector_11
fashion
use
tail
connector_4
tail
connector_20
leverage
os’s
component_22
pattern_10
to
serve
the
connector_data_4
instead
of
disk
connector_4
old
connector_data_4
be
typically
connector_4
from
the
disk
for
backfill
or
failure
recovery
purpose
and
be
infrequent
in
the
tiered
storage
approach
the
technology_2
cluster
be
configure
with
two
tier
of
storage
–
local
and
remote
local
tier
be
the
same
a
the
current
technology_2
that
us
the
local
disk
on
the
technology_2
pattern_8
to
component_18
the
requirement_18
segment
the
remote
tier
us
an
external
storage
component_9
such
a
technology_25
technology_24
gc
or
minio
to
component_18
the
complete
requirement_18
segment
two
separate
retention
period
be
define
correspond
to
each
of
the
tier
with
remote
tier
enable
the
retention
period
for
the
local
tier
can
be
significantly
reduce
from
day
to
few
hour
the
retention
period
for
remote
tier
can
be
much
long
month
or
even
year
tiered
storage
for
technology_2
allow
quality_attribute_12
storage
independent
of
memory
and
cpu
in
a
technology_2
cluster
enabling
technology_2
to
be
a
long
term
storage
solution
this
also
reduce
the
amount
of
connector_data_4
component_18
locally
on
technology_2
pattern_8
and
hence
the
amount
of
connector_data_4
that
need
to
be
copy
during
recovery
and
rebalancing
the
component_10
component_3
do
not
connector_21
at
all
technology_2
component_16
connector_19
connector_data_4
a
before
they
don’t
even
if
tiered
storage
be
use
under
the
hood
confluent
tiered
storage
confluent
tiered
storage
be
quality_attribute_11
today
in
confluent
component_23
and
use
under
the
hood
in
confluent
requirement_6
from
an
infrastructure
perspective
confluent
tiered
storage
require
an
external
connector_data_9
storage
technology_25
technology_24
gc
or
minio
but
from
and
development
perspective
the
complexity
of
end
to
end
connector_22
and
separation
of
connector_data_1
and
be
provide
out
of
the
component_24
under
the
hood
kip

–
tiered
storage
to
technology_2
kip

–
tiered
storage
support
to
technology_2
be
also
in
the
work
confluent
be
actively
work
on
this
with
the
open
component_17

uber
be
lead
this
initiative
technology_2
+
tiered
storage
be
an
excite
option
in
some
use
requirement_10
for
handle
large
connector_data_2
it
provide
a
single
infrastructure
to
the
operator
but
also
cost
connector_23
and
quality_attribute_9
elasticity
we
now
understand
the
technical
feasibility
of
handle
large
connector_data_2
connector_data_3
with
technology_2
let’s
now
discus
the
different
use
requirement_10
and
architecture
in
more
detail
use
requirement_10
and
architecture
use
technology_2
for
large
connector_data_1
the
component_6
of
the
content
of
your
large
connector_data_2
connector_data_6
quality_attribute_10
on
the
technical
use
requirement_10
do
you
want
to
connector_8
an
image
to
analyze
or
enhance
it
connector_3
a
video
to
a
remote
component_10
component_4
analyze
audio
noise
in
real
time
component_6
a
pattern_11
i
e
splittable
line
by
line
connector_8
an
pattern_12
i
e
non
splittable
to
a
component_10
technology_22
to
component_6
it
i
cover
a
few
use
requirement_10
for
handle
large
connector_data_2
manufacture
quality
assurance
in
production
line
quality_attribute_13
at
the
edge
in
the
factory
retail
augment
reality
for
quality_attribute_9
requirement_19
and
cross
up
sell
pharma
and
life
science
image
component_6
and
requirement_4
for
drug
discovery
coding_keyword_2
sector
quality_attribute_2
and
surveillance

content
delivery
of
large
video
bank
attachment
in
a
chat
component_4
for
requirement_16
component_2
the
follow
section
explore
these
use
requirement_10
with
different
architectural
approach
to
component_6
large
connector_data_2
connector_data_3
with
technology_1
technology_2
to
discus
their
pro
and
con
technology_2
requirement_7
connector_data_6
component_6
chunk
and
re
assemble
metadata
in
technology_2
and
connector_24
to
external
storage
externalize
large
connector_data_3
on
the
fly
technology_2
for
large
connector_data_2
connector_data_3
–
image
component_6
component_8
vision
and
image
recognition
be
use
in
many
requirement_12
include
automotive
manufacture
healthcare
retail
and
innovative
“silicon
valley
use
cases”
image
component_6
include
technology_22
such
a
technology_16
but
also
technology_15
connector_25
deep

algorithm
such
a
convolutional
neural
requirement_5
cnn
let’s
take
a
look
at
a
few
example
from
different
requirement_12
technology_2
requirement_7
image
component_6
for
component_7
vision
in
manufacture
component_7
vision
be
the
technology_15
and
use
to
provide
imaging
base
automatic
inspection
and
analysis
for
such
component_16
a
automate
inspection
component_6
control
and
robot
guidance
usually
in
requirement_12
a
technology_2
requirement_7
component_7
vision
implementation
connector_26
image
from
camera
to
technology_2
preprocessing

metadata
and
correlation
it
with
connector_data_4
from
other
backend
component_9
the
connector_data_2
be
then
connector_19
by
one
or
more
component_4
image
component_6
and
requirement_4
for
drug
discovery
in
pharma
and
life
science
“on
average
it
take
at
least
ten
year
for
a
medicine
to
complete
the
journey
from
initial
discovery
to
the
marketplace”
say
phrma
here
be
one
example
where
connector_11
at
quality_attribute_14
in
real
time
quality_attribute_15
up
this
component_6
significantly
recursion
have
several
technical
challenge
their
drug
discovery
component_6
be
manual
and
slow
bursty
pattern_6
mode
not
quality_attribute_16
to
solve
these
challenge
recursion
leverage
technology_2
and
it
ecosystem
to
build
a
massively
parallel
component_9
that
combine
experimental
biology
requirement_20
automation
and
real
time
connector_11
to
accelerate
drug
discovery
connector_27
out
recusion’s
technology_2
summit
talk
to
more
detail
i
see
plenty
of
requirement_16
in
various
requirement_12
connector_25
quality_attribute_16
real
time
requirement_4
infrastructure
with
the
technology_2
ecosystem
relate
to
the
above
use
requirement_10
i
explore
more
detail
in
the
coding_keyword_1
“apache
technology_2
and
connector_11
in
pharma
and
life
sciences“
the
follow
show
a
potential
ml
infrastructure
technology_2
requirement_7
image
recognition
for
augment
reality
in
retail
augment
reality
ar
be
an
interactive
experience
of
a
real
world
environment
where
the
connector_data_11
that
reside
in
the
real
world
be
enhance
by
component_8
generate
perceptual
connector_data_8
ar
component_16
be
usually
build
with
component_25
such
a
unity
or
unreal
use
requirement_10
exist
in
various
requirement_12
requirement_12


be
the
most
present
one
today
but
other
requirement_12
start
build
fascinate
component_4
think
about
pokemon
go
from
nintendo
for
your
smartphone
the
follow
show
an
example
of
ar
in
the
telco
requirement_12
for
provide
an
innovative
retail
component_2
the
requirement_16
make
a
picture
of
his
home
connector_26
the
picture
to
an
ott
component_2
of
the
telco
technology_18
and
connector_28
the
enhance
picture
e
g
with
a
couch
to
buy
for
your
home
technology_2
be
use
for
pattern_7
requirement_8
with
backend
component_2
and
connector_16
the
original
and
enhance
image
between
the
smartphone
and
the
ott
telco
component_2
component_7
vision
at
the
edge
in
industrial
iot
iiot
with
confluent
and
hivecell
technology_2
come
up
at
the
edge
more
and
more
here
be
an
example
of
component_7
vision
at
the
edge
with
technology_2
in
industrial
iot
iiot
requirement_12


i4
a
hivecell
technology_26
be
equipped
with
confluent
technology_11
pattern_13
requirement_8
with
the
camera
technology_2
pattern_8
and
technology_27
connector_11
component_23
technology_2
connector_3
connector_data_4
component_6
such
a
pattern_14
transformation
aggregation
etc
nvidia’s
triton
inference
component_5
image
recognition
use
train
analytic
component_26
technology_2
connector_2
and
confluent
replicator
pattern_15
of
the
component_7
vision
connector_data_12
to
the
requirement_6
video
connector_11
with
technology_1
technology_2
connector_11

be
the
component_6
of
connector_29
and
obtain

connector_data_4
be
continuously
connector_10
by
and
present
to
one
or
more
component_27
while
be
connector_30
by
a
technology_18
buffer
the
split
up
connector_data_4
package
of
video
on
the
component_10
side
ensure
a
continuous
flow
the
implementation
of
video
connector_11
with
technology_2
requirement_7
technology_15
be
pretty
straightforward
this
architecture
leverage
the
compose
connector_data_2
processor
requirement_17
requirement_8
pattern_9
eip
the
use
requirement_10
be
even
more
straightforward
a
we
don’t
need
a
content
base
pattern_16
in
our
requirement_10
we
combine
the
splitter
and
aggregator
eips
the
coding_keyword_1
“building
a
quality_attribute_7
multi
video
component_6
pipeline
with
technology_7
and
confluent
kafka”
show
a
great
demo
of
component_6
a
connector_3
of
video
frame
with
technology_2
split
and
aggregate
video
connector_1
for
quality_attribute_2
and
surveillance
in
the
coding_keyword_2
sector
the
follow
show
a
use
requirement_10
for
video
connector_11
with
technology_2
for
quality_attribute_2
and
surveillance
in
this
requirement_10
video
connector_11
be
part
of
a
modernize
siem
quality_attribute_2
connector_data_8
and
requirement_9
audio
connector_11
work
in
a
very
similar
way
hence
i
will
not
cover
it
separately
a
smart
city
be
another
example
where
video
image
and
audio
component_6
with
technology_2
come
into
play
technology_2
for
large
connector_data_2
connector_data_3
–
requirement_2
csv
technology_3
video
proprietary
up
above
we
have
see
example
for
component_6
specific
large
connector_data_2
image
video
audio
in
many
use
requirement_10
other
kind
of
need
to
be
component_6
large
include
pattern_11
connector_data_4
e
g
big
csv
or
connector_data_10
pattern_12
connector_data_4
e
g
complete
video
not
continuous
video
connector_3
or
other
binary
such
a
an
analytic
component_28
big
aggregate
from
offline
component_29
in
iot
big
csv
connector_data_10
or
technology_28
be
even
normality
in
modern
real
time
pattern_17
architecture
connector_31
car
be
one
example
in
theory
every
be
connector_17
in
real
time
connector_27
out
the
audi
keynote
at
technology_2
summit
for
this
use
requirement_10
in
practice
car
or
other
iot
component_30
be
offline
regularly
many
firmware
implementation
then
connector_8
the
connector_data_4
a
a
big
aggregate
a
tesla
describe
in
a
confluent

“one
of
the
unique
challenge
with
component_30
connector_data_4
connector_3
a
oppose
to
web
component_5
requirement_18
connector_data_4
connector_3
be
that
it
be
normal
for
component_29
to
become
disconnect
for
a
long
while
–
easily
month
–
and
to
then
connector_8
a
huge
amount
of
connector_data_4
a
they
come
back
online
quality_attribute_10
on
how
your
component_30
firmware
be
connector_32
this
could
mean
many
many
small
connector_data_1
which
can
be
wasteful
for
storage
and
bandwidth
consideration
or
more
likely
the
backlog
of
small
connector_data_1
pattern_6
together
a
a
couple
of
large
connector_data_2
if
we
be
to
blindly
connector_32
these
into
the
same
technology_2
topic
that
we
be
plan
to
use
for
regular
ingest
it
could
easily
overwhelm
our
cluster
”
similarly
to
the
video
connector_11
use
requirement_10
discuss
above
requirement_17
requirement_8
pattern_9
such
a
splitter
pattern_16
and
aggregator
be
perfect
for
this
scenario
download
the
big
at
once
split
it
up
component_6
by

and
if
necessary
connector_33
or
aggregate
the
again
claim
connector_27
requirement_17
requirement_8
pattern_9
for
non
splittable
large
connector_data_1
a
i
say
before
technology_2
be
not
the
right
technology_15
to
component_18
big

specific
technology_22
be
build
for
this
include
connector_data_9
connector_34
such
a
technology_25
technology_24
or
minio
the
claim
connector_27
eip
be
the
perfect
solution
for
this
problem
metadata
in
technology_2
and
connector_24
to
external
storage
for
content
delivery
of
large
video
in
the

requirement_12
many
large
video
be
produce
in
the

requirement_12
specific
storage
and
video
edit
technology_22
be
use
technology_2
do
not
connector_8
these
big

but
it
control
the
pattern_7
in
a
quality_attribute_17
decouple
real
time
architecture
externalize
large
connector_data_3
on
the
fly
for
component_13
requirement_8
from
proprietary
component_11
in
financial
component_12
big
have
to
be
component_6
in
many
requirement_12
in
financial
component_2
i
saw
several
use
requirement_10
where
large
proprietary
have
to
be
connector_7
between
different
component_13
component_4
similar
to
the
claim
connector_27
eip
use
above
you
can
also
leverage
technology_2
connector_2
and
it
single
connector_data_2
transformation
smt
feature
here
be
a
detail
example
of
component_6
large
connector_data_10
with
technology_2
connector_2
and
the
open
component_17
pulse
connector
“streaming
connector_data_4
into
technology_2
–
loading
connector_data_10
file“
natural
technology_17
component_6
nlp
use
technology_2
and
requirement_4
for
large
text
requirement_4
and
technology_2
be
a
perfect
fit
i
cover
this
topic
in
many

and
talk
in
the
past
or
start
with
this
coding_keyword_1
to
connector_35
an
idea
about
this
approach
“using
technology_1
technology_2
to
drive
cut
edge
machine_learning“
natural
technology_17
component_6
nlp
use
technology_2
and
requirement_4
for
large
text
be
a
great
example
“continuous
nlp
pipeline
with
technology_7
technology_12
and
technology_1
kafka”
show
how
to
connector_36
the
above
design
pattern_9
use
technology_2
connector_3
technology_2
connector_2
and
an
technology_24
serializer
deserializer
i
really
this
example
because
it
also
solve
the
impedance
mismatch
between
the
connector_data_4
scientist
who
love
technology_7
and
the
production
engineer
who
love
technology_12
“machine_learning
with
technology_7
jupyter
ksql
and
tensorflow”
explore
this
challenge
in
more
detail
large
connector_data_1
in
a
chat
component_4
for
requirement_16
component_2
in
bank
you

how
to
handle
large
with
technology_2
by
externalize
them
into
an
connector_data_9
component_18
and
only
connector_16
the
metadata
via
technology_2
in
some
use
requirement_10
this
be
too
much
effort
or
cost
connector_16
large
directly
via
technology_2
be
possible
and
sometimes
easy
to
connector_36
the
architecture
be
much
quality_attribute_18
and
more
cost
quality_attribute_19
i
already
discuss
the
requirement_11
off
above
but
here
be
an
excellent
use
requirement_10
of
connector_16
large
natively
with
technology_2
attachment
in
a
chat
component_4
for
requirement_16
component_2
an
example
of
a
financial
firm
use
technology_2
for
a
chat
component_9
be
goldman
sachs
they
lead
the
development
of
symphony
an
requirement_12
initiative
to
build
a
requirement_6
base
component_23
for
instant
connector_22
and
content
connector_14
that
securely
connector_37
requirement_21
participant
symphony
be
base
on
an
open
component_17
requirement_3
component_28
that
be
cost
quality_attribute_19
quality_attribute_20
and
quality_attribute_21
to
suit
end
component_31
need
many
other
finserv
requirement_22
invest
into
symphony
include
bank
of
america
bny
mellon
blackrock
citadel
citi
credit
suisse
deutsche
bank
goldman
sachs
hsbc
jefferies
jpmorgan
maverick
morgan
stanley
nomura
and
well
fargo
technology_2
be
a
perfect
fit
for
chat
component_4
the
pattern_8
storage
and
decouple
be
perfect
for
multi
component_23
and
multi
technology_15
infrastructure
offline
capability
and
connector_38
old
connector_data_1
be
build
into
technology_2
too
here
be
an
example
from
a
chat
component_23
in
the
gaming
requirement_12
attachment

image
or
any
other
binary
content
can
be
part
of
this
implementation
different
architecture
be
possible
for
instance
you
could
use
dedicate
technology_2
topic
for
handle
large
connector_data_2
or
you
put
them
into
your’
‘
chat
message’

with
confluent
schema
registry
the
schema
could
have
an
attribute
‘attachment’
or
you
externalize
the
attachment
use
the
claim
connector_27
eip
discuss
above
technology_2
requirement_7
handle
of
large
connector_data_1
have
it
use
requirement_10
a
you

in
this
coding_keyword_1
plenty
of
use
requirement_10
exist
for
handle
large
connector_data_1
with
technology_1
technology_2
and
it
ecosystem
technology_2
be
build
for
large
volume
quality_attribute_1
–
which
be
require
for
large
connector_data_2
‘scaling
technology_1
technology_2
to
10+
gb
per
second
in
confluent
cloud‘
be
an
impressive
example
however
not
all
large
connector_data_1
should
be
component_6
with
technology_2
often
you
should
use
the
right
storage
component_9
and
leverage
technology_2
for
the
pattern_7
the
different
design
pattern_9
and
choose
the
right
technology_15
for
each
problem
a
common
scenario
for
technology_2
requirement_7
component_6
of
large
connector_data_1
be
at
the
edge
where
other
connector_data_4
storage
be
often
not
quality_attribute_11
or
would
increase
the
cost
and
complexity
for
provision
the
infrastructure
what
be
your
experience
with
handle
large
connector_data_1
with
the
technology_2
ecosystem
do
you
or
do
you
plan
to
use
technology_1
technology_2
and
it
ecosystem
what
be
your
strategy
let’s
connector_2
on
linkedin
and
discus
it
stay
inform
about
coding_keyword_1
by
subscribe
to
my
newsletter
total

connector_5
connector_6

tweet

pin
it

please
leave
this
emptydont‘
miss
my
next
coding_keyword_1
subscribe
we
don’t
spam
connector_4
more
in
our
privacy
requirement_23
connector_27
your
inbox
or
spam
folder
to
confirm
your
subscription
relate
tagsanalyticsapache
kafkaaraudioaugmented
realitybankingbig
databig
fileschatchat
botchatbotcloudcloud
nativecsvdeep
learningedgeeipenterprise
requirement_8
patternfilehealthcarei4iiotimageindustry

0iotjsonkafkalarge
fileslarge
messageslogisticsmachine
learningmachine
visionmedianeural
networkpharmapredictive
maintenancereal
timesecurityspeech
translationsurveillancetiered
storagetransportationvideoxml
kai
waehner
build
requirement_6
requirement_7
connector_11
infrastructure
for
real
time
connector_data_4
component_6
and
requirement_1
leave
a
connector_data_13
cancel
replyyour
connector_39
will
not
be
publish
require
be
mark
*comment
*
name
*
*
connector_23
my
name

and
in
this
browser
for
the
next
time
i

pattern_18


you
also
technology_1
technology_2
+
technology_11
=
end
to
end
iot
requirement_8

slide
video
technology_1
technology_2
requirement_2
confluent
eai
internet
of
thing
technology_2
connector_2
pattern_1
pattern_2
technology_11
open_source
connector_3
component_6
bykai
waehner10

technology_11
and
technology_1
technology_2
be
a
perfect
combination
for
end
to
end
iot
requirement_8
from
edge
to
connector_data_4
center
this
coding_keyword_1
discus
two
different
approach
and
refer
to
implementation
on
technology_29
use
technology_1
technology_2
technology_2
connector_2
confluent
technology_11
pattern_13
and
mosquitto
connector_4
more



connector_4
more

2k
views20
minute
connector_4
can
technology_1
technology_2
replace
a
component_15
requirement_1
technology_1
technology_2
architecture
requirement_2
confluent
component_15
requirement_8
technology_2
connector_2
bykai
waehner12

can
and
should
technology_1
technology_2
replace
a
component_15
how
long
can
and
should
i
component_18
connector_data_4
in
technology_2
…
connector_4
more



technology_15
evangelist
kai
waehner
build
requirement_6
requirement_7
connector_11
infrastructure
for
real
time
connector_data_4
component_6
and
requirement_1
subscribe
to
my
newsletter
please
leave
this
empty
stay
inform
about
coding_keyword_1
we
don’t
spam
connector_4
our
privacy
requirement_23
for
more
info
connector_27
your
inbox
or
spam
folder
to
confirm
your
subscription
end
to
end
requirement_8
feature
coding_keyword_1

technology_1
technology_2
ksql
and
technology_1
plc4x
for
iiot
connector_data_4
requirement_8
and
component_6

technology_1
technology_2
vs
technology_13
mq
technology_30
esb
–
slide
+
video

deep

example
technology_1
technology_2
+
technology_7
+
kera
+
technology_8
+
technology_31
categoriescategories
select
category
5g
technology_32
gap
airline
airport
allgemein
msk
requirement_1
technology_1
technology_33
technology_1
technology_2
technology_1
mesos
technology_1
technology_34
technology_1
technology_4
component_3
component_3
gateway
component_3
requirement_9
component_4
component_5
architecture
ariba
asset
track
audio
augment
reality
automation
requirement_12
automotive
aviation
technology_25
technology_25
outpost
technology_25
wavelength
technology_35
bank
technology_36
bet
requirement_2
biotech
biotechnology
bitcoin
blockchain
bookmaker
bpm
bs
requirement_3
intelligence
requirement_24
citizen
requirement_6
requirement_6
requirement_7
technology_37
comparison
concur
condition
pattern_4
confluent
confluent
requirement_6
connector_31
car
connector_31
vehicle
conversational
requirement_20
core
bank
crm
crypto
cryptocurrency
cybersecurity
connector_data_4
at
rest
connector_data_4
historian
connector_data_4
hub
connector_data_4
in
motion
connector_data_4
requirement_8
connector_data_4
lake
connector_data_4
mesh
connector_data_4
science
connector_data_4
connector_11
connector_data_4
requirement_13
component_15
databricks
deep

defi
digital
forensics
digital
twin
disaster
recovery
quality_attribute_7
ledger
technology_9
domain
drive
design
eai
edge
edge
computing
eipaas
elasticsearch
elt
energy
requirement_17
architecture
erp
esb
ethereum
technology_30
connector_11
exactly
once
semantics
feature
coding_keyword_1
finance
requirement_12
food
forensics
fraud
fraud
detection
gamble
game
gaming
gcp
technology_38
government
technology_5
healthcare
hivecell
technology_39
hybrid
requirement_6
hyperledger
mq
idoc
iiot
in
memory
industrial
iot
requirement_12


insurance
insurance
requirement_12
requirement_8
internet
of
thing
intrusion
detection
inventory
requirement_9
iota
ipaas
it
certification
it
conference
technology_12
jee
technology_40
jupyter
technology_2
connector_2
technology_2
connector_1
kappa
architecture
ksql
technology_19
technology_10
lake
house
lambda
architecture
large
connector_data_1
component_13
libra
life
science
live
commerce
logistics
requirement_4
component_7
vision
component_32
manufacture
connector_data_2
component_33
pattern_1
pattern_2
technology_13
military
mining
quality_attribute_22
component_12
technology_11
national
quality_attribute_2
nft
nlp
technology_6
oil
and
gas
omnichannel
opc
ua
open
component_3
open
bank
open_source
technology_41
osisoft
technology_42
os
ott
over
the
top
payment
persistence
pharma
plc4x
predictive
quality_attribute_5
coding_keyword_2
sector
technology_7
qcon
qualitrics
technology_43
ransomware
recommendation
redpanda
pattern_19
retail
reverse
technology_30
ripple
rtls
sale
technology_44
technology_44
technology_45
scm
quality_attribute_2
serverless
component_2
mesh
siem
situational
awareness
smart
build
smart
city
smart
grid
pattern_3
technology_46
soar
social
requirement_5
sparkplug
splunk
connector_3
component_6
connector_11
requirement_1
supply
chain
telco
telecom
telecommunication
requirement_12
technology_8
threat
detection
threat
intelligence
tiered
storage
transaction
transportation
trend
uncategorized
use
requirement_10
v2x
video
video
connector_11
virtual
reality
web
technology_14
web
component_2
web3
technology_47
connector_data_10
zero
trust
tag
–
cloudanalytics
technology_1
technology_1
technology_33
technology_1
technology_2
technology_25
requirement_2
businessworks
requirement_6
requirement_6
requirement_7
confluent
deep

technology_9
eai
edge
requirement_17
component_4
requirement_8
requirement_17
component_2
bus
esb
connector_11
technology_5
hybrid
iiot
requirement_8
iot
j2ee
technology_12
jee
technology_2
technology_2
connector_2
technology_2
connector_1
ksql
technology_10
requirement_4
pattern_2
technology_13
technology_11
open_source
technology_41
real
time
pattern_3
streambase
connector_11
requirement_1
connector_3
component_6
talend
technology_48
connector_4
more

views4
minute
connector_4
technology_1
technology_2
biotechnology
healthcare
omnichannel
open
component_3
pharma
open
component_3
and
omnichannel
with
technology_1
technology_2
in
healthcare
bykai
waehner18

connector_4
more

views19
minute
connector_4
msk
technology_1
technology_2
technology_1
technology_34
technology_37
comparison
confluent
requirement_6
mq
technology_40
technology_43
redpanda
comparison
technology_40
connector_data_2
component_33
vs
technology_1
technology_2
bykai
waehner12

connector_4
more

views5
minute
connector_4
technology_1
technology_2
bitcoin
blockchain
cryptocurrency
cybersecurity
connector_data_4
connector_11
ethereum
fraud
detection
technology_1
technology_2
in
crypto
and
finserv
for
cybersecurity
and
fraud
detection
bykai
waehner29

connector_4
more

views4
minute
connector_4
technology_1
technology_2
biotech
confluent
requirement_6
connector_data_4
science
connector_data_4
connector_11
healthcare
insurance
technology_2
connector_1
life
science
requirement_4
requirement_4
and
connector_data_4
science
with
technology_2
in
healthcare
bykai
waehner18


©
kai
waehner
|
imprint
|
connector_data_4
privacy
by
continue
to
use
the

you
agree
to
the
use
of

more
connector_data_8
acceptthe
setting
on
this
be
set
to
allow

to
give
you
the
best
browse
experience
possible
if
you
continue
to
use
this
without
connector_21
your
setting
or
you
click
connector_40
below
then
you
be

to
this
close
