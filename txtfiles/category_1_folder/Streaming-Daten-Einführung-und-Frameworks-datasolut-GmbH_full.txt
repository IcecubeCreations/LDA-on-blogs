connector_1
daten
einführung
und
technology_1
datasolut
gmbh
home
ki
use
requirement_1
lösungen
next
best
offer
kundensegmentierung
requirement_2
lifetime
requirement_3
kundenanalyse
forecast
und
prognose
über
un
menü
home
ki
use
requirement_1
lösungen
next
best
offer
kundensegmentierung
requirement_2
lifetime
requirement_3
kundenanalyse
forecast
und
prognose
über
un
ki
projekt
starten
home
ki
use
requirement_1
lösungen
über
un
kontakt
menü
home
ki
use
requirement_1
lösungen
über
un
kontakt
connector_1
daten
einführung
und
überblick
wichtiger
technology_1
laurenz
wuttke
requirement_4
connector_1
daten
sind
daten
die
mit
einem
connector_1
technology_1
in
„echtzeit“
verarbeitet
werden
der
unterschied
zum
reinen
connector_data_1
component_1
ist
da
du
komplexe
operationen
aggregationen
join
etc
auf
den
datenströmen
anwenden
kannst
connector_1
daten
sind
im
requirement_4
umfeld
ein
interessantes
entwicklungsfeld
welch
sich
rapide
weiterentwickelt
und
in
vielen
use
requirement_1
einen
mehrwert
bringt
in
diesem
artikel
gebe
ich
einen
tiefen
einblick
in
die
grundlegenden
aspekte
die
für
connector_1
daten
relevant
sind
und
gehe
auf
die
bekanntesten
connector_1
daten
technology_1
ein
be
sind
connector_1
daten
arten
von
connector_1
datenwichtige
aspekte
bei
connector_1
datastreaming
connector_data_2
technology_1
im
vergleichstreaming
daten
use
requirement_1
im
marketingstreaming
requirement_5
be
sind
connector_1
daten
connector_1
daten
sind
daten
die
ununterbrochen
von
quellsystemen
generiert
und
in
kleinen
paketen
verschickt
werden
ein
requirement_4
connector_1
technology_1
nimmt
diesen
connector_2
entgegen
und
verarbeitet
die
informationen
im
arbeitsspeicher
bevor
diese
dann
auf
eine
fettplatte
geschrieben
werden
“a
type
of
connector_data_2
component_1
component_2
that
be
design
with
infinite
connector_data_2
set
in
mind
nothing
more
”tyler
akidau
engineer
at
connector_1
daten
können
au
verschiedensten
systemen
kommen
requirement_6
daten
au
einem
erp
component_3
e
commerce
pattern_1
order
basket
track
auf
requirement_7
component_4
geolocations
au
webanwendungen
geschäftsvorfälle
au
kundencentern
oder
nutzungsdaten
von
bestimmten
produkten
all
diese
informationen
können
mit
connector_2
daten
schneller
bereitgestellt
und
verarbeitet
werden
arten
von
connector_1
daten
grundsätzlich
lassen
sich
connector_1
daten
in
zwei
verschiedene
connector_1
arten
unterscheiden
requirement_8
connector_1
requirement_8
connector_2
und
micro
pattern_2
folgend
gehe
ich
auf
die
unterschiede
dieser
zwei
arten
ein
requirement_8
connector_1
beim
nativen
connector_1
wird
jeder
ankommende
datensatz
von
der
connector_1
component_2
sofort
verarbeitet
ohne
auf
andere
datensätze
zu
warten
einzelsatzverarbeitung
requirement_8
connector_1
reagiert
schneller
auf
einkommende
datensätze
be
für
eine
geringere
latenz
und
mehr
durchsatz
führt
requirement_8
connector_1
technology_1
technology_2
storm
technology_2
flink
technology_3
connector_2
samza
und
technology_4
continuous
component_1
experimental
release
in
technology_2
technology_4
micro
pattern_2
bedeutet
da
alle
paar
millisekunden
sekunden
ein
pattern_2
ausgeführt
wird
dadurch
entsteht
ein
kleiner
zeitverzug
technology_1
technology_2
technology_4
technology_2
technology_5
trident
requirement_8
connector_1
vs
micro
pattern_2
beide
typen
haben
vor
und
nachteile
requirement_8
connector_1
hat
den
vorteil
da
e
sehr
geringe
latenzen
erreichen
kann
gleichzeitig
bedeutet
die
da
e
schwer
ist
eine
hohe
fehlertoleranz
zu
erreichen
ohne
dabei
auch
den
durchsatz
zu
mindern
checkpoint
müssen
geschrieben
werden
etc
zustandsmanagement
hingegen
ist
bei
nativem
connector_1
einfach
micro
pattern_2
verarbeitet
die
daten
in
kleinen
pattern_2
und
hat
den
vorteil
da
dadurch
die
fehlertoleranz
gegeben
ist
auch
der
durchsatz
ist
per
se
nicht
schlecht
effizientes
zustandsmanagement
ist
eine
herausforderung
für
die
entwickler
requirement_8
streamingmicro
batchingdatensätze
werden
bei
ankunft
verarbeitet–
geringerer
durchsatz+
geringe
latenz–
fehlertoleranz
ist
ressourcenintensivdatensätze
werden
in
kleinen
pattern_2
verarbeitet+
höherer
durchsatz–
höhere
latenz+
einfachere
fehlertoleranz
wichtige
aspekte
bei
connector_1
connector_data_2
um
die
requirement_4
connector_1
technology_1
mit
den
einzelnen
stärken
und
schwächen
zu
verstehen
ist
e
wichtig
da
wir
kurz
über
die
unterschiedlichen
aspekte
von
connector_1
daten
und
probleme
die
in
der
streamverarbeitung
auftreten
reden
fehlertoleranz
im
falle
eines
fehlers
wie
bspw
technology_6
fehler
netzwerkprobleme
sollte
da
technology_1
in
der
lage
sein
den
prozess
ab
dem
punkt
neu
zu
starten
an
welchem
der
prozess
gestoppt
wurde
da
kann
durch
so
genannte
checkpoint
erreicht
werden
indem
metadaten
zu
den
verarbeiteten
daten
geschrieben
werden
so
wird
der
offset
ab
dem
checkpoint
wieder
geladen
state
requirement_9
beim
zustandsmanagement
wird
ein
zustand
gespeichert
bspw
count
über
verschiedene
schlüssel
in
einer
bestimmten
zeitspanne
hier
sollte
da
technology_1
in
der
lage
sein
den
zustand
zu
halten
und
ein
update
durchzuführen
garantierte
verarbeitung
e
gibt
grundsätzlich
unterschiedliche
arten
von
connector_2
verarbeitung
bei
atleast
once
wird
der
datensatz
auf
jeden
fall
einmal
verarbeitet
–
auch
bei
cluster
fehlern
atmost
once
kann
die
verarbeitung
nicht
garantieren
bei
exactly
once
wird
die
einmalige
verarbeitung
garantiert
und
ist
somit
die
präferierte
variante
oft
leidet
die
requirement_10
unter
diesem
ziel
geschwindigkeit
beschreibt
die
latenz
mit
der
ein
datensatz
verarbeitet
wird
zeilen
pro
sekunde
und
die
möglichkeit
der
skalierung
bei
mehr
last
die
latenz
sollte
so
gering
wie
möglich
und
der
durchsatz
so
hoch
wie
möglich
sein
beide
zu
erreichen
ist
oft
schwer
daher
geht
e
um
eine
gute
balance
entwicklungsstand
marktreife
im
streamingmarkt
gibt
e
viele
„neue“
player
die
verschiedene
ansätze
verfolgen
wichtig
ist
e
bei
der
auswahl
auf
ein
technology_1
zu
setzten
welch
bei
großen
unternehmen
erfolgreich
in
die
produktion
implementiert
wurde
auch
eine
große
hilft
dabei
da
technology_1
weiterzuentwickeln
und
ggf
hilfe
au
der
zu
bekommen
weitere
feature
um
komplexe
logik
auf
connector_3
abzubilden
brauchst
du
bestimmte
funktionen
time
component_1
bezeichnet
die
verarbeitung
basierend
auf
der
eventerzeugungszeit
manche
connector_1
technology_1
bieten
diese
funktion
nicht
an
und
verarbeiten
nach
ankunftszeitpunkt
zeitfenster
funktionen
windowing
sind
aggregationen
über
ein
bestimmtes
zeitfenster
bspw
sum
revenue
in
last
4h
anwendung
von
analytischen
modellen
im
connector_2
natürlich
bieten
einige
connector_1
technology_1
auch
die
möglichkeit
der
anwendung
eines
requirement_11
modells
im
connector_2
connector_1
connector_data_2
technology_1
im
vergleich
frameworkvorteilenachteileapache
storm
requirement_8
connector_2
–
requirement_8
streaming–
geringe
latenz–
hoher
durchsatz–
gut
für
nicht
komplexe
connector_1
use
requirement_1
–
keinen
impliziten
support
für
zustandsmanagment–
keine
feature
für
aggregationen
window
etc
–
verarbeitung
nur
atleast
onceapache
technology_4
pattern_3
connector_2
micro
pattern_2
–
unterstützt
lambda
architektur–
hoher
durchsatz–
hohe
fehlertoleranz–
einfaches
api–
große
community–
verarbeitung
exactly
once–
kein
requirement_8
stream–
viele
parameter
zum
tunen
von
streams–
stateless–
ist
hinter
flink
in
bezug
auf
advance
featuresapache
technology_4
continuous
component_1
requirement_8
connector_2
–
unterstützt
lambda
architektur–
hoher
durchsatz–
hohe
fehlertoleranz–
einfaches
api–
große
community–
verarbeitung
exactly
once
–
weniger
funktionen
verfügbar
groupby
etc
–
stark
in
den
anfängenapache
flink
requirement_8
connector_2
–
unterstützt
lambda–
führer
in
connector_1
umfeld–
geringe
latenz
und
hoher
durchsatz–
nicht
zu
viele
parameter
auto
adjust
–
verarbeitung
exactly
once–
späte
entwicklung
daher
nachteil
im
markt–
kleinere
al
spark–
keine
adaption
für
pattern_2
moduskafka
connector_2
requirement_8
connector_2
–
kleine
einfache
component_5
daher
gut
für
microservices–
gute
für
iot–
exactly
once–
braucht
kein
dediziertes
cluster
–
sehr
nah
an
technology_3
ohne
geht’s
nicht
–
mu
sich
noch
beweisen–
keine
riesen
prozesse
möglich
=
eher
einfache
logiksamza
requirement_8
connector_2
–
einfaches
api–
gut
darin
große
zustände
von
connector_3
zu
speichern
gut
für
join
von
connector_2
–
hohe
fehlertoleranz–
hoch
performant–
starke
verbundenheit
zu
technology_3
und
yarn–
atleast
once
processing–
wenig
erweiterte
connector_1
funktionen
watermark
connector_4
component_6
connector_1
daten
use
requirement_1
im
requirement_12
connector_1
daten
sind
noch
ein
sehr
neues
thema
welch
sich
zurzeit
stark
weiterentwickelt
für
viele
unternehmen
sind
use
requirement_1
mit
connector_1
daten
noch
ideen
oder
u
requirement_1
die
in
kleinen
proof
of
concept
projekten
erprobt
werden
zunehmender
einsatz
von
requirement_4
plattformen
fördert
da
thema
allerdings
stark
und
viele
unternehmen
zeigen
interesse
besonders
im
requirement_12
sind
die
use
requirement_1
nicht
so
offensichtlich
wie
im
iot
bereich
aber
auch
im
requirement_12
gibt
e
interessante
use
requirement_1
personalisierung
e
commerce
checkout
um
die
richtige
empfehlung
im
checkout
prozess
anbieten
zu
können
braucht
man
die
neusten
daten
in
real
time
dazu
zählt
die
klickhistorie
au
der
aktuellen
component_6
der
aktuelle
warenkorb
und
gespeicherte
interaktionen
au
einer
längeren
historie
um
hier
die
richtige
empfehlung
abzugeben
braucht
da
requirement_11
modell
die
daten
im
moment
de
checkout
so
können
die
wichtigen
sessioninformationen
einen
uplift
bringen
connector_2
technology_7
oft
ist
die
nacht
zu
kurz
für
die
bestehenden
technology_7
strecken
auch
hier
können
interessante
use
requirement_1
mit
connector_1
daten
umgesetzt
werden
die
daten
können
sofort
mit
requirement_4
connector_1
technology_1
verarbeitet
wertvolle
zeit
gespart
und
entscheidungen
schneller
getroffen
werden
hier
ist
ein
interessantes
video
zu
connector_2
technology_7
connector_4
requirement_12
kampagnen
die
informationen
schnell
zu
verarbeiten
ist
ein
wettbewerbsvorteil
mit
connector_data_2
connector_1
können
bestimmte
kundenevents
in
echtzeit
bearbeitet
werden
um
somit
den
kunden
anlassbezogen
über
ein
anstatt
in
einer
massenkampagne
anzusprechen
connector_1
requirement_5
connector_1
requirement_5
stellt
requirement_11
modelle
im
connector_2
bereit
soda
ein
modell
score
auf
die
gerade
eintreffenden
connector_1
daten
durchgeführt
wird
für
komplexe
architekturen
und
use
requirement_1
werden
anschließend
oft
requirement_11
feature
für
jeden
kunden
vorberechnet
und
in
einem
feature
component_7
gespeichert
bei
einem
eintreffenden
datensatz
wird
dann
da
profil
in
echtzeit
abgefragt
und
mit
dem
connector_2
gejoined
durch
die
weiteren
informationen
die
man
bspw
zu
einem
kunden
hat
kann
da
modell
mit
historischen
daten
angereichert
und
angewendet
werden
connector_1
requirement_5
wird
im
requirement_12
vor
allem
im
bereich
der
personalisierung
von
diensten
und
online
shop
eingesetzt
jede
neue
interaktion
führt
zu
einem
neuen
ergebnis
im
recommender
component_3
und
damit
zu
veränderten
empfehlungen
weitere
interessante
artikel
künstliche
intelligenz
ki
im
b2b
requirement_12
anwendung
&
praxisbeispiele
requirement_2
lifetime
requirement_3
clv
erklärung
berechnung
und
vorteile
be
macht
ein
connector_data_2
engineer
überblick
über
da
berufsbild
requirement_2
connector_data_2
component_8
–
funktionen
vorteile
und
unterschiede
requirement_11
vs
deep
wo
ist
der
unterschied
ihr
kontakt
laurenz
wuttke
unternehmen
sitzen
auf
einem
ungenutzten
berg
von
kundendaten
wir
von
datasolut
entwickeln
ki
die
ihr
requirement_12
optimiert
damit
sie
dem
richtigen
kunden
zur
richtigen
zeit
da
richtige
angebot
machen
können
termin
vereinbaren
auch
interessant
für
sie
requirement_2
lifetime
requirement_3
clv
erklärung
berechnung
und
vorteile
weiterlesen
»
kundensegmentierung
definition
methoden
und
vorgehen
weiterlesen
»
next
best
offer
nbo
für
jeden
kunden
da
richtige
angebot
weiterlesen
»
crm
kennzahlen
ratgeber
die
wichtigsten
kpi’s
im
überblick
weiterlesen
»
künstliche
intelligenz
im
vertrieb
vorteile
nutzen
und
anwendungsmöglichkeiten
weiterlesen
»
requirement_11
definition
algorithmen
methoden
und
beispiele
weiterlesen
»
connector_data_2
mining
algorithmen
definition
methoden
und
anwendungsbeispiele
weiterlesen
»
künstliche
intelligenz
ki
im
requirement_12
anwendung
und
beispiele
weiterlesen
»
personalisierung
im
requirement_12
definition
vorteile
und
beispiele
weiterlesen
»
künstliche
intelligenz
im
crm
weiterlesen
»
kundendaten
sammeln
richtig
nutzen
und
anwendungen
im
requirement_12
weiterlesen
»
kundenwert
wie
wertvoll
ist
jeder
einzelne
kunde
weiterlesen
»
kohortenanalyse
definition
anwendungsfälle
und
beispiel
weiterlesen
»
abc
analyse
definition
berechnung
und
beispiele
weiterlesen
»
churn
rate
definition
gründe
und
berechnung
für
kundenabwanderung
weiterlesen
»
rfm
analyse
requirement_12
optimieren
durch
intelligente
segmentierung
weiterlesen
»
kundenanalyse
methoden
nutzen
und
beispiele
weiterlesen
»
churn
prevention
kundenabwanderung
durch
gezielte
maßnahmen
senken
weiterlesen
»
künstliche
intelligenz
ki
im
b2b
requirement_12
anwendung
&
praxisbeispiele
weiterlesen
»
be
macht
ein
connector_data_2
engineer
überblick
über
da
berufsbild
weiterlesen
»
datasolut
gmbh
mehr
wert
mit
ki
hello@datasolut
technology_8
+49
linkedin
youtube
xing
f
mitglied
im
ki
bundesverband
navigation
lösungen
ki
use
requirement_1
über
un
karriere
kontakt
datasolut
wiki
unsere
lösungen
kundenanalyse
churn
requirement_9
requirement_2
lifetime
requirement_3
clv
next
best
offer
nbo
kundensegmentierung
forecast
künstliche
intelligenz
ki
im
requirement_12
anwendung
und
beispiele
kundenanalyse
methoden
nutzen
und
beispiele
churn
prevention
kundenabwanderung
durch
gezielte
maßnahmen
senken
requirement_2
lifetime
requirement_3
clv
erklärung
berechnung
und
vorteile
kundensegmentierung
definition
methoden
und
vorgehen
next
best
offer
nbo
für
jeden
kunden
da
richtige
angebot
crm
kennzahlen
ratgeber
die
wichtigsten
kpi’s
im
überblick
künstliche
intelligenz
im
vertrieb
vorteile
nutzen
und
anwendungsmöglichkeiten
requirement_11
definition
algorithmen
methoden
und
beispiele
connector_data_2
mining
algorithmen
definition
methoden
und
anwendungsbeispiele
personalisierung
im
requirement_12
definition
vorteile
und
beispiele
künstliche
intelligenz
im
crm
kundendaten
sammeln
richtig
nutzen
und
anwendungen
im
requirement_12
kundenwert
wie
wertvoll
ist
jeder
einzelne
kunde
kohortenanalyse
definition
anwendungsfälle
und
beispiel
abc
analyse
definition
berechnung
und
beispiele
churn
rate
definition
gründe
und
berechnung
für
kundenabwanderung
rfm
analyse
requirement_12
optimieren
durch
intelligente
segmentierung
©
datasolut
impressum
datenschutzerklärung
download
ki
use
requirement_1
für
requirement_12
und
vertrieb
mehr
umsatz
durch
gezielte
vorhersagen
durch
automatisierung
mehr
zeit
gewinnen
budget
und
ressourcen
gezielt
einsetzen
jetzt
eintragen
und
spannende
ki
projektbeispiele
au
der
praxis
erhalten
jetzt
pdf
herunterladen
mit
der
anmeldung
stimmen
sie
unserer
datenschutzerklärung
zu
