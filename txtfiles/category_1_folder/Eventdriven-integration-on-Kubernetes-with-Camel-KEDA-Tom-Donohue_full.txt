pattern_1
requirement_1
on
technology_1
with
technology_2
&
keda
|
tom
donohue
pattern_1
requirement_1
on
technology_1
with
technology_2
&
keda
|
tom
donohue
↓
tom
donohue
technology_3
newsletter
resource
about
me
pattern_1
requirement_1
on
technology_1
with
technology_2
&
keda
update
tag
technology_4
technology_5
technology_4
technology_2
technology_1
i’ve
be
work
with
a
team
this
week
who
be
investigate
how
they
could
use
technology_6
lambda
for
connector_data_1
component_1
the
component_1
be
vaguely
something
this
connector_1
some
connector_data_1
component_1
component_2
spin
it
up
when
an
happen
e
g
a
connector_data_2
arrive
on
an
technology_7
component_3
terminate
when
finish
so
they
want
to
use
technology_6
lambda
for
this
to
make
it
quality_attribute_1
and
serverless
these
be
go
to
create
lightweight
bit
of
connector_data_1
transformation
component_2
drive
by
that
use
minimal
compute
power
sound
quality_attribute_2
so
far
however
i
wonder
whether
it
be
possible
to
do
something
similar
with
the
current
of
technology_1
alternative
i
prefer
to
look
at
option
for
technology_1
because
although
it
do
have
a
steep
initial
curve
solution
for
k8s
be
le
tightly
couple
to
the
requirement_2
technology_8
technology_9
and
so
way
more
quality_attribute_3
keda
technology_1
pattern_1
autoscaling
after
dig
around
for
a
little
while
i
find
keda
technology_1
pattern_1
autoscaling
this
be
quite
and
back
by
technology_10
keda
be
a
way
of
auto
quality_attribute_4
component_4
in
technology_1
base
on
an
external
metric
the
metric
be
connector_2
by
a
set
of
scaler
which
support
thing
technology_11
artemis
technology_4
technology_12
technology_7
technology_10
component_5
bus
and
lot
more…
the
basic
idea
be
that
a
keda
scaler
pattern_2
one
of
these
connector_data_3
for
a
metric
the
metric
be
usually
something
the
number
of
connector_data_4
on
a
component_3
when
the
metric
go
above
a
certain
threshold
keda
can
quality_attribute_4
up
a
deployment
automatically
connector_data_5
“scaling
deployments”
or
create
a
connector_data_5
“scaling
jobs”
it
can
also
quality_attribute_4
down
deployment
when
the
metric
go
down
it
do
this
by
create
a
horizontal
pod
autoscaler
hpa
so
keda
be
more
concern
with
quality_attribute_5
component_4
base
on
an
external
metric
i
can
think
of
many
potential
use
requirement_3
for
this
but
i
think
primarily
i’m
interest
in
quality_attribute_5
up
pod
when
connector_data_4
be
connector_3
on
a
component_3
this
be
very
useful
because
i
often
work
with
connector_data_2
component_6
a
a
way
of
provide
to
an
component_7
the
component_6
be
entirely
external
to
the
component_8
so
it
make
sense
that
the
quality_attribute_5
should
be
external
too
and
when
i
think
of
connector_data_2
of
i
immediately
think
of
technology_11
and
technology_2
and
how
keda
could
be
use
i
think
i
feel
an
example
come
on…
keda
example
technology_4
technology_2
and
technology_11
we’re
go
to
see
what
keda
can
do
by
quality_attribute_6
a
demo
component_7
which
will
connector_4
connector_data_4
from
a
component_3
we’ll
use
technology_11
artemis
a
the
connector_data_2
pattern_3
and
use
keda’s
artemis
scaler
to
watch
for
connector_data_4
on
the
component_3
and
quality_attribute_4
the
component_7
up
or
down
a
basic
architecture
for
a
keda
quality_attribute_4
technology_2
technology_5
component_8
about
the
demo
component_8
i’ve
create
an
example
technology_2
component_8
which
u
quarkus
a
the
runtime
i’ve
publish
the
image
to
technology_13
hub
and
i
use
that
in
the
step
further
below
but
if
you’re
interest
in
how
it
be
create
connector_5
on
connector_6
the
on
technology_14
connector_6
the
image
on
technology_13
hub
i
decide
to
use
quarkus
because
it
boast
super
fast
startup
time
way
fast
than
technology_15
when
we’re
technology_16
to
we
want
to
be
able
to
start
up
quickly
and
not
wait
second
for
the
component_8
to
start
to
create
the
component_8
i
use
the
quarkus
component_8
generator
a
quarkus
be
configure
use
extension
i
need
to
find
a
quarkus
extension
which
would
help
me
create
a
connector_7
factory
to
talk
to
technology_11
artemis
so
i’m
use
the
technology_17
technology_18
extension
for
quarkus
which
wrap
up
the
technology_4
technology_17
technology_18
component_9
for
quarkus
component_7
this
allow
me
to
talk
to
technology_11
artemis
use
the
nice
open
technology_19
technology_20
the
technology_17
technology_18
extension
create
a
connector_7
factory
to
technology_11
when
it
find
certain
config
property
you
only
need
to
set
the
property
quarkus
technology_17
technology_21
url
quarkus
technology_17
technology_21
username
and
quarkus
technology_17
technology_21
password
the
extension
will
do
the
rest
automatically
a
it
say
in
the
doc
connector_8
out
how
to
configure
the
technology_17
technology_18
extension
for
quarkus
then
i
use
camel’s
technology_19
component_10
to
actually
connector_4
the
connector_data_2
this
will
detect
and
use
the
connector_7
factory
create
by
the
extension
i’ve
compile
and
packaged
the
component_7
into
a
requirement_4
binary
not
a
jar
this
will
help
it
to
start
up
very
fast
you
need
graalvm
to
be
able
to
do
this
mvnw
package
pnative
or
if
you
don’t
want
to
install
graalvm
you
can
tell
quarkus
to
use
a
helper
container
with
graalvm
bake
in
in
order
to
build
the
requirement_4
image
you’ll
need
technology_13
run
for
this
of
mvnw
package
pnative
dquarkus
requirement_4
container
build=true
the
output
from
this
be
a
requirement_4
binary
which
should
start
up
fast
than
a
typical
technology_22
base
component_7
nice
quality_attribute_2
for
rapid
quality_attribute_4
up
when
we
connector_9
a
connector_data_2
finally
i
build
a
container
image
with
technology_13
and
connector_10
it
up
to
technology_13
hub
there’s
a
dockerfile
provide
with
the
quarkus
quickstart
to
do
the
build
and
then
it’s
an
easy
technology_13
connector_10
technology_13
build
f
src
technology_13
dockerfile
requirement_4
t
monodot
technology_2
technology_23
quarkus
technology_13
connector_10
monodot
technology_2
technology_23
quarkus
now
we’re
ready
to
quality_attribute_6
the
component_8
quality_attribute_6
keda
and
configure
it
to
auto
quality_attribute_4
the
component_8
quality_attribute_6
keda
and
the
demo
component_8
first
install
keda
on
your
technology_1
cluster
you’ll
probably
need
to
have
cluster
admin
permission
to
be
able
to
do
this
if
you
need
a
technology_1
cluster
of
your
own
you
can
use
minikube
or
a
requirement_2
offer
amazon’s
eks
connector_5
about
my
experience
with
eks
on
technology_9
to
install
keda
you
should
probably
follow
the
instruction
on
the
keda
web
but
i
instal
it
with
helm
this
$
helm
repo
kedacore
technology_24
kedacore
technology_25
io
requirement_5
$
helm
repo
update
$
kubectl
create
namespace
keda
$
helm
install
keda
kedacore
keda
namespace
keda
create
a
namespace
for
our
demo
kubectl
create
namespace
keda
demo
now
we
need
to
quality_attribute_6
an
technology_11
artemis
connector_data_2
pattern_3
here’s
some
technology_26
to
create
a
component_5
and
deployment
for
it
in
technology_1
it
u
the
vromero
technology_5
artemis
image
of
artemis
on
technology_13
hub
and
connector_11
it
console
and
technology_23
port
i’m
customise
it
by
a
configmap
which
connector_12
the
internal
name
of
the
pattern_3
to
a
name
keda
demo
pattern_3
define
one
component_3
connector_13
alex
honk
if
we
don’t
do
this
then
the
component_3
will
be
create
when
a
component_11
connector_14
to
it
but
it
will
be
remove
again
when
the
component_11
disappear
and
so
keda
will
connector_6
confuse
so
we
define
the
component_3
first
$
kubectl
apply
f
technology_27
apiversion
v1
kind
connector_data_6
item
apiversion
v1
kind
component_5
metadata
creationtimestamp
name
artemis
namespace
keda
demo
spec
port
port
technology_20
technology_28
targetport
name
technology_23
port
technology_20
technology_28
targetport
name
console
selector
run
artemis
status
loadbalancer
{}
apiversion
component_12
v1
kind
deployment
metadata
creationtimestamp
label
run
artemis
name
artemis
namespace
keda
demo
spec
replica
selector
matchlabels
run
artemis
strategy
{}
template
metadata
creationtimestamp
label
run
artemis
spec
container
env
name
artemis_username
requirement_6
quarkus
name
artemis_password
requirement_6
quarkus
image
vromero
technology_5
artemis
alpine
name
artemis
port
containerport
containerport
volumemounts
name
config
volume
mountpath
var
lib
artemis
etc
override
volume
name
config
volume
configmap
name
artemis
apiversion
v1
kind
configmap
metadata
name
artemis
namespace
keda
demo
connector_data_1
pattern_3
technology_29
|
technology_29
version=
encoding=
utf
standalone=
no
configuration
xmlns=
urn
technology_5
xmlns
xsi=
technology_24
www
w3
xmlschema
instance
xsi
schemalocation=
urn
technology_5
schema
artemis
configuration
technology_30
core
xmlns=
urn
technology_5
core
xsi
schemalocation=
urn
technology_5
core
name
keda
demo
pattern_3
name
connector_15
connector_15
name=
dlq
anycast
component_3
name=
dlq
anycast
connector_15
connector_15
name=
expiryqueue
anycast
component_3
name=
expiryqueue
anycast
connector_15
connector_15
name=
alex
honk
anycast
component_3
name=
alex
honk
anycast
connector_15
connector_15
core
configuration
component_13
next
we
quality_attribute_6
the
demo
technology_2
quarkus
technology_19
component_11
component_7
and
some
configuration
so
we
create
a
deployment
i’m
quality_attribute_6
my
demo
image
monodot
technology_2
technology_23
quarkus
from
technology_13
hub
you
can
also
quality_attribute_6
my
image
or
you
can
build
and
quality_attribute_6
your
own
image
if
you
want
we
use
the
environment
variable
quarkus_qpid_jms_*
to
set
the
url
username
and
password
for
the
technology_11
artemis
pattern_3
these
will
override
the
property
quarkus
technology_17
technology_21
*
in
my
application’s
property
$
kubectl
apply
f
technology_27
apiversion
component_12
v1
kind
deployment
metadata
creationtimestamp
label
run
technology_2
technology_23
quarkus
name
technology_2
technology_23
quarkus
namespace
keda
demo
spec
replica
selector
matchlabels
run
technology_2
technology_23
quarkus
strategy
{}
template
metadata
creationtimestamp
label
run
technology_2
technology_23
quarkus
spec
container
env
name
quarkus_qpid_jms_url
requirement_6
technology_23
artemis
name
quarkus_qpid_jms_username
requirement_6
quarkus
name
quarkus_qpid_jms_password
requirement_6
quarkus
image
monodot
technology_2
technology_23
quarkus
late
name
technology_2
technology_23
quarkus
resource
{}
component_13
now
we
tell
keda
to
quality_attribute_4
the
pod
down
when
there
be
no
connector_data_2
and
back
up
when
there
be
connector_data_2
we
do
this
by
create
a
scaledobject
this
tell
keda
which
deployment
to
quality_attribute_4
and
when
to
quality_attribute_4
it
$
kubectl
apply
f
technology_27
apiversion
keda
k8s
io
v1alpha1
kind
scaledobject
metadata
name
technology_2
technology_23
quarkus
scaler
namespace
keda
demo
spec
scaletargetref
deploymentname
technology_2
technology_23
quarkus
pollinginterval
cooldownperiod
#
default
second
minreplicacount
maxreplicacount
connector_16
type
artemis
component_3
metadata
managementendpoint
artemis
keda
demo
brokername
keda
demo
pattern_3
username
quarkus_qpid_jms_username
password
quarkus_qpid_jms_password
queuename
alex
honk
brokeraddress
alex
honk
queuelength
component_13
by
the
way
to
connector_6
the
credential
to
use
the
artemis
technology_27
keda
will
look
for
any
environment
variable
on
the
deployment
pod
of
the
technology_2
component_8
this
mean
you
don’t
have
to
specify
the
credential
twice
so
here
i’m
use
quarkus_qpid_jms_username
and
_password
they
reference
the
environment
variable
on
the
demo
app’s
deployment
now
let’s
put
some
test
connector_data_4
onto
the
component_3
you
can
do
this
in
a
couple
of
different
way
either
point
and
click
use
the
artemis
web
console
or
use
the
jolokia
pattern_4
technology_27
either
way
we
need
to
be
able
to
reach
the
artemis
technology_1
component_5
which
isn’t
connector_17
outside
the
technology_1
cluster
you
can
connector_18
it
by
set
up
an
ingres
or
a
connector_19
in
technology_31
but
i
use
kubectl’s
port
connector_20
feature
instead
it’s
quality_attribute_7
this
allow
me
to
connector_21
the
technology_11
web
console
and
component_13
on
localhost
port
kubectl
port
connector_22
n
keda
demo
svc
artemis
leave
that
run
in
the
background
now
in
a
different
terminal
hit
the
artemis
jolokia
component_13
with
curl
via
the
kubectl
port
connector_20
pattern_5
we
want
to
connector_23
a
connector_data_2
to
an
artemis
component_3
connector_13
alex
honk
this
part
require
a
ridiculously
long
component_13
connector_data_5
so
i’ve
some
line
break
here
to
make
it
easy
to
connector_5
this
u
activemq’s
jolokia
pattern_4
component_13
to
put
a
connector_data_2
in
the
artemis
component_3
curl
x
connector_data_1
{\
type\
\
exec\
\
\
mbean\
\
\
technology_4
technology_5
artemis
broker=\\\
keda
demo
broker\\\
component=addresses
address=\\\
alex
honking\\\
subcomponent=queues
connector_24
type=\\\
anycast\\\
queue=\\\
alex
honking\\\
\
\
\
operation\
\
\
sendmessage
technology_32
util
connector_data_7
technology_32
lang
boolean
technology_32
lang
technology_32
lang
\
\
\
arguments\
\
\
hello
alex\
false
\
quarkus\
\
quarkus\
}
technology_24
quarkus
quarkus@localhost
console
jolokia
if
you
have
any
issue
with
this
use
the
artemis
web
ui
to
connector_23
a
connector_data_2
it’s
at
technology_24
localhost
console
all
quality_attribute_2
you
put
connector_data_4
in
the
component_3
you
should
see
the
technology_2
component_8
pod
start
up
and
connector_25
the
connector_data_2
keda
quality_attribute_4
up
the
demo
component_8
technology_2
technology_23
quarkus
when
it
notice
a
connector_data_2
after
all
connector_data_4
be
connector_4
there
will
be
no
connector_data_4
leave
on
the
component_3
keda
wait
for
the
cooldown
period
in
this
demo
i’ve
use
second
a
an
example
and
then
quality_attribute_4
down
the
deployment
back
to
zero
so
there
be
no
pod
run
this
be
autoscaling…
in
action
epilogue
you
forget
knative
knative
so
you’ve
probably
notice
that
i
didn’t
mention
knative
i
start
my
research
by
look
at
knative
knative
be
a
beast
of
a
project
it
be
announce
a
couple
of
year
ago
and
be
back
by
there
be
a
couple
of
major
part
to
knative
but
the
interest
one
to
me
be
knative
serve
this
be
the
“serverless
apps”
part
it
can
create
a
pod
from
nothing
when
a
web
connector_data_8
be
connector_9
and
then
delete
the
pod
when
it’s
no
long
need
this
basically
allow
you
to
have
pattern_6
that
run
only
when
need
but
be
heavily
focus
on
apis
knative
serve
can
also
do
more
complex
thing
manage
multiple
version
of
the
same
component_8
but
that’s
beyond
the
scope
of
today’s
knative
eventing
be
the
other
half
of
the
project
which
be
about
make
“events”
a
requirement_4
concept
in
technology_1
and
decouple
component_14
and
component_11
you
can
then
connector_1
component_12
which
respond
to
these
i
think
knative
eventing
might
be
able
to
create
pod
when
a
particular
be
connector_3
in
other
word
autoscaling
pod
base
on
an
but
after
bit
of
dig
it
seem
that
autoscaling
in
knative
eventing
be
still
a
work
in
progress
at
the
time
i
have
a
look
at
it
it’s
still
in
the
proposal
stage
autoscaling
for
knative
eventing
be
still
wip
i
think
that
mean
that
knative
be
out
of
the
run
for
now…
t
miss
my
next
join
my
newsletter
to
enjoy
my
late
think
and
recommend
connector_26
no
more
than
time
per
month
put
your
detail
in
the
form
below
to
join
today
your
subscribe
hp
icon
by
freepik
these
icon
and
ultimatearm
on
flaticon↗
what
do
you
think
you
can
use
markdown
in
your
to
connector_1
indent
each
line
with
space
or
to
paste
a
lot
of
you
can
put
it
in
pastebin
technology_33
and
connector_27
the
connector_26
in
your
if
you
want
to
pattern_7
or
to
this
please
enable
technology_34
tom
donohue
|
tom
technology_35
s
connector_28
opinion
and
stuff
i
m
work
on
about
me
•
recommend
resource
•
join
my
newsletter
•
me
•
atom
r
fee
©
tom
donohue
