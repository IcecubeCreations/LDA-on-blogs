benchmarking
connector_data_1
component_1
quality_attribute_1
–
brave
geek
skip
to
content
brave
geek
introspection
of
a
engineer
home
about
me
archive
real
kinetic
technology_1

on

2016december


by
tyler
treatbenchmarking
connector_data_1
component_1
quality_attribute_1
about
a
year
and
a
half
ago
i
publish
dissect
connector_data_1
component_1
which
break
down
a
few
different
pattern_1
component_2
and
do
some
requirement_1
benchmarking
it
be
a
naive
attempt
and
have
a
lot
of
problem
but
it
be
also
my
first
time
do
any
kind
of
component_3
benchmarking
it
turn
out
benchmarking
component_2
correctly
be
actually
pretty
difficult
and
many
folk
connector_1
it
wrong
i
don’t
claim
to
have
connector_1
it
right
but
over
the
past
year
and
a
half
i’ve

a
lot
try
to
build
some
quality_attribute_2
technology_2
and
improve
my
methodology
technology_2
and
methodology
the
dissect
connector_data_1
component_4
benchmark
use
a
technology_3
i
connector_2
which
publish
a
specify
number
of
connector_data_2
effectively
a
fast
a
possible
connector_3
them
and
component_5
the
end
to
end
quality_attribute_1
there
be
several
problem
with
this
first
load
generation
and
consumption
run
on
the
same
component_6
second
the
component_3
under
test
run
on
the
same
component_6
a
the
benchmark
client—both
of
these
confound
measurement
third
run
“pedal
to
the
metal”
and
look
at
the
connector_data_3
quality_attribute_1
isn’t
a
very
useful
benchmark
because
it’s
not
representative
of
a
production
environment
a
gil
tene

to
say
this
be
drive
your
car
a
fast
a
possible
crash
it
into
a
pole
and
look
at
the
shape
of
the
bumper
afterwards—it’s
always
go
to
look
bad
lastly
the
benchmark
component_5
average
quality_attribute_1
which
for
all
intent
and
purpose
be
a
useless
metric
to
look
at
i
connector_2
flotilla
to
automate
“scaled
up”
benchmarking—running
the
pattern_2
and
benchmark
component_7
on
separate
quality_attribute_3
vms
flotilla
also
attempt
to
capture
a
quality_attribute_2
pattern_3
of
quality_attribute_1
by
look
at
the
quality_attribute_1
distribution
though
it
only
go
up
to
the
99th
percentile
which
can
sweep
a
lot
of
really
bad
thing
under
the
rug
a
we’ll
see
late
however
it
still
run
test
at
full
throttle
which
isn’t
great
bench
be
an
attempt
to
connector_1
back
to
basic
it’s
a
quality_attribute_4
generic
benchmarking
technology_4
for
measure
quality_attribute_1
it
provide
a
straightforward
requester
which
can
be
connector_4
for
various
component_2
under
test
bench
work
by
attempt
to
issue
a
fix
rate
of
connector_data_4
per
second
and
measure
the
quality_attribute_1
of
each
connector_data_5
issue
synchronously
quality_attribute_1
be
capture
use
hdr
histogram
which
observe
the
complete
quality_attribute_1
distribution
and
allow
u
to
look
for
example
at
“six
nines”
quality_attribute_1
introduce
a
connector_data_5
schedule
allow
u
to
measure
quality_attribute_1
for
different
configuration
of
connector_data_5
rate
and
connector_data_1
size
but
in
a
“closed
loop”
test
it
create
another
problem
connector_5
coordinate
omission
the
problem
with
a
lot
of
benchmark
be
that
they
end
up
measure
component_8
time
rather
than
response_time
but
the
latter
be
likely
what
you
care
about
because
it’s
what
your
component_9
experience
the
best
way
to
describe
component_8
time
vs
response_time
be
to
think
of
a
cash
register
the
cashier
might
be
able
to
ring
up
a
requirement_2
in
under

second
99%
of
the
time
but
1%
of
the
time
it
take
three
minute
the
time
it
take
to
ring
up
a
requirement_2
be
the
component_8
time
while
the
response_time
consist
of
the
component_8
time
plus
the
time
the
requirement_2
wait
in
line
thus
the
response_time
be
dependent
upon
the
variation
in
both
component_8
time
and
the
rate
of
arrival
when
we
measure
quality_attribute_1
we
really
want
to
measure
response_time
now
let’s
think
about
how
most
quality_attribute_1
benchmark
work
they
usually
do
this
note
pattern_4
before
connector_data_5
t0
make
pattern_5
connector_data_5
note
pattern_4
after
connector_data_5
t1
component_5
quality_attribute_1
t1
–
t0
repeat
a
need
for
connector_data_5
schedule
what’s
the
problem
with
this
nothing
a
long
a
our
connector_data_4
fit
within
the
specify
connector_data_5
schedule
for
example
if
we’re
issue

connector_data_4
per
second
and
each
connector_data_5
take

m
to
complete
we’re
quality_attribute_2
however
if
one
connector_data_5
take

m
to
complete
that
mean
we
issue
only
one
connector_data_5
during
those

m
when
accord
to
our
schedule
we
should
have
issue

connector_data_4
in
that
window
nine
other
connector_data_4
should
have
be
issue
but
the
benchmark
effectively
coordinate
with
the
component_3
under
test
by
back
off
in
reality
those
nine
connector_data_4
wait
in
line—one
for

m
one
for

m
one
for

m
etc
most
benchmark
don’t
capture
this
time
spend
wait
in
line
yet
it
can
have
a
dramatic
effect
on
the
connector_data_3
the
graph
below
show
the
same
benchmark
with
coordinate
omission
both
uncorrected
red
and
correct
blue
hdr
histogram
attempt
to
correct
coordinate
omission
by
fill
in
additional
sample
when
a
connector_data_5
fall
outside
of
it
expect
interval
we
can
also
deal
with
coordinate
omission
by
simply
avoid
it
altogether—always
issue
connector_data_4
accord
to
the
schedule
connector_data_1
component_1
benchmark
i
benchmarked
several
pattern_1
component_2
use
bench—rabbitmq



technology_5




and




technology_6



pub
sub
and
nats



in
this
component_10
a
“request”
consist
of
publish
a
connector_data_1
to
the
component_11
and
wait
for
a
connector_6
i
e
a
quality_attribute_5
we
attempt
to
issue
connector_data_4
at
a
fix
rate
and
correct
for
coordinate
omission
then
plot
the
complete
quality_attribute_1
distribution
all
the
way
up
to
the

9999th
percentile
we
repeat
this
for
several
configuration
of
connector_data_5
rate
and
connector_data_5
size
it’s
also
important
to
note
that
each
connector_data_1
go
to
and
come
back
from
the
component_11
be
of
the
specify
size
i
e
the
“response”
be
the
same
size
a
the
“request
”
the
configuration
use
be
connector_data_6
below
each
configuration
be
run
for
a
sustain

second
256b
connector_data_4
at


connector_data_5
sec

kb
s
1kb
connector_data_4
at


connector_data_5
sec

connector_data_7
s
5kb
connector_data_4
at


connector_data_5
sec

connector_data_7
s
1kb
connector_data_4
at


connector_data_5
sec


connector_data_7
s
1mb
connector_data_4
at

connector_data_5
sec

connector_data_7
s
these
connector_data_1
size
be
mostly
arbitrary
and
there
might
be
a
quality_attribute_2
way
to
go
about
this
though
i
think
it’s
worth
point
out
that
the
ethernet
mtu
be

byte
so
accounting
for

the
maximum
amount
of
connector_data_8
you’ll
connector_1
in
a
single
technology_7
packet
will
likely
be
between

and

byte
the
component_3
under
test
and
benchmarking
component_12
be
on
two
different
m4
xlarge
technology_8
instance


ghz
intel
xeon
haswell
16gb
ram
with
enhance
requirement_3
enable
technology_6
and
nats
technology_6
pattern_6
and
nats
have
similar
requirement_1
characteristic
both
offer
very
lightweight
non
pattern_7
pattern_1
with
no
persistence
option
discount
redis’
rdb
and
aof
persistence
which
don’t
apply
to
pub
sub
and
both
support
some
level
of
topic
pattern_8
match
i’m
hesitant
to
connector_data_9
either
a
“message
queue”
in
the
traditional
sense
so
i
usually
refer
to
them
a
connector_data_1
pattern_2
or
bus
because
of
their
ephemeral
nature
both
be
a
nice
choice
for
low
quality_attribute_1
lossy
connector_data_1
technology_6
tail
quality_attribute_1
peak
around


m
nats
requirement_1
look
comparable
to
technology_6
quality_attribute_1
peak
around


m
the
resemblance
become
more
apparent
when
we
overlay
the
two
distribution
for
the
1kb
and
5kb
run
nats
tend
to
be
about


to


m
fast
the
1kb


connector_data_5
sec
run
us

concurrent
connector_7
with
concurrent
load
tail
quality_attribute_1
jump
up
peak
around

and

m
at
the

9999th
percentile
in
nats
and
technology_6
respectively
large
connector_data_2
1mb
don’t
hold
up
nearly
a
well
exhibit
large
tail
quality_attribute_1
start
around
the
95th
and
97th
percentile
in
nats
and
technology_6
respectively
1mb
be
the
default
maximum
connector_data_1
size
in
nats
the
quality_attribute_1
peak
around

m
again
keep
in
mind
these
be
pattern_5
quality_attribute_5
quality_attribute_1
apcera’s
ivan
kozlovic
point
out
that
the
version
of
the
nats
component_12
i
be
use
didn’t
include
a
recent
requirement_1
optimization
before
the
technology_9
requirement_4
scan
over
each
byte
in
the
connector_data_10
but
the

version
skip
to
the
end
the
previous
benchmark
be
update
to
use
the

version
the
optimization
do
have
a
noticeable
effect
illustrate
below
there
be
about
a
30%
improvement
with
the
5kb
quality_attribute_1
the
difference
be
even
more
pronounce
in
the
1mb
requirement_5
which
have
roughly
a
90%
improvement
up
to
the
90th
percentile
the
linear
quality_attribute_6
in
the
graph
below
hide
this
fact
but
at
the
90th
percentile
for
example
the
pre
optimization
quality_attribute_1
be

m
and
the
optimize
quality_attribute_1
be


m
clearly
the
large
tail
be
mostly
unaffected
however
in
general
this
show
that
nats
and
technology_6
be
quality_attribute_2
suit
to
small
connector_data_2
well
below
1mb
in
which
quality_attribute_1
tend
to
be
sub
millisecond
up
to
four
nine
technology_10
and
technology_5
technology_10
be
a
popular
technology_11
implementation
unlike
nats
it’s
a
more
traditional
connector_data_1
component_1
in
the
sense
that
it
support
bind
component_4
and
pattern_7
delivery
semantics
consequently
technology_10
be
a
more
“heavyweight”
pattern_9
solution
and
tend
to
pay
an
additional
premium
with
quality_attribute_1
in
this
benchmark
non
quality_attribute_7
component_4
be
use
a
a
connector_data_3
we
should
see
reduce
quality_attribute_1
since
we
aren’t
go
to
disk
quality_attribute_1
tend
to
be
sub
millisecond
up
to
the

7th
percentile
but
we
can
see
that
it
doesn’t
hold
up
to
nats
beyond
that
point
for
the
1kb
and
5kb
connector_data_10
technology_5
on
the
other
hand
require
disk
persistence
but
this
doesn’t
have
a
dramatic
effect
on
quality_attribute_1
until
we
look
at
the
94th
percentile
and
beyond
when
compare
to
technology_10
connector_8
should
be
to
component_13
pattern_10
with
flush
to
disk
happen
asynchronously
the
graph
below
be
for




once
again
the
1kb


connector_data_5
sec
run
be
quality_attribute_3
across

concurrent
connector_7
with
technology_10
we
see
the
dramatic
increase
in
tail
quality_attribute_1
a
we
do
with
technology_6
and
nats
the
technology_10
quality_attribute_1
in
the
concurrent
requirement_5
stay
in
line
with
the
previous
quality_attribute_1
up
to
about
the
99th
percentile
interestingly
technology_5
doesn’t
appear
to
be
significantly
affect
the
quality_attribute_1
of


connector_data_5
sec
at
1kb
per
connector_data_5
be
not
terribly
different
than
the
quality_attribute_1
of


connector_data_5
sec
at
1kb
per
connector_data_5
both
peak
around

m
what’s
particularly
interest
be
the
behavior
of
1mb
connector_data_2
vs
the
rest
with
technology_10
there’s
almost
a
14x
difference
in
max
quality_attribute_1
between
the
5kb
and
1mb
run
with
1mb
be
the
fast
with
technology_5




the
difference
be
over
126x
in
the
same
direction
we
can
plot
the
1mb
quality_attribute_1
for
technology_10
and
technology_5
since
it’s
difficult
to
discern
them
with
a
linear
quality_attribute_6
i
try
to
understand
what
be
cause
this
behavior
i’ve
yet
to
find
a
reasonable
explanation
for
technology_10
intuition
tell
me
it’s
a
connector_data_3
of
buffering—either
at
the
o
level
or
elsewhere—and
the
large
connector_data_2
cause
more
frequent
flush
remember
that
these
benchmark
be
with
transient
publish
there
should
be
no
disk
connector_9
occur
though
my
knowledge
of
rabbit’s
internals
be
admittedly
limit
the
fact
that
this
behavior
occur
in
technology_10
and
not
technology_6
or
nats
seem
odd
nagle’s
algorithm
be
disable
in
all
of
the
benchmark
tcp_nodelay
after
inspect
packet
with
wireshark
it
doesn’t
appear
to
be
a
problem
with
delay
acks
to
show
how
stagger
the
difference
be
we
can
plot
technology_5




and
technology_10
1mb
quality_attribute_1
alongside
technology_6
and
nats
5kb
quality_attribute_1
they
be
all
within
the
same
ballpark
whatever
the
requirement_5
be
both
technology_10
and
technology_5
appear
to
handle
large
connector_data_2
extremely
well
in
contrast
to
technology_6
and
nats
this
lead
me
to
believe
you’ll
see
quality_attribute_2
overall
quality_attribute_8
in
term
of
raw
connector_data_8
with
technology_10
and
technology_5
but
more
quality_attribute_9
tight
tail
quality_attribute_1
with
technology_6
and
nats
where
slas
be
important
it’s
hard
to
beat
nats
of

it’s
unfair
to
compare
technology_5
with
something
nats
or
technology_6
or
even
technology_10
since
they
be
very
different
and
sometimes
complementary
but
it’s
also
worth
point
out
that
the
former
be
much
more
operationally
complex
however
benchmarking
technology_5




blue
and
red
show
an
astound
difference
in
tail
quality_attribute_1
compare
to




orange
and
green
technology_5

9’s
requirement_1
be
much
more
in
line
with
rabbitmq’s
at
high
percentile
a
see
below
likewise
it’s
a
much
close
comparison
to
nats
when
look
at
the
1kb
and
5kb
run
a
with


technology_5


do
an
impressive
deal
with
1mb
connector_data_2
in
comparison
to
nats
especially
when
look
at
the
92nd
percentile
and
beyond
it’s
hard
to
decipher
in
the
graph
below
but
technology_5

9’s
99th

9th
and

99th
percentile
quality_attribute_1
be




and


m
respectively
my
initial
think
be
that
the
difference
between
technology_5


and


be
attribute
to
a
connector_10
in
fsync
behavior
to
quote
the
technology_5
documentation
technology_5
always
immediately
connector_8
all
connector_data_8
to
the
filesystem
and
support
the
ability
to
configure
the
flush
requirement_6
that
control
when
connector_data_8
be
force
out
of
the
o
pattern_10
and
onto
disk
use
the
and
flush
this
flush
requirement_6
can
be
control
to
force
connector_data_8
to
disk
after
a
period
of
time
or
after
a
certain
number
of
connector_data_2
have
be
connector_2
however
there
don’t
appear
to
be
any
connector_11
in
the
default
flush
configuration
between


and


the
default
configuration
disable
component_14
fsync
entirely
instead
rely
on
the
os’s
background
flush
jay
kreps
indicate
it’s
a
connector_data_3
of
several
“high
percentile
quality_attribute_1
issues”
that
be
fix
in


after
scan
the


release
note
i
be
unable
to
determine
specifically
what
those
fix
might
be
either
way
the
difference
be
certainly
not
something
to
scoff
at
conclusion
a
always
interpret
these
benchmark
connector_data_11
with
a
critical
eye
and
perform
your
own
test
if
you’re
evaluate
these
component_3
this
be
more
an
exercise
in
benchmark
methodology
and
technology_2
than
an
actual
component_3
analysis
and
a
always
there’s
still
a
lot
of
room
for
improvement
if
anything
i
think
these
connector_data_11
show
how
much
we
can
miss
by
not
look
beyond
the
99th
percentile
in
almost
all
requirement_5
everything
look
pretty
quality_attribute_2
up
to
that
point
but
after
that
thing
can
connector_1
really
bad
this
be
important
to
be
conscious
of
when
discuss
slas
i
think
the
key
takeaway
be
to
consider
your
expect
load
in
production
benchmark
configuration
around
that
determine
your
allowable
component_8
level
and
iterate
or
provision
more
resource
until
you’re
within
those
limit
the
other
important
takeaway
with
respect
to
benchmarking
be
to
look
at
the
complete
quality_attribute_1
distribution
otherwise
you’re
not
connector_12
a
clear
picture
of
how
your
component_3
actually
behave
follow
@tyler_treatshare
this
pockettwitterlinkedinredditfacebook
relate
categoriesbenchmarking
pattern_1
tagsbench
benchmarking
benchmark
coordinate
omission
flotilla
hdrhistogram
technology_5
quality_attribute_1
connector_data_1
component_1
connector_data_1
nats
technology_10
technology_6
component_2

connector_data_12
to
“benchmarking
connector_data_1
component_1
latency”
pingback
benchmarking
connector_data_1
component_1
quality_attribute_1
–
daily
hacker
news
david
collier
brown
say


at


be
the
problem
you’re
observe
be
very
real
but
very
hard
to
notice
in
the

micro
benchmark
these
be
arguably
the
best
way
to
detect
and
diagnose
them
the
major
difference
here
be
that
your
test
doesn’t
mix
in
random
distribution
of
connector_data_5
if
there’s
room
for

connector_data_4
in
a
second
i
connector_13
you
a
hand
them
to
the
component_3
under
test
one
at
a
time
every

millisecond
that’s
a
uniform
distribution
and
any
odd
behaviour
stick
out
a
sore
thumb
a
an
irregularity
now
consider
a
component_3
where
a
collection
of

court
spread
across
the
country
issue
connector_data_4
to
a
component_11
with
an
average
of

court
component_15
active
each
issue
a
connector_data_5
every
second
there’s

interval
they
can
land
in
and
randomly
many
will
land
in
an
interval
that’s
empty
a
few
will
land
in
an
interval
where
there’s
already
a
connector_data_5
be
component_16
and
a
very
few
land
in
a
interval
where
more
that
one
connector_data_5
be
be
component_16
this
of

leave
some
interval
entirely
empty
plug
that
into
a
component_1
modeller
pdq
you’ll
see
the
response_time
start
off
close
to
horizontal
at
light
load
but
by
80%
of
your
target
load
be
already
curve
upwards
the
handle
of
a
hockey
stick
“_
”
this
extra
quality_attribute_1
from
load
and
the
evil
of
probability
drown
out
the
shout
of
pain
from
the

millisecond
connector_6
and
it
downstream
victim
and
keep
u
from
realize
how
serious
a

millisecond
quality_attribute_1
really
be
–dave
i
wish
i
could
paste
in
a
graph
but
here’s
the
connector_data_8
i
plot
and
at
80%
load
the
average
response_time
be
already
bloat
to

040s

millisecond
and
at
100%
it
be
connector_12
close
to

100
“#
close
solution
from
pdq
where
component_8
time
=

”
“#
think
time
=

dmax
=

component_4
=
1”
load
connector_6































































connector_data_13
yehosef
say


at


be
very
interest
benchmark
and
comparison
–
thanks
i
be
not
able
to
tell
–
be
any
of
the
technology_10
test
run
use
persistence
it
quality_attribute_2
to
the
maximum
quality_attribute_8
but
it’s
also
quality_attribute_2
to
compare
technology_5
and
rabbit
where
persistence
be
require
connector_data_13
rick
jones
say


at


pm
it
would
be
worthwhile
to
compare
the
cpu
utilization
for
all
these
different
solution
perhaps
something
along
the
line
of
netperf’s
component_8
demand
a
well
a
the
requirement_3
utilization
connector_data_13
quinton
pike
say


at


be
agree
it
would
be
great
to
see
cpu
and
memory
consumption
of
the
different
choice
this
be
sometimes
a
factor
when
choose
a
solution
connector_data_13
wener
say


at


be
why
not
technology_6
block
connector_data_6
to
this
comparison
we
use
technology_6
block
connector_data_6
a
our
mq
for
a
long
time
it
work
connector_data_13
ygl
say


at


be
how
about
the
requirement_1
connector_data_13
pingback
technology_10
vs
technology_5
|
impendency
pingback
utilize
technology_12
technology_6
pattern_10
a
backend
for
chat
component_17
–
developparadise
matyas
say


at


be
it
would
be
really
interest
to
see
how
do
technology_13
technology_14
compare
in
term
of
quality_attribute_1
and
quality_attribute_8
with
the
solution
mention
already
in
the

connector_data_13
john
say


at


be
interest
in

if
you
be
formalize
your
“bench”
technology_2
s
and
would
make
them
quality_attribute_10
to
others
to
try
out
we
be
test
open_source
technology_5
now
and
have
talk
about
test
technology_6
look
nats
would
be
interest
to
u
a
well
connector_data_13
tyler
treat
say


at


pm
bench
be
quality_attribute_10
here
technology_15
technology_16
technology_17
tylertreat
bench
connector_data_13
pinespundit
say


at


be
tyler
i
will
have
my
test
lead
review
this
thank
you
for
your
quick
turnaround
right
now
we
connector_14
wav
through
nifi
technology_5
and
run
fft’s
in
technology_18
—
a
our
demonstration
use
requirement_5
have
be
connector_15
requirement_7
connector_data_8
use
tiki
and
technology_5
your
would
give
u
a
chance
to
run
a
test
and
compare
the
connector_data_11
to
your
benchmark
consider
the
disparity
in
the
implementation
of

very
thankfully
yours
jr
connector_data_13
pingback
technology_5
quality_attribute_1
–
spinque
pingback
technology_5
quality_attribute_1
–
spinque
–
stag
pingback
對各類
connector_data_1
component_1
的效能測試
–
gea
suan
lin
s
anil
kumar
choudhury
say


at


be
would
you
to
connector_16
the
artifact
use
for
this
test
a
i
be
interest
to
run
the
same
test
today
with
late
version
of
all
these
with
a
edge
hw
raspberry
pi4
connector_data_13
leave
a
connector_data_13
cancel
replyyour
connector_17
will
not
be
publish
require
be
mark
*comment
*
name
*
*
connector_18
me
of
follow
up

by

connector_18
me
of

by

δ
navigation
previous
postprevious
from
the
grind
up
reason
about
quality_attribute_3
component_2
in
the
real
worldnext
postnext
so
you
wanna
go
fast
popularyou
cannot
have
exactly
once
deliveryeverything
you
about
quality_attribute_1
be
wrongbenchmarking
connector_data_1
component_1
latencystructuring
a
requirement_8
infrastructure
organizationa
look
at
nanomsg
and
quality_attribute_11
technology_9
why
technology_19
shouldn
t
be
your
first
choice
recent
sre
doesn’t
quality_attribute_6
connector_data_14
a
requirement_8
infrastructure
organization
we
suck
at
meet
connector_12
big
win
with
small
team
on
tight
deadline
continuous
deployment
for
technology_20
glue
category
algorithm
requirement_9
technology_21
technology_20
bash
benchmarking
requirement_10
requirement_8
component_18
science
pattern_11
consult
culture
connector_data_8
connector_data_15
component_19
design
pattern_8
devops
quality_attribute_3
component_2
economics
gcp
go
infinitum
technology_22
technology_23
technology_24
liftbridge
requirement_11
mathematics
pattern_1
postmortem
technology_25
real
kinetic
quality_attribute_12
architecture
engineering
technology_26
component_2
theory
unix
archive


























































tag
agile
algorithm
technology_21
component_17
component_20
architecture
benchmarking
requirement_10
cap
theorem
requirement_8
requirement_8
requirement_12
consensus
consistency
consult
culture
component_19
design
pattern_8
devops
quality_attribute_3
requirement_7
quality_attribute_3
component_2
engineering
culture
engineering
empathy
fault
tolerance
gcp
go
infinitum
technology_22
technology_5
connector_data_1
orient
technology_27
connector_data_1
component_4
pattern_1
pattern_12
nats
nats
connector_19
ops
requirement_1
component_16
technology_28
development
productivity
raft
quality_attribute_11
serverless
technology_29
engineering
connector_20
component_16
component_2
proudly
powered
by
technology_30
