technology_1
vs
technology_2
what
be
technology_1
what
be
technology_2
and‚Ä¶
|
by
brachi
packter
|
itnextopen
in
apphomenotificationslistsstorieswritepublished
initnextbrachi
packterfollowdec
2018¬∑6
min
readsavekafka
vs
rabbitmqwhat
be
technology_1
what
be
technology_2
and
what
be
the
strength
and
weakness
of
each
frameworkphoto
by
markus
spiske
on
unsplash**disclaimer
i‚Äôm
not
use
technology_1
or
technology_2
in
production
yet
so
this
isn‚Äôt
base
on
some
deep
experience
fyi***kafka
vs
rabbitmqthere
be
countless
on
the
internet
compare
among
these
two
lead
technology_3
most
of
them
tell
you
the
strength
of
each
but
not
provide
a
full
wide
comparison
of
feature
support
and
specialty
when
i
make
a
decision
about
which
technology_4
to
choose
i
always
wish
to
see
a
comparison
component_1
then
i
can
quickly
connector_1
what
be
the
key
feature
of
my
specific
scenario
and
connector_2
a
decision
technology_2
in
a
nutshellwho
be
the
player
consumer2
publisher3
exchange4
routethe
flow
start
from
the
pattern_1
which
connector_3
a
connector_data_1
to
exchange
exchange
be
a
technology_5
pattern_2
that
to
connector_4
the
connector_data_1
to
the
component_2
component_3
can
define
which
component_2
they
be
connector_5
from
by
define
bind
technology_2
connector_6
the
connector_data_1
to
the
component_4
and
once
connector_7
and
acknowledgment
have
arrive
connector_data_1
be
remove
from
the
component_2
any
piece
in
this
component_5
can
be
quality_attribute_1
out
component_6
component_4
and
also
the
technology_2
itself
can
be
cluster
and
highly
quality_attribute_2
kafkawho
be
the
players1
component_4
component_4
groups2
producer3
technology_1
component_7
connect4
technology_1
connector_8
connect5
topic
and
topic
partition6
technology_1
stream7
broker8
zookeeperkafka
be
a
quality_attribute_3
component_5
and
have
several
member
in
the
game
but
once
you
understand
well
the
flow
this
become
easy
to
manage
and
to
work
with
component_6
connector_3
a
connector_data_1
component_8
to
a
topic
a
topic
be
a
category
or
fee
name
to
which
component_9
be
publish
it
can
be
component_10
to
connector_2
quality_attribute_4
requirement_1
component_3
subscribe
to
a
topic
and
start
to
connector_9
connector_data_2
from
it
when
a
topic
be
component_10
then
each
component_10
connector_2
it
own
component_4
instance
we
connector_10
all
instance
of
same
component_4
a
component_4
group
in
technology_1
connector_data_2
be
always
remain
in
the
topic
also
if
they
be
connector_7
limit
time
be
define
by
retention
requirement_2
also
technology_1
u
sequential
disk
i
o
this
approach
technology_6
the
requirement_1
of
technology_1
and
make
it
a
leader
option
in
component_11
implementation
and
a
quality_attribute_5
choice
for
requirement_3
use
requirement_4
let‚Äôs
compare
distribution
and
parallelismboth
give
a
quality_attribute_4
distribution
solution
but
with
some
difference
let‚Äôs
talk
about
component_4
in
technology_2
you
can
quality_attribute_1
out
the
number
of
component_4
this
mean
for
each
component_2
instance
you
will
have
many
component_4
this
connector_10
competitive
component_3
because
they
compete
to
connector_7
the
connector_data_1
in
this
form
the
connector_data_1
component_12
work
be
spread
by
all
the
active
component_4
but
still
connector_data_1
can
be
procced
only
once
in
technology_1
the
way
to
quality_attribute_6
component_3
be
by
topic
component_10
and
each
component_4
from
the
group
be
dedicate
to
one
component_10
you
can
use
the
component_10
mechanism
to
connector_3
each
component_10
different
set
of
connector_data_2
by
requirement_5
key
for
example
by
component_13
location
etc
high
availabilityboth
solution
be
highly
quality_attribute_2
technology_1
do
it
by
use
technology_7
to
manage
the
state
of
the
clusterrabbitmq
have
provide
cluster
and
highly
quality_attribute_2
component_11
for
several
major
version
version
ship
with
‚Äúquorum
queues‚Äù
which
use
the
raft
consensus
algorithm
to
provide
connector_data_3
pattern_3
with
high
requirement_1
than
‚Äúclassic‚Äù
ha
component_2
performancekafka
leverage
the
strength
of
sequential
disk
i
o
and
require
le
hardware
this
can
lead
to
high
quality_attribute_7
several
million
of
connector_data_2
in
a
second
with
a
tiny
number
of
technology_8
technology_2
also
can
component_12
a
million
connector_data_2
in
a
second
but
require
30+
technology_8
replicationkafka
have
replicate
the
pattern_4
by
design
and
if
the
master
pattern_4
be
down
automatically
all
the
work
be
pass
to
another
one
which
have
a
full
replica
of
the
die
one
no
connector_data_1
lose
in
technology_2
component_11
aren‚Äôt
automatically
replicable
this
need
to
be
configure
version
simplify
this
if
your
cluster
have
at
least
three
technology_8
all
you
must
do
be
declare
your
component_2
a
a
quorum
component_2
and
pattern_3
be
take
care
of
for
you
multi
subscriberin
technology_1
connector_data_2
can
be
subscribe
by
multi
component_4
mean
many
component_4
type
not
many
instance
of
the
same
one
in
technology_2
connector_data_2
can
be
connector_11
to
numerous
component_11
quality_attribute_8
on
the
exchange
type
such
a
fanout
or
topic
and
the
component_2
bind
in
each
component_2
only
one
component_4
of
that
component_2
can
component_12
the
connector_data_1
but
if
the
connector_data_1
go
to
multiple
component_11
it
can
be
component_12
by
multiple
component_4
connector_data_1
orderingbecause
technology_1
have
component_10
you
can
connector_2
connector_data_2
order
in
this
unit
connector_data_1
be
connector_11
to
topic
by
connector_data_1
key
so
when
choose
a
correct
key
you
will
connector_2
one
component_10
for
any
key
with
order
connector_data_1
this
can‚Äôt
be
achieve
in
technology_2
only
by
try
by
mimic
this
behavior
by
define
many
component_11
and
connector_12
each
connector_data_1
to
a
different
component_2
at
quality_attribute_1
this
can
be
hard
to
connector_2
compaction
requirement_6
if
the
same
connector_data_1
key
have
arrive
multiple
time
then
technology_1
connector_13
only
the
last
requirement_7
in
the
requirement_6
and
delete
old
connector_data_1
connector_data_1
protocolsrabbitmq
support
any
technology_9
component_2
technology_10
technology_11
stomp
text
base
technology_12
lightweight
pattern_5
connector_data_1
and
technology_13
while
technology_1
support
primitive
int8
int16
int32
int64
and
binary
connector_data_1
connector_data_1
lifetimebecause
technology_1
be
a
requirement_6
connector_data_2
be
always
there
you
can
control
this
by
define
a
connector_data_1
retention
requirement_2
technology_2
be
a
component_2
connector_data_2
remove
once
connector_7
and
acknowledgment
arrive
in
technology_2
you
can
configure
connector_data_2
to
be
persistent
mark
the
component_2
a
quality_attribute_9
and
connector_data_2
a
persistent
connector_data_1
acknowledgmentin
both
technology_3
component_14
connector_2
confirmation
that
the
connector_data_1
arrive
in
the
component_2
topic
and
also
the
component_4
connector_14
an
acknowledgment
when
the
connector_data_1
connector_7
successfully
so
you
can
be
sure
that
connector_data_2
didn‚Äôt
connector_2
lose
in
the
way
quality_attribute_10
connector_15
to
a
topic
queuein
technology_1
connector_data_1
be
connector_16
to
a
topic
by
key
in
technology_2
there
be
more
option
for
example
by
regular
expression
and
wildcard
connector_1
the
doc
for
more
connector_data_4
connector_data_1
priorityin
technology_2
you
can
define
connector_data_1
priority
and
connector_7
connector_data_1
with
high
priority
first
for
more
connector_data_4
look
in
technology_13
www
technology_2
technology_14
priority
htmlhard
to
achieve
in
technology_1
can
be
do
by
connector_data_1
key
but
on
large
quality_attribute_1
this
can
be
hard
monitoringin
technology_1
you
have
3rd
party
technology_15
license
for
a
production
environmentconfluent
technology_13
www
confluent
io
technology_16
control
center
landoop
technology_13
www
landoop
technology_14
freeburrow
technology_13
technology_17
technology_14
linkedin
burrowkafka
technology_15
technology_13
www
kafkatool
technology_14
in
technology_2
you
have
a
build
in
requirement_8
ui
default
host_name
also
note
that
version
support
external
pattern_6
via
prometheus
and
grafana13
transaction
supportboth
support
atomic
connector_17
mean
if
you
connector_17
a
bunch
of
connector_data_2
to
component_2
and
one
fail
all
the
transaction
be
rollbacked
this
extremely
use
in
technology_1
connector_18
component_12
let‚Äôs
recapuse
technology_1
if
you
needtime
travel
quality_attribute_9
connector_19
logmany
component_3
for
the
same
messagehigh
quality_attribute_7
million
of
connector_data_2
per
second
connector_18
processingreplicabilityhigh
availabilitymessage
orderuse
technology_2
if
you
need
quality_attribute_10
routingpriority
queuea
technology_9
technology_10
connector_data_1
queueconclusion
actually
technology_2
be
enough
for
quality_attribute_11
use
requirement_4
with
low
traffic
of
connector_data_3
you
have
certain
benefit
a
priority
component_2
and
quality_attribute_10
connector_15
option
but
for
massive
connector_data_3
and
high
quality_attribute_7
use
technology_1
without
debate
if
you
need
a
connector_19
requirement_6
or
multiple
component_3
for
the
same
connector_data_1
then
go
to
technology_1
because
technology_2
can‚Äôt
assist
you
with
it
15more
from
itnextfollowitnext
be
a
component_15
for
it
developer
&
engineer
to
connector_20
knowledge
connector_21
collaborate
and
experience
next
gen
technology_4
connector_22
more
from
itnextrecommended
from
mediumlachlan
evensoninmicrosoft
azurekubernetes
requirement_2
‚Äî
turn
cncf
project
into
technology_16
responsiblyvermanikitalaunch
an
technology_18
technology_19
instance
use
terraform
codewendy
raven
mcnairingeek
culturefizzbuzzjim
laimvvm
without
vm
with
combinelukasz
lazewskirunning
lukso
technology_8
on
m1
macgokumarket
exchangeingokumarketairdrop
alert
üíù
love
for
feb
mar
month
airdrop
be
now
live
üíü
ü™Çted
martinstart
use
your
mac
a
prochinmay
venkata
sabbaminart
of
codingdeeper
insight
of
component_16
pool
&
need
of
pattern_7
programming
in
technology_20
‚Ä¶
part
abouthelptermsprivacyget
the
appget
startedbrachi
packter556
followersi
love
everything
relate
to
and
techfollowmore
from
mediumolga
shafranindev
geniuskafka
cluster
on
technology_21
composeshaaf
syedcreate
technology_22
pattern_8
connector_23
and
more
in
connector_data_3
grid
3rob
golderinlydtech
consultingkafka
transaction
part
exactly
once
messagingyasser
karimienterprise
component_17
‚Äî
part
performancehelpstatuswritersblogcareersprivacytermsaboutknowable
