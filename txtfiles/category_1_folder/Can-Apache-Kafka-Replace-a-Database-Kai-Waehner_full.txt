can
technology_1
technology_2
replace
a
component_1
kai
waehner
home
highlight
activity
talk
at
international
conference
video
component_2
publication
requirement_1
requirement_1
technology_1
technology_3
requirement_2
requirement_3
intelligence
deep
technology_4
in
memory
jupyter
requirement_4
technology_5
open_source
technology_2
connector_1
technology_6
social
requirement_5
technology_7
requirement_6
requirement_6
technology_1
mesos
requirement_6
requirement_7
technology_8
technology_9
open_source
persistence
component_3
mesh
internet
of
thing
internet
of
thing
requirement_2
iiot
technology_10
open_source
plc4x
requirement_8
requirement_8
component_4
requirement_9
component_5
component_6
blockchain
bpm
eai
esb
it
certification
it
conference
technology_11
jee
pattern_1
pattern_2
technology_12
open_source
technology_1
technology_2
technology_2
connector_2
persistence
component_3
mesh
pattern_3
social
requirement_5
web
technology_13
connector_3
component_7
connector_3
component_7
technology_1
technology_2
requirement_2
confluent
technology_2
connector_2
technology_2
connector_1
ksql
persistence
about
me
stay
in
technology_14
evangelist
‚Äì
requirement_2
requirement_1
‚Äì
technology_12
‚Äì
technology_1
technology_2
technology_14
evangelist
‚Äì
requirement_2
requirement_1
‚Äì
technology_12
‚Äì
technology_1
technology_2
home
highlight
activity
talk
at
international
conference
video
component_2
publication
requirement_1
requirement_6
internet
of
thing
requirement_8
connector_3
component_7
technology_1
sparkbig
databusiness
intelligencedeep
learninghadoopin
memoryjupyterkafka
streamsmachine
learningnosqlopen
sourcepythonsocial
networktensorflow
technology_1
mesoscloud
nativedockerkubernetesopen
sourcepersistenceservice
mesh
big
dataiiotmqttopen
sourceplc4x
technology_1
kafkaapi
managementapplication
serverblockchainbpmeaiesbit
certificationsit
conferencesjava
jeekafka
connectmessagingmicroservicesmiddlewareopen
sourcepersistenceservice
meshsoasocial
networkweb
technology_13
technology_1
kafkabig
dataconfluentkafka
connectkafka
streamsksqlpersistence
about
me
stay
in
search
for
search
requirement_1
technology_1
technology_2
architecture
requirement_2
confluent
component_1
requirement_8
technology_2
connector_2
can
technology_1
technology_2
replace
a
component_1
minute
connector_4
bykai
waehner12
total
connector_5
connector_6
people
connector_7
the
story
can
and
should
technology_1
technology_2
replace
a
component_1
how
long
can
and
should
i
component_8
connector_data_1
in
technology_2
how
can
i
query
and
component_7
connector_data_1
in
technology_2
these
be
common
question
that
come
up
more
and
more
short
answer
‚Äúyes‚Äù
or
‚Äúit
depends‚Äù
be
not
quality_attribute_1
enough
for
you
then
this
connector_4
for
you
this
explain
the
idea
behind
component_1
and
different
feature
storage
connector_8
and
transaction
to
evaluate
when
technology_2
be
a
quality_attribute_1
fit
and
when
it
be
not
jay
kreps
the
co
founder
of
technology_1
technology_2
and
confluent
explain
already
in
why
‚Äúit‚Äôs
okay
to
component_8
connector_data_1
in
technology_1
kafka‚Äù
however
many
thing
have
improve
and
component_9
and
feature
be
in
the
last
three
year
this
update
cover
the
core
concept
of
technology_2
from
a
component_1
perspective
it
include
technology_2
requirement_7
ons
tiered
storage
for
long
term
cost
quality_attribute_2
storage
and
technology_15
a
connector_9
component_1
the
relation
and
requirement_10
off
between
technology_2
and
other
component_1
be
explore
to
complement
each
other
instead
of
think
about
a
replacement
this
discussion
include
different
option
for
connector_10
and
connector_11
base
pattern_4
directional
requirement_8
i
also
create
a
slide
deck
and
video
component_2
about
this
topic
what
be
a
component_1
technology_16
technology_5
technology_4
let‚Äôs
think
about
the
term
‚Äúdatabase‚Äù
on
a
very
high
level
accord
to
wikipedia
‚Äúa
component_1
be
an
organize
collection
of
connector_data_1
generally
component_8
and
connector_12
electronically
from
a
component_10
component_11
the
component_1
requirement_9
component_11
technology_17
be
the
that
connector_13
with
end
component_12
component_5
and
the
component_1
itself
to
capture
and
analyze
the
connector_data_1
the
technology_17
additionally
encompass
the
core
facility
provide
to
administer
the
component_1
the
sum
total
of
the
component_1
the
technology_17
and
the
associate
component_13
can
be
refer
to
a
a
‚Äúdatabase
system‚Äù
often
the
term
‚Äúdatabase‚Äù
be
also
use
to
loosely
refer
to
any
of
the
technology_17
the
component_1
component_11
or
an
component_5
associate
with
the
component_1
component_10
scientist
classify
component_1
requirement_9
component_14
accord
to
the
component_1
component_15
that
they
support
relational
component_1
become
dominant
in
the
1980s
these
component_16
connector_data_1
a
row
and
column
in
a
series
of
component_17
and
the
vast
majority
use
technology_18
for
connector_14
and
query
connector_data_1
in
the
2000s
non
relational
component_1
become
popular
refer
to
a
technology_5
because
they
use
different
query
technology_19
‚Äù
base
on
this
definition
we
that
there
be
many
component_1
on
the
requirement_11
technology_16
technology_20
postgres
technology_4
technology_21
elasticsearch
technology_22
technology_23
influxdb
technology_2
hold
on
technology_2
yes
indeed
let‚Äôs
explore
this
in
detail‚Ä¶
storage
transaction
component_7
and
query
connector_data_1
a
component_1
infrastructure
be
use
for
storage
connector_8
and
component_7
of
connector_data_1
often
with
specific
delivery
and
quality_attribute_3
guarantee
aka
transaction
there
be
not
one
component_1
a
we
all
should
from
all
the
technology_5
and
requirement_2
technology_24
on
the
requirement_11
for
each
use
requirement_12
you
should
choose
the
right
component_1
it
quality_attribute_4
on
your
requirement
how
long
to
component_8
connector_data_1
what
connector_data_2
should
the
connector_data_1
have
do
you
need
complex
connector_8
or
retrieval
of
connector_data_1
via
key
and
requirement_13
require
acid
transaction
exactly
once
semantics
or
‚Äújust‚Äù
at
least
once
delivery
guarantee
these
and
many
more
question
have
to
be
answer
before
you
decide
if
you
need
a
relational
component_1
technology_20
or
postgres
a
requirement_2
pattern_5
component_18
technology_4
a
document
component_8
technology_21
a
key
requirement_13
component_8
rocksdb
a
time
series
component_1
influxdb
an
in
memory
pattern_6
memcached
or
something
else
every
component_1
have
different
characteristic
thus
when
you
ask
yourself
if
you
can
replace
a
component_1
with
technology_2
which
component_1
and
what
requirement
be
you
talk
about
what
be
technology_1
technology_2
obviously
it
be
also
crucial
to
understand
what
technology_2
be
to
decide
if
technology_2
can
replace
your
component_1
otherwise
it
be
really
hard
to
proceed
with
this
evaluation‚Ä¶
üôÇ
technology_2
be
an
connector_9
component_18
=
connector_data_3
connector_3
component_7
component_1
requirement_8
first
of
all
technology_2
be
not
a
pattern_7
pattern_1
component_11
to
connector_15
connector_data_1
from
a
to
b
this
be
what
some
unaware
people
typically
respond
to
such
a
question
when
they
think
technology_2
be
the
next
mq
or
technology_25
nope
technology_2
be
not
a
pattern_1
component_11
a
comparison
with
other
pattern_1
solution
be
an
apple
to
orange
comparison
but
still
valid
to
decide
when
to
choose
technology_2
or
a
pattern_1
component_11
technology_2
be
an
connector_9
component_18
requirement_14
from
various
requirement_15
present
hundred
of
use
requirement_12
where
they
use
technology_2
successfully
for
much
more
than
connector_data_3
connector_16
out
all
the
talk
from
the
technology_2
summit
include
free
slide
deck
and
video
component_2
one
of
the
reason
why
technology_1
technology_2
become
the
de
facto
technology_26
for
so
many
different
use
requirement_12
be
it
combination
of
four
powerful
concept
publish
and
subscribe
to
connector_1
of
similar
to
a
connector_data_3
component_19
or
requirement_16
pattern_1
component_11
component_8
connector_1
of
in
a
fault
tolerant
storage
a
long
a
you
want
hour
day
month
forever
component_7
connector_1
of
in
real
time
a
they
occur
requirement_8
of
different
component_20
and
connector_17
no
matter
if
real
time
pattern_5
or
connector_data_4
connector_18
decouple
quality_attribute_5
highly
quality_attribute_6
connector_9
pattern_2
with
these
four
pillar
build
into
one
quality_attribute_7
connector_9
component_18
you
can
decouple
various
component_13
i
e
component_21
and
component_22
in
a
quality_attribute_8
quality_attribute_5
and
fault
tolerant
way
a
you
can
see
storage
be
one
of
the
key
principle
of
technology_2
therefore
quality_attribute_4
on
your
requirement
and
definition
technology_2
can
be
use
a
a
component_1
be
‚Äúkafka
core‚Äù
a
component_1
with
acid
guarantee
i
won‚Äôt
cover
the
whole
discussion
about
how
‚Äúkafka
core‚Äù
mean
technology_2
pattern_8
and
it
concept
quality_attribute_7
connector_19
requirement_17
pattern_9
component_23
guarantee
order
etc
fit
into
the
acid
atomicity
consistency
isolation
quality_attribute_3
transaction
property
of
component_1
this
be
discus
already
by
martin
kleppmann
at
technology_2
summit
san
francisco
‚Äúis
technology_2
a
component_1
‚Äù
and
a
little
bit
le
technically
by
tim
berglund
‚Äúdissolving
the
problem
‚Äì
make
an
acid
compliant
component_1
out
of
technology_1
kafka‚Äù
tl
dr
technology_2
be
a
component_1
and
provide
acid
guarantee
however
it
work
differently
than
other
component_1
technology_2
be
also
not
replace
other
component_1
but
a
complementary
technology_27
in
your
toolset
the
component_24
side
of
technology_2
in
pattern_1
component_11
the
component_24
component_4
provide
component_21
and
component_25
to
connector_15
and
connector_4
connector_data_3
all
other
component_26
be
connector_20
use
low
level
programming
or
additional
technology_13
in
component_1
the
component_24
component_4
provide
a
query
technology_19
to
create
connector_data_1
connector_data_5
and
enable
the
component_24
to
component_8
and
connector_21
connector_data_1
all
other
component_26
be
connector_20
use
low
level
programming
or
additional
technology_13
in
an
connector_9
component_18
the
component_24
component_4
be
use
for
connector_22
and
connector_23
connector_data_1
in
a
pattern_1
component_11
however
in
contrary
to
pattern_1
and
component_1
the
component_24
component_4
provide
much
more
requirement_18
independent
quality_attribute_5
quality_attribute_8
component_9
component_13
can
be
build
with
the
technology_2
apis
therefore
a
technology_2
component_24
component_5
be
a
quality_attribute_7
component_11
that
query
component_27
and
connector_24
continuous
connector_1
of
connector_data_1
many
component_13
can
be
build
without
the
need
for
another
additional
technology_13
the
technology_2
ecosystem
‚Äì
technology_2
connector_3
technology_15
technology_28
technology_2
and
much
more‚Ä¶
the
technology_2
ecosystem
provide
various
different
component_9
to
connector_20
component_5
technology_2
itself
include
a
technology_11
and
technology_29
component_24
technology_30
technology_2
connector_1
for
connector_3
component_7
with
technology_11
and
technology_2
connector_2
to
quality_attribute_9
with
different
component_20
and
connector_17
without
cod
many
additional
technology_2
requirement_7
component_24
component_28
and
technology_13
exist
here
be
some
example
librdkafka
a
technology_31
technology_32
implementation
of
the
technology_1
technology_2
technology_33
provide
component_29
component_22
and
admin
component_24
it
be
design
with
connector_data_3
delivery
quality_attribute_10
and
high
requirement_19
in
mind
current
figure
exceed
million
msg
second
for
the
component_29
and
million
msg
second
for
the
component_22
in
addition
to
the
technology_31
technology_32
it
be
often
use
a
wrapper
to
provide
technology_2
component_30
from
other
programming
technology_19
such
a
technology_34
golang
technology_6
and
technology_35
pattern_10
pattern_11
provide
a
pattern_12
to
a
technology_2
cluster
it
make
it
easy
to
produce
and
connector_25
connector_data_3
pattern_13
the
state
of
the
cluster
and
perform
administrative
action
without
use
the
requirement_7
technology_2
technology_33
or
component_24
technology_15
an
connector_9
component_1
for
technology_1
technology_2
that
enable
you
to
build
connector_9
component_13
leverage
your
familiarity
with
relational
component_1
technology_28
for
technology_2
apply
core
technology_28
concept
to
the
development
of
technology_2
base
pattern_1
and
connector_9
solution
it
provide
a
‚Äútemplate‚Äù
a
a
high
level
abstraction
for
connector_22
connector_data_3
include
first
support
for
technology_2
connector_3
additional
technology_28
technology_13
technology_28
requirement_6
connector_3
and
technology_28
requirement_6
connector_data_1
flow
also
provide
requirement_7
support
for
connector_9
with
technology_2
faust
a
technology_32
for
build
connector_9
component_13
in
technology_6
similar
to
the
original
technology_2
connector_1
technology_32
but
more
limit
requirement_18
and
le
mature
technology_7
i
o
+
technology_2
plugin
a
requirement_7
requirement_8
into
technology_7
for
connector_9
requirement_4
i
e
directly
connector_23
component_15
from
technology_2
for
component_16
train
and
component_16
score
instead
of
use
another
connector_data_1
lake
many
more‚Ä¶
domain
drive
design
ddd
dumb
pip
smart
the
importance
of
kafka‚Äôs
component_24
side
be
crucial
for
the
discussion
of
potentially
replace
a
component_1
because
technology_2
component_13
can
be
stateless
or
stateful
the
latter
keep
state
in
the
component_5
instead
of
use
an
external
component_1
the
storage
section
below
contain
more
detail
about
how
the
component_24
component_5
can
component_8
connector_data_1
long
term
and
be
highly
quality_attribute_6
with
this
you
understand
that
technology_2
have
a
powerful
component_6
and
a
powerful
component_24
side
many
people
be
not
aware
of
this
when
they
evaluate
technology_2
versus
other
pattern_1
solution
or
storage
component_11
this
in
conjunction
with
the
capability
to
do
real
decouple
between
component_29
and
component_25
leverage
the
underlie
storage
of
technology_2
it
become
clear
why
technology_1
technology_2
become
the
de
facto
technology_26
and
technology_36
for
pattern_14
architecture
‚Äì
not
replace
other
traditional
technology_12
but
also
build
the
component_24
component_13
use
domain
drive
design
ddd
for
decouple
component_5
dumb
pip
and
smart
connector_16
out
the
‚Äúmicroservices
technology_1
technology_2
and
domain
drive
design
ddd
‚Äù
for
more
detail
on
this
discussion
again
why
be
this
important
for
the
discussion
around
technology_2
be
a
component_1
for
every
pattern_14
you
create
you
should
ask
yourself
do
i
really
need
a
‚Äúreal
database‚Äù
backend
in
my
pattern_14
with
all
it
complexity
and
cost
regard
development
test
pattern_15
often
the
answer
be
yes
of
but
i
see
more
and
more
component_13
where
keep
the
state
directly
in
the
technology_2
component_5
be
quality_attribute_1
easy
or
both
storage
‚Äì
how
long
can
you
component_8
connector_data_1
in
technology_2
and
what
be
the
component_1
under
the
hood
the
short
answer
connector_data_1
can
be
component_8
in
technology_2
a
long
a
you
want
technology_2
even
provide
the
option
to
use
a
retention
time
of
this
mean
‚Äúforever‚Äù
the
long
answer
be
much
more
complex
you
need
to
think
about
the
cost
and
quality_attribute_11
of
the
technology_2
pattern_8
should
you
use
hdds
or
sdds
or
maybe
even
technology_37
base
technology_14
pure
storage
connector_26
a
nice
example
leverage
technology_37
storage
to
connector_26
million
connector_data_6
per
second
with
three
component_21
and
3x
pattern_9
it
quality_attribute_4
on
how
much
connector_data_1
you
need
to
component_8
and
how
fast
you
need
to
connector_27
connector_data_1
and
be
able
to
recover
from
failure
publish
with
technology_1
technology_2
at
the
york
time
be
a
famous
example
for
connector_28
connector_data_1
in
technology_2
forever
technology_2
be
use
for
connector_28
all
the
ever
publish
by
the
york
time
and
replace
their
technology_30
base
approach
the
connector_1
component_4
be
use
to
fee
publish
content
in
real
time
to
the
various
component_13
and
component_14
that
make
it
quality_attribute_6
to
our
reader
another
great
example
be
the
account
activity
replay
component_4
from
twitter
it
u
technology_2
a
storage
to
provide
‚Äúa
connector_data_1
recovery
technology_27
that
developer
connector_21
from
a
far
back
a
five
day
this
component_4
recover
that
weren‚Äôt
connector_29
for
various
reason
include
inadvertent
component_6
outage
during
real
time
delivery
attempt
‚Äù
until
now
we
be
talk
about
the
most
commonly
use
technology_2
feature
requirement_17
base
storage
with
retention
time
and
disk
attach
to
the
pattern_8
however
you
also
need
to
consider
the
additional
capability
of
technology_2
to
have
a
complete
discussion
about
long
term
storage
in
a
technology_2
infrastructure
compact
topic
tiered
storage
and
component_24
side
storage
all
of
these
feature
can
quickly
connector_30
your
mind
of
how
you
think
about
technology_2
it
use
requirement_12
and
it
architecture
compact
topic
‚Äì
requirement_17
compaction
and
‚Äúevent
updates‚Äù
requirement_17
compaction
ensure
that
technology_2
will
always
retain
at
least
the
last
requirement_13
for
each
connector_data_3
key
within
the
requirement_17
of
connector_data_1
for
a
single
topic
component_23
it
connector_31
use
requirement_12
and
scenario
such
a
restore
state
after
component_5
crash
or
component_11
failure
or
reload
pattern_6
after
component_5
restart
during
operational
quality_attribute_12
therefore
requirement_17
compaction
do
not
have
a
retention
time
obviously
the
big
requirement_10
off
be
that
requirement_17
compaction
do
not
keep
all
and
the
full
order
of
connector_30
for
this
you
need
to
use
the
normal
technology_2
topic
with
a
specific
retention
time
or
you
can
use
to
component_8
all
connector_data_1
forever
the
big
requirement_10
off
here
be
high
cost
for
the
disk
and
more
complex
and
quality_attribute_11
tiered
storage
‚Äì
long
term
storage
in
technology_1
technology_2
kip
technology_2
improvement
proposal
be
create
to
standardize
the
for
tiered
storage
in
technology_2
to
provide
different
implementation
by
different
contributor
and
vendor
the
kip
be
not
connector_20
yet
and
the
be
still
under
discussion
by
contributor
from
different
requirement_14
confluent
already
provide
a
commercial
implementation
for
technology_2
to
use
tiered
storage
for
connector_28
connector_data_1
long
term
in
technology_2
at
low
cost
the
‚Äúinfinite
storage
in
confluent
platform‚Äù
talk
about
the
motivation
and
implementation
of
this
game
connector_30
technology_2
on
tiered
storage
for
technology_2
reduce
cost
due
to
cheap
connector_data_7
storage
increase
quality_attribute_11
due
to
the
separation
between
storage
and
component_7
and
ea
due
to
simplify
and
much
fast
rebalancing
here
be
some
example
for
connector_28
the
complete
requirement_17
in
technology_2
long
term
instead
of
leverage
compact
topic
component_22
e
g
a
complete
pattern_2
or
a
replacement
of
an
exist
component_5
error
handle
e
g
re
component_7
of
connector_data_1
in
requirement_12
of
error
to
fix
error
and
component_7
again
compliance
regulatory
component_7
reprocess
of
already
component_7
connector_data_1
for
legal
reason
could
be
very
old
connector_data_1
e
g
pharma
year
old
query
and
analysis
of
exist
no
need
for
another
connector_data_1
component_8
connector_data_1
lake
technology_15
position
first
but
the
various
limitation
technology_2
requirement_7
requirement_1
technology_27
e
g
rockset
with
technology_2
connector
and
full
technology_18
support
for
technology_38
et
al
requirement_4
and
component_16
train
connector_25
for
component_16
train
with
a
different
one
requirement_4
technology_13
and
different
hyperparameters
or
b
different
requirement_4
technology_13
the
last
example
be
discus
in
more
detail
here
connector_9
requirement_4
with
tiered
storage
no
need
for
a
connector_data_1
lake
component_24
side
component_1
‚Äì
stateful
technology_2
component_24
component_13
and
pattern_2
a
discus
above
technology_2
be
not
the
component_6
side
you
build
highly
quality_attribute_6
and
quality_attribute_5
real
time
component_13
on
the
technology_2
component_24
side
rocksdb
for
stateful
technology_2
component_13
often
these
technology_2
component_24
component_13
have
to
keep
important
state
technology_2
connector_1
and
technology_15
leverage
rocksdb
for
this
you
could
also
use
in
memory
storage
or
replace
rocksdb
with
another
storage
i
have
never
see
the
latter
option
in
the
real
world
though
rocksdb
be
a
key
requirement_13
component_8
for
run
mission
critical
workload
it
be
optimize
for
fast
low
quality_attribute_13
storage
in
technology_2
connector_1
component_5
that
solve
the
problem
of
abstract
connector_27
to
local
quality_attribute_14
storage
instead
of
use
an
external
component_1
use
an
external
component_1
would
require
external
connector_32
pattern_16
every
time
an
be
component_7
a
clear
anti
pattern_17
in
connector_9
architecture
rocksdb
allow
engineer
to
focus
their
energy
on
the
design
and
implementation
of
other
area
of
their
component_14
with
the
peace
of
mind
of
rely
on
rocksdb
for
connector_27
to
quality_attribute_14
storage
it
be
battle
test
at
several
silicon
valley
requirement_14
and
use
under
the
hood
of
many
famous
component_1
technology_1
technology_39
cockroachdb
or
technology_20
myrocks
rocksdb
be
eat
the
component_1
world
cover
the
history
and
use
requirement_12
in
more
detail
technology_15
a
connector_9
component_1
technology_2
connector_1
and
technology_15
‚Äì
the
connector_9
component_1
for
technology_2
‚Äì
allow
build
stateful
connector_9
component_5
include
powerful
concept
join
slide
window
and
interactive
connector_8
of
the
state
the
follow
example
show
how
you
build
a
stateful
payment
component_5
the
component_24
component_5
keep
the
connector_data_1
in
it
own
component_5
for
real
time
join
and
other
connector_data_1
correlation
it
combine
the
concept
of
a
connector_3
unchangeable
and
a
component_17
update
connector_data_8
in
a
relational
component_1
keep
in
mind
that
this
component_5
be
highly
quality_attribute_5
it
be
typically
not
a
single
instance
instead
it
be
a
quality_attribute_7
cluster
of
component_24
instance
to
provide
high
quality_attribute_15
and
parallelize
connector_data_1
component_7
even
if
something
go
down
vm
container
disk
requirement_5
the
overall
component_11
will
not
lose
and
connector_data_1
and
continue
run
a
you
can
see
many
question
have
to
be
answer
and
various
feature
have
to
be
consider
to
make
the
right
decision
about
how
long
and
where
you
want
to
component_8
connector_data_1
in
technology_2
one
quality_attribute_1
reason
to
component_8
connector_data_1
long
term
in
technology_2
be
to
be
able
to
use
the
connector_data_1
at
a
late
point
in
time
for
component_7
correlation
or
requirement_1
query
and
component_7
‚Äì
can
you
connector_25
and
analyze
the
technology_2
storage
technology_2
provide
different
option
to
connector_25
and
query
connector_data_1
connector_8
in
technology_2
can
be
either
connector_11
i
e
continuously
component_7
and
connector_33
or
connector_10
i
e
the
component_24
connector_data_9
you
it
from
your
favorite
technology_18
component_1
i
will
show
you
different
option
in
the
follow
section
component_22
component_13
connector_10
technology_2
component_30
connector_10
the
connector_data_1
from
the
pattern_8
this
decouple
component_29
pattern_8
and
component_25
and
make
the
infrastructure
quality_attribute_5
and
quality_attribute_8
technology_2
itself
include
a
technology_11
and
technology_29
component_24
to
connector_25
connector_data_1
however
technology_2
component_30
be
quality_attribute_6
for
almost
any
other
programming
technology_19
include
widespread
technology_19
technology_40
technology_34
technology_6
technology_35
or
golang
and
exotic
technology_19
technology_41
connector_16
out
yeva
byzek‚Äôs
example
to
see
your
favorite
programming
technology_19
in
action
additionally
confluent
provide
a
pattern_10
pattern_11
this
allow
consumption
of
via
technology_42
s
from
any
technology_19
or
technology_27
support
this
technology_26
component_13
have
different
option
to
connector_25
from
the
technology_2
pattern_8
continuous
consumption
of
the
late
in
real
time
or
pattern_5
specific
time
frame
or
component_23
all
connector_data_1
from
the
begin
connector_3
component_7
component_13
pattern_2
connector_10
and
connector_11
technology_2
connector_1
and
technology_15
connector_10
from
the
pattern_8
component_7
the
connector_data_1
and
then
connector_11
the
connector_data_10
back
into
another
technology_2
topic
these
connector_8
be
run
continuously
powerful
connector_8
be
possible
include
join
and
stateful
aggregation
these
feature
be
use
for
connector_9
technology_43
and
real
time
requirement_1
at
quality_attribute_16
but
also
to
build
mission
critical
requirement_3
component_13
and
pattern_2
this
discussion
need
much
more
detail
and
cannot
be
cover
in
this
focus
on
the
component_1
perspective
connector_34
start
e
g
with
my
intro
to
connector_9
with
technology_15
from
requirement_2
spain
in
madrid
cover
use
requirement_12
and
more
technical
detail
‚Äúconfluent
developer‚Äù
be
another
great
point
for
connector_35
start
with
build
connector_9
component_5
the
provide
plenty
of
video
demo
and
more
around
technology_1
technology_2
the
feature
‚Äúinteractive
queries‚Äù
allow
query
requirement_13
from
the
component_24
applications‚Äô
state
component_8
typically
connector_20
with
rocksdb
under
the
hood
the
be
connector_10
via
technology_14
pattern_10
technology_42
or
connector_11
via
pattern_18
a
websockets
pattern_11
technology_2
connector_1
provide
the
core
requirement_18
the
interactive
query
have
to
be
connector_20
by
yourself
on
top
pro
quality_attribute_17
con
not
provide
out
of
the
component_31
technology_2
a
query
component_32
and
it
limitation
none
of
the
above
describe
technology_2
query
capability
be
a
powerful
a
your
beloved
technology_16
component_1
or
elasticsearch
therefore
technology_2
will
not
replace
other
component_1
it
be
complementary
the
idea
behind
technology_2
be
to
continuously
component_7
connector_9
connector_data_1
with
additional
option
to
query
component_8
connector_data_1
technology_2
be
quality_attribute_1
enough
a
component_1
for
some
use
requirement_12
however
the
query
capability
of
technology_2
be
not
quality_attribute_1
enough
for
some
other
use
requirement_12
technology_2
be
then
often
use
a
central
connector_9
component_18
where
one
or
more
component_1
and
other
component_5
build
their
own
materialize
real
time
pattern_13
leverage
their
own
technology_14
the
principle
be
often
connector_36
‚Äûturning
the
component_1
inside
out‚Äú
this
design
pattern_17
allow
use
the
right
component_1
for
the
right
problem
technology_2
be
use
in
these
scenario
a
quality_attribute_5
connector_9
component_18
for
connector_data_1
requirement_8
for
decouple
between
different
component_21
and
component_25
to
handle
backpressure
to
continuously
component_7
and
correlate
incoming
for
enabling
the
creation
and
update
of
materialize
pattern_13
within
other
component_1
to
allow
interactive
connector_8
directly
to
technology_2
quality_attribute_4
on
the
use
requirement_12
and
use
technology_14
technology_2
a
single
component_33
of
truth
and
lead
component_11
for
many
scenario
it
be
great
if
the
central
connector_9
component_18
be
the
central
single
component_33
of
truth
technology_2
provide
an
pattern_19
real
time
infrastructure
that
be
quality_attribute_5
and
decouple
all
the
component_21
and
component_22
however
in
the
real
world
something
an
erp
component_11
will
often
stay
the
lead
component_11
even
it
connector_11
the
connector_data_1
via
technology_2
to
the
rest
of
the
requirement_16
that‚Äôs
totally
fine
technology_2
be
the
central
connector_9
component_18
do
not
force
you
to
make
it
the
lead
component_11
for
every
for
some
component_13
and
component_1
the
exist
component_33
of
truth
be
still
the
component_33
of
truth
after
the
requirement_8
with
technology_2
the
key
point
here
be
that
your
single
component_33
of
truth
should
not
be
a
component_1
that
connector_24
the
connector_data_1
at
rest
e
g
in
a
connector_data_1
lake
technology_4
or
technology_22
technology_23
this
way
your
central
storage
be
a
slow
pattern_5
component_11
you
cannot
simply
connector_2
a
real
time
component_22
to
it
on
the
other
side
if
an
connector_9
component_18
be
your
central
pattern_20
then
you
can
ingest
it
into
your
connector_data_1
lake
for
connector_data_1
component_7
at
rest
but
you
can
also
easily
another
real
time
component_22
requirement_7
ansi
technology_18
query
pattern_20
to
connector_10
technology_38
qlik
power
pattern_4
et
al
to
analyze
technology_2
connector_27
to
massive
volume
of
connector_9
connector_data_1
through
technology_2
have
technology_3
a
strong
interest
in
interactive
real
time
requirement_20
and
requirement_1
with
the
idea
be
similar
to
what
be
build
on
top
of
traditional
component_1
technology_16
or
technology_20
use
technology_38
qlik
or
power
pattern_4
and
pattern_5
technology_13
technology_4
use
technology_44
presto
or
bigquery
the
component_12
want
to
ask
question
and
connector_34
answer
quickly
leverage
rockset
a
quality_attribute_5
technology_18
search
and
requirement_1
component_32
base
on
rocksdb
and
in
conjunction
with
pattern_4
and
requirement_1
technology_27
technology_38
you
can
directly
query
the
technology_2
requirement_17
with
ansi
technology_45
no
limitation
at
quality_attribute_16
in
real
time
this
be
a
quality_attribute_1
time
to
question
your
connector_data_1
lake
strategy
isn‚Äôt
it
üôÇ
connector_16
out
detail
about
the
technical
implementation
and
use
requirement_12
here
‚Äúreal
time
requirement_1
and
pattern_21
requirement_20
with
technology_1
technology_2
and
rockset‚Äú
bosch
power
technology_27
be
a
great
real
world
example
for
use
technology_2
a
long
term
storage
and
rockset
for
real
time
requirement_1
and
powerful
interactive
query
transaction
‚Äì
delivery
and
component_7
guarantee
in
technology_2
tl
dr
technology_2
provide
end
to
end
component_7
guarantee
quality_attribute_3
and
high
quality_attribute_15
to
build
the
most
critical
requirement_3
component_5
i
have
see
many
mission
critical
infrastructure
build
on
technology_2
in
various
requirement_15
include
bank
telco
insurance
retail
automotive
and
many
others
i
want
to
focus
on
delivery
guarantee
and
quality_attribute_18
a
critical
characteristic
of
pattern_1
component_14
and
component_1
transaction
be
require
in
many
component_13
to
guarantee
no
connector_data_1
loss
and
deterministic
behavior
transaction
component_7
in
component_1
be
connector_data_8
component_7
that
be
divide
into
individual
indivisible
connector_36
transaction
each
transaction
must
succeed
or
fail
a
a
complete
unit
it
can
never
be
only
partially
complete
many
component_1
with
pattern_22
capability
include
two
phase
connector_19
xa
transaction
do
not
quality_attribute_16
well
and
be
hard
to
operate
therefore
many
quality_attribute_7
component_14
provide
‚Äúat
least
once
semantics‚Äù
exactly
once
semantics
eos
in
technology_2
in
the
contrary
technology_2
be
a
quality_attribute_7
component_11
that
provide
various
guarantee
delivery
different
configuration
option
allow
at
least
once
at
most
once
and
exactly
once
semantics
eos
exactly
once
semantics
be
what
people
compare
to
component_1
transaction
the
idea
be
similar
you
need
to
guarantee
that
each
produce
connector_data_8
be
connector_25
and
component_7
exactly
once
many
people
argue
that
this
be
not
possible
to
connector_20
with
technology_2
because
individual
indivisible
can
fail
in
a
quality_attribute_7
component_11
in
the
technology_2
world
many
people
refer
to
the
famous
hacker
news
discussion
‚Äúyou
cannot
have
exactly
once
delivery‚Äù
and
similar
twitter
conversation
in
mid
of
the
‚Äúunbelievable
thing‚Äù
happen
technology_1
technology_2
support
for
exactly
once
semantics
eos
note
that
it
do
not
include
the
term
‚Äútransaction‚Äù
intentionally
because
it
be
not
a
transaction
because
a
transaction
be
not
possible
in
a
quality_attribute_7
component_11
however
the
connector_data_10
be
the
same
each
component_22
connector_37
each
produce
connector_data_3
exactly
once
‚Äúexactly
once
semantics
be
possible
here‚Äôs
how
technology_2
do
it‚Äù
cover
the
detail
of
the
implementation
in
short
eos
include
three
feature
idempotence
exactly
once
in
order
semantics
per
component_23
transaction
atomic
connector_38
across
multiple
component_23
exactly
once
connector_3
component_7
in
technology_1
technology_2
matthias
j
technology_46
do
a
great
explain
eos
at
technology_2
summit
in
london
slide
and
video
component_2
be
quality_attribute_6
for
free
eos
work
differently
than
transaction
in
component_1
but
provide
the
same
connector_data_10
in
the
end
it
can
be
turn
on
by
configuration
by
the
way
the
requirement_19
penalty
compare
to
at
least
once
semantics
be
not
big
typically
something
between
and
25%
slow
end
to
end
component_7
exactly
once
semantics
in
the
technology_2
ecosystem
technology_2
connector_2
technology_2
connector_3
technology_15
non
technology_11
component_24
eos
be
not
part
of
technology_2
core
and
the
relate
technology_11
technology_29
component_24
most
technology_2
component_9
support
exactly
once
delivery
guarantee
include
some
but
not
all
technology_2
connector_2
connector
for
example
technology_22
technology_23
and
elasticsearch
technology_2
connector_1
and
technology_15
to
component_7
connector_data_1
exactly
once
for
connector_9
technology_43
or
in
requirement_3
component_5
non
technology_11
component_24
librdkafka
‚Äì
the
core
foundation
of
many
technology_2
component_30
in
various
programming
technology_19
‚Äì
support
for
eos
recently
will
technology_2
replace
your
exist
component_1
in
general
no
but
you
should
always
ask
yourself
do
you
need
another
connector_data_1
component_8
in
addition
to
technology_2
sometimes
yes
sometimes
no
we
discus
the
characteristic
of
a
component_1
and
when
technology_2
be
sufficient
each
component_1
have
specific
feature
guarantee
and
query
option
use
technology_21
a
document
component_8
elasticsearch
for
text
search
technology_16
or
technology_20
for
traditional
relational
use
requirement_12
or
technology_4
for
a
requirement_2
lake
to
run
connector_data_11
reduce
for
report
this
hopefully
help
you
make
the
right
decision
for
your
next
project
however
hold
on
the
question
be
not
always
‚Äúkafka
vs
component_1
xyz‚Äù
often
technology_2
and
component_1
be
complementary
let‚Äôs
discus
this
in
the
follow
section‚Ä¶
technology_2
connector_2
‚Äì
requirement_8
between
technology_2
and
other
component_1
technology_1
technology_2
include
technology_2
connector_2
a
technology_13
for
connector_2
technology_2
with
external
component_14
such
a
component_1
key
requirement_13
component_8
search
index
and
component_11
use
technology_2
connector_2
you
can
use
exist
connector
implementation
for
common
connector_data_1
component_20
and
connector_17
to
move
connector_data_1
into
and
out
of
technology_2
this
include
many
connector
to
various
component_1
to
query
connector_data_1
from
a
component_33
component_11
can
either
be
connector_10
e
g
with
the
technology_47
connector
or
connector_11
via
chance
connector_data_1
capture
cdc
e
g
with
the
debezium
connector
technology_2
connector_2
can
also
connector_26
into
any
connector_17
connector_data_1
storage
include
various
relational
technology_5
and
requirement_2
infrastructure
technology_16
technology_21
technology_4
technology_48
or
technology_22
technology_23
confluent
hub
be
a
great
resource
to
find
the
quality_attribute_6
component_33
and
connector_17
connector
for
technology_2
connector_2
the
hub
include
open_source
connector
and
commercial
offer
from
different
vendor
to
more
about
technology_2
connector_2
you
might
want
to
connector_16
out
robin
moffat‚Äôs
he
have
connector_20
and
explain
ten
of
fantastic
example
leverage
technology_2
connector_2
to
quality_attribute_9
with
many
different
component_33
and
connector_17
component_1
technology_1
technology_2
be
a
component_1
with
acid
guarantee
but
complementary
to
other
component_1
technology_1
technology_2
be
a
component_1
it
provide
acid
guarantee
and
be
use
in
hundred
of
requirement_14
for
mission
critical
deployment
however
in
many
requirement_12
technology_2
be
not
competitive
to
other
component_1
technology_2
be
an
connector_9
component_18
for
connector_data_3
storage
component_7
and
requirement_8
at
quality_attribute_16
in
real
time
with
zero
downtime
and
zero
connector_data_1
loss
with
these
characteristic
technology_2
be
often
use
a
central
connector_9
requirement_8
pattern_20
materialize
pattern_13
can
be
build
by
other
component_1
for
their
specific
use
requirement_12
real
time
time
series
requirement_1
near
real
time
ingestion
into
a
text
search
infrastructure
or
long
term
storage
in
a
connector_data_1
lake
in
summary
if
you
connector_34
ask
if
technology_2
can
replace
a
component_1
then
here
be
different
answer
technology_2
can
component_8
connector_data_1
forever
in
a
quality_attribute_19
and
high
quality_attribute_6
manner
provide
acid
guarantee
different
option
to
query
historical
connector_data_1
be
quality_attribute_6
in
technology_2
technology_2
requirement_7
ons
technology_15
or
tiered
storage
make
technology_2
more
powerful
than
ever
before
for
connector_data_1
component_7
and
pattern_19
long
term
storage
stateful
component_13
can
be
build
leverage
technology_2
component_30
pattern_2
requirement_3
component_5
without
the
need
for
another
external
component_1
not
a
replacement
for
exist
component_1
technology_20
technology_21
elasticsearch
or
technology_4
other
component_1
and
technology_2
complement
each
other
the
right
solution
have
to
be
selected
for
a
problem
often
purpose
build
materialize
pattern_13
be
create
and
update
in
real
time
from
the
central
pattern_19
infrastructure
different
option
be
quality_attribute_6
for
pattern_4
directional
connector_10
and
connector_11
base
requirement_8
between
technology_2
and
component_1
to
complement
each
other
please
me
what
you
think
and
connector_2
on
linkedin‚Ä¶
stay
inform
about
by
subscribe
to
my
newsletter
total
connector_5
connector_6
tweet
pin
it
please
leave
this
emptydont‚Äò
miss
my
next
subscribe
we
don‚Äôt
spam
connector_4
more
in
our
privacy
requirement_21
connector_16
your
inbox
or
spam
folder
to
confirm
your
subscription
relate
tagsanalyticsapache
kafkabackupcdcchange
connector_data_1
capturecloudconfluentdata
lakedatabaseexactly
onceflashhadoophddhybrid
architectureintegrationkafkakafka
connectksqlksqldbmiddlewaremysqlnosqloraclepostgrespower
biprocessingqlikquerys3saassddsparksqlstoragestream
processingtableautiered
storagetransactionsxa
kai
waehner
build
requirement_6
requirement_7
connector_9
infrastructure
for
real
time
connector_data_1
component_7
and
requirement_1
leave
a
connector_data_12
cancel
replyyour
connector_31
will
not
be
publish
require
be
mark
*comment
*
name
*
*
connector_39
my
name
and
in
this
browser
for
the
next
time
i
pattern_13
you
also
technology_1
technology_2
+
technology_10
=
end
to
end
iot
requirement_8
slide
video
technology_1
technology_2
requirement_2
confluent
eai
internet
of
thing
technology_2
connector_2
pattern_1
pattern_2
technology_10
open_source
connector_3
component_7
bykai
waehner10
technology_10
and
technology_1
technology_2
be
a
perfect
combination
for
end
to
end
iot
requirement_8
from
edge
to
connector_data_1
center
this
discus
two
different
approach
and
refer
to
implementation
on
technology_49
use
technology_1
technology_2
technology_2
connector_2
confluent
technology_10
pattern_11
and
mosquitto
connector_4
more
connector_4
more
0k
views3
minute
connector_4
technology_1
technology_2
vs
technology_12
mq
technology_43
esb
‚Äì
slide
+
video
technology_1
technology_2
requirement_2
confluent
eai
esb
feature
in
memory
requirement_8
technology_2
connector_2
technology_2
connector_1
ksql
pattern_1
pattern_2
technology_12
open_source
pattern_3
connector_3
component_7
bykai
waehner7
this
connector_5
a
slide
deck
and
video
component_2
of
the
difference
between
an
pattern_23
connector_9
component_18
technology_1
technology_2
and
technology_12
connector_data_3
component_34
mq
extract
transform
load
technology_43
and
requirement_16
component_3
bus
esb
connector_4
more
technology_14
evangelist
kai
waehner
build
requirement_6
requirement_7
connector_9
infrastructure
for
real
time
connector_data_1
component_7
and
requirement_1
subscribe
to
my
newsletter
please
leave
this
empty
stay
inform
about
we
don‚Äôt
spam
connector_4
our
privacy
requirement_21
for
more
info
connector_16
your
inbox
or
spam
folder
to
confirm
your
subscription
end
to
end
requirement_8
feature
technology_1
technology_2
ksql
and
technology_1
plc4x
for
iiot
connector_data_1
requirement_8
and
component_7
technology_1
technology_2
vs
technology_12
mq
technology_43
esb
‚Äì
slide
+
video
deep
example
technology_1
technology_2
+
technology_6
+
kera
+
technology_7
+
technology_50
categoriescategories
select
category
5g
technology_51
gap
airline
airport
allgemein
msk
requirement_1
technology_1
technology_52
technology_1
technology_2
technology_1
mesos
technology_1
technology_53
technology_1
technology_3
component_4
component_4
gateway
component_4
requirement_9
component_5
component_6
architecture
ariba
asset
track
audio
augment
reality
automation
requirement_15
automotive
aviation
technology_22
technology_22
outpost
technology_22
wavelength
technology_54
bank
technology_55
bet
requirement_2
biotech
biotechnology
bitcoin
blockchain
bookmaker
bpm
b
requirement_3
intelligence
requirement_22
citizen
requirement_6
requirement_6
requirement_7
technology_56
comparison
concur
condition
pattern_21
confluent
confluent
requirement_6
connector_40
car
connector_40
vehicle
conversational
requirement_23
core
bank
crm
crypto
cryptocurrency
cybersecurity
connector_data_1
at
rest
connector_data_1
historian
connector_data_1
hub
connector_data_1
in
motion
connector_data_1
requirement_8
connector_data_1
lake
connector_data_1
mesh
connector_data_1
science
connector_data_1
connector_9
connector_data_1
requirement_24
component_1
databricks
deep
defi
digital
forensics
digital
twin
disaster
recovery
quality_attribute_7
ledger
technology_8
domain
drive
design
eai
edge
edge
computing
eipaas
elasticsearch
elt
energy
requirement_16
architecture
erp
esb
ethereum
technology_43
connector_9
exactly
once
semantics
feature
finance
requirement_15
food
forensics
fraud
fraud
detection
gamble
game
gaming
gcp
technology_57
government
technology_4
healthcare
hivecell
technology_42
hybrid
requirement_6
hyperledger
mq
idoc
iiot
in
memory
industrial
iot
requirement_15
insurance
insurance
requirement_15
requirement_8
internet
of
thing
intrusion
detection
inventory
requirement_9
iota
ipaas
it
certification
it
conference
technology_11
jee
technology_58
jupyter
technology_2
connector_2
technology_2
connector_1
kappa
architecture
ksql
technology_15
technology_9
lake
house
lambda
architecture
large
connector_data_6
component_35
libra
life
science
live
commerce
logistics
requirement_4
component_36
vision
component_37
manufacture
connector_data_3
component_19
pattern_1
pattern_2
technology_12
military
mining
quality_attribute_20
component_38
technology_10
national
quality_attribute_21
nft
nlp
technology_5
oil
and
gas
omnichannel
opc
ua
open
component_4
open
bank
open_source
technology_16
osisoft
technology_59
o
ott
over
the
top
payment
persistence
pharma
plc4x
predictive
quality_attribute_12
sector
technology_6
qcon
qualitrics
technology_25
ransomware
recommendation
redpanda
pattern_10
retail
reverse
technology_43
ripple
rtls
sale
technology_60
technology_60
technology_61
scm
quality_attribute_21
serverless
component_3
mesh
siem
situational
awareness
smart
build
smart
city
smart
grid
pattern_3
technology_62
soar
social
requirement_5
sparkplug
splunk
connector_3
component_7
connector_9
requirement_1
supply
chain
telco
telecom
telecommunication
requirement_15
technology_7
threat
detection
threat
intelligence
tiered
storage
transaction
transportation
trend
uncategorized
use
requirement_12
v2x
video
video
connector_9
virtual
reality
web
technology_13
web
component_3
web3
technology_63
connector_data_13
zero
trust
tag
‚Äì
cloudanalytics
technology_1
technology_1
technology_52
technology_1
technology_2
technology_22
requirement_2
businessworks
requirement_6
requirement_6
requirement_7
confluent
deep
technology_8
eai
edge
requirement_16
component_5
requirement_8
requirement_16
component_3
bus
esb
connector_9
technology_4
hybrid
iiot
requirement_8
iot
j2ee
technology_11
jee
technology_2
technology_2
connector_2
technology_2
connector_1
ksql
technology_9
requirement_4
pattern_2
technology_12
technology_10
open_source
technology_16
real
time
pattern_3
streambase
connector_9
requirement_1
connector_3
component_7
talend
technology_64
connector_4
more
views4
minute
connector_4
technology_1
technology_2
biotechnology
healthcare
omnichannel
open
component_4
pharma
open
component_4
and
omnichannel
with
technology_1
technology_2
in
healthcare
bykai
waehner18
connector_4
more
views19
minute
connector_4
msk
technology_1
technology_2
technology_1
technology_53
technology_56
comparison
confluent
requirement_6
mq
technology_58
technology_25
redpanda
comparison
technology_58
connector_data_3
component_19
vs
technology_1
technology_2
bykai
waehner12
connector_4
more
views5
minute
connector_4
technology_1
technology_2
bitcoin
blockchain
cryptocurrency
cybersecurity
connector_data_1
connector_9
ethereum
fraud
detection
technology_1
technology_2
in
crypto
and
finserv
for
cybersecurity
and
fraud
detection
bykai
waehner29
connector_4
more
views4
minute
connector_4
technology_1
technology_2
biotech
confluent
requirement_6
connector_data_1
science
connector_data_1
connector_9
healthcare
insurance
technology_2
connector_1
life
science
requirement_4
requirement_4
and
connector_data_1
science
with
technology_2
in
healthcare
bykai
waehner18
¬©
kai
waehner
|
imprint
|
connector_data_1
privacy
by
continue
to
use
the
you
agree
to
the
use
of
more
connector_data_8
acceptthe
set
on
this
be
set
to
allow
to
give
you
the
best
browse
experience
possible
if
you
continue
to
use
this
without
connector_30
your
set
or
you
click
connector_41
below
then
you
be
to
this
close
