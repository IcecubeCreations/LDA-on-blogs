evaluate
persistent
replicate
connector_data_1
component_1
servicesservices
component_2
backend
development
technology_1
development
technology_2
technology_3
development
requirement_1
component_2
blockchain
development
private
blockchain
for
requirement_2
requirement_3
solution
frontend
development
softwaremill
academy
internet
of
thing
industriesindustries
fintech
healthcare

and
enterteinment
education
telecommunication
how
we
workhow
we
work
how
we
work
faq
our
story
portfolioportfolio
component_3
project
open_source
our
technology_4
technology_5
visualisation
technology_6
companycompany
team
about
u
remote
technology_7
join
usjoin
u
join
the
team
handbook
for
requirement_4
show
your
devskin
blogblog

connector_data_2
time
news
technology_8
technology_5
ebook
remote
development
ebook
audit
whitepaper
hire
u
content
evaluate
persistent
replicate
connector_data_1
queueskafkaperformancepostgresqlmongodbredispulsarmessage
queuemessagingclusteringevent
streamingnatssqseventstorerocketmqsplit
brainrabbitmqactivemqredpandamqperfadam
warski26
jul


minute
readintroductionmessage
component_1
be
central
to
many
quality_attribute_1
component_4
and
often
provide
a
technology_9
for
pattern_1
component_5
and
connector_1
between
micro
component_6
they
be
useful
in
a
number
of
situation
any
time
we
want
to
connector_2
a
connector_data_3
asynchronously
we
put
the
connector_data_3
on
a
component_7
some
executor
could
be
another
component_8
component_5
or
component_9
eventually
run
it
or
one
component_10
might
produce
a
connector_3
of
that
be
component_11
by
the
connector_data_1
component_7
other
decouple
component_10
connector_4
the
asynchronously
either
on
line
or
after
some
period
of
time
various
connector_data_1
component_7
implementation
can
give
various
guarantee
on
connector_data_1
persistence
and
delivery
for
some
use
requirement_5
it
be
enough
to
have
an
in
memory
volatile
connector_data_1
component_7
for
others
we
want
to
be
sure
that
once
the
connector_data_1
connector_5
complete
the
connector_data_1
be
persistently
enqueued
and
will
be
eventually
connector_6
despite
technology_10
or
component_12
crash
the
mqperf
test
inspect
component_4
on
the
quality_attribute_2
side
of
this
spectrum
which
try
to
make
sure
that
connector_data_4
be
not
lose
by
persist
connector_data_4
to
diskreplicating
connector_data_4
across
the
networkwe
will
examine
the
characteristic
of
a
number
of
connector_data_1
component_7
and
connector_data_2
connector_7
component_12
compare
their
feature
pattern_2
technology_11
support
technology_12
operational
complexity
and
requirement_6
all
of
these
factor
might
impact
which
component_12
be
best
suit
for
a
give
connector_data_3
in
some
requirement_5
you
might
need
top
requirement_6
which
might
come
with
tradeoff
in
term
of
other
feature
in
others
requirement_6
isn’t
the
factor
but
instead
quality_attribute_3
with
exist
technology_12
connector_data_1
connector_8
capability
or
deployment
overhead
play
the
central
role
when
talk
about
requirement_6
we’ll
take
into
account
both
how
many
connector_data_4
per
second
a
give
component_7
component_12
can
component_5
but
also
at
the
component_5
quality_attribute_4
which
be
an
important
factor
in
component_4
which
should
technology_13
to
connector_data_2
in
near
real
time
a
be
often
the
requirement_5
with
various
connector_3
another
important
aspect
be
connector_data_1
connector_5
quality_attribute_4
that
be
how
long
it
take
for
a
component_3
to
be
sure
a
connector_data_1
be
persist
in
the
component_7
component_12
this
directly
impact
e
g
the
quality_attribute_4
of
technology_14
and
end
user_experienceversion
history26
jul

refresh
of
the

edition
test
of
redpanda
and
technology_15
connector_3

pattern_3
and
compression
info
to
the
summary
co
author
with
bartłomiej
turos
and
robert
dziewoński

dec


edition
extend
feature
comparison
update
benchmark
component_1
technology_16
technology_17
nats
connector_3
drop
technology_18

in
favor
of
technology_18
artemis
co
author
with
kasper
kondzielski

2017updated
the
connector_data_5
for
artemis
use
memory
connector_data_6
journal
type
and
improve
technology_19
test
client18

edition
update
with
version

quality_attribute_4
measurement

artemis
and
eventstore
co
author
with
maciej
opała4

edition
update
with
version

technology_20
site1
2014original
at
adam
warski
s
blogtested
queuesthere
be
a
number
of
open
component_13
pattern_4
project
quality_attribute_5
but
only
some
support
both
persistence
and
pattern_2
we
ll
evaluate
the
requirement_6
and
characteristic
of

connector_data_1
component_7
in
no
particular
order

sqsmongodbpostgresqlrabbitmqkafkapulsaractivemq
artemisrocketmqnats
streamingeventstoreredpandaredis
streamsyou
might
rightfully
notice
that
not
all
of
these
be
connector_data_1
component_7
component_12
both
technology_21
and
technology_17
and
to
some
degree
eventstore
be
general
purpose
component_14
however
use
some
of
their
mechanism
it’s
possible
to
connector_9
a
connector_data_1
component_7
on
top
of
them
if
such
a
quality_attribute_6
component_7
meet
the
requirement
and
the
component_14
component_12
be
already
quality_attribute_7
for
other
purpose
it
might
be
reasonable
to
quality_attribute_8
it
and
reduce
operational
cost
except
for
sqs
all
of
the
component_4
be
open
component_13
and
can
be
self
component_15
on
your
own
component_16
or
use
any
of
the
requirement_7
technology_22
both
directly
or
through
technology_23
some
component_4
be
also
quality_attribute_5
a
component_15
a
a
component_6
offer
component_7
characteristicswe’ll
be
test
and
examine
the
requirement_6
of
a
single
specific
component_7
usage
scenario
in
detail
a
well
a
discuss
other
possible
component_7
specific
use
requirement_5
more
generally
in
our
scenario
a
mention
in
the
introduction
we’ll
put
a
focus
on
quality_attribute_9
the
scenario
try
to
reflect
a
reasonable
default
that
you
might
start
with
when
develop
component_17
leverage
a
connector_data_1
component_7
however
by
definition
we’ll
cover
only
a
fraction
of
possible
use
requirement_5
there
be
three
basic
on
a
component_7
which
we
ll
be
use
connector_5
a
connector_data_1
to
the
queuereceiving
a
connector_data_1
from
the
queueacknowledging
that
a
connector_data_1
have
be
processedon
the
sender
side
we
want
to
have
a
guarantee
that
if
a
connector_data_1
connector_5
connector_data_7
complete
successfully
the
connector_data_1
will
be
eventually
component_5
of

we
will
never
connector_10
a
100%
guarantee
so
we
have
to
connector_11
some
scenario
in
which
connector_data_4
will
be
lose
such
a
a
catastrophic
failure
destroy
all
of
our
geographically
quality_attribute_1
component_18
still
we
want
to
minimise
connector_data_1
loss
that
s
why
connector_data_1
should
survive
a
restart
of
the
component_18
that
be
connector_data_4
should
be
persist
to
a
quality_attribute_10
component_11
hard
disk
however
we
connector_11
lose
connector_data_4
due
to
unflushed
disk
buffer
we
do
not
require
fsyncs
to
be
do
for
each
connector_data_1
connector_data_1
should
survive
a
permanent
failure
of
a
component_18
that
be
connector_data_4
should
be
replicate
to
other
component_18
we
ll
be
mostly
interest
in
pattern_5
pattern_2
that
be
when
the
connector_5
connector_data_7
can
only
complete
after
the
connector_data_2
be
replicate
note
that
this
additionally
protect
from
connector_data_1
loss
due
to
hard
disk
buffer
not
be
flush
some
component_4
also
offer
pattern_1
pattern_2
where
connector_data_4
be
connector_11
before
be
replicate
and
thus
there
s
more
potential
for
connector_data_1
loss
we
ll
make
it
clear
late
which
component_4
offer
what
kind
of
pattern_2
on
the
receiver
side
we
want
to
be
able
to
connector_12
a
connector_data_1
and
then
acknowledge
that
the
connector_data_1
be
component_5
successfully
note
that
connector_13
alone
should
not
remove
the
connector_data_1
from
the
component_7
a
the
receiver
crash
at
any
time
include
right
after
connector_12
before
component_5
but
that
could
also
lead
to
connector_data_4
be
component_5
twice
e
g
if
the
receiver
crash
after
component_5
before
acknowledge
hence
our
component_7
should
support
at
least
once
delivery
with
at
least
once
delivery
connector_data_1
component_5
should
be
idempotent
that
be
component_5
a
connector_data_1
twice
shouldn
t
cause
any
problem
once
we
assume
that
characteristic
a
lot
of
thing
be
simplify
connector_data_1
acknowledgment
can
be
do
asynchronously
a
no
harm
be
do
if
an
ack
be
lose
and
the
connector_data_1
re
connector_6
we
also

t
have
to
worry
about
quality_attribute_1
transaction
in
fact
no
component_12
can
provide
exactly
once
delivery
when
quality_attribute_11
with
external
component_4
and
if
it
claim
otherwise
connector_14
the
fine

it
s
always
a
choice
between
at
most
once
and
at
least
once
by
require
idempotent
component_5
the
life
of
the
connector_data_1
pattern_6
be
easy
however
the
cost
be
shift
to
connector_15
component_19
appropriately
requirement_6
test
methodologywe
ll
be
perform
three
measurement
during
the
test
quality_attribute_12
in
connector_data_1
second
how
fast
on
average
the
component_7
be
that
be
how
many
connector_data_4
per
second
can
be
connector_5
and
how
many
connector_data_4
per
second
can
be
connector_16
&
acknowledged95th
percentile
of
component_5
quality_attribute_4
over
a

minute
window
how
much
time
in
millisecond
pass
between
a
connector_data_1
connector_5
and
a
connector_data_1
connector_12
that
be
how
fast
the
pattern_6
pass
the
connector_data_1
from
the
sender
to
the
receiver95th
percentile
of
connector_5
quality_attribute_4
over
a

minute
window
how
long
it
take
for
a
connector_data_1
connector_5
to
complete
that
s
when
we
be
sure
that
the
connector_data_1
be
safely
persist
in
the
cluster
and
can
e
g
respond
to
our
component_3
s
technology_14
connector_data_8
connector_data_1
connector_12
when
set
up
the
component_7
our
goal
be
to
have

identical
replicate
technology_10
run
the
connector_data_1
component_7
component_18
with
automatic
fail
over
that’s
not
always
possible
with
every
component_7
implementation
hence
we’ll
make
it
explicit
what’s
the
pattern_2
setup
in
each
requirement_5
the
component_20
for
the
test
a
well
a
the
technology_24
script
use
to
setup
the
component_1
be
quality_attribute_5
on
technology_25
each
test
run
be
parametrised
by
the
type
of
the
connector_data_1
component_7
test
optional
connector_data_1
component_7
parameter
number
of
component_3
technology_10
number
of
component_21
on
each
component_3
technology_10
and
connector_data_1
count
a
component_3
technology_10
be
either
connector_17
or
connector_13
connector_data_1
in
the
test
we
use
from

to

component_3
technology_10
of
each
type
each
run
from

to

component_8
by
default
there
be
twice
a
many
receiver
technology_10
a
sender
technology_10
but
that’s
not
a
strict
rule
and
we’re
modify
these
proportion
base
on
what’s
work
best
for
a
give
component_7
implementation
each
sender
component_8
try
to
connector_5
the
give
number
of
connector_data_4
a
fast
a
possible
in
pattern_7
of
random
size
between

and

connector_data_1
the
connector_data_4
be
pick
from
a
pool
of
connector_data_1
randomly
generate
on
startup
the
receiver
try
to
connector_12
connector_data_4
also
in
pattern_7
of
up
to

connector_data_1
and
after
connector_13
them
acknowledge
their
delivery
which
should
cause
the
connector_data_1
to
be
remove
from
the
component_7
the
test
end
when
no
connector_data_4
be
connector_16
for
a
minute
the
component_1
have
to
connector_9
the
mq

the
should
have
the
follow
characteristic
connector_5
should
be
pattern_5
that
be
when
it
complete
we
want
to
be
sure
what
sure
mean
exactly
vary
that
the
connector_data_4
be
sentreceive
should
connector_12
connector_data_4
from
the
component_7
and
block
them
from
be
connector_16
by
other
component_3
if
the
technology_10
crash
the
connector_data_4
should
be

to
the
component_7
and
re
connector_6
either
immediately
or
after
a
time
outack
should
acknowledge
delivery
and
component_5
of
the
connector_data_1
acknowledgment
can
be
pattern_1
that
be
we

t
have
to
be
sure
that
the
connector_data_4
really
connector_10
deletedserver
setupboth
the
component_3
and
the
pattern_4
component_16
use
r5
2xlarge
memory
optimize
technology_26
instance
each
such
instance
have

virtual
cpu
64gib
of
ram
and
ssd
storage
in
some
requirement_5
additional
gp2
disk
where
use
all
instance
be
start
in
a
single
quality_attribute_13
zone
eu
west

while
for
production
deployment
it
be
certainly
quality_attribute_14
to
have
the
replica
quality_attribute_1
across
different
location
in
technology_26
terminology
different
quality_attribute_13
zone
but
a
the
aim
of
the
test
be
to
measure
requirement_6
a
single
quality_attribute_13
zone
be
use
to
minimise
the
effect
of
requirement_8
quality_attribute_4
a
much
a
possible
the
component_16
be
provision
automatically
use
technology_24
all
of
the
technology_27
be
quality_attribute_5
in
the
technology_25
pattern_8
hence
the
test
should
be
reproducible
test
connector_data_5
be
aggregate
use
prometheus
and
visualize
use
grafana
we
ll
see
some
requirement_9
snapshot
with
specific
connector_data_5
late
while
the
above
might
not
guarantee
the
best
possible
requirement_6
for
each
component_7
we
might
have
use
r5
24xlarge
for
example
the
goal
be
to
connector_10
some
common
grind
for
comparison
between
the
various
component_12
hence
the
connector_data_5
should
be
treat
only
comparatively
and
the
test
should
always
be
repeat
in
the
target
environment
before
make
any
decision
mongodbversionserver


technology_1
driver


5replicationconfigurable
pattern_1
&
synchronousreplication
typeactive
passivemongo
have
two
feature
which
make
it
possible
to
easily
connector_9
a
quality_attribute_10
replicate
connector_data_1
component_7
on
top
of
it
very
quality_attribute_6
pattern_2
setup
we
ll
be
use
a

technology_10
replica
set
and
various
document
level
atomic

find
and
modify
the
implementation
be
a
handful
of
line
of

take
a
look
at
mongomq
pattern_2
in
mongo
follow
a
leader
follower
setup
that
be
there’s
a
single
technology_10
handle
connector_18
which
connector_10
replicate
to
follower
technology_10
a
an
optimization
connector_19
can
be
offload
to
follower
but
we
won’t
be
use
this
feature
here
horizontal
quality_attribute_15
be
possible
by
sharding
and
use
multiple
replica
set
but
a
far
a
connector_data_1
component_7
be
concern
this
would
make
the
component_7
implementation
significantly
more
complex
hence
this
component_7
implementation
be
bind
by
the
capacity
of
the
leader
technology_10
requirement_8
component_22
split
brain
scenario
which
be
one
of
the
most
dangerous
fault
type
in
replicate
component_14
be
handle
by
make
sure
that
only
the
component_22
with
the
majority
of
technology_10
be
operational
we
be
able
to
control
the
guarantee
which
connector_5
give
u
by
use
an
appropriate
connector_18
concern
when
connector_15
connector_data_1
writeconcern
w1
ensure
that
once
a
connector_5
complete
the
connector_data_4
have
be
connector_18
to
disk
but
the
buffer
not
be
yet
flush
so
it
s
not
a
100%
guarantee
on
a
single
technology_10
this
correspond
to
pattern_1
replicationwriteconcern
w2
ensure
that
a
connector_data_1
be
connector_18
to
at
least

technology_10
a
we
have

technology_10
in
total
that
s
a
majority
in
the
cluster
this
correspond
to
pattern_5
replicationthe
downside
of
the
mongo
base
component_7
be
that
connector_data_1
can
t
be
connector_16
in
bulk
–
the
find
and
modify
only
work
on
a
single
document
at
a
timewhen
there
s
a
lot
of
connector_20
try
to
connector_12
connector_data_1
the
collection
will
encounter
a
lot
of
contention
and
all
be
serialise
and
this
show
in
the
connector_data_9
connector_21
be
much
fast
than
connector_12
but
the
requirement_6
isn’t
bad
despite
this
a
single
component_8
single
technology_10
pattern_5
pattern_2
setup
achieve

msg
s
connector_22
and
connector_12
the
maximum
connector_5
quality_attribute_12
with
multiple
component_8
technology_10
that
we
be
able
to
achieve
be
about


msg
s

component_8

technology_10
while
the
maximum
connector_12
rate
be


msg
s

component_8

technology_10
an
interest
thing
to
note
be
that
the
connector_12
quality_attribute_12
quickly
achieve
it
maximum
requirement_10
and

more
component_21
component_3
only
decrease
requirement_6
the
more
pattern_9
the
lower
overall
quality_attribute_12
with
pattern_1
pattern_2
the
connector_data_5
be
of
quality_attribute_14
up
to


msg
s
connector_22
and


msg
s
connector_12
a
you
can
see
here
the
difference
between
connector_5
and
connector_12
requirement_6
be
even
big
what
about
quality_attribute_4
in
both
pattern_5
and
pattern_1
test
the
connector_5
quality_attribute_4
be
about

m
and
this
doesn
t
deteriorate
when

more
concurrent
component_3
a
for
the
component_5
quality_attribute_4
measurement
only
make
sense
when
the
connector_12
rate
be
the
same
a
the
connector_17
rate
when
the
component_23
aren
t
able
to
connector_12
connector_data_4
a
fast
a
they
be
connector_5
the
component_5
time
go
arbitrarily
up
with

technology_10
run

component_21
each
mongo
achieve
a
quality_attribute_12
of


msg
s
with
a
component_5
quality_attribute_4
of

m
anything
above
that
cause
connector_23
to
fall
back
behind
connector_5
here
s
the
requirement_9
for
that
test
requirement_6
connector_data_5
in
detail
when
use
pattern_5
pattern_2
be
a
follow
threadssender
nodesreceiver
nodessend
msg
sreceive
msg
sprocessing
latencysend
latency112958

































00overall
if
you
be
already
use
mongo
in
your
component_19
you
have
small
traffic
and
don’t
need
to
use
any
of
the
more
advance
pattern_4
technology_12
or
feature
a
component_7
implementation
on
top
of
mongo
might
work
fine
postgresqlversionserver


technology_1
driver


12replicationconfigurable
pattern_1
&
synchronousreplication
typeactive
passivewhen
connector_24
a
component_7
on
top
of
technology_17
we
be
use
a
single
component_24
create
component_24
if
not
exist

uuid
primary
key
content
text
not

next_delivery
timestamptz
not

connector_5
a
connector_data_1
amount
to
insert
connector_data_2
to
the
component_24
connector_13
a
connector_data_1
bump
the
next
delivery
pattern_10
make
the
connector_data_1
invisible
for
other
receiver
for
some
period
of
time
during
which
we
assume
that
the
connector_data_1
should
be
component_5
or
be
otherwise
redelivered
this
be
similar
to
how
technology_28
work
which
be
discuss
next
acknowledge
a
connector_data_1
amount
to
delete
the
connector_data_1
from
the
component_14
when
connector_13
connector_data_1
we
issue
two
connector_25
in
a
single
transaction
the
first
look
up
the
connector_data_4
to
connector_12
and
put
a
connector_18
lock
on
them
the
second
connector_data_10
the
next
delivery
pattern_10
select

content
from
where
next_delivery
=
$now
for
update
skip
lock
limit
n
update
set
next_delivery
=
$nextdelivery
where
in
thanks
to
transactionality
we
make
sure
that
a
single
connector_data_1
be
connector_16
by
a
single
receiver
at
any
time
use
connector_18
lock
for
update
and
skip
lock
help
improve
the
requirement_6
by
allow
multiple
component_23
to
connector_12
connector_data_4
concurrently
try
to
minimise
contention
a
with
other
pattern_4
component_12
we
replicate
connector_data_2
technology_17
us
leader
follower
pattern_2
by
set
the
follow
configuration
option
a
describe
in
a
by
kasper
synchronous_standby_names
be
set
to
any

slave1
slave2
synchronous_commit
be
set
to
remote_writeit’s
also
possible
to
configure
pattern_1
pattern_2
a
well
a
require
an
fsync
after
each
connector_18
however
an
important
limitation
of
technology_17
be
that
by
default
there’s
no
automatic
failover
in
requirement_5
the
leader
fail
one
of
the
follower
must
be
promote
by
hand
which
in
a
way
solve
the
split
brain
problem
there
be
however
both
open
component_13
and
commercial
solution
which
provide
for
automatic
failover
in
term
of
requirement_6
a
baseline
single
component_8
setup
achieve
around


msg
s
connector_22
and
connector_12
such
a
component_7
can
handle
at
most


msg
s
connector_22
and
connector_16
use

component_21
on

connector_17
and

connector_13
technology_10
increasing
pattern_9
above
that
cause
connector_12
requirement_6
to
degrade
connector_5
quality_attribute_4
be
usually
at
48ms
however
total
component_5
quality_attribute_4
be
quite
poor
a
with
mongo
take
into
account
only
the
test
where
the
connector_5
quality_attribute_12
be
on
par
with
connector_12
quality_attribute_12
component_5
quality_attribute_4
vary
from

m
to


m
here
be
the
connector_data_5
in
full
threadssender
nodesreceiver
nodessend
msg
sreceive
msg
sprocessing
latencysend
latency1124





















































00same
a
with
technology_21
if
you
require
a
very
basic
connector_data_1
component_7
implementation
without
a
lot
of
traffic
and
already
have
a
replicate
technology_17
instance
in
your
deployment
such
an
implementation
might
be
a
quality_attribute_14
choice
thing
to
look
out
for
in
this
requirement_5
be
long
component_5
quality_attribute_4
and
manual
failover
unless
third
party
extension
be
use

storeversion20


technology_29
component_3


0replicationsynchronousreplication
typeactive
passiveeventstore
be
first
and
foremost
a
component_14
for
component_13
and
complex
component_5
however
it
also
support
the
compete
component_25
pattern_11
or
a
we
it
connector_data_1
component_7
how
do
it
technology_30
up
compare
to
other
connector_data_1
pattern_6
eventstore
offer
a
lot
in
term
of
create
connector_3
subscribe
to
them
and
transform
through
projection
in
the
test
we
ll
only
be
connector_15
to
a
connector_3
each
connector_data_1
will
become
an

and
create
persistent
subscription
that
be
subscription
where
the
consumption
state
be
component_11
on
the
component_18
to
connector_14
on
the
component_3
you
can
connector_14
more
about
component_13
compete
component_25
and
subscription
type
in
the
doc
to
safely
replicate
connector_data_2
eventstore
us
quorum
base
pattern_2
use
a
gossip
technology_12
to
disseminate
knowledge
about
the
cluster
state
a
majority
of
technology_10
have
to
confirm
every
connector_18
for
it
to
be
consider
successful
that’s
also
how
quality_attribute_16
against
split
brain
be
connector_9
a
all
of
the
test
be
technology_29
base
we
ll
be
use
the
technology_29
component_3
which
be
build
on
top
of
technology_3
and
hence
fully
non
block
however
the
test
technology_31
be
pattern_5
because
of
that
the
eventstoremq
implementation
hide
the
pattern_1
nature
behind
pattern_5
sender
and
receiver

even
though
the
test
will
be
use
multiple
component_8
all
of
them
will
be
use
only
one
connector_20
to
eventstore
per
technology_10
compare
to
the
default
configuration
the
component_3
have
a
few
modify
option
readbatchsize
historybuffersize
and
maxcheckpointsize
be
all
bump
to

to
allow
more
connector_data_4
to
be
pre
fetchedthe
in
flight
connector_data_4
buffer
size
be
increase
from
the
default

to
a

a
this
be
by
default
not
quality_attribute_17
in
the
technology_29
component_3
we
have
to
copy
some
from
the
driver
and
adjust
the
property
see
the
mypersistentsubscriptionactor

how
do
eventstore
perform
a
baseline
setup
achieve

msg
s
and
when
use

sender
with

component_8
and

receiver
technology_10
in
the
test
we
have
achieve
a
quality_attribute_12
of


msg
s
with
the
95th
percentile
of
component_5
quality_attribute_4
be
at
most

m
and
the
connector_5
quality_attribute_4

m
connector_12
rat
be
quality_attribute_18
a
be
the
quality_attribute_4
here
s
a
summary
of
the
eventstore
test
that
we
ve
run
threadssender
nodesreceiver
nodessend
msg
sreceive
msg
sprocessing
latencysend
latency112793



























00eventstore
also
provide
a
handy
web
console
compare
to
the
other
general
purpose
component_14
technology_17
and
technology_21
eventstore
offer
the
best
requirement_6
but
it’s
also
the
most
specialise
orient
towards
work
with
connector_26
in
the
first
place
sqsversionamazon
technology_1
technology_32


797replication
pattern_2
type
sqs
quality_attribute_6
connector_data_1
component_7
be
a
connector_data_1
component_7
a
a
component_6
offer
from
web
component_6
it
support
only
a
handful
of
pattern_4

far
from
the
complexity
of
e
g
technology_33
but
thanks
to
the
easy
to
understand

and
the
a
a
component_6
nature
it
be
very
useful
in
a
number
of
situation
the
primary
to
connector_27
technology_28
and
connector_5
connector_data_4
be
use
an
sqs
specific
technology_14
technology_34
technology_28
provide
at
least
once
delivery
it
also
guarantee
that
if
a
connector_5
complete
the
connector_data_1
be
replicate
to
multiple
technology_10
quote
from
the


technology_28
run
within

s
high
quality_attribute_13
connector_data_2
center
so
component_1
will
be
quality_attribute_5
whenever
component_17
need
them
to
prevent
connector_data_4
from
be
lose
or
become
unavailable
all
connector_data_4
be
component_11
redundantly
across
multiple
component_16
and
connector_data_2
center
when
connector_13
a
connector_data_1
it
be
block
from
other
receiver
for
a
period
of
time
connector_28
the
visibility
timeout
if
the
connector_data_1
isn’t
delete
acknowledge
before
that
time
pass
it
will
be
re
connector_6
a
the
component_12
assume
that
previous
component_5
have
fail
technology_28
also
offer
feature
such
a
deduplication

and
pattern_12
component_7
for
test
the
elasticmq
project
offer
an
in
memory
implementation
we

t
really
how
technology_28
be
connector_9
but
it
most
probably
spread
the
load
across
many
component_18
so
include
it
here
be
a
bit
of
an
unfair
competition
the
other
component_4
use
a
single
fix

technology_10
replicate
cluster
while
technology_28
can
employ
multiple
replicate
cluster
and
connector_29
balance
the
connector_data_4
between
them
still
it
might
be
interest
to
compare
to
self
component_15
solution
a
baseline
single
component_8
setup
achieve

msg
s
connector_22
and
the
same
number
of
msg
connector_12
with
a
component_5
quality_attribute_4
of

m
and
connector_5
quality_attribute_4
of

m
these
connector_data_5
be
not
impressive
but
technology_28
quality_attribute_19
nicely
both
when
increasing
the
number
of
component_8
and
the
number
of
technology_10
on
a
single
technology_10
with

component_8
we
can
connector_5
up
to


msg
s
and
connector_12
on
two
technology_10
up
to


msg
s
with

sender
and

receiver
technology_10
these
number
go
up
to


msg
s
connector_5
and


msg
s
connector_12
however
at
these
connector_data_1
rat
the
component_6
cost
might
outweigh
the
cost
of
set
up
a
self
component_15
connector_data_1
pattern_6
a
for
quality_attribute_4
technology_28
can
be
quite
unpredictable
compare
to
other
component_1
which
we’ll
cover
late
we
ve
observe
component_5
quality_attribute_4
from

m
up
to


m
connector_5
quality_attribute_4
be
more
constrain
and
be
usually
around

m
here
s
the
requirement_9
for
the
test
use

technology_10
each
run

component_8
and
full
test
connector_data_9
threadssender
nodesreceiver
nodessend
msg
sreceive
msg
sprocessing
latencysend
latency112528































































































00rabbitmqversion3



technology_1
technology_33
component_3


0replicationsynchronousreplication
typeactive
passiverabbitmq
be
one
of
the
lead
open
component_13
pattern_4
component_12
it
be
connector_18
in
technology_35
connector_30
technology_36
and
be
a
very
popular
choice
when
pattern_4
be
involve
use
technology_37
it
be
possible
to
define
complex
connector_data_1
delivery
topology
it
support
both
connector_data_1
persistence
and
pattern_2
we
ll
be
test
a

technology_10
rabbit
cluster
use
quorum
component_7
which
be
a
relatively
addition
to
what
technology_37
offer
quorum
component_1
be
base
on
the
raft
consensus
algorithm
a
leader
be
automatically
elect
in
requirement_5
of
technology_10
failure
a
long
a
a
majority
of
technology_10
be
quality_attribute_5
that
way
connector_data_2
be
quality_attribute_2
also
in
requirement_5
of
requirement_8
component_22
to
be
sure
that
connector_21
complete
successfully
we
ll
be
use
pattern_13
confirm
a
rabbit
extension
to
technology_33
instead
of
transaction
use
technology_38
technology_36



the
only
way
to
guarantee
that
a
connector_data_1
isn
t
lose
be
by
use
transaction
make
the
pattern_14
pattern_15
publish
the
connector_data_1
connector_31
in
this
requirement_5
transaction
be
unnecessarily
heavyweight
and
decrease
quality_attribute_12
by
a
factor
of

to
remedy
this
a
confirmation
mechanism
be
introduce
a
connector_data_1
be
confirm
after
it
have
be
replicate
to
a
majority
of
technology_10
this
be
where
raft
be
use
moreover
connector_data_4
have
to
be
connector_18
to
disk
and
fsynced
such
strong
guarantee
be
probably
one
of
the
reason
for
mediocre
requirement_6
a
basic
single
component_8
setup
achieve
around


msg
s
sent&received
with
a
component_5
quality_attribute_4
of


m
and
connector_5
quality_attribute_4
of

m
the
component_7
can
be
quality_attribute_19
up
to


msg
s
use

component_8

sender
technology_10
and

receiver
technology_10
threadssender
nodesreceiver
nodessend
msg
sreceive
msg
sprocessing
latencysend
latency1122























































00let’s
take
a
close
look
at
the
test
which
achieve
high
requirement_6
a
you
can
see
the
connector_12
rate
connector_5
and
component_5
quality_attribute_4
be
quite
quality_attribute_18
which
be
also
an
important
characteristic
to
examine
under
load
the
component_5
quality_attribute_4
be
around

m
while
the
connector_5
quality_attribute_4
in
this
requirement_5
be

m
note
that
connector_data_4
be
always
connector_22
and
connector_16
at
the
same
rate
which
would
indicate
that
connector_data_1
connector_17
be
the
limit
factor
when
it
come
to
quality_attribute_12
rabbit
s
requirement_6
be
a
consequence
of
some
of
the
feature
it
offer
for
a
comparison
with
technology_5
see
for
example
this
quora
question
the
technology_37
implementation
of
the
mq
be
again
pretty
straightforward
we
be
use
the
mention
pattern_13
confirm
and
set
the
quality
of
component_6
when
connector_13
so
that
at
most

connector_data_4
be
connector_6
unconfirmed
in
flight
an
important
side
technology_10
technology_37
have
a
great
web
base
console
quality_attribute_5
with
almost
no
setup
which
offer
some
very
quality_attribute_14
insight
into
how
the
component_7
be
perform
technology_20
artemisversion2


technology_1
driver


0replicationsynchronousreplication
typeactive
passiveartemis
be
the
successor
to
popular
technology_18

which
hasn’t
see
any
significant
development
lately
artemis
emerge
from
a
donation
of
the
hornetq
to
technology_39
and
be
be
develop
by
both
redhat
and
technology_18
developer
technology_37
it
support
technology_33
a
well
a
other
pattern_4
technology_12
for
example
stomp
and
technology_40
artemis
support
a
couple
of
high
quality_attribute_13
deployment
option
either
use
pattern_2
or
a
connector_32
component_11
we’ll
be
use
the
over
the
requirement_8
setup
that
be
pattern_2
unlike
other
test
pattern_6
artemis
replicate
connector_data_2
to
one
backup
technology_10
the
basic
unit
here
be
a
live
backup
pair
the
backup
happen
synchronously
that
be
a
connector_data_1
be
consider
connector_22
only
when
it
be
replicate
to
the
other
component_18
failover
and
failback
can
be
configure
to
happen
automatically
without
operator
intervention
moreover
component_1
in
artemis
can
be
sharded
across
multiple
live
backup
pair
that
be
we
can
quality_attribute_7
a
couple
of
such
pair
and
use
them
a
a
single
cluster
a
we
aren’t
able
to
create
a
three
technology_10
cluster
instead
we’ll
use
a
six
technology_10
setup
in
a
“star”
configuration
three
live
leader
component_18
all
of
which
serve
traffic
of
the
component_7
use
for
test
each
of
them
have
a
backup
component_18
split
brain
issue
be
connector_33
by
an
implementation
of
quorum
vote
this
be
similar
to
what
we’ve
see
e
g
in
the
technology_37
implementation
the
artemis
test
component_3
be
base
on
technology_41
and
doesn’t
contain
any
artmis
specific
us
only
technology_38
technology_19
concept
connector_17
connector_data_1
connector_13
and
transaction
we
only
need
to
use
an
artemis
specific
connector_20
factory
see
artemismq
the
configuration
connector_34
compare
to
the
default
be
the
xmx
technology_1
parameter
bump
to
48gin
pattern_6
technology_42
the
global
max
size
set
connector_35
to
48gjournal
type
set
to
mappedjournal
datasync
journal
pattern_16
non
pattern_15
and
journal
pattern_16
pattern_15
all
set
to
falseperformance
wise
artemis
do
very
well
our
baseline
single
component_8
setup
achieve


msg
s
by

technology_10
we
can
quality_attribute_19
that
connector_data_9
to


msg
s
use

connector_17
technology_10

receiver
technology_10
each
run

component_8
in
that
last
requirement_5
the
95th
percentile
of
connector_5
quality_attribute_4
be
a
quality_attribute_18

m
and
maximum
component_5
quality_attribute_4
of

m
however
a
the
artemis
team
note
the
connector_33
component_26
currently
connector_9
in
artemis
isn
t
the
best
fit
for
the
mqperf
benchmark
connector_36
connector_data_4
from
a
single
component_7
on
a
single
pattern_6
be
basically
a
single
component_8
component_5
which
on
one
hand
ensure
that
connector_data_4
be
connector_4
in
order
but
on
the
other
prevent
quality_attribute_15
a
more
component_25
be

quite
the
contrary
this
can
be
alleviate
by
use
dedicate
component_1
for
component_27
or
pattern_17
topic
with
pattern_18
however
we
then
need
component_19
side
coordination
which
assign
component_1
to
component_27
ensure
that
there
s
at
least
one
component_27
for
each
component_7
and
perform
rebalancing
on
failure
here
be
all
of
the
connector_data_9
threadssender
nodesreceiver
nodessend
msg
sreceive
msg
sprocessing
latencysend
latency11213

































































00artemis
also
offer
a
web
console
which
help
to
visualise
the
current
cluster
state
nats
streamingversion0


technology_1
driver


3replicationsynchronousreplication
typeactive
passivenats
be
a
lightweight
pattern_4
component_12
popular
especially
in
the
domain
of
iot
component_19
it
support
a
number
of
connector_1
pattern_11
such
a
connector_data_8
connector_data_11
pattern_19
and
wildcard
subscription
nats
offer
component_23
in
most
popular
technology_43
a
well
a
requirement_11
with
many
external
component_12
however
in
itself
nats
doesn’t
offer
cluster
pattern_2
or
connector_data_1
acknowledgment
for
that
purpose
nats
connector_7
build
upon
nats
provide
support
for
replicate
persistent
connector_data_1
quality_attribute_10
subscription
and
use
acknowledgement
guarantee
at
least
once
delivery
it
embed
a
nats
component_18
extend
it
technology_12
with
additional
capability
a
nats
connector_7
component_18
connector_37
an
ever
grow
requirement_12
of
connector_data_1
which
be
delete
after
reach
the
configure
size
connector_data_1
count
or
connector_data_1
age
limit
in
this
respect
the
design
be
similar
to
a
technology_5
topic’s
retention
requirement_13
the
component_18
be
quality_attribute_6
to
setup
not
a
lot
of
configuration
be
need
the
component_3
component_28
be
similarly
straightforward
to
use
a
with
other
component_7
implementation
discuss
previously
nats
connector_7
us
the
raft
technology_12
for
replicate
connector_data_2
in
a
cluster
a
connector_18
be
successful
only
after
a
successful
consensus
round
when
the
majority
of
technology_10
connector_11
it
hence
this
design
should
be
resilient
against
split
brain
scenario
there’s
a
single
leader
technology_10
which
connector_11
connector_18
this
mean
a
the
documentation
emphasis
that
this
setup
isn’t
horizontally
quality_attribute_20
an
alternate
version
of
a
nats
base
cluster
component_12
jetstream
be
be
develop
which
promise
horizontal
quality_attribute_21
what’s
interest
be
a
whole
section
in
the
doc
dedicate
to
the
use
requirement_5
of
at
least
once
persistent
pattern_4
when
to
use
it
and
more
importantly
when
not
to
use
it

be
aware
that
use
an
at
least
once
guarantee
be
the
facet
of
pattern_4
with
the
high
cost
in
term
of
compute
and
storage
the
nats
maintainer
highly
recommend
a
strategy
of
default
to
core
nats
use
a
component_6
pattern_11
connector_data_8
connector_data_11
to
guarantee
delivery
at
the
component_19
level
and
use
connector_7
only
when
necessary
it’s
always
quality_attribute_14
to
consider
your
architectural
requirement
but
in
our
test
of
we’ll
focus
on
the
replicate
&
persistent
setup
speak
of
test
our
baseline
test
achieve


msg
s
this
quality_attribute_19
up
to


msg
s
when
use

component_21
on

sender
technology_10
and

receiver
technology_10
quality_attribute_4
be
also
look
quality_attribute_14
with
95th
connector_5
percentile
be
at
most

m
while
connector_data_4
have
be
usually
component_5
within

m
here’s
a
summary
of
the
test
run
threadssender
nodesreceiver
nodessend
msg
sreceive
msg
sprocessing
latencysend
latency1121

































































00redis
streamsversion6


jedis
component_3


1replicationactive
passivereplication
typeasynchronousredis
be
probably
best

a
a
really
fast
and
useful
key
requirement_10
pattern_20
component_14
it
might
be
le

that
technology_15
support
both
persistence
and
pattern_2
a
well
a
fail
over
and
sharding
use
cluster
however
technology_15
also
offer
a
connector_7
component_10
the
logical
design
borrow
some
concept
from
technology_5
such
a
component_27
group
however
the
internal
implementation
be
entirely
different
the
documentation
include
a
comprehensive

provide
usage
guideline
and
detail
the
design
along
with
it
limitation
use
connector_26
with
technology_15
be
connector_9
use
the
xadd
xrange
xread
xreadgroup
and
xack
command
in
addition
to
the
basic
of

an
element
to
a
connector_3
it
offer
three
basic
mode
of
connector_38
connector_data_2
range
scan
to
connector_14
an
arbitrary
connector_3
element
or
elementsfan
out
connector_19
where
every
component_27
connector_19
every
connector_data_1
topic
semantics
component_27
group
connector_19
where
every
component_27
connector_19
a
dedicate
set
of
connector_data_4
component_7
semantics
we
ll
be
use
the
component_27
group
requirement_14
each
component_27
group
and
each
component_27
within
a
group
be
identify
by
a
unique
identifier
to
connector_12
a
connector_data_1
a
component_27
need
to
issue
the
xreadgroup
command
with
the
connector_3
name
component_27
group

and
component_27

when
a
connector_data_1
be
component_5
it
need
to
be
acknowledge
use
xack
for
each
connector_3
and
component_27
group
technology_15
maintain
component_18
side
state
which
determine
which
component_27
connector_16
which
connector_data_1
which
connector_data_4
be
not
yet
connector_16
by
any
component_27
and
which
have
be
acknowledge
what
s
important
be
that
component_27

have
to
be
manage
by
the
component_19
this
mean
that
if
a
component_27
with
a
give
go
offline
permanently
it
s
possible
that
some
connector_data_4
will
connector_10
stick
in
a
connector_12
but
not
acknowledge
state
to
remedy
the
situation
other
component_25
should
periodically
issue
a
xautoclaim
command
which
reassign
connector_data_1
if
they
haven
t
be
component_5
for
the
give
amount
of
time
this
be
a
mechanism
similar
to
sqs
s
visibility
timeouts
however
initiate
by
the
component_3
not
the
component_18
moreover
after
a
component_27
restart
it
should
first
connector_39
if
there
be
some
unacknowledged
connector_data_4
which
be
assign
to
it

if
so
they
should
be
reprocess
combine
with
auto
claim
we
connector_10
an
implementation
of
at
least
once
delivery
unlike
in
technology_5
or
other
pattern_4
component_12
the
component_23
need
to
take
care
and
connector_9
this
correctly
to
make
sure
no
connector_data_4
be
lose
pattern_2
in
technology_15
be
pattern_1
unless
we
use
the
wait
command
after
each
to
make
sure
it
s
propagate
across
the
cluster
we
win
t
be
use
this
option
in
our
test
a
it
go
against
the
way
technology_15
should
be
use
and
even
the
documentation
state
that
it
will
make
the
component_12
very
slow
hence
upon
failure
some
connector_data_2
loss
be
possible
note
that
it
be
recommend
to
have
persistence
enable
when
use
pattern_2
a
otherwise
it
s
possible
to
have
the
entire
state
truncate
upon
a
technology_10
restart
persistence
by
default
flush
connector_data_2
to
disk
asynchronously
every
second
but
this
can
be
configure
to
flush
after
each
command
however
again
cause
a
huge
requirement_6
penalty
additional
feature
of
technology_15
connector_26
include
connector_data_1
delivery
counter
allow
connector_24
a
dead
letter
component_7
observability
command
and
specify
a
maximum
number
of
element
in
a
connector_3
truncate
the
connector_3
if
that
limit
be
exceed
what
s
worth
note
be
a
dedicate
section
in
the
documentation
explicitly
state
the
feature
and
limitation
of
the
persistence
&
pattern_2
component_12
clearly
state
when
connector_data_2
loss
might
occur
this
leave
no
doubt
when
choose
the
right
tradeoff
in
a
component_12
s
design
finally

s
focus
on
quality_attribute_15
technology_15
connector_3
all
of
the
connector_7
above
operate
on
a
single
technology_15
key
reside
on
a
single
technology_15
master
component_18

be
then
replicate
to
slave
what
if
we
technology_44
to
quality_attribute_19
our
component_12
above
that
one
solution
be
to
use
technology_15
cluster
and
multiple
connector_3
key
when
connector_17
connector_data_2
we
then
have
to
choose
a
connector_3
key
either
randomly
or
in
some
deterministic
fashion
this
resemble
technology_5
s
component_22
and
component_22
key
on
the
component_27
side
we
might
connector_4
from
all
key
at
once
we
could
also
have
dedicate
component_25
for
key
but
then
we
technology_44
need
some
way
to
maintain
a
cluster
wide
pattern_21
of
the
component_27
key
association
to
ensure
that
each
key
be
connector_4
by
some
component_27
which
isn
t
an
easy
connector_data_3
the
number
of
key
also
need
to
be
large
enough
to
ensure
that
they
be
evenly
quality_attribute_1
across
the
shard
distribution
be
base
on
key
hash
requirement_10

s
look
at
the
requirement_6
test
connector_data_9
a

technology_10
active
passive
setup
achieve
up
to


msg
s
however
when
we
employ
a
sharded
cluster
of

technology_10
that
be
3x
master
+

replica
and
with

connector_3
key
we
can
connector_10
up
to


msg
s
however
with
quite
high
quality_attribute_4
here
be
the
test
connector_data_5
in
full
threadssender
nodesreceiver
nodessend
msg
sreceive
msg
sprocessing
latencysend
latency12420

















628144178pulsarversion2

2replicationconfigurable
pattern_1
&
synchronousreplication
typeactive
activeapache
technology_16
be
a
quality_attribute_1
connector_7
and
pattern_4
component_29
it
be
often
position
in
a
similar
segment
a
technology_39
technology_5
and
the
two
component_30
be
often
compare
and
contrast
technology_16
be
initially
develop
at
yahoo
and
now
continue
to
quality_attribute_22
a
an
open
component_13
project
it
build
upon
two
other
technology_39
project
technology_45
for
cluster
discovery
and
coordinationbookkeeper
a
the
replicate
storage
servicea
technology_16
deployment
consist
of
technology_10
which
take
on
one
of
three
role
bookie
handle
persistent
storage
of
messagesbroker
a
stateless
component_6
which
connector_11
connector_data_4
from
component_31
dispatch
connector_data_4
to
component_25
and
connector_40
with
bookie
to
component_11
datazookeeper
which
provide
coordination
component_2
for
the
above
twohence
a
minimal
deployment
should
in
fact
consist
of
more
than

technology_10
although
we
can
colocate
a
couple
of
role
on
a
single
component_9
for
our
test
we
have
decide
to
use
separate
component_32
for
separate
role
and
hence
we
end
up
with

technology_45
technology_10

bookie
technology_10
and

pattern_6
technology_10
when
work
with
technology_16
we’re
deal
with
three
concept
connector_data_1
topic
and
subscription
component_33
connector_5
connector_data_4
to
topic
either
individually
or
in
pattern_7
component_25
can
subscribe
to
a
topic
in
four
mode
exclusive
failover
connector_32
and
key_shared
provide
a
subscription
name
combine
a
connector_32
or
unique
subscription
name
with
one
of
the
four
consumption
mode
we
can
achieve
pattern_22
topic
connector_data_1
component_7
or
a
combination
of
these
behaviour
technology_16
be
very
quality_attribute_23
in
this
regard
connector_data_1
in
technology_16
be
delete
after
they
be
acknowledge
and
this
be
track
per
subscription
that
be
if
there
be
no
pattern_23
to
a
topic
connector_data_4
will
be
mark
for
deletion
right
after
be
connector_5
acknowledge
a
connector_data_1
in
one
subscription
doesn’t
affect
other
subscription
additionally
we
can
specify
a
connector_data_1
retention
requirement_13
to
keep
connector_data_4
for
a
long
time
moreover
topic
can
be
component_22
behind
the
scene
technology_16
create
an
internal
topic
for
every
component_22
these
component_22
be
something
quite
different
than
in
technology_5
however
from
the
component_31
and
component_27
point
of
pattern_21
such
a
topic
behave
a
a
single
one
a
a
single
topic
be
always
handle
by
a
single
pattern_6
increasing
the
number
of
component_22
we
can
increase
quality_attribute_12
by
allow
multiple
pattern_6
to
connector_11
and
dispatch
connector_data_1
a
mention
above
all
storage
be
handle
by
technology_39
bookkeeper
entry
connector_data_1
be
component_11
in
sequence
connector_28
ledger
we
can
configure
how
many
copy
of
a
ledger
be
create
managedledgerdefaultensemblesize
in
how
many
copy
a
connector_data_1
be
component_11
managedledgerdefaultwritequorum
and
how
many
technology_10
have
to
acknowledge
a
connector_18
managedledgerdefaultackquorum
follow
our
persistence
requirement
we’ve
be
use

ledger
copy
and
require
at
least

copy
of
each
connector_data_1
the
set
above
correspond
to
pattern_5
pattern_2
but
by
set
the
quorum
to

or

we
would
connector_10
an
pattern_1
one
unlike
previously
discuss
component_7
technology_16
be
an
active
active
component_12
that
be
every
technology_10
be
equal
and
can
handle
component_34
connector_data_8
coordination
be
perform
via
technology_45
which
also
quality_attribute_24
the
cluster
against
split
brain
problem
technology_16
offer
a
number
of
additional
feature
such
a
technology_16

technology_46
transaction
geo
pattern_2
multi
tenancy
connector
to
many
popular
connector_data_2
component_5
component_4
technology_16
io
a
schema
registry
and
others
requirement_6
wise
it
show
that
each
technology_10
can
handle
pattern_4
traffic
a
baseline
setup
use
a
single
component_22
achieve


msg
s
use

sender
and

receiver
technology_10
each
run

component_8
we
connector_10


msg
s
however
we
can
also
increase
the
number
of
component_22
thus
increasing
pattern_9
we
achieve
the
best
connector_data_5
use

component_22
that
be
a
single
pattern_6
be
handle

component_22
on
average

more
component_22
didn’t
further
increase
requirement_6
here
we
connector_10
up
to


msg
s
use

sender
technology_10
each
run

component_8
and

receiver
technology_10
each
run

component_8
connector_5
quality_attribute_4
be
quality_attribute_18
and
the
95th
percentile
be

m
component_5
quality_attribute_4
vary
from

m
to
at
most

m
in
the
test
which
achieve
high
quality_attribute_12
here
be
the
full
test
connector_data_9
for

component_22
threadssender
nodesreceiver
nodessend
msg
sreceive
msg
sprocessing
latencysend
latency1121







































































00and
use

component_22
threadssender
nodesreceiver
nodessend
msg
sreceive
msg
sprocessing
latencysend
latency1485































































00rocketmqversion4

1replicationconfigurable
pattern_1
&
synchronousreplication
typeactive
passiverocketmq
be
a
unify
pattern_4
component_35
and
lightweight
connector_data_2
component_5
component_29
the
connector_data_1
pattern_6
be
initially
create
a
a
replacement
for
technology_18

not
the
artemis
version
we
discuss
before
but
it
predecessor
it
aim
to
support
similar
use
requirement_5
provide
technology_19
and
requirement_15
among
others
and
put
a
focus
on
requirement_6
there
be
three
technology_10
type
from
which
a
rocketmq
cluster
be
create
pattern_6
master
which
connector_11
component_3
connector_20
connector_23
and
connector_21
messagesbroker
slave
which
replicate
connector_data_2
from
the
mastername
component_18
which
provide
component_6
discovery
and
routingeach
pattern_6
cluster
can
work
in
pattern_5
or
pattern_1
pattern_2
mode
which
be
configure
on
the
pattern_6
level
in
our
test
we’ve
be
use
pattern_5
pattern_2
in
theory
it
should
be
possible
to
quality_attribute_7
a
pattern_6
cluster
with
a
single
master
and
two
slave
to
achieve
a
pattern_2
factor
of

however
we
couldn’t
connector_10
this
setup
to
work
hence
instead
we’ve
settle
on
a
similar
configuration
a
with
technology_18
artemis
three
copy
of
pattern_24
pair
with
artemis
a
component_7
can
be
quality_attribute_7
on
multiple
pattern_6
and
the
connector_data_4
be
sharded
load
balance
when
produce
and
connector_36
from
the
topic
additionally
we’ve
quality_attribute_7
a
single
name
component_18
but
in
production
deployment
this
component_10
should
be
cluster
a
well
with
a
minimum
of
three
technology_10
speak
of
topic
rocketmq
support
both
pattern_22
topic
a
well
a
typical
connector_data_1
component_7
where
each
connector_data_1
be
connector_4
by
a
single
component_27
this
correspond
to
pattern_17
and
cluster
connector_data_1
consumption
mode
moreover
connector_data_4
can
be
connector_4
in
order
or
concurrently
we’ve
be
use
the
latter
option
connector_data_1
be
connector_4
and
acknowledge
per
component_27
group
which
be
specify
when
configure
the
component_27
when
create
a
component_27
group
historical
connector_data_4
can
be
connector_12
a
long
a
they
be
still
quality_attribute_5
by
default
rocketmq
retain
connector_data_4
for

day
rocketmq
support
transaction
however
there’s
no
build
in
deduplication
moreover
the
documentation
be
quite
basic
make
this
component_12
a
bit
challenge
to
setup
and
understand
there’s
no
mention
if
and
which
consensus
algorithm
be
use
and
if
split
brain
scenario
be
in
any
way
connector_33
however
there
be
a
recommendation
to
quality_attribute_7
at
least

name
component_18
which
would
hint
at
a
quorum
base
approach
however
rocketmq
definitely
make
up
for
these
deficiency
in
requirement_6
our
baseline
test
with
a
single
sender
and

component_8
achieve


msg
s
however
component_5
quality_attribute_4
be
quite
large
in
that
particular
test

second
it’s
quite
easy
to
overwhelm
rocketmq
with
connector_21
so
that
the
receiver
component_21
can’t
keep
up
the
most
we’ve
be
able
to
achieve
where
connector_21
be
connector_23
be
on
par
be
with

sender
technology_10

receiver
technology_10
run

component_21
each
in
that
requirement_5
the
pattern_6
component_5


msg
s
connector_5
quality_attribute_4
be
always
within

47ms
however
a
mention
component_5
quality_attribute_4
connector_10
high
pretty
quickly
the
high
quality_attribute_12
with
reasonable
component_5
quality_attribute_4

m
achieve


msg
s
here’s
a
summary
of
our
test
threadssender
nodesreceiver
nodessend
msg
sreceive
msg
sprocessing
latencysend
latency11213

































































00kafkaversion2

0replicationconfigurable
pattern_1
&
synchronousreplication
typeactive
activekafka
be
a
quality_attribute_1

connector_3
component_29
it
be
widely
quality_attribute_7
and
have
gain
considerable
popularity
in
recent
year
originally
develop
at
linkedin
it
be
now
an
open
component_13
project
with
commercial
extension
and
support
offer
by
confluent
a
technology_5
cluster
consist
of
a
number
of
pattern_6
technology_10
which
handle
persistence
pattern_2
component_3
connector_20
they
both
connector_11
and
connector_5
connector_data_1
in
addition
there’s
a
technology_45
cluster
which
be
use
for
component_6
discovery
and
coordination
however
there
be
plan
to
replace
that
component_10
with
one
build
directly
into
the
technology_5
pattern_6
technology_5
take
a
different
approach
to
connector_data_1
compare
to
what
we’ve
see
before
the
component_18
itself
be
a
connector_7
pattern_19
component_12
or
at
an
even
more
basic
level
a
quality_attribute_1
requirement_12
each
technology_5
topic
can
have
multiple
component_22
by
use
more
component_22
the
component_25
of
the
connector_data_4
and
the
quality_attribute_12
be
quality_attribute_19
and
pattern_9
of
component_5
increase
it’s
not
uncommon
for
a
topic
to
have
10
or
100
of
component_22
on
top
of
the
pattern_19
component_12
which
persist
connector_data_4
within
component_22
point
to
point
pattern_4
component_7
be
build
by
put
a
significant
amount
of
component_36
into
the
component_27
this
again
contrast
technology_5
when
compare
with
other
pattern_4
component_4
we
ve
look
at
there
usually
it
be
the
component_18
that
contain
most
of
the
connector_data_1
connector_4
by
one
component_27
component_36
here
it
s
the
component_27
each
component_27
in
a
component_27
group
connector_19
connector_data_4
from
a
number
of
dedicate
component_22
hence
it
doesn
t
make
sense
to
have
more
component_27
component_21
than
component_22
or
in
other
word
a
single
component_22
be
connector_4
by
exactly
one
component_27
within
a
component_27
group
a
long
a
there
be
any
component_27
connector_data_1
aren
t
acknowledge
on
the
component_18
which
be
a
very
important
design
difference
but
instead
component_5
connector_data_1
offset
be
manage
by
component_25
and
connector_18
per
parition
back
to
a
special
technology_5
component_11
or
a
component_3
specific
component_11
either
automatically
in
the
background
or
manually
this
allow
technology_5
to
achieve
much
quality_attribute_14
requirement_6
such
a
design
have
a
couple
of
consequence
only
connector_data_4
from
each
component_22
be
component_5
in
order
a
custom
component_22
connector_41
strategy
can
be
definedall
component_25
should
connector_4
connector_data_4
at
the
same
quality_attribute_25
connector_data_4
from
a
slow
component_27
win
t
be
take
over
by
a
fast
consumermessages
be
acknowledge
up
to
an
offset
that
be
connector_data_4
can
t
be
selectively
acknowledge
no
advance
pattern_4
option
be
quality_attribute_5
such
a
connector_8
or
delay
connector_data_1
delivery
you
can
connector_14
more
about
the
design
of
the
component_27
in
technology_5
s
doc
which
be
quite
comprehensive
and
provide
a
quality_attribute_14
start
point
when
set
up
the
pattern_6
it
be
also
possible
to
a
pattern_25
on
top
of
technology_5
to
connector_9
individual
connector_data_1
acknowledgment
and
re
delivery
see
our
on
the
requirement_6
of
kmq
and
the
kmq
project
this
technology_11
us
an
additional
topic
to
track
connector_data_1
acknowledgement
in
requirement_5
a
connector_data_1
isn’t
acknowledge
within
specify
time
it
be
re
connector_6
this
be
quite
similar
to
how
technology_28
work
when
test
technology_5
we’ve
primarily
test
“vanilla”
technology_5
but
also
include
a
kmq
test
for
comparison
to
achieve
guarantee
connector_21
and
at
least
once
delivery
we
use
the
follow
configuration
see
the
kafkamq

topic
be
create
with
a
pattern_2
factor
of
3for
the
sender
the
connector_data_8
require
acks
option
be
set
to

pattern_5
pattern_2
in
conjunction
with
min
insync
replica
topic
config
set
to

a
connector_5
connector_data_8
block
until
it
be
connector_11
by
at
least

replica
a
quorum
when
we
have

technology_10
in
total
if
you
technology_44
pattern_1
pattern_2
this
can
be
set
to

a
connector_5
connector_data_8
block
until
it
be
connector_11
by
the
component_22
leader
component_27
offset
be
connector_31
every

second
manually
during
that
time
connector_data_1
connector_13
be
block
a
connector_14
connector_18
lock
be
use
to
assure
that
that
way
we
can
achieve
at
least
once
delivery
only
connector_42
when
connector_data_4
have
be
observe
it’s
important
to
connector_10
the
above
configuration
right
you
can
connector_14
more
about
proper
no
connector_data_2
loss
technology_5
configuration
on
our

a
well
a
how
to
guarantee
connector_data_1
order
by
default
even
within
a
component_22
connector_data_4
might
be
reorder
a
technology_5
us
technology_45
requirement_8
component_22
be
handle
at
that
level
technology_5
have
a
number
of
feature
which
be
useful
when
design
a
pattern_4
or
connector_data_2
connector_7
component_12
such
a
deduplication
transaction
a
technology_47

connector
to
multiple
popular
connector_data_2
component_5
component_12
a
schema
registry
and
a
connector_7
technology_31
with
in
technology_5
exactly
once
component_5
guarantee
let’s
look
at
the
requirement_6
test
here
technology_5
have
no
equal
the
number
be
impressive
a
baseline
test
achieve
around


msg
s
use

sender
technology_10
and

receiver
technology_10
run

component_21
each
we
can
achieve


msg
s
however
we
didn’t
stop
here
it
turn
out
that
the
connector_17
part
be
the
bottleneck
and
it
might
not
be
surprise
a
that’s
where
most
coordination
happen
we
wait
for
connector_data_4
to
be
persist
and
acknowledge
while
on
the
receiver
side
we
allow
pattern_1
periodic
offset
connector_31
by
use

component_21
on

sender
technology_10
with

receiver
technology_10
but
run
only

component_21
each
we
achieve


msg
s
we’ve
be
use
at
least

component_22
for
the
test
quality_attribute_15
this
up
if
there
be
more
total
receiver
component_8
to

or

component_22
what
about
quality_attribute_4
they
be
very
quality_attribute_18
even
under
high
load
95th
percentile
of
both
connector_5
and
connector_23
quality_attribute_4
be
steadily
at

m
here’s
the
requirement_9
from
the
test
run
with
the
big
quality_attribute_12
a
mention
before
we’ve
also
test
a
setup
with
selective
connector_data_1
acknowledgment
use
kmq
the
implementation
be
here

another
topic
for
track
redeliveries
and
perform
additional
connector_data_1
marker
connector_21
do
impact
requirement_6
but
not
that
much
use

component_21
on

sender
and

component_21
on

sender
we’ve
achieve
a
quality_attribute_12
of


msg
s
however
component_5
quality_attribute_4
go
up
to
about


m
finally
here
be
our
technology_5
test
connector_data_5
in
full
threadssender
nodesreceiver
nodessend
msg
sreceive
msg
sprocessing
latencysend
latency1127







































































































































00redpandaversion21

4replicationconfigurable
pattern_1
&
synchronousreplication
typeactive
activethe
redpanda
component_12
target
mission
critical
workload
and
connector_43
a
technology_5
quality_attribute_26
technology_34
hence
the
way
pattern_4
work
in
redpanda
carry
over
from
technology_5
we
ve
connector_10
topic
component_22
component_27
group
etc
in
fact
we
re
use
exactly
the
same
component_3
to
test
both
redpanda
and
technology_5
however
the
devil
lie
in
the
detail

s
start
with
connector_data_2
quality_attribute_9
redpanda
s
motto
zero
connector_data_2
loss
indicate
it
focus
on
mission
critical
component_12
by
default
redpanda
s
configuration
for
a

technology_10
cluster
correspond
to
the
follow
technology_5
property
acks=
1min
insync
replicas=2
quorum
requirement_12
flush
interval
messages=1the
last
one
be
especially
interest
a
that
s
where
redpanda
differ
from
what
you
technology_44
often
use
in
a
synchronously
replicate
technology_5
setup
and
also
from
what
we
ve
use
in
our
test
in
technology_5
set
requirement_12
flush
interval
connector_data_1
to

ensure
that
the
disk
pattern_20
be
flush
on
every
connector_data_1
and
that
s
what
happen
in
redpanda
a
well
in
other
word
once
a
connector_data_1
be
connector_11
by
the
quorum
it
be
guarantee
that
it
will
be
persistently
component_11
on
disk
the
default
in
technology_5
and
in
our
test
be
an
unbounded
number
of
connector_data_1
hence
disk
flush
happen
asynchronously
this
approach
to
disk
quality_attribute_9
be
similar
to
what
we
ve
see
in
technology_37
keep
this
in
mind
while
connector_44
the
connector_data_9
on
the
inside
redpanda
us
a
mixture
of
technology_48
and
go
while
technology_5
be
technology_29
base
moreover
one
of
the
sell
point
of
redpanda
be
that
it
eliminate
the
connector_45
on
technology_45
instead
it
us
the
raft
consensus
technology_12
this
have
very
practical
consequence
redpanda
will
connector_11
a
connector_18
once
a
majority
of
technology_10
the
quorum
connector_11
it
technology_5
on
the
other
hand
will
wait
for
a
confirmation
from
all
in
pattern_16
replica
which
might
take
a
long
time
if
the
isr
set
be
large
than
the
quorum
this
also
mean
that
any
disturbance
in
the
cluster
will
have
large
implication
on
quality_attribute_4
in
technology_5
than
in
redpanda
it
s
worth
note
that
technology_5
go
in
the
same
direction
with
it
kraft
implementation
redpanda
come
with
other
interest
feature
such
a
an
auto
tuner
which
detect
the
optimal
setting
give
the
hardware
it
s
run
on
or
the
wasm
transformation
support
think
of
it
a
an
in
component_5
technology_5
connector_26
stage
another
interest
aspect
be
that
redpanda
connector_43
prometheus
metric
natively

s
take
a
look
at
the
requirement_6
connector_data_9
our
test
environment
go
against
redpanda
s
guideline
not
to
use
requirement_8
block
component_37
we
re
use
eb
s
gp2
drive
however
we
want
to
keep
the
test
environment
the
same
for
all
component_7
redpanda
achieve
up
to
about


msg
s
use

component_22

sender
technology_10

receiver
technology_10
each
run

component_8
again
that
s
quite
similar
to
what
technology_37
achieve
maybe
that
s
the
limit
of
component_1
which
fsync
each
connector_16
connector_data_1
or
in
our
test
scenario
a
pattern_7
of
up
to

connector_data_1
how
do
technology_5
behave
when
we
set
requirement_12
flush
interval
messages=1
turn
out
it
s
a
bit
fast
we
ve
manage
to
connector_10
to


msg
s
use

component_22

sender
technology_10
run

component_21
each
and

receiver
technology_10
run

component_21
each
however
the
quality_attribute_4
go
up
to
about
800ms
finally
here
be
redpanda
s
test
connector_data_5
in
full
similarly
to
technology_5
both
connector_5
and
component_5
quality_attribute_4
oscillate
around
47ms
though
they
do
connector_10
slightly
high
a
we
increase
the
number
of
sender
to
connector_10
the
most
requirement_6
threadssender
nodesreceiver
nodessend
msg
sreceive
msg
sprocessing
latencysend
latency25124











369141137summary
of
featuresbelow
you
can
find
a
summary
of
some
of
the
characteristic
of
the
component_1
that
we’ve
test
of
this
connector_data_12
isn’t
comprehensive
rather
it
touch
on
area
that
we’ve
mention
above
and
which
be
important
when
consider
pattern_2
connector_data_1
persistence
and
connector_data_2
quality_attribute_9
however
each
component_12
have
a
number
of
unique
feature
which
be
out
of
scope
here
which
component_7
to
choose
it
quality_attribute_27
unfortunately
there
be
no
easy
answer
to
such
a
question
a
always
which
connector_data_1
component_7
to
choose
quality_attribute_27
on
specific
project
requirement
all
of
the
above
solution
have
some
quality_attribute_14
side
sqs
be
an
a
a
component_6
offer
so
especially
if
you
be
use
the
technology_49
requirement_7
it
s
an
easy
choice
quality_attribute_14
requirement_6
and
no
setup
require
it
s
cheap
for
low
to
moderate
workload
but
might
connector_10
expensive
with
high
loadif
you
be
already
use
mongo
technology_17
or
eventstore
you
can
either
use
it
a
a
connector_data_1
component_7
or
easily
build
a
connector_data_1
component_7
on
top
of
the
component_14
without
the
need
to
create
and
maintain
a
separate
pattern_4
clusterif
you
want
to
have
high
persistence
guarantee
technology_37
ensure
pattern_2
across
the
cluster
and
on
disk
on
connector_data_1
connector_5
it
s
a
very
popular
choice
use
in
many
project
with
full
technology_36
implementation
and
support
for
many
pattern_4
topologiesactivemq
artemis
be
a
popular
battle
test
and
widely
use
pattern_4
pattern_6
with
wide
technology_12
support
and
quality_attribute_14
performancenats
connector_7
support
many
useful
connector_1
pattern_11
and
be
especially
popular
in
iot
deploymentsredis
connector_26
offer
quality_attribute_14
requirement_6
on
top
of
a
popular
and
familiar
key
requirement_10
storerocketmq
offer
a
technology_41
quality_attribute_26

with
great
performancepulsar
build
provide
a
wide
feature
set
with
many
pattern_4
technology_11
quality_attribute_5
it’s
gain
popularity
due
to
it’s
quality_attribute_23
nature
accommodate
for
a
wide
range
of
use
requirement_5
and
great
performancekafka
offer
the
best
requirement_6
and
quality_attribute_21
at
the
cost
of
feature
set
it
be
the
de
facto
technology_38
for
component_5
connector_26
across
requirement_16
redpanda
connector_43
a
technology_5
quality_attribute_26

focus
on
zero
connector_data_2
loss
and
provide
additional
connector_data_2
component_5
and
observability
featuresstill
not
sure
which
connector_data_1
component_7
be
the
best
fit
for
your
problem
u
help
you
in
choose
a
particular
technology_50
entire
tech
technology_30
or
architecture
give
your
unique
requirement
and
constraint
head
over
to
our
consult
component_2
offer
or
u
right
away
here’s
a
summary
of
the
requirement_6
test
first
zoom
in
on
our
component_14
base
component_7
rabbit
nats
connector_3
technology_15
connector_3
artemis
redpanda
and
technology_5
in
the
flush
variant
with
technology_28
for
comparison
and
include
all
of
the
test
component_7
finally
the
component_5
quality_attribute_4
have
a
wide
distribution
across
the
pattern_6
usually
it
s
below
150ms
with
rocketmq
technology_17
and
kmq
fare
bad
under
high
load
there
be
of
many
other
aspect
besides
requirement_6
which
should
be
take
into
account
when
choose
a
connector_data_1
component_7
such
a
administration
overhead
requirement_8
component_22
tolerance
feature
set
regard
connector_41
documentation
quality
maturity
etc
while
there
s
no
connector_data_1
component_7
silver
bullet
hopefully
this
summary
will
be
useful
when
choose
the
best
component_12
for
your
project
creditsthe
follow
team
member
contribute
to
this
work
grzegorz
kocur
maciej
opała
marcin
kubala
krzysztof
ciesielski
kasper
kondzielski
tomasz
król
adam
warski
clebert
suconic
michael
andré
pearce
greg
young
and
francesco
nigro
help
out
with
some
configuration
aspect
of
artemis
and
eventstore
thanks
please
enable
technology_51
to
pattern_21
the

powered
by
disqus


powered
by
disqus
contentslet
s
do
thing
together
+48




pl
+44



uk
hello@softwaremill
comyour
personal
connector_data_2
connector_46
in
this
form
will
be
use
only
to
you
and
talk
about
your
project
for
more
connector_data_13
see
our
privacy
requirement_13
connector_5
messagesee
alsoportfolioservicescompanyjoin
ushire
usblogfollow
uslatest
on
blogmaria
wąchal
|



minute
readmeeting
with
the
technology_29
at
geeconconferenceslessons
learnedcompany
cultureteam©

softwaremill
all
right
reserve
privacy
requirement_13
