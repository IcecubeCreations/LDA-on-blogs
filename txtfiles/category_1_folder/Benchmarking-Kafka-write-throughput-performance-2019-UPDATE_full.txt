benchmarking
technology_1
connector_1
quality_attribute_1
requirement_1

update
blogmenublogcloseblogall
articlestech
tipsopen
sourceapache
kafka®flink®m3apache
cassandra®opensearch®postgresql®mysqlredis™influxdb®grafana®solutionstime
series
databasesiotintegrationsproduct
updatesannouncementsopen
micotherpricingcase
studiesaboutcareerspress
roomsupportcontact
usfree
trialget
startedsign
insupportdocumentationcontact
ussign
in|blogall
articlestech
tipsopen
sourceapache
kafka®flink®m3apache
cassandra®opensearch®postgresql®mysqlredis™influxdb®grafana®solutionstime
series
databasesiotintegrationsproduct
updatesannouncementsopen
micbenchmarking
technology_1
connector_1
quality_attribute_1
requirement_1

update
it
s
be
a
long
time
come
but
we
ve
now
have
update
connector_1
quality_attribute_1
technology_1
benchmark
number
and
a
few
extra
surprise

2019heikki
nousiainenheikki
nousiainen
technology_2
feedchief
technology_3
officer
at
aivenback
in

we
publish
a
requirement_1
benchmark
to
showcase
the
vast
volume
of
technology_4
technology_1
can
component_1
natural
to
aiven
component_2
we
evaluate
the
requirement_1
across
the
coding_keyword_1
requirement_2
technology_5
we
support
a
number
of
connector_2
have
be
make
to
technology_1
and
the
resource
that
the
coding_keyword_1
requirement_2
technology_5
offer
since
then
a
such
we
felt
it
be
a
due
time
for
a
refresher
and
decide
to
remeasure
connector_1
requirement_1
in
this
test
that
say
we
make
some
small
connector_2
to
the
benchmark
set
up
so
that
it
quality_attribute_2
reflect
real
world
workload
we
also
calculate
the
monthly
quality_attribute_1
cost
for
each
plan
on
each
requirement_2
this
time
so
let’s
jump
in

aiven
technology_1
benchmark
setup
a
with
the
previous
test
we
really
want
to
estimate
the
true
requirement_1
you’d
expect
from
use
aiven
technology_1
that
be
we
use
technology_6
aiven
plan
and
configuration
technology_6
component_3
configuration
and
run
the
test
over
the
external
requirement_3

but
this
time
around
we’re
use
a
pattern_1
factor
of

to
match
the
regular
use
requirement_4
with
pattern_1
this
test
account
for
the
requirement_3
traffic
between
the
pattern_2
a
well
we
use
a
single
topic
for
our
connector_1
with
a
component_4
count
set
to
either

or

quality_attribute_3
on
the
number
of
pattern_2
in
each
test
cluster
a
the
test
cluster
be
regular
aiven
component_2
the
component_4
and
replica
be
spread
out
across
quality_attribute_4
zone
connector_data_1
be
produce
via
the
librdkafka_performance
technology_7
with
a
connector_data_2
size
of

byte
a
default
pattern_3
size
of


and
no
compression
continue
our
quest
to
simulate
real
world
use
component_3
connector_3
be
make
over
tl
we
use
technology_1
version


run
with
technology_8

a
a
side
note
it’ll
be
interest
to
benchmark
aiven
technology_1
run
with
technology_8

in
future
test
because
we
expect
technology_8
improvement
to
positively
impact
it
requirement_1
during
the
test
we
keep
increasing
the
number
of
produce
component_5
until
we
reach
the
maximum
quality_attribute_1
rate
each
plan
tier’s
cluster
could
connector_4
to
verify
our
connector_5
we
leave
the
load
run
for
some
time
if
you’re
interest
in
verify
our
connector_data_3
you
can
connector_6
the
test
here
in
our
test
we
actually
use
google’s
manage
technology_9
component_2
to
easily
quality_attribute_5
number
of
load
generate
technology_10
up
and
down
aiven
technology_1
requirement_5

benchmark
connector_data_4
we
first
test
the
requirement_1
of
our
requirement_5

plan
that’s
a
three
pattern_2
cluster
with


cpu
quality_attribute_3
on
the
requirement_2
and
4gb
ram
per
instance
on
web
component_2
this
plan
handle
about


connector_data_1
per
second
while
the
same
plan
on
requirement_2
component_6
and
technology_11
handle
around


since
our
previous
test
omit
pattern_1
the
somewhat
lower
requirement_1
of
gcp
and
technology_11
can
be
explain
by
this
test’s
inclusion
of
it
surprisingly
aws’s
requirement_1
jump
from


connector_data_2
second
in
the
previous
test
to
this
number
this
be
explain
by
the
more
recent
instance
type
and
requirement_3
improvement
technology_12
have
be

in
their
requirement_2
aiven
technology_1
requirement_5

requirement_1
in
connector_data_5
second
we
then
use
the
connector_data_2
rat
to
derive
quality_attribute_1
number
which
be
over

connector_data_5
second
for
technology_13
and
under

connector_data_5
second
for
gcp
and
technology_11
pretty
impressive
but
what
be
the
cost
per
requirement_1
requirement_5

monthly
quality_attribute_1
cost
those
plan
be
requirement_6
$660
month
on
technology_12
u
east

$500
month
on
gcp
u
east1
and
$550
month
on
technology_11
eastus2
that’d
be
over
$10
per
connector_data_5
s
per
month
for
this
plan
size
in
technology_13
and
$15
and
$16
per
connector_data_5
s
for
gcp
and
technology_11
respectively
aiven
requirement_5

benchmark
connector_data_4
next
we
move
on
to
increasing
the
size
of
the
pattern_2
the
next
test
be
base
on
requirement_5

plan
tier
essentially
double
the
resource
to


cpu
and

gb
ram
per
instance
this
time
there
be
a
slight
increase
in
technology_12
to


connector_data_1
per
second
but
large
one
in
technology_11
and
gcp
to


and


respectively
technology_12
requirement_1
didn’t
move
from
the
previous
plan
size
a
look
into
our
pattern_4
reveal
that
both
test
be
cap
by
the
quality_attribute_6
requirement_3
bandwidth
on
the
pattern_2
instance
aiven
technology_1
requirement_5

requirement_1
in
connector_data_5
second
again
we
use
these
same
number
convert
to
quality_attribute_1
that’s

connector_data_5
s
for
technology_13

connector_data_5
s
for
gcp
and

connector_data_5
s
for
technology_11
requirement_5

monthly
quality_attribute_1
cost
with
the
requirement_5

plan
monthly
estimate
cost
increase
across
the
board
at
$19
per
connector_data_5
s
for
technology_12
and
technology_11
and
around
$22
per
connector_data_5
s
for
gcp
however
it’s
important
to
note
that
quality_attribute_1
be
only
one
way
to
measure
requirement_7
for
example
requirement_5

plan
come
with
double
the
storage
of
requirement_5

plan
which
allow
for
long
retention
time
aiven
technology_1
premium
6x

benchmark
connector_data_4
our
last
test
double
the
number
of
pattern_2
we
want
to
verify
how
well
technology_1
quality_attribute_5
vertically
a
it
do
quite
perfectly
in
our
previous
round
of
test
thus
we
run
this
one
with
a
six
pattern_2
premium
6x

plan
tier
with
similarly
size
instance
a
requirement_5

and
the
connector_data_2
rat
an
impressive


connector_data_1
per
second
on
technology_13


on
technology_11
and


on
gcp
well
in
line
with
the
expect
connector_data_3
aiven
technology_1
premium
6x

requirement_1
in
connector_data_5
second
and
the
same
a
quality_attribute_1
figure

connector_data_5
s
on
technology_13

on
technology_11
and

on
gcp
premium
6x

monthly
quality_attribute_1
cost
from
the
plan
requirement_6
estimate
monthly
cost
be
around
$19
per
connector_data_5
s
for
technology_13
$18
for
technology_11
and
$23
for
gcp
wrap
up
technology_4
technology_1
continue
to
perform
a
well
a
we’ve
come
to
expect
and
quality_attribute_5
nicely
with
both

resource
and
increase
cluster
size
it’s
performant
quality_attribute_7
and
cost
quality_attribute_8
—
a
solid
centerpiece
of
the
modern
connector_data_6
architecture
again
we’d
to
stress
that
monthly
quality_attribute_1
cost
should
not
be
consider
in
isolation
when
compare
plan
although
important
there
be
additional
factor
that
come
into
play
when
requirement_6
plan
such
a
storage
additionally
we
can’t
stress
enough
that
workload
vary
and
you
should
definitely
benchmark
your
own
representative
flow
for
a
more
quality_attribute_9
test
we’ll
be
connector_7
connector_5
connector_1
test
in
the
near
future
aiven
technology_1
aiven
technology_1
be
one
of

integrable
component_7
offer
on
the
aiven
component_6
it’s
a
fully
manage
and
component_8
technology_1
component_2
quality_attribute_6
in
technology_13
gcp
technology_11
digitalocean
upcloud
and
packet
after
launch
your
aiven
technology_1
component_2
in
minute
you
can
rest
assure
they’ll
remain
operational
performant
up
to
date
and
quality_attribute_10
find
out
more
about
aiven
technology_1
keep
up
to
date
on
our
changelog
find
u
on
social
and
try
the
aiven
component_6
free
for

day
benchmarkskafkashare
on
facebookproductsaiven
for
technology_4
kafka®aiven
for
technology_4
kafka®
connectaiven
for
technology_4
kafka®
mirrormaker
2aiven
for
technology_4
flink®
betaaiven
for
m3aiven
for
m3
aggregatoraiven
for
technology_4
cassandra®aiven
for
opensearch®aiven
for
postgresql®aiven
for
mysql®aiven
for
redis™*aiven
for
influxdb®aiven
for
grafana®solutionstime
series
databasesevent
drive
architectureobservabilityaiven
for
iotaiven
for
retailaiven
for
energyaiven
for
developersintegrationsall
solutionsresourcespricingblogcase
studiesdocumentationchangelogsecurity
&
compliancedevopsaiven
statuscompanyaboutpress
roomcareerssupportpartnersopen
sourcecluster
startup
programaiven
invoice
addressesterms
&
policiesterms
of
servicesladata
component_1
agreementprivacy
policycookie
policysupport
servicessubprocessors
&
subcontractorslet‘s
connectaiven
facebookaiven
linkedinaiven
twitteraiven
youtubeaiven
emailapache
technology_4
technology_1
technology_1
technology_4
flink
flink
technology_4
technology_14
and
technology_14
be
either
register
trademark
or
trademark
of
the
technology_4
foundation
in
the
unite
state
and
or
other
country
clickhouse
be
a
register
trademark
of
clickhouse
inc
technology_15
clickhouse
technology_16
m3
m3
aggregator
m3
coordinator
opensearch
technology_17
technology_18
influxdb
grafana
terraform
and
technology_9
be
trademark
and
property
of
their
respective
owner
*redis
be
a
trademark
of
technology_19
ltd
and
the
technology_19
component_9
logo
be
a
mark
of
technology_19
ltd
any
right
therein
be
reserve
to
technology_19
ltd
any
use
by
aiven
be
for
referential
purpose
only
and
do
not
indicate
any
sponsorship
endorsement
or
affiliation
between
technology_19
and
aiven
all
technology_20
and
component_2
name
use
in
this
be
for
identification
purpose
only
and
do
not
imply
endorsement
