technology_1
summit
talk
recap
real
world
technology_1
deployment
gerhard
lazu
technology_2
technology_2
tour
requirement_1
documentation
support
login
connector_1
start
start
technology_1
summit
talk
recap
real
world
technology_1
deployment
gerhard
lazu
technology_1
summit
be
a
one
day
conference
which
bring
light
to
technology_1
from
a
number
of
angle
among
others
gerhard
lazu
&
wayne
lund
talk
about
what
it
look
to
succeed
with
technology_1
in
production
come
and
join
u
in
explore
what
it
look
to
succeed
with
technology_1
in
production
we
will
cover
different
requirement_2
pattern_1
implementation
that
rely
on
technology_1
for
financial
requirement_3
vehicle
telemetry
pattern_2
medical
equipment
real
world
technology_1
deployment
this
talk
be
about
real
world
technology_1
deployment
have
spend
many
year
help
and
from
requirement_2
requirement_4
mostly
pivotal
but
also
vmware
and
other
requirement_5
and
have
from
component_1
on
the
mailing
connector_data_1
and
have
collaborate
with
them
there
be
many
thing
that
seem
to
have
in
common
and
seem
to
have
be
helpful
i
m
here
today
to
connector_2
some
of
those
thing
that
i
hope
that
you
can
apply
straight
away
the
technology_1
pattern_3
work
in
every
requirement_6
the
one
thing
which
become
obvious
after
year
and
year
be
that
the
technology_1
pattern_3
work
in
every
requirement_6
technology_1
pattern_3
be
very
quality_attribute_1
it
s
very
mature
the
quality_attribute_2
sometimes
it
work
not
in
it
advantage
s
put
it
that
michael
be
all
the
thing
that
you
can
do
with
component_2
and
some
thing
you
should
never
attempt
to
do
and
yet
you
still
can
that
tend
to
be
a
component_3
of
many
many
issue
the
one
thing
which
i
really
about
the
technology_1
pattern_3
be
that
it
connector_3
quality_attribute_3
with
every
release
which
every
patch
release
which
roughly
ship
every
month
there
be
constant
improvement
be
connector_4
in
the
pattern_3
every
month
that
s
great
there
be
some
very
big
improvement
such
a
the
quorum
component_2
which
you
have
no
idea
how
big
it
be
even
i
t
how
big
it
be
because
i
haven
t
work
a
closely
with
it
but
it
s
a
big
improvement
they
tend
to
ship
roughly
every
year
component_4
runtimes
and
requirement_7
the
limitation
of
technology_1
and
more
important
to
the
component_5
be
quality_attribute_3
understand
and
we
re
connector_5
them
further
we
ll
cover
some
of
them
but
there
be
one
thing
that
be
not
problematic
but
thing
connector_1
interest
when
it
come
to
component_4
their
runtimes
and
the
az
where
those
component_5
run
the
pattern_3
doesn
t
work
in
isolation
it
have
all
these
component_6
all
these
component_7
that
it
need
to
talk
to
that
s
typically
when
problem
start
some
component_5
be
engineer
quality_attribute_3
than
others
some
be
very
quality_attribute_3
some
be
very
bad
some
be
terrible
you
should
never
put
them
in
production
it
s
what
it
be
the
big
problem
be
that
some
component_5
be
build
and
they
can
never
be
improve
so
there’s
no
amount
of
configuration
or
tune
that
you
can
do
in
technology_1
to
make
up
for
poor
component_4
if
you
can
t
connector_6
your
component_4
there
s
nothing
technology_1
can
do
for
you
those
be
really
tough
discussion
the
component_4
runtimes
be
very
diverse
we
live
in
an
age
where
you
can
connector_7
in
anything
you
want
it
doesn
t
really
matter
you
connector_8
it
to
the
requirement_7
and
it
work
a
technology_3
runtime
be
very
different
to
a
golang
runtime
to
an
technology_4
runtime
and
because
everything
be
more
and
more
magical
and
easy
there
be
some
requirement_3
off
to
be
have
there
if
you
re
connector_9
a
component_8
with
many
container
and
those
container
run
within
vms
and
the
vms
run
on
a
component_9
you
have
all
these
pattern_4
of
complexity
who
where
the
problem
be
another
thing
which
we
keep
come
across
not
a
often
these
day
but
definitely
two
three
year
ago
be
you
have
this
capex
vs
opex
capex
be
where
an
it
infrastructure
an
it
department
buy
some
hardware
we
win
t
mention
any
name
they
spend
million
on
it
so
it
quality_attribute_3
run
quality_attribute_3
and
we
quality_attribute_3
connector_1
the
most
out
of
it
it
tend
to
connector_1
overload
it
tend
to
connector_1
maybe
not
ideal
but
you
have
the
investment
so
you
have
to
make
use
of
it
opex
it
s
much
much
quality_attribute_3
where
you
can
if
it
s
not
the
right
thing
you
put
your
credit
card
and
connector_1
a
big
instance
technology_1
be
a
river
not
a
lake
we
keep
mention
this
over
and
over
again
this
precede
my
time
technology_1
be
not
a
component_10
technology_1
be
a
river
it
s
not
a
lake
connector_data_2
should
flow
through
it
constantly
and
yet
some
people
or
some
component_5
t
seem
to
do
that
and
then
you
need
to
expire
connector_data_3
you
need
to
do
all
sort
of
thing
which
complicate
thing
greatly
you
re
ask
the
pattern_3
to
do
all
this
work
for
you
to
do
all
the
metric
all
the
thing
and
then
the
connector_data_2
go
away
so
all
this
work
for
nothing
the
one
thing
which
i
would
say
be
if
you
can
keep
your
component_2
empty
i
it
s
not
practical
in
all
scenario
but
that
s
when
technology_1
shin
when
thing
flow
through
it
it
be
a
connector_data_3
pattern_3
again
it
s
not
a
component_10
low
quality_attribute_4
technology_1
s
come
to
some
specific
workload
some
specific
requirement
from
technology_1
this
be
a
low
quality_attribute_4
we
connector_data_4
it
a
low
quality_attribute_4
technology_1
some
consideration
and
some
challenge
when
it
come
to
low
quality_attribute_4
pattern_1
with
technology_1
we
come
across
this
use
of
technology_1
in
the
component_11
of
financial
requirement_3
the
specific
use
requirement_6
have
to
be
with
four
financial
requirement_8
and
financial
instrument
all
it
mean
in
term
of
the
four
financial
requirement_8
be
four
exchange
the
financial
instrument
be
connector_10
key
and
you
have
all
these
connector_data_2
which
have
to
flow
through
technology_1
very
very
fast
you
have
connector_data_2
per
second
the
connector_data_2
be
fairly
small
they
be
basically
keep
track
of
connector_11
in
the
financial
instrument
all
the
requirement_1
connector_6
basically
the
goal
be
to
connector_12
every
connector_data_3
within
millisecond
if
a
connector_data_3
take
more
than
m
it
be
no
long
useful
they
have
to
drop
the
connector_data_3
the
component_12
would
lose
money
if
connector_data_2
will
take
more
than
m
pattern_5
→
pattern_3
raw
requirement_9
quality_attribute_4
where
do
you
start
you
quality_attribute_5
technology_1
you
run
your
component_4
and
it
s
slow
what
do
you
do
well
the
first
thing
that
you
should
do
when
low
quality_attribute_4
be
important
be
look
at
your
requirement_9
requirement_7
avg
max
std
a
49ms
62ms
12ms
b
25ms
69ms
07ms
technology_5
12ms
15ms
02ms
pattern_5
~$
pattern_6
s
technology_6
pattern_3
by
gerhard
lazu
we
have
three
technology_7
requirement_7
a
requirement_7
a
when
it
come
to
the
raw
requirement_9
quality_attribute_4
the
average
quality_attribute_4
be
m
this
be
before
technology_1
step
in
it
s
pattern_4
pattern_4
the
maximum
quality_attribute_4
be
m
which
be
really
bad
there
be
some
spike
this
be
a
requirement_7
i
win
t
mention
any
name
in
a
requirement_7
different
zone
container
all
sort
of
stuff
you
have
spike
which
be
so
big
that
there
s
no
way
technology_1
could
have
component_13
that
connector_data_3
within
1ms
there
s
no
way
because
your
quality_attribute_4
be
requirement_7
b
be
slightly
quality_attribute_3
but
requirement_7
technology_5
be
what
you
actually
want
the
pattern_5
to
pattern_3
the
requirement_9
quality_attribute_4
from
pattern_5
to
pattern_3
the
maximum
be
m
which
be
perfect
but
i
would
to
emphasize
the
technology_8
deviation
m
this
be
predictably
low
quality_attribute_4
which
be
key
low
quality_attribute_4
be
not
sufficient
it
have
to
be
quality_attribute_6
it
have
to
be
constant
pattern_3
→
component_14
raw
requirement_9
quality_attribute_4
now
it
s
not
enough
to
measure
the
quality_attribute_4
from
the
pattern_5
to
the
pattern_3
you
also
have
to
measure
the
quality_attribute_4
from
the
pattern_3
to
the
component_14
in
this
requirement_6
requirement_7
technology_5
again
win
m
that
s
amaze
to
have
to
have
such
low
quality_attribute_4
the
maximum
quality_attribute_4
for
requirement_7
technology_5
be
lower
than
the
technology_8
deviation
for
requirement_7
b
and
a
and
that
be
significant
pattern_5
→
pattern_3
→
component_14
put
together
requirement_7
a
m
that
s
the
majority
of
the
m
it
s
only
spend
in
the
requirement_9
technology_9
there
be
no
way
your
connector_data_2
will
flow
within
m
because
technology_1
need
some
time
your
pattern_5
need
some
time
your
component_15
need
some
time
requirement_7
technology_5
be
m
much
quality_attribute_3
we
can
do
some
work
with
that
requirement_9
quality_attribute_4
statistic
by
gerhard
lazu
you
would
think
that
point
in
time
quality_attribute_4
measurement
be
enough
they
be
not
you
need
to
continuously
pattern_7
your
requirement_9
quality_attribute_4
this
be
not
for
low
quality_attribute_4
connector_data_3
this
be
for
when
your
cluster
have
component_16
how
do
you
that
it
s
due
to
technology_1
or
to
your
requirement_9
if
you
t
pattern_7
your
quality_attribute_4
in
this
specific
requirement_6
we
can
see
that
the
quality_attribute_4
be
nice
and
consistent
m
we
can
see
some
dip
which
be
okay
this
be
fine
the
problem
be
when
you
have
spike
and
they
re
very
high
you
need
to
be
aware
when
that
happen
because
your
connector_data_2
might
start
expire
your
connector_data_2
be
not
make
it
through
why
because
of
high
quality_attribute_4
requirement_9
quality_attribute_4
1kb
connector_data_3
pattern_5
→
component_17
→
component_14
this
be
the
first
thing
that
you
can
do
today
in
technology_1
and
you
will
have
a
quality_attribute_3
time
you
ll
have
low
quality_attribute_4
pattern_1
with
it
pattern_5
confirm
pattern_5
confirm
keep
the
connector_data_5
buffer
empty
there
be
many
buffer
between
your
component_4
and
the
component_17
never
mind
the
component_14
many
component_13
many
port
many
thing
go
on
if
you
do
not
use
pattern_5
confirm
and
connector_13
connector_data_2
to
one
component_17
a
fast
a
possible
you
will
peak
in
this
specific
requirement_6
connector_data_2
per
second
but
look
at
the
quality_attribute_4
the
99th
percentile
be
m
that
s
crazy
high
that
s
if
you
publish
confirm
every
connector_data_3
you
can
only
connector_8
but
the
quality_attribute_4
be
m
in
our
requirement_6
we
have
to
connector_8
through
connector_data_2
per
second
the
optimal
pattern_5
confirm
configuration
for
u
be
every
connector_data_3
i
want
to
make
it
to
match
today
s
date
it
s
every
it
s
a
lucky
number
there
s
a
problem
look
at
the
line
the
connector_data_3
quality_attribute_4
the
99th
percentile
be
under
m
m
there
be
very
little
headroom
anything
go
wrong
and
you
start
drop
connector_data_3
not
quality_attribute_3
the
connector_data_3
quality_attribute_4
top
corner
very
very
high
distribution
so
on
and
so
forth
there
be
many
thing
which
you
should
keep
track
by
the
way
if
you
want
to
how
to
do
this
or
where
this
be
quality_attribute_7
this
be
publicly
quality_attribute_7
talk
to
me
after
component_17
confirm
every
connector_data_3
kb
connector_data_3
move
on
we
that
if
we
publish
confirm
every
connector_data_3
we
have
a
very
low
quality_attribute_4
but
the
quality_attribute_8
suffer
i
m
wonder
“what
would
happen
if
we
make
use
of
erlang’s
pattern_8
and
we
run
more
pattern_5
and
more
component_14
will
the
quality_attribute_4
stay
low
”
and
it
do
if
we
have
five
pattern_5
and
five
component_14
we
already
achieve
our
connector_data_2
per
second
but
look
at
the
quality_attribute_4
m
compare
to
what
we
have
before
a
big
improvement
and
sure
enough
if
you
have
pattern_5
and
component_15
go
into
a
single
component_17
look
at
that
quality_attribute_4
and
you
re
still
achieve
connector_data_2
per
second
great
obviously
this
can
be
counterproductive
it
s
very
important
to
measure
if
you
do
your
quality_attribute_8
go
down
and
your
quality_attribute_4
go
up
always
measure
these
number
might
not
be
optimal
for
you
but
they
be
optimal
here
this
be
what
it
look
when
you
have
pattern_5
and
component_14
you
confirm
every
connector_data_3
this
be
what
the
flow
look
you
have
under
microsecond
the
99th
percentile
you
have
high
quality_attribute_8
everything
be
great
this
be
one
component_17
by
the
way
no
sharded
component_17
no
multiple
component_17
one
component_17
connector_data_3
s
with
component_17
mirror
most
of
you
use
component_17
mirror
maybe
most
of
the
requirement_4
that
i
work
with
they
use
component_17
mirror
by
default
this
be
the
quality_attribute_4
that
you
connector_1
when
you
have
one
component_17
mirror
m
connector_data_3
you
another
component_17
mirror
it
double
and
it
connector_3
much
much
bad
from
here
bless
a
technology_1
wayne
enter
the
stage
in
my
role
with
pivotal
i
work
with
requirement_4
in
either
of
pre
sale
or
after
they’ve
purchase
in
a
consumption
help
everybody
s
subscription
today
and
so
we
re
help
them
to
connector_12
the
technology_10
in
the
requirement_6
of
this
large
requirement_2
requirement_4
they
be
try
to
connector_14
a
large
it
be
an
mq
pattern_3
replacement
they
have
various
type
of
workload
those
workload
include
the
fact
that
they
be
use
other
of
our
component_7
that
also
use
technology_1
in
their
requirement_6
that
be
technology_11
requirement_7
component_7
which
be
a
set
of
component_7
that
we
have
in
develop
requirement_7
requirement_10
component_18
they
go
through
all
the
generation
of
we
connector_data_4
them
tile
which
be
our
package
release
of
technology_1
that
run
on
technology_12
i
really
t
connector_1
involve
in
technology_1
unless
it
s
run
on
technology_12
in
their
requirement_6
they
be
use
it
with
technology_11
requirement_7
dataflow
technology_11
requirement_7
connector_15
and
technology_11
requirement_7
component_7
all
use
the
technology_1
underneath
a
well
a
all
the
component_5
that
they
be
migrate
from
mq
pattern_3
they
have
be
with
u
now
for
about
three
year
and
in
our
early
day
of
work
with
them
because
there
be
so
much
effort
and
energy
be
apply
to
replace
the
old
workload
onto
technology_1
pattern_3
we
actually
have
weekly
meet
with
them
of
which
some
of
those
gerhard
be
involve
and
listen
to
them
explain
their
requirement_11
or
quality_attribute_9
issue
that
be
come
up
with
technology_1
in
our
early
release
of
technology_1
on
pcf
tile
it
be
pre
provision
we
use
a
provision
technology_13
underneath
requirement_7
foundry
that
s
connector_16
bosh
bosh
be
really
a
vm
for
quality_attribute_10
term
a
vm
manager
they
would
manage
the
cluster
that
we
spin
up
those
pre
provision
rabbit
cluster
would
basically
provision
a
component_6
by
quality_attribute_11
or
provision
a
vhost
for
them
and
so
it
be
a
pattern_9
environment
and
in
their
particular
scenario
where
they
re
try
to
run
technology_11
requirement_7
component_7
and
technology_11
requirement_7
dataflow
and
then
also
their
component_5
on
technology_1
they
be
find
that
pattern_9
component_19
would
be
very
hard
to
manage
and
so
it
use
to
look
i
m
show
on
the
right
where
the
component_5
use
container
they
re
all
quality_attribute_5
in
container
and
then
the
bosh
release
of
rabbit
be
manage
vms
and
it
would
go
through
an
ha
pattern_10
and
then
hit
the
component_6
that
be
background
to
introduce
that
what
we
want
to
help
them
with
recently
be
the
fact
that
our
generation
of
tile
a
refer
to
a
on
demand
pattern_3
the
on
demand
pattern_3
bring
up
a
separate
cluster
per
connector_data_6
for
provision
that
isolate
that
workload
they
have
do
this
previously
with
almost
a
hack
or
a
workaround
that
we
have
that
we’ve
connector_16
tile
replicator
the
tile
replicator
would
bring
up
another
pattern_9
environment
they
actually
have
three
that
they
be
run
they
separate
out
technology_11
requirement_7
component_7
that
be
use
technology_1
from
their
pattern_11
workload
from
their
more
transient
type
of
workload
they
have
three
that
they
be
run
and
so
they
want
to
test
how
the
technology_1
would
perform
under
two
scenario
in
their
connector_data_5
center
one
be
the
fact
that
they
be
migrate
to
on
demand
technology_1
pattern_3
which
would
provide
the
isolation
they
technology_14
be
wait
for
the
second
one
be
they
want
to
introduce
a
technology_10
that
s
connector_17
by
our
sibling
requirement_5
vmware
that
s
connector_16
nsx
t
which
provide
a
rich
requirement_12
base
quality_attribute_12
and
requirement_9
isolation
for
container
to
container
requirement_9
with
a
meet
at
with
gerhard
he
introduce
them
to
this
project
that
it
s
quality_attribute_13
to
all
of
you
it
s
connector_16
the
workload
project
so
we
go
into
the
connector_data_5
center
to
help
with
that
when
we
go
in
the
connector_data_5
center
there
be
one
other
issue
that
be
very
interest
to
them
and
that
be
the
topic
of
how
could
they
quality_attribute_11
to
technology_1
cluster
across
quality_attribute_14
zone
they
have
connector_18
a
paper
that
be
author
by
dan
carwin
that’s
sit
down
here
on
the
impact
of
quality_attribute_14
zone
and
technology_1
cluster
what
they
want
to
do
be
avoid
the
requirement_9
partitioning
or
split
brain
a
some
people
connector_data_4
it
and
so
the
advice
that
be
give
the
that
dan
connector_7
the
white
paper
be
basically
connector_19
technology_15
and
technology_16
but
didn
t
really
say
a
lot
about
vsphere
we
suggest
they
use
the
workload
project
and
test
it
for
themselves
because
give
the
right
situation
vsphere
could
quality_attribute_11
technology_1
technology_17
across
quality_attribute_14
zone
and
so
that
be
part
of
what
we
be
test
run
the
workload
project
i
ve
mention
this
already
we
run
three
of
the
workload
in
the
project
the
situation
that
come
to
u
be
that
they
say
“we
want
you
to
tell
u
what
type
of
topology
you
need
to
run
with
your
technology_1
so
give
u
the
right
answer
”
we
say
”we
technology_14
rather
you
run
the
workload
project
and
you
tell
yourself
whether
you
have
the
right
topology
and
whether
this
be
work
”
in
a
particular
requirement_6
i
think
it
be
the
lazy
component_17
one
the
lqs
be
actually
do
with
discussion
with
gerhard
listen
to
the
client’s
description
of
their
workload
and
then
these
use
requirement_6
be
lay
out
for
them
the
lqs
be
the
lazy
component_17
implementation
the
dq
be
quality_attribute_15
component_17
and
within
that
component_20
if
we
take
you
out
there
you
technology_14
find
that
it
describe
what
physical
configuration
be
be
use
under
what
requirement_9
it
actually
show
you
typical
off
of
our
continuously
run
requirement_11
test
what
datadog
be
reveal
through
pattern_2
those
connector_20
in
our
requirement_6
there
be
also
an
implementation
that
allow
u
to
do
what
we
connector_data_4
cf
connector_8
for
pivotal
technology_12
you
can
connector_8
the
component_4
out
use
requirement_11
test
parameter
you
can
affect
everything
that
you
saw
in
early
demo
today
number
of
component_14
number
of
pattern_5
delay
on
connector_data_3
and
other
parameter
that
you
can
pass
we
actually
run
that
with
this
in
this
requirement_6
on
the
final
test
that
we
do
with
this
component_6
what
they
really
want
to
do
be
test
the
saturation
in
the
requirement_9
we
use
the
non
quality_attribute_15
component_2
with
autoack
that
would
basically
keep
everything
in
memory
connector_7
nothing
to
disk
and
flood
the
requirement_9
in
their
requirement_6
i
t
if
you
can
see
this
but
there
s
this
be
all
quality_attribute_14
zone
they
spread
a
technology_1
cluster
on
vsphere
across
the
quality_attribute_14
zone
in
the
bottom
one
it
show
where
it
be
a
single
lazy
component_17
or
i
have
that
mix
up
what
we
find
out
by
run
the
workload
project
in
their
configuration
use
the
admin
technology_13
that
there
be
very
little
difference
in
the
connector_21
on
spread
the
technology_17
across
the
quality_attribute_14
zone
and
have
it
all
on
a
single
quality_attribute_14
zone
there
be
a
slight
degradation
but
not
enough
to
bother
them
in
their
particular
situation
they
want
to
be
able
to
strike
their
technology_1
technology_17
across
quality_attribute_14
zone
that
will
not
fit
others
in
fact
that
s
oftentimes
one
of
the
more
frequent
question
that
come
in
to
our
support
“why
be
i
have
a
split
brain
or
a
requirement_9
partitioning
”
because
they
ve
spread
their
technology_17
across
their
az
which
be
not
typically
a
quality_attribute_3
idea
in
this
particular
vsphere
configuration
it
work
this
be
one
example
of
how
we
use
actual
test
for
the
component_6
to
be
comfortable
with
the
technology_1
configuration
that
they
want
to
use
in
their
production
environment
high
quality_attribute_8
technology_1
vehicle
telemetry
and
gerhard
enter
the
stage
wayne
give
you
a
taste
for
high
quality_attribute_8
when
he
talk
about
how
many
connector_data_2
per
second
to
saturate
the
requirement_9
i
want
to
also
talk
about
a
high
quality_attribute_8
technology_1
deployment
this
be
the
component_11
of
vehicle
telemetry
and
come
from
car
real
world
high
quality_attribute_8
technology_1
this
specific
technology_1
deployment
have
to
handle
peak
of
car
we
have
two
rush
hour
morning
and
evening
rush
hour
when
those
peak
would
happen
you
technology_14
have
million
vehicle
all
connector_5
all
sort
of
even
though
the
connector_data_2
per
second
weren
t
a
high
per
se
it
have
only
per
second
the
problem
be
their
size
they
be
very
big
connector_data_3
the
other
problem
be
that
there
be
two
component_7
connector_22
those
connector_data_3
you
be
effectively
multiplexing
the
ingres
those
external
component_18
they
would
have
a
maximum
quality_attribute_8
which
would
be
lower
than
the
ingres
rate
this
be
a
problem
because
what
do
you
do
with
the
extra
connector_data_2
come
in
in
this
requirement_6
the
right
thing
for
this
requirement_4
be
to
buffer
those
connector_data_3
if
you
have
million
connector_data_3
that
s
a
lot
of
connector_data_3
the
expectation
be
that
all
of
them
will
eventually
be
connector_12
that
rush
hour
peak
be
go
to
go
away
and
those
back
end
component_7
would
also
be
continuously
improve
i
obviously
can
t
mention
any
name
but
the
requirement_4
be
present
in
this
room
and
so
i
m
basically
say
the
same
thing
again
because
even
though
this
connector_data_3
be
connector_4
some
time
ago
it
didn
t
make
it
through
the
entire
hopefully
if
i
m
talk
about
this
on
stage
it
s
official
and
everyone
listen
to
this
talk
will
do
the
thing
that
we
recommend
them
do
we
talk
about
component_4
do
technology_1
have
enough
requirement_9
capacity
the
first
question
that
you
need
to
answer
be
“does
technology_1
have
enough
requirement_9
capacity
”
in
this
requirement_6
there
be
a
lot
of
connector_data_5
come
in
and
a
lot
of
connector_data_5
go
out
and
you
have
to
count
both
connector_data_5
come
in
and
connector_data_5
go
out
because
technology_1
be
a
river
those
connector_data_2
have
to
eventually
go
out
it
s
not
sufficient
to
provision
sufficient
capacity
for
incoming
connector_data_3
you
also
have
to
count
outgoing
connector_data_3
also
5+5
you
would
think
it
s
but
it
s
the
reason
why
it
s
be
because
you
need
extra
capacity
what
happen
if
a
load
balancer
go
away
be
you
go
to
drop
half
the
connector_data_2
or
not
connector_23
what
s
go
to
happen
so
you
always
need
to
have
more
capacity
these
be
connector_data_3
body
there
be
a
technology_18
overhead
there
be
technology_19
ip
overhead
there
be
lot
and
lot
of
thing
which
overhead
you
can
t
count
the
connector_data_3
connector_data_7
and
nothing
else
the
load
balancer
if
you
have
load
balancer
from
the
technology_1
it
doesn
t
matter
how
fast
the
technology_1
technology_17
requirement_9
be
you
need
to
do
the
same
for
the
load
balancer
i
would
argue
that
you
might
not
want
load
balancer
in
front
of
technology_1
but
that
s
my
perspective
and
it
s
very
contentious
so
s
discus
after
this
talk
i
enjoy
that
discussion
very
much
high
quality_attribute_14
pattern_10
you
can
see
here
that
we
be
measure
the
ingres
and
the
egress
for
the
high
quality_attribute_14
pattern_10
there
be
two
high
quality_attribute_14
pattern_10
that
s
roughly
gigabit
per
ha
pattern_10
time
gigabit
they
be
the
one
which
have
the
high
requirement_9
quality_attribute_8
connector_13
connector_data_2
to
fast
disk
you
have
all
these
connector_data_2
come
in
you
have
sufficient
requirement_9
can
your
disk
cope
with
those
connector_data_3
or
can
your
memory
cope
with
those
connector_data_3
there
be
a
lot
of
connector_data_5
come
in
what
do
you
do
with
them
our
recommendation
be
to
connector_13
connector_data_2
straight
to
disk
you
would
use
lazy
component_17
what
you
do
not
want
to
do
be
mirror
those
lazy
component_2
because
that
a
lot
of
requirement_9
overhead
and
especially
do
not
automatically
synchronize
lazy
component_2
which
have
lot
of
connector_data_2
in
them
it
s
very
bad
s
talk
about
that
a
well
it
s
not
sufficient
to
manage
disk
quality_attribute_8
there
be
two
valley
that
you
need
to
keep
in
mind
the
disk
quality_attribute_8
which
be
maybe
byte
megabyte
or
whatever
it
be
and
the
iop
the
quality_attribute_8
might
be
sufficient
but
your
iop
might
not
you
need
to
be
aware
of
both
requirement_13
our
friend
from
intel
be
here
today
they
have
a
very
quality_attribute_3
story
about
intel
optane
nvmes
they’re
amaze
disk
i
can
tell
you
more
about
them
we
ve
do
some
benchmark
they
re
great
we
can
see
here
the
disk
quality_attribute_8
we
what
our
limit
be
very
important
we
where
we
be
within
those
limit
both
for
bandwidth
and
iop
if
you
t
measure
these
thing
finger
in
the
wind
it
doesn
t
work
it
really
doesn
t
work
you
can
also
see
the
technology_1
connector_data_2
which
be
pattern_12
up
we
have
million
and
slowly
grow
what
s
your
capacity
be
you
within
capacity
what
s
happen
also
we
can
see
the
memory
usage
be
nice
and
flat
and
quality_attribute_16
through
all
technology_17
for
the
entire
duration
of
this
peak
rush
hour
it
s
a
simulation
persistent
connector_data_3
component_21
most
of
you
might
not
this
but
there
be
an
technology_4
component_13
which
be
responsible
for
persist
connector_data_2
to
disk
there
be
only
one
in
there
use
to
be
one
per
technology_17
so
all
the
component_2
everything
on
one
technology_1
technology_17
would
go
through
this
one
technology_4
component_13
that
would
flush
connector_data_2
to
disk
would
connector_7
connector_data_2
to
disk
and
that
would
connector_1
overload
in
our
requirement_6
since
there
be
one
per
vhost
the
work
that
we
do
have
somewhat
an
impact
on
our
consideration
for
the
persistent
component_21
how
do
you
when
the
connector_data_3
component_21
be
under
pressure
you
might
not
have
see
this
or
might
not
have
notice
this
but
your
component_2
will
enter
in
a
flow
state
that
mean
that
the
connector_data_3
component_21
be
exercise
back
pressure
on
the
component_17
there
be
a
very
quality_attribute_3
it
go
way
back
when
which
explain
the
back
pressure
in
technology_1
the
connector_data_3
component_21
be
the
last
connector_24
in
the
chain
which
exercise
back
pressure
metric
when
many
connector_25
pattern_13
and
component_2
by
default
there
be
too
many
metric
connector_26
but
component_1
expect
that
and
component_1
that
and
that
s
one
of
rabbitmq’s
great
feature
you
have
the
ui
and
you
can
see
all
the
metric
that
s
great
but
if
you
have
many
connector_25
many
pattern_13
many
component_17
it
might
not
be
such
a
quality_attribute_3
thing
actually
in
the
entire
metric
component_12
be
rewrite
because
one
technology_17
use
to
handle
all
the
metric
and
would
continuously
crash
over
for
this
specific
requirement_4
and
we
have
two
team
member
which
do
an
amaze
work
on
that
it
take
them
quite
a
lot
of
toil
to
connector_1
it
do
but
it
s
so
much
quality_attribute_3
since
do
you
need
to
generate
metric
every
second
the
fact
that
the
ui
need
to
refresh
every
second
and
be
expect
fresh
metric
you
might
not
need
to
capture
them
every
second
it
might
be
bad
for
your
use
requirement_6
do
you
need
to
keep
them
for
up
to
hour
okay
you
have
bucket
and
you
have
rotation
but
do
you
need
them
my
preference
be
to
extract
all
the
metric
into
purpose
build
component_22
which
be
external
to
technology_1
it
will
connector_27
you
a
lot
of
trouble
it
definitely
work
in
this
requirement_6
component_23
sharded
component_2
for
high
quality_attribute_8
technology_1
sharding
have
be
mention
today
i
think
at
least
once
technology_1
sharding
work
very
well
but
it
s
not
the
first
thing
that
you
should
go
to
quality_attribute_17
on
your
use
requirement_6
in
this
requirement_6
it
do
make
sense
we
want
to
have
a
single
logical
component_17
you
can
t
define
it
it
s
there
in
the
component_12
you
use
it
and
the
component_17
be
back
by
component_17
shard
that
run
on
every
single
technology_17
the
component_17
be
always
quality_attribute_7
a
long
a
there
be
one
technology_17
quality_attribute_7
if
you
t
have
pause
minority
s
talk
about
that
a
well
if
you
want
the
best
thing
in
this
requirement_6
be
that
the
pattern_5
and
component_14
they
publish
and
connector_12
from
component_17
shard
local
to
their
technology_17
this
will
limit
inter
cluster
traffic
it
s
really
quality_attribute_3
you
can
see
here
how
we
have
all
these
different
technology_17
that
have
a
very
even
spread
when
it
come
to
ingest
connector_data_2
and
connector_28
connector_data_3
it
s
a
nice
even
spread
technology_1
sharding
make
it
super
easy
high
quality_attribute_18
technology_1
with
that
we
go
to
the
last
workload
type
the
last
technology_1
workload
talk
about
high
quality_attribute_18
it
be
in
the
component_11
of
medical
equipment
a
real
world
high
quality_attribute_18
technology_1
the
problem
here
be
the
number
of
connector_25
and
more
importantly
number
of
component_17
there
be
component_17
every
medical
component_24
have
one
component_17
there
be
many
long
live
connector_25
the
quality_attribute_8
be
rather
low
only
connector_data_2
per
second
and
they
be
there
be
small
connector_data_2
a
well
the
challenge
be
the
component_2
and
the
connector_25
but
more
the
component_17
few
technology_17
be
best
how
do
you
quality_attribute_18
rabbit
you
more
technology_17
right
well
maybe
not
actually
few
technology_17
be
best
there
be
a
few
reason
for
it
every
technology_17
in
the
cluster
connector_29
with
every
other
technology_17
the
more
technology_17
you
the
chatter
between
technology_17
increase
a
lot
but
that
s
not
the
worst
part
when
a
technology_17
go
away
you
have
a
cluster
technology_17
that
go
away
all
the
remain
technology_17
have
to
clean
up
the
state
of
that
technology_17
they
all
do
it
concurrently
there
be
a
to
do
that
go
way
back
many
year
but
we
re
work
on
it
the
worst
part
possibly
be
that
the
technology_1
metadata
need
to
synchronize
across
all
technology_17
the
more
technology_17
you
any
have
to
be
synchronize
in
all
technology_17
before
“yep
it
s
all
quality_attribute_3
”
these
be
the
technology_1
metadata
bind
component_17
definition
exchange
stuff
that
this
be
what
your
three
technology_17
cluster
look
right
technology_1
be
a
complete
graph
every
technology_17
talk
to
every
other
technology_17
it
look
very
nice
this
be
what
happen
when
you
go
to
seven
technology_17
right
it
look
bad
criss
cross
lot
of
stuff
connector_25
be
not
free
connector_25
be
not
free
they
cost
memory
it
connector_3
bad
because
component_25
have
more
and
more
memory
so
by
default
the
technology_19
technology_20
be
use
more
and
more
memory
today
in
a
typical
component_12
they
will
use
about
a
kb
even
if
they
re
not
use
anything
if
you
tune
this
you
can
free
up
many
gb
of
memory
by
tune
this
one
parameter
you
can
do
this
straight
from
technology_1
by
the
way
you
t
need
to
go
in
the
kernel
be
default
metric
right
for
you
again
the
default
metric
keep
come
up
because
you
might
connector_26
metric
that
you
t
even
care
about
there
s
a
lot
of
pressure
on
the
metric
component_12
even
though
it
s
quality_attribute_3
do
you
need
to
component_21
all
those
metric
do
you
need
to
generate
them
a
often
and
again
extract
same
advice
a
before
exchange
and
component_17
type
difference
lastly
you
technology_14
think
that
every
exchange
and
every
component_17
type
maybe
be
fast
when
it
come
to
there
be
difference
for
example
if
you
have
to
bind
a
component_2
to
exchange
if
the
exchange
be
a
topic
exchange
and
if
the
component_17
be
a
quality_attribute_15
component_17
you
will
top
up
around
bind
second
this
be
quality_attribute_3
now
it
connector_3
quality_attribute_3
all
the
time
to
do
component_17
it
will
take
minute
a
direct
exchange
be
the
fast
and
a
non
quality_attribute_15
component_17
be
fast
the
reason
for
this
be
there
be
le
in
mnesia
it
mean
that
the
same
component_17
bind
you
can
finish
them
in
six
minute
it
s
a
big
difference
from
in
summary
this
be
where
i
want
to
connector_1
to
the
summary
it
s
very
very
important
to
what
you
re
try
to
connector_1
from
technology_1
because
it
s
so
quality_attribute_1
you
can
connector_1
anything
from
it
everything
be
possible
within
reason
obviously
but
everything
be
possible
you
can
go
a
crazy
a
you
want
what
be
you
try
to
achieve
be
it
low
quality_attribute_4
that
you
care
about
be
it
quality_attribute_8
that
you
care
about
what
do
you
care
about
it
s
important
not
to
mix
workload
if
you
have
a
technology_1
that
s
suppose
to
connector_4
you
low
quality_attribute_4
and
high
quality_attribute_8
that
s
not
go
to
work
think
about
racetrack
in
a
race
track
car
go
a
fast
a
possible
think
about
motorway
it
s
about
volume
they
re
different
problem
surprisingly
90%
of
technology_1
issue
be
down
to
component_4
you
wouldn
t
believe
what
a
difference
a
quality_attribute_3
component_4
or
a
quality_attribute_3
component_6
that
what
it
s
try
to
achieve
and
it
s
configure
for
it
intend
purpose
it
make
a
huge
difference
how
can
you
help
maybe
some
of
you
be
wonder
“this
be
great
i
want
to
help
”
how
can
you
help
contribute
your
observation
take
a
look
at
the
baseline
wayne
mention
workload
“what
s
possible
what
s
the
baseline
”
so
that
we
can
be
your
environment
bad
be
you
do
something
bad
be
we
improve
thing
be
thing
connector_30
bad
or
quality_attribute_3
in
technology_1
we
hope
it
s
important
to
what
the
start
point
be
tell
u
about
your
workload
i
m
sure
you
have
workload
that
we
haven
t
hear
about
maybe
you
haven
t
even
think
about
this
maybe
quality_attribute_19
the
most
important
thing
hence
quorum
component_17
what
metric
be
important
we
would
to
when
it
come
to
tune
different
thing
or
run
different
workload
which
metric
do
you
wish
you
have
in
technology_1
we
can
make
some
assumption
but
we
would
your
input
i
think
we
have
a
few
more
minute
for
question
either
to
myself
or
wayne
thank
you
applause
question
from
the
audience
what
s
your
minimum
technology_17
count
in
technology_1
pattern_3
cluster
with
high
quality_attribute_14
two
be
enough
or
should
i
start
with
three
i
would
say
three
i
would
say
three
because
pause
minority
and
quorum
component_17
they
require
three
technology_17
it
be
mention
to
not
use
multi
quality_attribute_14
zone
in
a
cluster
i
do
so
fairly
heavily
across
multiple
component_2
with
high
technology_21
quality_attribute_8
i
be
wonder
what
kind
of
scenario
you
see
where
people
be
run
into
component_16
issue
be
it
a
traffic
issue
be
it
a
requirement_7
technology_7
issue
because
i
haven
t
see
it
i
think
we
would
find
it
s
a
requirement_7
technology_7
issue
because
cluster
require
low
quality_attribute_4
for
the
pattern_14
between
the
technology_17
oftentimes
it
s
not
fast
enough
when
you
spread
that
across
quality_attribute_14
zone
and
say
technology_15
that
s
where
i’ve
run
into
it
a
lot
we
talk
about
the
concept
of
az
s
from
a
pcf
perspective
and
az
s
from
the
requirement_7
perspective
they
re
not
always
talk
about
the
same
concept
it
s
really
important
to
understand
what
they
do
and
if
they
connector_1
physically
quality_attribute_11
the
time
to
pass
the
pattern_14
between
the
technology_17
be
not
sufficient
and
so
technology_1
will
connector_1
confuse
and
think
it
s
in
a
split
brain
scenario
when
it
be
a
quality_attribute_4
issue
with
the
pattern_14
yeah
i
ve
run
into
it
even
when
it
wasn
t
pivotal
requirement_7
foundry
when
they
be
run
on
straight
technology_15
come
back
on
this
multi
az
set
up
what
kind
of
component_16
handle
mode
be
you
use
be
you
successfully
use
pause
minority
across
quality_attribute_14
zone
it
be
the
default
requirement_12
for
pcf
be
pause
minority
they
t
have
to
select
that
but
that
generally
be
what
we
see
requirement_4
do
because
that
s
the
default
from
our
configuration
there
be
some
very
nice
requirement_14
in
this
presentation
how
can
technology_1
component_1
adopt
this
kind
of
awesome
pattern_2
and
generate
all
those
requirement_14
can
you
please
tell
u
more
about
it
that’s
such
a
lead
question
thank
you
michael
thank
you
the
component_6
requirement_14
when
it
come
to
connector_data_3
quality_attribute_4
perf
test
since
have
requirement_10
support
with
prometheus
a
well
a
others
it
s
use
micrometer
so
it
s
able
to
connector_31
a
lot
of
metric
internally
about
the
component_6
via
micrometer
when
it
come
to
technology_1
there
s
a
plugin
a
third
party
plug
in
plug
in
prometheus
technology_1
exporter
we
haven
t
see
any
requirement_14
here
but
it
s
another
quality_attribute_3
way
of
connector_30
those
metric
in
prometheus
if
you
use
that
the
requirement_14
that
you
ve
see
at
the
very
begin
they
be
grafana
there
s
a
requirement_15
i
mention
that
it
s
you
can
see
more
detail
here
you
can
see
the
connector_24
to
the
actual
requirement_15
that
s
a
low
quality_attribute_4
one
we
have
a
few
others
we
have
one
which
basically
track
the
technology_4
memory
allocation
and
memory
allocator
it’s
very
detail
it
s
part
of
be
requirement_15
there
be
a
few
others
which
we
haven
t
make
yet
but
we
re
slowly
connector_30
there
enjoy
this
t
forget
to
connector_2
it
with
others
😉
daniel
marklund
developer
free
ebook
the
optimal
technology_1
guide
download
your
copy
tweet
by
technology_2
technology_2
requirement_16
lead
technology_1
a
a
component_18
start
your
manage
cluster
today
technology_2
be
100%
free
to
try
start
your
free
plan
today
000+
component_1
include
these
smart
requirement_5
home
tour
requirement_1
documentation
support
requirement_4
about
u
resource
changelog
faq
legal
and
requirement_12
quality_attribute_12
and
compliance
status
need
help
support
open
hour
a
day
day
a
week
talk
to
sale
+1
sale
inquiry
only
open
cst
bring
to
you
by
www
84codes
technology_22
our
component_7
cloudkarafka
–
technology_23
technology_24
elephantsql
–
technology_25
cloudmqtt
–
technology_26
©
copyright
cloudamqp
technology_1
and
the
technology_1
logo
be
trademark
of
vmware
inc
