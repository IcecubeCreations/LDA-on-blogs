build
a
high
requirement_1
technology_1
requirement_2
build
a
high
requirement_1
technology_1
requirement_2
dave
cheney
dave@cheney
net
version
{revnumber}
component_1
of
content
problem
statement
design
time
complexity
tokenisation
eliminate
allocation
through
component_2
design
connector_1
scan
decoding
unmarshalling
thematic
idea
requirement_1
matter
sometimes
further
work
bonus
abstract
technology_1
be
important
damn
near
everything
that
we
do
a
programmer
or
operator
involve
technology_1
at
some
point
technology_1
decoding
be
expensive
if
your
technology_2
talk
technology_1
then
requirement_1
of
marshal
connector_data_1
in
and
out
of
technology_1
be
important
this
be
a
talk
about
design
an
quality_attribute_1
replacement
for
encoding
technology_3
decoder
the
for
this
talk
be
quality_attribute_2
technology_4
technology_5
technology_6
pkg
technology_3
thanks
to
jon
forrest
and
dave
russell
for
copy
edit
problem
statement
technology_1
be
an
important
connector_data_1
interchange
technology_7
damn
near
everything
we
do
a
programmer
involve
technology_1
in
some
way
at
the
same
time
technology_1
decoding
be
expensive
every
go
release
we
see
improvement
in
the
quality_attribute_3
of
the
encoding
technology_3
package
sometimes
these
be
large
improvement
the
move
away
from
segment
technology_8
in
go
more
recently
these
improvement
have
be
moderate
in
the
cycle
iâve
see
two
requirement_1
improvement
that
have
to
be
roll
back
because
while
they
make
it
fast
they
break
a
subtle
implicit
behaviour
that
people
be
rely
on
technology_9
f
hyrum’s
law
in
the
go
ecosystem
there
be
a
bunch
of
alternative
technology_1
technology_10
usually
maintain
by
a
small
number
of
people
so
this
suggest
to
me
that
this
be
a
problem
with
some
meat
on
it
bone
and
equally
not
impenetrable
i
figure
i’d
give
it
a
try
connector_data_2
at
the
low
level
pkg
technology_3
scanner
can
tokenize
connector_2
technology_1
without
allocation
provide
it
be
supply
a
few
kilobyte
of
buffer
benchmarkscanner
canada
n
op
connector_data_3
s
b
op
allocs
op
benchmarkscanner
citm_catalog
n
op
connector_data_3
s
b
op
allocs
op
benchmarkscanner
twitter
n
op
connector_data_3
s
b
op
allocs
op
benchmarkscanner
n
op
connector_data_3
s
b
op
allocs
op
benchmarkscanner
example
n
op
connector_data_3
s
b
op
allocs
op
benchmarkscanner
sample
n
op
connector_data_3
s
b
op
allocs
op
at
the
next
level
pkg
technology_3
decoder
connector_data_4
be
3x
fast
than
encoding
technology_3
decoder
connector_data_4
benchmarkdecodertoken
pkgjson
canada
n
op
connector_data_3
s
b
op
allocs
op
benchmarkdecodertoken
encodingjson
canada
n
op
connector_data_3
s
b
op
allocs
op
benchmarkdecodertoken
pkgjson
citm_catalog
n
op
connector_data_3
s
b
op
allocs
op
benchmarkdecodertoken
encodingjson
citm_catalog
n
op
connector_data_3
s
b
op
allocs
op
benchmarkdecodertoken
pkgjson
twitter
n
op
connector_data_3
s
b
op
allocs
op
benchmarkdecodertoken
encodingjson
twitter
n
op
connector_data_3
s
b
op
allocs
op
benchmarkdecodertoken
pkgjson
n
op
connector_data_3
s
b
op
allocs
op
benchmarkdecodertoken
encodingjson
n
op
connector_data_3
s
b
op
allocs
op
benchmarkdecodertoken
pkgjson
example
n
op
connector_data_3
s
b
op
allocs
op
benchmarkdecodertoken
encodingjson
example
n
op
connector_data_3
s
b
op
allocs
op
benchmarkdecodertoken
pkgjson
sample
n
op
connector_data_3
s
b
op
allocs
op
benchmarkdecodertoken
encodingjson
sample
n
op
connector_data_3
s
b
op
allocs
op
because
allocation
make
up
a
large
proportion
of
the
decoder
connector_data_4
technology_11
pkg
technology_3
decoder
provide
an
alternative
component_2
that
produce
significantly
few
allocation
and
be
10x
fast
benchmarkdecodernexttoken
pkgjson
canada
n
op
connector_data_3
s
b
op
allocs
op
benchmarkdecodernexttoken
encodingjson
canada
n
op
connector_data_3
s
b
op
allocs
op
benchmarkdecodernexttoken
pkgjson
citm_catalog
n
op
connector_data_3
s
b
op
allocs
op
benchmarkdecodernexttoken
encodingjson
citm_catalog
n
op
connector_data_3
s
b
op
allocs
op
benchmarkdecodernexttoken
pkgjson
twitter
n
op
connector_data_3
s
b
op
allocs
op
benchmarkdecodernexttoken
encodingjson
twitter
n
op
connector_data_3
s
b
op
allocs
op
benchmarkdecodernexttoken
pkgjson
n
op
connector_data_3
s
b
op
allocs
op
benchmarkdecodernexttoken
encodingjson
n
op
connector_data_3
s
b
op
allocs
op
benchmarkdecodernexttoken
pkgjson
example
n
op
connector_data_3
s
b
op
allocs
op
benchmarkdecodernexttoken
encodingjson
example
n
op
connector_data_3
s
b
op
allocs
op
benchmarkdecodernexttoken
pkgjson
sample
n
op
connector_data_3
s
b
op
allocs
op
benchmarkdecodernexttoken
encodingjson
sample
n
op
connector_data_3
s
b
op
allocs
op
at
the
high
level
pkg
technology_3
can
unmarshal
connector_data_1
into
a
go
connector_data_5
with
the
same
component_2
a
encoding
technology_3
this
be
very
much
a
work
in
progress
but
the
connector_data_2
be
promise
for
folk
who
want
to
use
this
package
a
a
drop
in
replacement
benchmarkdecoderdecodeinterfaceany
pkgjson
canada
n
op
connector_data_3
s
b
op
allocs
op
benchmarkdecoderdecodeinterfaceany
encodingjson
canada
n
op
connector_data_3
s
b
op
allocs
op
benchmarkdecoderdecodeinterfaceany
pkgjson
citm_catalog
n
op
connector_data_3
s
b
op
allocs
op
benchmarkdecoderdecodeinterfaceany
encodingjson
citm_catalog
n
op
connector_data_3
s
b
op
allocs
op
benchmarkdecoderdecodeinterfaceany
pkgjson
twitter
n
op
connector_data_3
s
b
op
allocs
op
benchmarkdecoderdecodeinterfaceany
encodingjson
twitter
n
op
connector_data_3
s
b
op
allocs
op
benchmarkdecoderdecodeinterfaceany
pkgjson
n
op
connector_data_3
s
b
op
allocs
op
benchmarkdecoderdecodeinterfaceany
encodingjson
n
op
connector_data_3
s
b
op
allocs
op
benchmarkdecoderdecodeinterfaceany
pkgjson
example
n
op
connector_data_3
s
b
op
allocs
op
benchmarkdecoderdecodeinterfaceany
encodingjson
example
n
op
connector_data_3
s
b
op
allocs
op
benchmarkdecoderdecodeinterfaceany
pkgjson
sample
n
op
connector_data_3
s
b
op
allocs
op
benchmarkdecoderdecodeinterfaceany
encodingjson
sample
n
op
connector_data_3
s
b
op
allocs
op
this
be
a
story
of
how
i
go
about
build
this
package
i’m
use
a
pre
release
version
of
go
build
from
component_3
if
you’re
use
an
old
version
your
number
vary
when
go
come
out
you
should
upgrade
design
the
design
of
this
package
have
the
follow
feature
reasonably
quality_attribute_4
with
the
encoding
technology_3
package
this
package
offer
the
same
high
level
technology_3
decoder
component_2
with
high
quality_attribute_5
and
or
reduce
allocation
a
success
criterion
for
this
package
would
be
a
a
drop
in
replacement
for
encoding
technology_3
support
connector_2
itâs
nice
if
you
can
have
the
entire
input
in
memory
but
thatâs
unrealistic
input
size
be
usually
unknown
and
potentially
unbounded
buffer
in
memory
be
a
quality_attribute_6
risk
buffer
before
component_4
introduce
quality_attribute_7
connector_2
connector_3
you
component_4
connector_data_1
a
it
arrive
and
logically
overlap
with
transfer
or
connector_4
this
package
support
connector_2
via
io
reader
input
component_5
which
be
also
require
for
quality_attribute_8
with
encoding
technology_3
allocation
free
or
bind
component_2
in
addition
to
the
encoding
technology_3
technology_11
provide
an
alternative
component_2
that
can
operate
with
minimal
ideally
no
allocation
time
complexity
let’s
talk
about
the
time
complexity
of
this
problem
technology_1
doesn’t
use
length
marker
to
how
much
to
connector_4
we
have
to
connector_4
it
all
this
mean
the
lower
bind
on
the
time
to
component_4
the
input
be
the
size
of
the
input
but
connector_1
the
input
isn’t
enough
we
have
to
follow
the
technology_1
state
component_6
to
figure
out
where
the
connector_data_4
start
and
end
now
connector_1
n
byte
isn’t
the
full
story
we
need
to
component_4
those
n
byte
so
the
requirement_1
be
at
least
connector_4
n
+parse
n
but
there
be
other
cost
if
we
have
to
allocate
memory
to
connector_4
or
component_4
those
byte
that
overhead
will
grow
with
the
size
of
the
input
we
that
the
big
factor
in
the
requirement_1
of
a
requirement_3
be
the
size
of
the
input
ideally
we
want
n
to
be
the
number
of
byte
in
the
input
that
be
we
want
to
component_4
each
byte
only
once
if
we
touch
the
same
byte
more
than
once
that
overhead
and
complicate
component_4
if
we
have
to
keep
those
byte
around
to
come
back
and
look
at
them
again
we
don’t
want
to
component_4
a
byte
more
than
once
we
want
to
avoid
component_4
a
connector_data_4
more
than
once
limit
connector_data_6
in
the
pattern_1
path
inside
the
scanner
or
decoder
encoding
technology_3
u
one
connector_data_7
per
byte
pkg
technology_3
do
quality_attribute_9
at
one
connector_data_7
per
connector_data_4
we
want
to
limit
the
number
of
connector_data_6
per
connector_data_4
ideally
o
connector_data_4
not
o
byte
if
we
do
nothing
else
weâd
be
ahead
limit
copy
if
we
design
to
limit
copy
of
connector_data_1
then
we
limit
the
number
time
we
re
visit
a
byte
limit
allocation
if
you
limit
the
number
of
place
you
can
copy
from
and
to
ideally
only
copy
within
exist
buffer
then
you
naturally
limit
allocation
limit
allocation
reduce
runtime
in
two
way
reduce
the
overhead
in
take
the
allocation
the
heap
be
a
connector_5
resource
allocate
on
the
heap
require
work
with
connector_5
connector_data_1
connector_data_8
this
mean
lock
pattern_2
contention
etc
technology_9
f
amdahl’s
law
reduce
the
overhead
of
free
allocation
the
le
allocation
you
make
the
le
heap
you
connector_6
and
the
le
garbage
you
produce
reduce
these
two
factor
reduce
the
overhead
of
background
and
foreground
garbage
collection
tokenisation
technology_1
be
a
connector_7
of
connector_data_4
to
build
high
level
component_7
pretty
printer
and
decoder
we
need
to
break
the
connector_7
into
connector_data_4
go’s
technology_1
decoder
have
two
component_8
a
scanner
or
tokeniser
that
convert
a
connector_7
a
byte
into
a
connector_7
of
technology_1
connector_data_4
an
unmarshaller
that
apply
a
connector_7
of
technology_1
connector_data_4
to
a
go
connector_data_5
let’s
talk
about
tokenization
first
what
be
a
connector_data_4
technology_1
be
regular
well
define
grammar
there
be
a
great
set
of
requirement_4
over
on
technology_3
{
a
b
true
technology_9
two
}
be
a
connector_7
of
{
the
opening
brace
signify
a
collection
of
name
requirement_5
pair
a
the
a
a
colon
the
delimiter
between
the
key
and
the
requirement_5
in
the
key
requirement_5
pair
the
number
one
a
comma
the
delimiter
between
one
key
requirement_5
pair
and
the
next
b
the
b
true
the
boolean
requirement_5
for
true
technology_9
the
technology_9
the
opening
square
brace
signify
and
order
connector_data_9
of
requirement_5
two
a
or
requirement_5
rare
close
square
brace
terminate
the
connector_data_9
of
requirement_5
}
close
curly
brace
terminate
the
key
requirement_5
collection
encoding
technology_3
do
this
with
the
decoder
connector_data_4
technology_11
you
declare
a
technology_3
decoder
then
connector_data_7
connector_data_4
until
err
be
non
nil
package
encoding
technology_3
fmt
func
{
input
=
`{
a
b
true
technology_9
two
}`
dec
=
technology_3
newdecoder
newreader
input
for
{
tok
err
=
dec
connector_data_4
if
err
=
nil
{
break
}
fmt
printf
%v\t
%t
\n
tok
tok
}
}
when
we
run
this
we
connector_8
the
follow
output
{
technology_3
delim
a
float64
b
true
bool
technology_9
technology_3
delim
float64
two
nil
nil
technology_3
delim
}
technology_3
delim
this
be
rather
convenient
tok
be
an
interface{}
requirement_5
so
it
can
represent
both
the
requirement_5
be
and
also
it
type
be
number
be
float64
booleans
be
real
true
and
false
even
be
represent
a
a
nil
but
there
be
a
cost
to
this
convenience
to
see
why
let’s
talk
about
a
var
b
=
make
byte
var
s
=
b
when
we
connector_9
the
statement
s
=
b
the
compiler
make
a
copy
of
b
because
the
rule
of
go
mandate
that
be
immutable
if
a
and
a
byte
slice
connector_5
the
same
back
connector_data_1
then
connector_10
b
could
connector_10
the
content
of
s
this
would
be
bad
thus
the
expression
b
make
a
copy
of
the
content
of
b
now
look
at
the
input
to
the
technology_3
decoder
it’s
an
io
reader
%
go
doc
encoding
technology_3
newdecoder
package
technology_3
encoding
technology_3
func
newdecoder
r
io
reader
*decoder
newdecoder
a
decoder
that
connector_3
from
r
the
decoder
introduce
it
own
buffer
and
connector_4
connector_data_1
from
r
beyond
the
technology_1
requirement_5
connector_data_10
let’s
look
at
the
io
reader
connector_4
%
go
doc
io
reader
connector_4
package
io
io
func
connector_4
p
byte
n
err
error
you
give
connector_4
a
byte
buffer
connector_4
to
you
the
number
of
byte
it
connector_4
into
the
buffer
and
possibly
an
error
now
we
the
input
be
a
connector_7
of
byte
and
the
output
be
run
float64s
bools
and
at
a
minimum
the
input
hello
be
go
to
connector_data_11
in
a
byte
slice
byte{
h
e
l
l
o
}
and
that
byte
slice
be
go
to
be
copy
to
a
package
encoding
technology_3
fmt
io
func
{
input
=
`
hello
`
var
r
io
reader
=
newreader
input
connector_3
a
byte
dec
=
technology_3
newdecoder
r
tok
_
=
dec
connector_data_4
fmt
printf
%s\t
%t
\n
tok
tok
}
the
convenience
of
the
decoder
connector_data_4
component_2
mean
one
allocation
per
connector_data_4
but
it
connector_11
bad
requirement_5
assign
to
escape
a
more
serious
issue
from
a
requirement_1
point
of
pattern_3
be
assign
a
requirement_5
to
an
generally
cause
an
allocation
because
of
the
design
of
the
decoder
connector_data_4
technology_11
the
concrete
requirement_5
assign
to
each
connector_data_4
cause
the
requirement_5
to
escape
to
the
heap
so
not
only
do
we
have
an
allocation
for
every
byte
to
conversion
but
each
connector_data_4
escape
to
the
heap
the
number
of
allocation
be
tie
to
the
number
of
connector_data_4
in
the
and
the
size
of
those
allocation
will
be
in
part
relate
to
the
size
of
the
the
reason
for
this
be
the
garbage
collector
we
all
that
an
requirement_5
be
a
two
word
connector_data_8
it
look
something
this
type
struct
{
type
uintptr
connector_data_1
uintptr
}
uintptr
above
be
not
to
suggest
that
type
and
connector_data_1
be
pointer
although
in
most
requirement_6
they
be
that
the
size
of
those
be
large
enough
to
hold
the
connector_12
of
a
requirement_5
in
memory
—
the
size
of
a
pointer
it’s
unsigned
because
a
sign
pointer
would
halve
the
connector_12
space
and
a
negative
pointer
doesn’t
make
any
sense
requirement_5
be
special
in
that
they
component_9
both
the
requirement_5
and
the
type
of
the
requirement_5
another
property
of
requirement_5
be
they
can
hold
any
requirement_5
regardless
of
their
type
in
early
go
version
it
be
possible
for
an
to
component_10
a
uintptr
or
small
requirement_5
directly
in
the
connector_data_1
of
the
however
this
connector_10
in
go
todo
connector_13
because
it
be
not
possible
to
connector_10
two
atomically
which
cause
a
problem
for
the
concurrent
collector
var
x
interface{}
=
x
=
one
from
the
point
of
pattern_3
of
the
compiler
this
must
connector_10
the
type
component_10
in
x
from
to
and
the
requirement_5
from
to
one
atomically
to
do
this
the
compiler
connector_14
a
pointer
to
the
requirement_5
in
the
connector_data_1
slot
this
mean
each
connector_data_4
escape
to
the
heap
but
it
connector_11
bad
we
that
a
go
be
itself
a
small
struct
type
struct
{
ptr
*
byte
len
}
so
to
convert
a
byte
connector_data_4
to
a
first
we
copy
the
byte
that
go
on
the
heap
then
a
be
create
and
that
go
on
the
heap
and
finally
the
pointer
to
that
go
into
the
connector_data_1
slot
in
the
package
encoding
technology_3
test
func
benchmarkjsondecodehello
b
*testing
b
{
input
=
`
hello
`
r
=
newreader
input
connector_3
a
byte
dec
=
technology_3
newdecoder
r
b
reportallocs
b
setbytes
int64
len
input
b
resettimer
for
i
=
i
b
n
i++
{
r
seek
tok
_
=
dec
connector_data_4
if
tok
=
hello
{
b
fatal
}
}
}
%
go
test
bench=
memprofile=m
p
technology_3
tok_test
go
goo
darwin
goarch
amd64
benchmarkjsondecodehello
n
op
connector_data_3
s
b
op
allocs
op
pass
ok
command
line
argument
951s
take
away
component_2
design
influence
allocation
eliminate
allocation
through
component_2
design
spoiler
alert
most
of
the
speedup
of
this
package
come
from
reduce
allocation
specifically
the
time
not
spend
in
the
heap
allocation
path
and
the
time
not
spend
in
gc
cycle
be
quality_attribute_2
for
scan
if
we
want
to
build
an
component_2
that
have
lower
allocation
than
encoding
technology_3
we
have
to
connector_12
each
of
the
problem
i’ve
discus
implicit
connector_data_4
let’s
look
back
at
the
sequence
of
connector_data_4
{
a
b
true
technology_9
two
and
}
it
turn
out
that
the
first
character
in
the
connector_data_4
tell
you
what
the
connector_data_4
be
{
}
collection
start
end
start
end
t
true
f
false
n
a
number
this
be
the
first
improvement
in
the
scanner
next
and
decoder
nexttoken
apis
rather
than
convert
the
byte
to
a
requirement_5
it
the
connector_data_4
straight
from
the
input—​a
quality_attribute_10
subslice
package
fmt
technology_5
technology_6
pkg
technology_3
func
{
input
=
`{
a
b
true
technology_9
two
}`
dec
=
technology_3
newdecoder
newreader
input
for
{
tok
err
=
dec
nexttoken
if
err
=
nil
{
break
}
fmt
printf
%s\t
%t
\n
tok
tok
}
}
{
uint8
a
uint8
uint8
b
uint8
true
uint8
technology_9
uint8
uint8
uint8
two
uint8
uint8
uint8
}
uint8
there
be
a
few
subtlety
with
this
technology_11
because
the
output
be
a
subslice
of
the
input
not
a
copy
there
be
restriction
on
how
long
the
output
be
valid
for
this
be
similar
to
the
bufio
scanner
technology_11
sometimes
people
want
to
type
of
the
connector_data_4
collection
number
etc
sometimes
they
want
the
connector_data_4
requirement_5
the
the
number
in
a
form
they
can
work
with
scanner
next
and
decoder
nexttoken
aren’t
convenient
for
that
but
they
can
be
use
to
build
high
level
abstraction
connector_1
let’s
talk
about
connector_1
connector_data_1
this
can
be
tricky
to
do
efficiently
because
technology_1
be
not
length
delimit
you
have
to
connector_4
until
you
find
the
end
of
the
connector_data_4
the
traditional
way
to
do
this
be
with
an
io
reader
you
can
connector_4
one
byte
at
a
time
but
you
need
a
place
to
component_10
the
thing
you’re
walk
over
also
might
need
to
put
the
byte
back
you
can
connector_4
into
a
buffer
then
look
in
buffer
for
start
and
end
of
connector_data_4
if
the
end
connector_data_4
isnât
in
the
buffer
you
need
to
do
a
lot
of
bookkeeping
and
copy
to
move
the
connector_data_1
around
the
the
buffer
or
grow
the
buffer
to
make
room
for
more
connector_data_1
encoding
technology_3
do
a
combination
of
these
often
with
a
smatter
of
pattern_4
pool
to
try
to
quality_attribute_11
small
connector_data_12
transparently
the
alternative
be
an
idea
inspire
by
steven
schveighoffer’s
iopipe
and
phil
pearl
a
bytereader
connector_15
a
slide
window
over
an
io
reader
type
bytereader
struct
{
connector_data_1
byte
offset
r
io
reader
err
error
}
release
discard
n
byte
from
the
front
of
the
window
func
b
*bytereader
release
n
{
b
offset
+=
n
}
window
the
current
window
the
window
be
invalidate
by
connector_data_6
to
release
or
extend
func
b
*bytereader
window
byte
{
b
connector_data_1
b
offset
}
extend
extend
the
window
with
connector_data_1
from
the
underlie
reader
func
b
*bytereader
extend
{
example
whitespace
technology_1
contain
a
mixture
of
connector_data_4
and
whitespace
space
tab
newline
and
carriage
can
occur
between
connector_data_4
and
be
ignore
thus
the
search
for
a
connector_data_4
begin
with
a
search
for
the
first
non
whitespace
character
{
a
b
true
technology_9
two
}
this
be
a
quality_attribute_9
time
to
talk
about
optimise
the
search
for
whitespace
with
an
example
of
use
a
bytereader
func
countwhitespace
br
*bytereader
{
n
=
w
=
br
window
for
{
for
_
technology_9
=
range
w
{
if
iswhitespace
technology_9
{
n++
}
}
br
release
len
w
if
br
extend
==
{
n
}
w
=
br
window
}
}
this
do
the
minimum
visit
each
character
and
make
one
connector_data_7
which
be
inlined
and
count
the
number
of
whitespace
character
any
useful
technology_1
decoder
cannot
go
fast
that
this
what’s
the
fast
way
to
connector_16
iswhitespace
here’s
the
implementation
that
encoding
technology_3
u
with
a
different
name
func
iswhitespace
technology_9
byte
bool
{
technology_9
=
&&
technology_9
==
||
technology_9
==
\t
||
technology_9
==
\r
||
technology_9
==
\n
}
base
on
this
research
this
be
quality_attribute_12
the
fast
var
whitespace
=
bool{
true
\t
true
\n
true
\r
true
}
func
iswhitespace
technology_9
byte
bool
{
whitespace
technology_9
}
name
time
op
countwhitespace
canada
10ms
â±
2%
countwhitespace
citm_catalog
838âµs
â±
1%
countwhitespace
twitter
306âµs
â±
1%
countwhitespace
937âµs
â±
1%
countwhitespace
example
40âµs
â±
1%
countwhitespace
sample
333âµs
â±
1%
name
quality_attribute_13
countwhitespace
canada
04gb
s
â±
2%
countwhitespace
citm_catalog
06gb
s
â±
1%
countwhitespace
twitter
06gb
s
â±
1%
countwhitespace
07gb
s
â±
1%
countwhitespace
example
04gb
s
â±
1%
countwhitespace
sample
06gb
s
â±
1%
so
this
be
our
baseline
scan
now
we
can
tell
which
character
be
connector_data_4
and
which
be
simply
whitespace
let’s
step
up
a
level
and
talk
about
break
up
those
connector_data_4
next
a
byte
reference
the
the
next
lexical
connector_data_4
in
the
connector_7
the
byte
be
valid
until
next
be
connector_17
again
if
the
connector_7
be
at
it
end
or
an
error
have
occur
next
a
zero
length
byte
slice
a
valid
connector_data_4
begin
with
one
of
the
follow
{
connector_data_5
start
start
}
connector_data_5
end
end
literal
comma
literal
colon
t
technology_1
true
f
technology_1
false
n
technology_1
a
possibly
contain
backslash
escape
entites
a
number
func
s
*scanner
next
byte
{
release
the
previous
connector_data_4
s
br
release
s
po
s
po
=
technology_9
=
s
connector_data_4
length
=
switch
technology_9
{
requirement_6
objectstart
objectend
colon
comma
arraystart
arrayend
length
=
s
po
=
requirement_6
true
length
=
validatetoken
&s
br
true
s
po
=
length
requirement_6
false
length
=
validatetoken
&s
br
false
s
po
=
length
requirement_6
length
=
validatetoken
&s
br
s
po
=
length
requirement_6
length
=
parsestring
&s
br
if
length
{
nil
}
s
po
=
length
requirement_6
eof
nil
default
ensure
the
number
be
correct
length
=
s
parsenumber
if
length
{
nil
}
}
s
br
window
length
}
this
be
the
core
loop
of
scanner
next
scanner
next
skip
over
any
intermediate
whitespace
determine
the
connector_data_4
from
the
first
character
in
the
window
then
continue
to
connector_4
until
the
connector_data_4
be
connector_4
or
we
hit
the
end
of
the
input
let’s
look
at
how
connector_data_4
work
then
we’ll
talk
about
some
optimisation
func
s
*scanner
connector_data_4
byte
{
w
=
s
br
window
for
{
for
_
technology_9
=
range
w
{
if
whitespace
technology_9
{
s
pos++
continue
}
release
whitespace
s
br
release
s
po
s
po
=
technology_9
}
if
s
br
extend
==
{
eof
}
w
=
s
br
window
s
po
}
}
var
whitespace
=
bool{
true
\r
true
\n
true
\t
true
}
we
start
by
connector_18
the
current
window
from
the
bytereader
this
be
a
byte
slice
of
all
the
connector_data_1
that
be
yet
to
be
connector_4
we’re
look
for
the
first
non
whitespace
character
if
the
character
be
a
whitespace
we
increment
s
po
to
ignore
the
character
and
loop
around
if
we
do
find
a
non
whitespace
character
we
release
s
po
character
from
the
front
of
the
window
now
the
start
of
the
window
be
properly
align
with
the
first
character
of
the
connector_data_4
it
turn
out
that
we
also
connector_8
the
first
character
of
the
connector_data_4
for
free
it’s
in
technology_9
so
we
can
that
a
a
hint
to
scanner
next
if
we
run
out
of
character
without
hit
a
connector_data_4
then
we
connector_17
extend
to
grow
the
window
if
we
couldn’t
grow
then
we’ve
run
out
of
input
and
haven’t
connector_8
a
connector_data_4
so
give
up
otherwise
update
w
with
a
window
this
be
the
basic
of
bytereader
we’ll
see
that
pattern_5
repeat
across
the
scanner
some
thing
to
note
note
the
lack
of
error
handle
it’s
not
part
of
the
inner
loop
it
only
happen
when
we
have
to
connector_4
more
connector_data_1
from
the
underlie
reader
extend
hide
the
component_4
of
connector_1
into
grow
refilling
the
buffer
it
make
the
loop
above
it
scanner
connector_data_4
quality_attribute_10
if
there
be
connector_data_1
in
the
window
component_4
it
extend
if
you
need
too
give
up
if
you
can’t
extend
release
be
similar
it
shrink
the
start
of
the
window
to
exclude
connector_data_1
that
we
don’t
care
about
extend
be
not
in
the
pattern_1
path
so
there
be
no
need
to
optimise
it
it
requirement_1
be
a
of
the
buffer
it
be
give
in
practice
a
buffer
of
8k
be
sufficient
let’s
talk
about
the
requirement_1
of
this
name
time
op
scanner
canada
41ms
â±
2%
scanner
citm_catalog
55ms
â±
3%
scanner
twitter
03ms
â±
1%
scanner
21ms
â±
1%
scanner
example
4âµs
â±
1%
scanner
sample
822âµs
â±
1%
name
quality_attribute_13
scanner
canada
510mb
s
â±
2%
scanner
citm_catalog
677mb
s
â±
3%
scanner
twitter
615mb
s
â±
1%
scanner
461mb
s
â±
1%
scanner
example
608mb
s
â±
1%
scanner
sample
837mb
s
â±
1%
this
be
a
benchmark
you
saw
early
minus
a
few
optimisation
we’ll
talk
about
next
compare
the
requirement_1
of
scanner
next
to
our
whitespace
benchmark
we
can
see
that
we’re
between
and
5ths
of
our
baseline
let’s
talk
about
the
first
improvement
we
can
make
to
the
note
the
amount
of
work
be
spend
to
keep
s
po
up
to
date
we
that
s
po
be
set
to
before
scanner
next
connector_data_6
this
and
we
set
s
po
to
zero
on
the
way
out
of
the
so
the
connector_19
we
make
to
s
po
within
the
be
invisible—​it’s
zero
on
entry
and
zero
on
exit
we
can
rewrite
the
to
keep
a
local
po
requirement_5
which
have
an
impressive
effect
on
connector_data_4
func
s
*scanner
connector_data_4
byte
{
w
=
s
br
window
po
=
for
{
for
_
technology_9
=
range
w
{
if
whitespace
technology_9
{
pos++
continue
}
release
whitespace
s
br
release
po
technology_9
}
if
s
br
extend
==
{
eof
}
w
=
s
br
window
po
}
}
var
whitespace
=
bool{
true
\r
true
\n
true
\t
true
}
name
old
time
op
time
op
delta
scanner
canada
39ms
â±
1%
43ms
â±
4%
~
p=1
n=5+5
scanner
citm_catalog
52ms
â±
1%
80ms
â±
4%
46%
p=0
n=5+5
scanner
twitter
03ms
â±
2%
95ms
â±
3%
41%
p=0
n=5+5
scanner
24ms
â±
2%
18ms
â±
1%
~
p=0
n=5+5
scanner
example
4âµs
â±
1%
9âµs
â±
2%
68%
p=0
n=5+5
scanner
sample
828âµs
â±
2%
528âµs
â±
2%
24%
p=0
n=5+5
name
old
quality_attribute_13
quality_attribute_13
delta
scanner
canada
512mb
s
â±
1%
509mb
s
â±
4%
~
p=1
n=5+5
scanner
citm_catalog
685mb
s
â±
1%
958mb
s
â±
4%
+39
84%
p=0
n=5+5
scanner
twitter
616mb
s
â±
2%
665mb
s
â±
3%
+8
01%
p=0
n=5+5
scanner
458mb
s
â±
2%
465mb
s
â±
1%
~
p=0
n=5+5
scanner
example
608mb
s
â±
1%
688mb
s
â±
2%
+13
23%
p=0
n=5+5
scanner
sample
831mb
s
â±
2%
1303mb
s
â±
2%
+56
84%
p=0
n=5+5
by
keep
po
local
the
compiler
avoid
those
temporary
connector_20
back
to
memory
the
question
i
have
for
you
be
why
do
this
improve
some
input
and
not
others
the
answer
i
think
be
different
input
have
different
amount
of
whitespace
for
example
canada
only
have
whitespace
character
whereas
citm
have
there
be
a
large
improvement
we
can
make
for
the
runtime
of
this
and
it
relate
to
inlining
inlining
be
the
component_4
of
automatically
or
manually
copy
the
body
of
a
into
in
line
with
it
caller
this
avoid
the
overhead
of
the
connector_data_7
usually
inlining
be
perform
automatically
by
the
compiler
accord
to
a
set
of
rule
it
control
the
go
compiler
have
reasonable
support
for
inlining
but
have
a
number
of
limitation
%
go
build
gcflags=
m=2
&1
|
grep
cannot
|
grep
v
decoder
reader
go
cannot
inline
*bytereader
extend
too
complex
cost
exceed
budget
scanner
go
cannot
inline
*scanner
connector_data_4
unhandled
op
for
scanner
go
cannot
inline
validatetoken
unhandled
op
for
scanner
go
cannot
inline
parsestring
unhandled
op
for
scanner
go
cannot
inline
*scanner
parsenumber
unhandled
op
for
scanner
go
cannot
inline
*scanner
next
too
complex
cost
exceed
budget
the
first
be
the
size
of
the
bytereader
extend
cannot
be
inlined
because
it
be
too
complex
the
second
be
statement
within
the
scanner
connector_data_4
cannot
be
inlined
because
it
contain
a
for
statement
also
note
that
scanner
next
the
caller
of
scanner
connector_data_4
cannot
be
inlined
because
it
be
also
too
complex
let’s
go
back
to
the
constraint
scanner
next
be
connector_17
for
each
connector_data_4
in
the
input
this
mean
that
scanner
connector_data_4
be
connector_17
for
each
connector_data_4
in
the
input
scanner
connector_data_4
cannot
be
automatically
inlined
into
it
caller
because
it
be
too
complex
therefore
we’re
pay
for
an
extra
connector_data_7
for
each
connector_data_4
we
can
remove
this
overhead
by
manually
inlining
scanner
connector_data_4
into
it
caller
func
s
*scanner
next
byte
{
release
the
previous
connector_data_4
s
br
release
s
po
w
=
s
br
window
po
=
for
{
for
_
technology_9
=
range
w
{
if
whitespace
technology_9
{
pos++
continue
}
release
whitespace
s
br
release
po
length
=
switch
technology_9
{
requirement_6
objectstart
objectend
colon
comma
arraystart
arrayend
length
=
s
po
=
requirement_6
true
length
=
validatetoken
&s
br
true
s
po
=
length
requirement_6
false
length
=
validatetoken
&s
br
false
s
po
=
length
requirement_6
length
=
validatetoken
&s
br
s
po
=
length
requirement_6
length
=
parsestring
&s
br
if
length
{
nil
}
s
po
=
length
default
ensure
the
number
be
correct
length
=
s
parsenumber
if
length
{
nil
}
}
s
br
window
length
}
if
s
br
extend
==
{
eof
nil
}
w
=
s
br
window
po
}
}
the
connector_data_2
support
our
thesis
name
old
time
op
time
op
delta
scanner
canada
36ms
â±
1%
50ms
â±
0%
68%
p=0
n=5+5
scanner
citm_catalog
80ms
â±
1%
56ms
â±
2%
16%
p=0
n=5+5
scanner
twitter
965âµs
â±
2%
833âµs
â±
2%
75%
p=0
n=5+5
scanner
15ms
â±
1%
61ms
â±
1%
82%
p=0
n=5+5
scanner
example
9âµs
â±
2%
6âµs
â±
1%
42%
p=0
n=5+5
scanner
sample
515âµs
â±
1%
472âµs
â±
2%
34%
p=0
n=5+5
name
old
quality_attribute_13
quality_attribute_13
delta
scanner
canada
516mb
s
â±
1%
642mb
s
â±
0%
+24
50%
p=0
n=5+5
scanner
citm_catalog
960mb
s
â±
1%
1105mb
s
â±
2%
+15
16%
p=0
n=5+5
scanner
twitter
654mb
s
â±
2%
759mb
s
â±
1%
+15
94%
p=0
n=5+5
scanner
468mb
s
â±
1%
537mb
s
â±
1%
+14
69%
p=0
n=5+5
scanner
example
689mb
s
â±
2%
787mb
s
â±
1%
+14
17%
p=0
n=5+5
scanner
sample
33gb
s
â±
1%
46gb
s
â±
1%
+9
11%
p=0
n=5+5
by
connector_21
the
connector_data_7
we’ve
improve
quality_attribute_5
by
24%
the
large
improvement
come
from
canada
which
basically
contain
no
whitespace
so
the
connector_data_7
to
scanner
connector_data_4
almost
always
immediately
have
do
no
work
while
also
pay
for
all
the
s
po
and
release
overhead
this
be
where
the
inner
loop
of
the
scanner
stand
today
note
that
citm
be
over
50%
of
the
baseline
sample
be
nearly
75%
to
recap
the
major
optimisation
be
whitespace
technology_9
avoid
s
po
update
they
cannot
be
registerised
cpu
have
to
do
a
connector_9
on
every
iteration
s
po
connector_data_13
reduce
from
one
per
byte
to
one
per
connector_data_4
scanner
next
and
scanner
connector_data_4
be
effectively
one
spread
over
two
each
be
too
large
to
be
inlined
so
we’re
pay
for
an
extra
connector_data_7
per
connector_data_4
manually
inlining
them
increase
the
indentation
depth
of
the
but
connector_22
substantial
speedup
most
technology_1
contain
some
whitespace
it’s
moderately
optimise
for
human
readability
it
turn
out
the
more
whitespace
the
fast
pkg
technology_3
decode
decoding
so
far
we
have
a
scanner
which
tokenises
input
at
75%
of
the
baseline
quality_attribute_13
we
establish
before
but
there
be
a
few
more
thing
we
need
to
make
the
scanner
fully
functional
the
first
part
of
that
be
validation
validation
technology_1
be
a
state
component_6
quality_attribute_14
on
the
current
connector_data_4
you’re
in
some
be
valid
some
not
be
for
example
if
you’ve
connector_4
these
connector_data_4
{
username
then
the
only
valid
connector_data_4
be
to
track
this
we
need
to
pattern_6
some
component_11
on
top
of
scanner
next
to
assert
that
the
connector_data_4
sequence
be
valid
this
be
the
role
of
decoder
nexttoken
statevalue
=
stateobjectstring
=
iota
stateobjectcolon
stateobjectvalue
stateobjectcomma
statearrayvalue
statearraycomma
stateend
func
technology_12
*decoder
nexttoken
byte
error
{
tok
=
technology_12
scanner
next
if
len
tok
{
nil
io
eof
}
switch
technology_12
state
{
requirement_6
statevalue
technology_12
statevalue
tok
requirement_6
stateobjectstring
technology_12
stateobjectstring
tok
requirement_6
stateobjectcolon
technology_12
stateobjectcolon
tok
requirement_6
stateobjectvalue
technology_12
stateobjectvalue
tok
requirement_6
stateobjectcomma
technology_12
stateobjectcomma
tok
requirement_6
statearrayvalue
technology_12
statearrayvalue
tok
requirement_6
statearraycomma
technology_12
statearraycomma
tok
requirement_6
stateend
fallthrough
default
nil
io
eof
}
}
this
be
pretty
straightforward
stuff
we
take
track
the
current
state
in
technology_12
state
and
base
on
it
requirement_5
we
dispatch
to
the
various
state
click
to
see
the
component_3
for
the
various
state
func
technology_12
*decoder
stateobjectstring
tok
byte
byte
error
{
switch
tok
{
requirement_6
}
inobj
=
technology_12
pop
switch
{
requirement_6
technology_12
len
==
technology_12
state
=
stateend
requirement_6
inobj
technology_12
state
=
stateobjectcomma
requirement_6
inobj
technology_12
state
=
statearraycomma
}
tok
nil
requirement_6
technology_12
state
=
stateobjectcolon
tok
nil
default
nil
fmt
errorf
stateobjectstring
miss
key
}
}
func
technology_12
*decoder
stateobjectcolon
tok
byte
byte
error
{
switch
tok
{
requirement_6
colon
technology_12
state
=
stateobjectvalue
technology_12
nexttoken
default
tok
fmt
errorf
stateobjectcolon
expect
colon
}
}
func
technology_12
*decoder
stateobjectvalue
tok
byte
byte
error
{
switch
tok
{
requirement_6
{
technology_12
state
=
stateobjectstring
technology_12
connector_23
true
tok
nil
requirement_6
technology_12
state
=
statearrayvalue
technology_12
connector_23
false
tok
nil
default
technology_12
state
=
stateobjectcomma
tok
nil
}
}
func
technology_12
*decoder
stateobjectcomma
tok
byte
byte
error
{
switch
tok
{
requirement_6
}
inobj
=
technology_12
pop
switch
{
requirement_6
technology_12
len
==
technology_12
state
=
stateend
requirement_6
inobj
technology_12
state
=
stateobjectcomma
requirement_6
inobj
technology_12
state
=
statearraycomma
}
tok
nil
requirement_6
comma
technology_12
state
=
stateobjectstring
technology_12
nexttoken
default
tok
fmt
errorf
stateobjectcomma
expect
comma
}
}
func
technology_12
*decoder
statearrayvalue
tok
byte
byte
error
{
switch
tok
{
requirement_6
{
technology_12
state
=
stateobjectstring
technology_12
connector_23
true
tok
nil
requirement_6
technology_12
state
=
statearrayvalue
technology_12
connector_23
false
tok
nil
requirement_6
inobj
=
technology_12
pop
switch
{
requirement_6
technology_12
len
==
technology_12
state
=
stateend
requirement_6
inobj
technology_12
state
=
stateobjectcomma
requirement_6
inobj
technology_12
state
=
statearraycomma
}
tok
nil
requirement_6
nil
fmt
errorf
statearrayvalue
unexpected
comma
default
technology_12
state
=
statearraycomma
tok
nil
}
}
func
technology_12
*decoder
statearraycomma
tok
byte
byte
error
{
switch
tok
{
requirement_6
inobj
=
technology_12
pop
switch
{
requirement_6
technology_12
len
==
technology_12
state
=
stateend
requirement_6
inobj
technology_12
state
=
stateobjectcomma
requirement_6
inobj
technology_12
state
=
statearraycomma
}
tok
nil
requirement_6
comma
technology_12
state
=
statearrayvalue
technology_12
nexttoken
default
nil
fmt
errorf
statearraycomma
expect
comma
%v
technology_12
technology_8
}
}
func
technology_12
*decoder
statevalue
tok
byte
byte
error
{
switch
tok
{
requirement_6
{
technology_12
state
=
stateobjectstring
technology_12
connector_23
true
tok
nil
requirement_6
technology_12
state
=
statearrayvalue
technology_12
connector_23
false
tok
nil
requirement_6
nil
fmt
errorf
statevalue
unexpected
comma
default
technology_12
state
=
stateend
tok
nil
}
}
let’s
look
at
the
connector_data_11
name
time
op
decodernexttoken
pkgjson
canada
64ms
â±
1%
decodernexttoken
encodingjson
canada
1ms
â±
1%
decodernexttoken
pkgjson
citm_catalog
42ms
â±
2%
decodernexttoken
encodingjson
citm_catalog
8ms
â±
1%
decodernexttoken
pkgjson
twitter
18ms
â±
1%
decodernexttoken
encodingjson
twitter
1ms
â±
0%
decodernexttoken
pkgjson
10ms
â±
2%
decodernexttoken
encodingjson
5ms
â±
1%
decodernexttoken
pkgjson
example
2âµs
â±
1%
decodernexttoken
encodingjson
example
266âµs
â±
1%
decodernexttoken
pkgjson
sample
559âµs
â±
0%
decodernexttoken
encodingjson
sample
18ms
â±
2%
name
quality_attribute_13
decodernexttoken
pkgjson
canada
399mb
s
â±
1%
decodernexttoken
encodingjson
canada
6mb
s
â±
1%
decodernexttoken
pkgjson
citm_catalog
713mb
s
â±
2%
decodernexttoken
encodingjson
citm_catalog
1mb
s
â±
1%
decodernexttoken
pkgjson
twitter
537mb
s
â±
1%
decodernexttoken
encodingjson
twitter
2mb
s
â±
0%
decodernexttoken
pkgjson
318mb
s
â±
2%
decodernexttoken
encodingjson
0mb
s
â±
1%
decodernexttoken
pkgjson
example
517mb
s
â±
1%
decodernexttoken
encodingjson
example
0mb
s
â±
1%
decodernexttoken
pkgjson
sample
23gb
s
â±
0%
decodernexttoken
encodingjson
sample
216mb
s
â±
2%
compare
to
encoding
technology_3
we’re
10x
fast
but
there
be
some
thing
we
can
do
to
improve
compute
goto
central
to
the
of
decoder
nexttoken
be
the
switch
statement
a
we
saw
early
in
the
whitespace
benchmark
switch
be
the
second
bad
performer
this
be
because
switch
in
the
general
requirement_6
at
least
be
connector_16
a
a
set
of
if
{}
else
if
{}
effectively
what
the
compiler
see
be
func
technology_12
*decoder
nexttoken
byte
error
{
tok
=
technology_12
scanner
next
if
len
tok
{
nil
io
eof
}
if
technology_12
state
==
statevalue
{
technology_12
statevalue
tok
}
if
technology_12
state
==
stateobjectstring
{
technology_12
stateobjectstring
tok
}
if
technology_12
state
==
stateobjectcolon
{
technology_12
stateobjectcolon
tok
}
if
technology_12
state
==
stateobjectvalue
{
technology_12
stateobjectvalue
tok
}
if
technology_12
state
==
stateobjectcomma
{
technology_12
stateobjectcomma
tok
}
if
technology_12
state
==
statearrayvalue
{
technology_12
statearrayvalue
tok
}
if
technology_12
state
==
statearraycomma
{
technology_12
statearraycomma
tok
}
nil
io
eof
}
benchmarking
this
explicit
if
{}
else
{}
…​
version
confirm
this
be
close
to
what
the
compiler
be
see
decodernexttoken
pkgjson
canada
60ms
â±
0%
65ms
â±
0%
+0
96%
p=0
n=5+5
decodernexttoken
encodingjson
canada
9ms
â±
1%
6ms
â±
1%
~
p=0
n=5+5
decodernexttoken
pkgjson
citm_catalog
41ms
â±
1%
45ms
â±
1%
+1
42%
p=0
n=5+5
decodernexttoken
encodingjson
citm_catalog
8ms
â±
1%
7ms
â±
0%
~
p=0
n=5+5
decodernexttoken
pkgjson
twitter
17ms
â±
1%
18ms
â±
2%
~
p=1
n=5+5
decodernexttoken
encodingjson
twitter
2ms
â±
1%
1ms
â±
1%
~
p=0
n=5+5
decodernexttoken
pkgjson
11ms
â±
3%
09ms
â±
1%
~
p=1
n=5+5
decodernexttoken
encodingjson
7ms
â±
2%
2ms
â±
1%
~
p=0
n=5+5
decodernexttoken
pkgjson
example
0âµs
â±
0%
0âµs
â±
1%
~
p=0
n=5+5
decodernexttoken
encodingjson
example
263âµs
â±
1%
264âµs
â±
1%
~
p=0
n=5+5
decodernexttoken
pkgjson
sample
560âµs
â±
1%
558âµs
â±
1%
~
p=0
n=5+5
decodernexttoken
encodingjson
sample
16ms
â±
1%
19ms
â±
1%
~
p=0
n=5+5
name
old
quality_attribute_13
quality_attribute_13
delta
decodernexttoken
pkgjson
canada
402mb
s
â±
0%
398mb
s
â±
0%
95%
p=0
n=5+5
decodernexttoken
encodingjson
canada
7mb
s
â±
1%
3mb
s
â±
1%
~
p=0
n=5+5
decodernexttoken
pkgjson
citm_catalog
716mb
s
â±
1%
706mb
s
â±
1%
39%
p=0
n=5+5
decodernexttoken
encodingjson
citm_catalog
3mb
s
â±
1%
6mb
s
â±
0%
~
p=0
n=5+5
decodernexttoken
pkgjson
twitter
539mb
s
â±
1%
537mb
s
â±
2%
~
p=1
n=5+5
decodernexttoken
encodingjson
twitter
9mb
s
â±
1%
2mb
s
â±
1%
~
p=0
n=5+5
decodernexttoken
pkgjson
318mb
s
â±
2%
319mb
s
â±
1%
~
p=1
n=5+5
decodernexttoken
encodingjson
0mb
s
â±
2%
1mb
s
â±
1%
~
p=0
n=5+5
decodernexttoken
pkgjson
example
521mb
s
â±
0%
520mb
s
â±
1%
~
p=0
n=5+5
decodernexttoken
encodingjson
example
5mb
s
â±
1%
3mb
s
â±
1%
~
p=0
n=5+5
decodernexttoken
pkgjson
sample
23gb
s
â±
1%
23gb
s
â±
1%
~
p=0
n=5+5
decodernexttoken
encodingjson
sample
218mb
s
â±
1%
216mb
s
â±
1%
~
p=0
n=5+5
switch
be
convenient
but
not
optimal
in
the
pattern_1
path
this
problem
turn
up
in
many
place
bytecode
pattern_7
be
a
classic
example
one
of
the
optimisation
compiler
can
make
although
the
go
compiler
do
not
connector_16
this
currently
be
to
turn
this
set
of
if
…​
else
clause
into
a
component_1
this
can
be
space
quality_attribute_1
if
the
state
space
be
small
and
dense
often
it
be
not
and
the
connector_data_11
might
be
something
this
var
statetable
=
func
*decoder
byte
byte
error
{
statevalue
*decoder
statevalue
stateobjectstring
*decoder
stateobjectstring
stateobjectcolon
*decoder
stateobjectcolon
stateobjectvalue
*decoder
stateobjectvalue
stateobjectcomma
*decoder
stateobjectcomma
statearrayvalue
*decoder
statearrayvalue
statearraycomma
*decoder
statearraycomma
stateend
*decoder
stateend
}
func
technology_12
*decoder
nexttoken
byte
error
{
tok
=
technology_12
scanner
next
if
len
tok
{
nil
io
eof
}
statetable
technology_12
state
technology_12
tok
}
unfortunately
this
won’t
compile
because
there
be
an
initalisation
loop
decoder
go
initialization
loop
component_12
davecheney
devel
technology_3
decoder
go
statetable
refer
to
component_12
davecheney
devel
technology_3
decoder
go
*decoder
stateobjectcolon
refer
to
component_12
davecheney
devel
technology_3
decoder
go
*decoder
nexttoken
refer
to
component_12
davecheney
devel
technology_3
decoder
go
statetable
fail
technology_5
technology_6
pkg
technology_3
build
failed\
but
there
be
a
quality_attribute_9
trick
that
we
can
use
that
be
more
space
quality_attribute_1
than
this
component_1
it’s
one
that
encoding
technology_3
u
and
be
sometimes
connector_17
a
compute
goto
if
you
look
at
the
component_1
above
there
be
a
pattern_5
each
state
enumeration
be
match
with
exactly
one
we
talk
about
state
requirement_5
a
a
pattern_8
for
the
we
want
to
connector_data_7
what
if
we
could
component_10
the
directly
and
connector_data_7
it
directly
and
infact
we
can
do
that
a
decoder
decode
technology_1
requirement_5
from
an
input
connector_7
type
decoder
struct
{
scanner
*scanner
state
func
*decoder
byte
byte
error
technology_8
}
func
technology_12
*decoder
nexttoken
byte
error
{
tok
=
technology_12
scanner
next
if
len
tok
{
nil
io
eof
}
technology_12
state
technology_12
tok
}
the
the
technology_12
state
technology_12
tok
form
be
a
a
expression
it’s
rare
to
see
this
in
most
go
but
in
effect
it
you
component_10
a
a
a
requirement_5
then
late
connector_data_7
that
by
supply
your
own
receiver
expression
aren’t
that
common
because
in
go
the
ability
to
capture
the
receiver
of
a
be
package
type
t
struct{}
func
t
foo
func
{
x
=
t
foo
expression
var
t
t
y
=
t
foo
regular
requirement_5
}
the
connector_data_2
aren’t
that
promise
name
old
time
op
time
op
delta
decodernexttoken
pkgjson
canada
60ms
â±
0%
61ms
â±
0%
~
p=0
n=5+5
decodernexttoken
encodingjson
canada
9ms
â±
1%
4ms
â±
0%
~
p=0
n=5+5
decodernexttoken
pkgjson
citm_catalog
41ms
â±
1%
42ms
â±
1%
~
p=0
n=5+5
decodernexttoken
encodingjson
citm_catalog
8ms
â±
1%
7ms
â±
1%
~
p=0
n=5+5
decodernexttoken
pkgjson
twitter
17ms
â±
1%
20ms
â±
2%
+2
70%
p=0
n=5+5
decodernexttoken
encodingjson
twitter
2ms
â±
1%
1ms
â±
1%
~
p=1
n=5+5
decodernexttoken
pkgjson
11ms
â±
3%
37ms
â±
4%
+4
26%
p=0
n=5+5
decodernexttoken
encodingjson
7ms
â±
2%
6ms
â±
2%
~
p=0
n=5+5
decodernexttoken
pkgjson
example
0âµs
â±
0%
6âµs
â±
1%
+2
25%
p=0
n=5+5
decodernexttoken
encodingjson
example
263âµs
â±
1%
265âµs
â±
2%
~
p=0
n=5+5
decodernexttoken
pkgjson
sample
560âµs
â±
1%
553âµs
â±
0%
15%
p=0
n=5+5
decodernexttoken
encodingjson
sample
16ms
â±
1%
17ms
â±
1%
~
p=0
n=5+5
name
old
quality_attribute_13
quality_attribute_13
delta
decodernexttoken
pkgjson
canada
402mb
s
â±
0%
401mb
s
â±
0%
~
p=0
n=5+5
decodernexttoken
encodingjson
canada
7mb
s
â±
1%
0mb
s
â±
0%
~
p=0
n=5+5
decodernexttoken
pkgjson
citm_catalog
716mb
s
â±
1%
713mb
s
â±
1%
~
p=0
n=5+5
decodernexttoken
encodingjson
citm_catalog
3mb
s
â±
1%
6mb
s
â±
1%
~
p=0
n=5+5
decodernexttoken
pkgjson
twitter
539mb
s
â±
1%
524mb
s
â±
2%
62%
p=0
n=5+5
decodernexttoken
encodingjson
twitter
9mb
s
â±
1%
0mb
s
â±
1%
~
p=1
n=5+5
decodernexttoken
pkgjson
318mb
s
â±
2%
305mb
s
â±
3%
07%
p=0
n=5+5
decodernexttoken
encodingjson
0mb
s
â±
2%
7mb
s
â±
2%
~
p=0
n=5+5
decodernexttoken
pkgjson
example
521mb
s
â±
0%
509mb
s
â±
1%
19%
p=0
n=5+5
decodernexttoken
encodingjson
example
5mb
s
â±
1%
1mb
s
â±
2%
~
p=0
n=5+5
decodernexttoken
pkgjson
sample
23gb
s
â±
1%
24gb
s
â±
0%
+1
16%
p=0
n=5+5
decodernexttoken
encodingjson
sample
218mb
s
â±
1%
217mb
s
â±
1%
~
p=0
n=5+5
but
it
unlock
several
optimisation
outline
func
technology_12
*decoder
nexttoken
byte
error
{
technology_12
state
technology_12
}
func
technology_12
*decoder
stateobjectcolon
byte
error
{
tok
=
technology_12
scanner
next
if
len
tok
{
nil
io
errunexpectedeof
}
switch
tok
{
requirement_6
colon
technology_12
state
=
*decoder
stateobjectvalue
technology_12
nexttoken
default
tok
fmt
errorf
stateobjectcolon
expect
colon
}
}
move
the
tok
=
technology_12
scanner
next
connector_data_7
into
each
state
might
seem
a
step
backwards
but
it
have
several
positive
effect
the
first
be
not
pass
tok
into
each
state
this
connector_24
word
on
the
connector_data_7
technology_8
the
second
be
by
move
the
if
len
tok
into
the
same
a
the
switch
it
enable
bind
connector_13
elimination
previously
when
the
len
tok
connector_13
happen
in
decoder
nexttoken
decoder
stateobjectcolon
doesn’t
anything
about
the
length
of
tok
when
the
compiler
encounter
switch
tok
it
need
to
put
a
bind
connector_13
to
make
sure
tok
be
at
least
element
long
when
the
if
connector_13
be
move
into
the
same
the
compiler
that
if
we
connector_8
further
than
the
connector_13
then
tok
be
at
least
element
long
so
the
bind
connector_13
be
not
need
we
can
see
this
in
the
debug
connector_data_14
`
%
go
build
gcflags=
d=ssa
prove
debug=2
&1
|
grep
135\
decoder
go
prove
isinbounds
v31
`
the
final
optimisation
occur
because
decoder
nexttoken
which
be
previously
too
complex
to
inline
decoder
go
cannot
inline
*decoder
nexttoken
too
complex
cost
exceed
budget
be
now
inlinable
bench_test
go
inlining
connector_data_7
to
*decoder
nexttoken
*decoder
func
byte
error
{
technology_12
state
technology_12
}
which
mean
connector_data_6
to
dec
nexttoken
in
for
{
_
err
=
dec
nexttoken
if
err
==
io
eof
{
break
}
connector_13
b
err
n++
}
become
a
direct
connector_data_7
to
the
current
state
for
{
_
err
=
dec
state
dec
this
be
what
the
compiler
see
if
err
==
io
eof
{
break
}
connector_13
b
err
n++
}
let’s
look
at
the
connector_data_2
decodernexttoken
pkgjson
canada
60ms
â±
0%
73ms
â±
1%
54%
p=0
n=5+5
decodernexttoken
encodingjson
canada
9ms
â±
1%
2ms
â±
1%
~
p=0
n=5+5
decodernexttoken
pkgjson
citm_catalog
41ms
â±
1%
17ms
â±
2%
94%
p=0
n=5+5
decodernexttoken
encodingjson
citm_catalog
8ms
â±
1%
6ms
â±
1%
~
p=0
n=5+5
decodernexttoken
pkgjson
twitter
17ms
â±
1%
05ms
â±
1%
84%
p=0
n=5+5
decodernexttoken
encodingjson
twitter
2ms
â±
1%
9ms
â±
1%
02%
p=0
n=5+5
decodernexttoken
pkgjson
11ms
â±
3%
15ms
â±
1%
77%
p=0
n=5+5
decodernexttoken
encodingjson
7ms
â±
2%
0ms
â±
2%
~
p=0
n=5+5
decodernexttoken
pkgjson
example
0âµs
â±
0%
0âµs
â±
0%
15%
p=0
n=5+5
decodernexttoken
encodingjson
example
263âµs
â±
1%
263âµs
â±
0%
~
p=0
n=5+5
decodernexttoken
pkgjson
sample
560âµs
â±
1%
510âµs
â±
1%
92%
p=0
n=5+5
decodernexttoken
encodingjson
sample
16ms
â±
1%
16ms
â±
1%
~
p=0
n=5+5
name
old
quality_attribute_13
quality_attribute_13
delta
decodernexttoken
pkgjson
canada
402mb
s
â±
0%
476mb
s
â±
1%
+18
39%
p=0
n=5+5
decodernexttoken
encodingjson
canada
7mb
s
â±
1%
1mb
s
â±
1%
~
p=0
n=5+5
decodernexttoken
pkgjson
citm_catalog
716mb
s
â±
1%
795mb
s
â±
2%
+11
05%
p=0
n=5+5
decodernexttoken
encodingjson
citm_catalog
3mb
s
â±
1%
3mb
s
â±
1%
~
p=0
n=5+5
decodernexttoken
pkgjson
twitter
539mb
s
â±
1%
604mb
s
â±
1%
+12
16%
p=0
n=5+5
decodernexttoken
encodingjson
twitter
9mb
s
â±
1%
0mb
s
â±
1%
+2
05%
p=0
n=5+5
decodernexttoken
pkgjson
318mb
s
â±
2%
377mb
s
â±
1%
+18
71%
p=0
n=5+5
decodernexttoken
encodingjson
0mb
s
â±
2%
2mb
s
â±
2%
~
p=0
n=5+5
decodernexttoken
pkgjson
example
521mb
s
â±
0%
593mb
s
â±
0%
+13
82%
p=0
n=5+5
decodernexttoken
encodingjson
example
5mb
s
â±
1%
6mb
s
â±
0%
~
p=0
n=5+5
decodernexttoken
pkgjson
sample
23gb
s
â±
1%
35gb
s
â±
1%
+9
80%
p=0
n=5+5
decodernexttoken
encodingjson
sample
218mb
s
â±
1%
218mb
s
â±
1%
~
p=0
n=5+5
18%
improvement
over
the
previous
version
unmarshalling
the
second
part
of
decoding
be
conversion
from
technology_1
connector_data_4
to
go
connector_data_5
in
go
this
be
connector_17
unmarshalling
this
part
of
the
package
be
very
much
a
work
in
progress
unmarshalling
be
the
most
expensive
part
of
the
package
because
it
combine
reflect
which
be
expensive
with
unavoidable
allocation
benchmarkdecoderdecodeinterfaceany
pkgjson
canada
n
op
connector_data_3
s
b
op
allocs
op
benchmarkdecoderdecodeinterfaceany
encodingjson
canada
n
op
connector_data_3
s
b
op
allocs
op
benchmarkdecoderdecodeinterfaceany
pkgjson
citm_catalog
n
op
connector_data_3
s
b
op
allocs
op
benchmarkdecoderdecodeinterfaceany
encodingjson
citm_catalog
n
op
connector_data_3
s
b
op
allocs
op
benchmarkdecoderdecodeinterfaceany
pkgjson
twitter
n
op
connector_data_3
s
b
op
allocs
op
benchmarkdecoderdecodeinterfaceany
encodingjson
twitter
n
op
connector_data_3
s
b
op
allocs
op
benchmarkdecoderdecodeinterfaceany
pkgjson
n
op
connector_data_3
s
b
op
allocs
op
benchmarkdecoderdecodeinterfaceany
encodingjson
n
op
connector_data_3
s
b
op
allocs
op
benchmarkdecoderdecodeinterfaceany
pkgjson
example
n
op
connector_data_3
s
b
op
allocs
op
benchmarkdecoderdecodeinterfaceany
encodingjson
example
n
op
connector_data_3
s
b
op
allocs
op
benchmarkdecoderdecodeinterfaceany
pkgjson
sample
n
op
connector_data_3
s
b
op
allocs
op
benchmarkdecoderdecodeinterfaceany
encodingjson
sample
n
op
connector_data_3
s
b
op
allocs
op
can
use
unsafe
here
thematic
idea
allocation
affect
requirement_1
the
garbage
collector
might
be
fast
to
allocate
and
quality_attribute_1
to
connector_25
but
not
allocate
will
always
be
fast
when
deal
with
connector_data_1
allocation
can
be
the
big
requirement_1
cost
of
an
algorithm
o
n
allocations—​per
connector_data_4
or
per
byte—​can
be
the
limit
constraint
on
an
algo
you
can
never
go
below
that
floor
component_2
designâ
influence
requirement_1
the
encoding
technology_3
decoder
component_2
require
allocation
a
a
primitive
requirement_5
via
an
cause
it
to
escape
to
the
heap
—
it
effectively
become
a
pointer
to
the
requirement_5
this
include
careful
attention
to
the
per
byte
and
per
connector_data_4
overhead
connector_22
a
technology_1
decoder
that
perform
3x
fast
than
enconding
technology_3
decoder
connector_data_4
and
10x
fast
with
the
alternative
nexttoken
technology_11
o
n
per
byte
of
input
be
the
second
limit
optimise
the
pattern_1
path
to
convert
per
byte
into
per
connector_data_4
line
connector_data_15
etc
pattern_9
be
key
to
avoid
connector_data_7
overhead
note
how
i
predict
the
outcome
of
encoding
technology_3
decoder
connector_data_4
without
look
at
the
beyond
this
be
the
domain
of
micro
optimisation
thing
move
statement
across
connector_data_7
boundary
to
play
inlining
trick
don’t
reach
for
the
trick
i
show
here
without
connector_12
the
big
o
effect
in
your
technology_11
it
wonât
make
any
difference
requirement_1
matter
sometimes
i
start
this
project
because
i
want
to
apply
some
idea
that
i
saw
to
go
i
believe
that
i
could
connector_16
an
quality_attribute_1
technology_1
requirement_2
base
on
my
assumption
that
encoding
technology_3
be
slow
than
it
could
be
because
of
it
technology_11
it
turn
out
that
i
be
right
it
look
there
be
3x
requirement_1
in
some
unmarshalling
path
and
between
8x
and
10x
requirement_1
in
tokenisation
if
you’re
prepare
to
connector_26
a
different
technology_11
in
this
presentation
i
make
some
statement
about
requirement_1
but
these
be
because
i
specifically
construct
the
question
such
that
the
run
time
of
the
algorithm
be
the
most
important
feature
don’t
extrapolate
my
word
to
mean
that
all
should
optimise
for
runtime
and
allocation
above
all
else
sometimes
requirement_1
matter
most
time
it
doesn’t
it
probably
matter
more
when
connector_27
technology_10
it
probably
matter
when
deal
with
input
connector_data_1
of
an
unknown
size
and
quality
it
certainly
doesn’t
matter
unless
you
have
metric
that
show
a
path
be
too
slow
and
profile
to
identify
the
cause
further
work
the
basic
be
do
now
what
quality_attribute_9
quality_attribute_8
with
the
encoding
technology_3
package
reduce
allocation
in
decoder
nexttoken
probably
by
replace
the
bool
state
technology_8
with
a
bit
vector
decode
encode
in
scanner
parsestring
i
think
this
can
be
do
without
allocation
because
the
unencoded
form
be
always
small
scanner
parsenumber
be
slow
because
it
visit
it
input
twice
once
at
the
scanner
and
a
second
time
when
it
be
convert
to
a
float
i
do
an
experiment
and
the
first
requirement_3
can
be
fast
if
we
look
to
find
the
termination
of
the
number
without
validation
canada
technology_3
go
from
650mb
s
to
820mb
sec
the
readbuffer
component_13
be
generally
applicable
to
other
kind
of
requirement_3
technology_13
decoding
technology_4
connector_data_10
component_3
…​
bonus
benchmarking
be
hard
especially
on
laptop
osx
seem
to
be
very
poor
at
component_4
isolation
download
a
while
run
a
benchmark
cost
10%
connector_28
my
component_3
on
icloud
cost
10%
randomly
osx
seem
to
scan
the
binary
on
first
run
which
can
slow
the
first
benchmark
in
a
run
workaround
use
go
test
technology_9
and
pause
before
run
the
test
binary
workaround
shut
down
everything
on
the
component_6
don’t
touch
it
don’t
it
go
to
sleep
technology_4
www
hyrumslaw
technology_6
technology_4
en
wikipedia
wiki
amdahl%27s_law
brad
fitzpatrick
connector_17
the
connector_data_4
component_2
a
garbage
factory
back
in
so
i’m
certainly
not
the
first
to
make
this
observation
the
type
cannot
be
express
directly
in
go
connector_4
technology_4
research
swtch
technology_6
to
make
thing
even
le
clear
in
go
a
subset
of
can
be
component_10
directly
without
escape
technology_4
www
youtube
technology_6
watch
v=un
bzdyumog
technology_4
philpearl
technology_5
io
reader
technology_4
technology_5
technology_6
davecheney
whitespace
the
difference
between
the
manually
inlined
and
compiler
inlined
version
turn
out
to
be
two
instruction
swap
semantically
this
make
no
difference
but
obviously
matter
for
how
the
processor
schedule
the
instruction
for
connector_29
complexity
be
determine
by
give
each
statement
a
weight
the
weight
be
somewhat
arbitrary
but
more
or
le
each
connector_data_4
cost
connector_data_6
cost
technology_4
technology_5
technology_6
golang
go
issue
cover
improve
the
inlining
cost
component_13
version
{revnumber}
last
update
+1000
