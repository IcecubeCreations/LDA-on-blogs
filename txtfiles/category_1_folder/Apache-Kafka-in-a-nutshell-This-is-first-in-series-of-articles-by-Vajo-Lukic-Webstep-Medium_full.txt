technology_1
technology_2
in
a
nutshell
this
be
first
in
series
of
articles…
|
by
vajo
lukic
|
webstep
|
mediumget
unlimited
accessopen
in
apphomenotificationslistsstorieswritepublished
inwebstepvajo
lukicfollowmar

2019·12
min
readapache
technology_2
in
a
nutshellthis
be
first
in
series
of

about
technology_1
technology_2
webstep
ab
have
recently
become
a
partner
with
the
requirement_1
confluent
one
of
the
distributor
of
technology_2
and
one
of
the
reason
behind
this

the
purpose
of
this
be
to
help
everyone
who
be
interest
in
technology_2
to
understand
what
it
be
and
to
reduce
the

curve
of

technology_2
introductionwhether
you
be
an
experience
it
professional
or
start
your
it
career
it
can
be
a
little
bit
overwhelm
to
start
with
some
technology_3
first

step
can
be
difficult
if
the

curve
be
steep
and
sometimes
people
give
up
to
early
my
goal
here
be
to
help
you
to
climb
that
first
hill
and
to
successfully
acquire
skill
and
to
use
technology_1
technology_2
when
i
start

about
technology_1
technology_2
two
year
ago
i
do
not
even
dream
about
give
a
presentation
about
it
sometime
and
that
be
exactly
what
have
happen
recently
my
colleague
from
webstep
ab
here
in
stockholm
sweden
be
very
kind
to
invite
me
to
present
technology_1
technology_2
to
them
it
have
be
an
honor
to
connector_1
the
invitation
and
to
connector_2
a
chance
to
have
a
friendly
and
stimulate
discussion
about
technology_2
if
you
want
to
drop
by
and
take
part
in
one
of
future
webstep

you
can
find
the
calendar
here
webstep

motivation
for

kafkafor
all
of
u
it
professional
the
time
be
extremely
valuable
there
be
never
enough
time
and
sometimes

hour
be
too
short
to
explore
test
and
all
excite
technology_3
for
that
reason
we
need
to
make
decision
and
to
choose
wisely
what
to
spend
the
time
on
and
what
to
ignore
or
leave
for
late
technology_2
have
become
one
of
the
most
popular
technology_1
project
it
be
enough
to
look
at
trend
and
see
how
interest
in
technology_2
compare
with
other
similar
technology_3
in
the
last

year
interest
in
technology_1
technology_2
have
increase
more
than
300%
while
some
other
technology_3
technology_4
for
example
be
stagnate
when
you
be
decide
whether
to
invest
your
precious
time
in

some
“hot”
open
component_1
technology_3
one
very
quality_attribute_1
way
to
do
that
be
simply
to
connector_3
the
interest
and
time
investment
by
the
open
component_1

in
kafka’s
requirement_2
that
interest
be
still
grow
strong
and
here
for
example
you
can
see
number
of
open
and
close
issue
over
time
action
speak
loud
than
word
and
here
you
can
clearly
see
that
there
be
many
people
who
be
put
the
time
and
effort
into
technology_2
simply
because
they
find
it
valuable
strong
open
component_1
be
a
guarantee
that
certain
technology_3
be
go
to
be
there
for
some
time
and
therefore
be
worth

and
invest
the
time
into
technology_2
have
gain
huge
popularity
and
success
in
requirement_1
linkedin
netflix
spotify
klarna
etc
thanks
to
it
property
for
high
quality_attribute_2
horizontal
quality_attribute_3
and
quality_attribute_4
while
you
might
not
have
million
of
requirement_3
these
requirement_1
technology_2
can
still
provide
very
valuable
component_2

increase
team
agility
quick
connector_4
to
connector_data_1
real
time
connector_data_1
component_3
easy
connector_data_1
requirement_4
and
pattern_1
component_4
connector_5
here
you
can
find
an
extensive
connector_data_2
of
requirement_1
which
be
“powered
by
kafka”
core
technology_2
conceptsso
what
be
technology_2
quality_attribute_5
on
how
you
use
it
in
your
requirement_5
architecture
technology_2
can
have
many
face
because
of
the
role
it
play
and
it
property
it
can
be
describe
this
technology_2
be
a
quality_attribute_6
horizontally
quality_attribute_7
highly
quality_attribute_8
fault
tolerant
connector_6
logkafka
be
a
pattern_2
pattern_3
systemkafka
be
a
connector_7
connector_data_1
platformkafka’s
architecture
be
build
around
concept

requirement_6
connector_data_3
schema
retention
component_5
topic
pattern_4
component_6
component_7
offset
let’s
describe
some
of
these
concept
in
more
detail
the
loglog
be
probably
the
quality_attribute_9
possible
abstraction
of
a
storage
of
any
kind
fundamentally
it
be
an
append
only
totally
order
sequence
of
component_8
connector_8
component_9
be
only
be
append
to
the
end
of
the
requirement_6
and
each
entry
be
assign
a
unique
sequential
number
any
connector_9
be
be
connector_10
from
leave
to
right
by
replay
all
the
component_9
from
the
requirement_6
exactly
in
the
same
order
a
they
have
happen
we
should
be
able
to
re
create
current
state
at
any
time
we
want
again
and
again
if
we
have
the
requirement_6
order
of
component_9
in
the
requirement_6
be
indicate
the
time
flow
component_9
on
the
leave
be
consider
a
“older”
than
those
on
the
right
requirement_6
be
very
important
in
technology_2
because
that
be
where
all
the
connector_data_4
be
component_10
this
by
linkedin
be
one
of
the
best
explanation
of
requirement_6
and
their
purpose
connector_data_3
and
schemathe
unit
of
connector_data_1
in
technology_2
be
a
connector_data_3
a
connector_data_3
be
a
component_8
or
a
row
in
the
component_11
it
be
important
to
that
for
technology_2
any
connector_data_3
be
simply
an
of
byte
technology_2
be
completely
agnostic
to
the
connector_data_3
content
it
do
not
care
what
the
connector_data_3
be
technology_2
do
not
interpret
it
or
validate
it
it
connector_11
it
each
connector_data_3
can
also
contain
a
piece
of
meta
connector_data_1
which
be
consider
a
the
key
with
this
each
connector_data_3
can
be
consider
a
key
requirement_7
pair
while
connector_data_3
content
be
meaningless
to
technology_2
it
be
advise
that
a
schema
be
enforce
on
each
connector_data_3
so
that
it
can
be
understand
and
interpret
by
any
component_2
or
people
who
need
it
a
schema
can
be
create
with
one
of
many
quality_attribute_8
serialization
technology_5
technology_6
connector_data_5
or
avro
quality_attribute_5
on
your
component_12
preference
technology_5
technology_7
and
connector_data_5
be
often
use
simply
because
they
be
convenient
human
readable
technology_5
but
it
be
much
more
quality_attribute_10
to
use
binary
formatslike
technology_1
avro
google’s
technology_8
buffer
and
technology_1
technology_9
these
technology_5
be
much
quality_attribute_1
fit
for
inter
component_4
connector_5
and
connector_data_1
serialization
technology_1
avrois
a
recommend
technology_5
for
technology_2
because
of
it
property
technology_1
technology_10
be
binary
connector_data_1
serialization
component_13
which
provide
rich
connector_data_1
connector_data_6
technology_10
need
le
encoding
since
it
connector_11
name
and
type
in
the
schema
reduce
duplication
one
of
it
most
important
property
be
that
it
support
the
evolution
of
the
schema
avro
do
not
require
generation
it
quality_attribute_11
well
with
technology_11
script
technology_12
technology_13
technology_14
technology_15
technology_16
and
technology_11
technology_10
connector_12
use
in
the
technology_17
ecosystem
a
well
a
by
technology_2
it
be
very
similar
to
technology_9
technology_8
buffer
technology_6
etc
topic
and
partitionsin
technology_2
connector_data_4
be
organize
in
topic
you
can
think
of
topic
a
component_14
in
the
component_11
or
a
folder
in
the
component_13
topic
be
further
split
into
several
component_5
component_5
be
unique
to
technology_1
technology_2
and
be
not
see
in
the
traditional
connector_data_3
pattern_5
component_13
component_5
can
be
consider
a
a
requirement_6
when
connector_13
connector_data_4
be
append
to
the
end
of
the
component_5
preserve
the
order
connector_data_4
be
connector_13
to
one
component_5
but
copy
to
at
least
two
more
component_5
replica
for
pattern_6
when
connector_14
they
be
connector_14
from
“left”
to
“right”
since
each
topic
be
split
into
multiple
component_5
it
be
important
to
remember
that
order
be
only
guarantee
inside
the
component_5
but
total
order
across
entire
topic
and
all
component_5
be
not
component_6
and
consumersthere
be
two
type
of
component_15
component_16
of
technology_2
component_17
and
component_7
component_17
be
create
connector_data_3
in
other
pattern_3
component_13
they
might
be
connector_15
pattern_7
connector_data_3
be
generally
produce
to
a
specific
topic
component_17
do
not
connector_13
to
a
specific
component_5
they
evenly
quality_attribute_6
connector_data_4
to
all
component_5
of
the
topic
default
partitioning
strategy
for
connector_data_4
without
a
key
be
round
robin
for
connector_data_4
with
the
key
component_6
will
always
connector_16
connector_data_4
with
the
same
key
to
the
same
component_5
it
be
also
possible
for
component_17
to
direct
connector_data_4
to
a
single
component_5
to
achieve
this
component_6
rely
on
the
connector_data_3
key
and
on
a
partitioner
to
generate
the
hash
of
the
key
and
to
connector_data_7
it
to
a
component_5
component_7
connector_14
connector_data_4
and
in
other
component_13
they
can
be
connector_15
pattern_8
or
reader
component_18
subscribe
to
one
or
more
topic
and
connector_14
connector_data_4
in
the
same
order
hey
have
be
connector_13
offset
be
a
piece
of
meta
connector_data_1
that
technology_2

to
each
connector_data_3
that
be
be
produce
offset
be
requirement_7
that
continually
increase
component_7
be
use
offset
to
keep
the
track
of
connector_data_4
which
have
be
connector_14
each
connector_data_3
have
a
unique
offset
in
some
component_5
by
connector_17
the
offset
of
the
last
connector_18
connector_data_3
component_7
can
be
stop
and
start
again
without
lose
the
track
of
connector_data_1
it
have
component_3
offset
be
usually
component_10
in
technology_2
in
special
topic
reserve
for
that
one
or
more
component_18
that
connector_14
together
from
the
same
topic
be
form
a
component_7
group
this
make
sure
that
each
component_5
be
be
connector_14
by
one
member
of
the
group
one
component_7
can
connector_14
from
one
or
more
component_5
but
one
component_5
can
only
be
connector_18
by
one
component_7
to
avoid
duplication
of
connector_14
connector_data_3
component_7
group
be
enabling
easy
horizontal
quality_attribute_12
also
if
some
component_7
fail
remain
member
of
it
group
will
re
balance
the
component_5
they
be
connector_18
to
make
sure
that
all
the
connector_data_4
be
be
connector_14
pattern_4
and
clustersa
pattern_4
be
a
single
technology_2
component_19
they
connector_19
connector_data_4
from
component_6
assign
offset
to
them
and
component_10
them
to
disk
they
also
serve
component_7
serve
them
connector_data_4
on
their
connector_data_8
quality_attribute_5
on
it
hardware
a
single
pattern_4
can
easily
component_3
million
of
connector_data_4
per
second
and
manage
thousand
of
component_5
technology_2
pattern_4
usually
operate
a
part
of
the
cluster
where
one
pattern_4
be
act
a
a
pattern_9
the
pattern_9
assign
component_5
to
pattern_4
pattern_10
pattern_4
failure
and
perform
other
administrative
connector_data_9
although
a
single
component_5
can
be
assign
to
many
pattern_4
only
one
pattern_4
at
the
time
be
consider
a
the
owner
of
component_5
or
a
a
leader
all
connector_14
and
connector_13
on
some
component_5
must
go
through
the
leader
of
that
component_5
other
pattern_4
provide
the
pattern_6
of
connector_data_4
in
a
component_5
so
that
some
other
pattern_4
can
take
leader’s
role
in
the
requirement_2
of
current
leader
failure
those
pattern_4
that
have
the
same
connector_data_1
connector_data_3
a
the
leader
be
connector_15
in
pattern_11
replica
when
set
up
a
technology_2
cluster
for
the
first
time
one
of
the
most
important
parameter
be
a
“number
of
in
pattern_11
replicas”
with
this
parameter
you
choose
connector_data_1
consistency
or
connector_data_1
quality_attribute_13
in
the
requirement_2
of
failure
the
high
the
number
of
in
pattern_11
replica
the
lower
the
chance
of
lose
any
connector_data_1
but
high
time
when
connector_20
to
technology_2
and
vice
versa
retentionone
of
the
key
property
of
technology_2
be
the
connector_data_1
retention
this
be
where
technology_2
differ
from
other
pattern_3
technology_3
which
usually
do
not
persist
the
connector_data_1
for
long
period
with
other
pattern_3
technology_3
connector_data_3
connector_14
be
usually
a
destructive

mean
that
connector_data_3
connector_12
delete
after
connector_14
have
be
confirm
this
be
not
the
requirement_2
with
technology_2
technology_2
pattern_4
have
a
default
set
for
topic
to
retain
the
connector_data_1
either
for
some
period
e
g

day
or
when
the
topic
reach
certain
size
in
byte
e
g

gb
when
these
predefined
limit
be
reach
connector_data_4
be
expire
and
delete
also
individual
topic
can
be
configure
to
keep
the
connector_data_1
if
it
provide
requirement_7
this
property
can
be
extremely
useful
in
certain
situation
for
example
if
the
component_1
component_13
be
serve
connector_data_4
much
fast
than
the
target
component_13
can
component_3
them
technology_2
who
sit
in
the
middle
can
retain
the
connector_data_4
until
target
component_13
connector_12
upgrade
or
connector_12
free
of
it
current
big
component_3
load
with
this
technology_2
act
a
a
buffer
between
different
component_20
and
prevent
load
crash
or
big
delay
another
such
requirement_2
be
connector_data_1
reprocess
for
requirement_8
intelligence
and
report
purpose
since
technology_2
retain
the
connector_data_1
for
long
period
any
late
arrive
connector_data_4
can
easily
be

to
current
snapshot
or
any
error
in
those
snapshot
can
be
fix
simply
by
replay
the
same
connector_data_4
once
again
through
update
version
of
the
connector_data_1
component_3

zookeeperone
other
important
part
of
technology_2
architecture
be
an
technology_1
technology_18
technology_18
be
a
centralized
component_4
for
quality_attribute_6
component_20
technology_2
be
technology_18
be
necessary
for
technology_2
to
run
it
keep
all
meta
connector_data_1
connector_data_10
for
technology_2
pattern_4
connector_data_10
topic
configuration
cluster
membership
and
perform
leader
election
technology_2
benchmarksthese
number
be
a
little
bit
old
but
still
very
relevant
the
best
thing
about
this
be
that
with

version
of
technology_2
these
number
connector_2
improve
even
more
benchmark
be
from

component_1
connector_21
setup

component_21
intel
xeon


ghz
processor
with
six
core
six

rpm
sata
drive
32gb
of
ram
1gb
ethernetsingle
component_6
component_22
no
pattern_12


component_8
sec


connector_data_11
sec
single
component_6
component_22
3x
pattern_1
pattern_12


component_8
sec


connector_data_11
sec
single
component_6
component_22
3x
pattern_13
pattern_12


component_8
sec


connector_data_11
sec
three
component_6
3x
pattern_14
pattern_12



component_8
sec


connector_data_11
sec
single
component_7


component_8
sec


connector_data_11
sec
three
component_7



component_8
sec


connector_data_11
sec
end
to
end
quality_attribute_14

m
median

m
99th
percentile

m

9th
percentile
why
be
technology_2
so
fast
it
us
some
clever
trick
combine
with
some
quality_attribute_1
engineering
principle
partitioning
of
the
topic
connector_13
quality_attribute_12
horizontally
component_7
group
connector_14
quality_attribute_12
horizontally
optimize
quality_attribute_2
by
pattern_15
connector_9
and
writesusing
requirement_6
to
component_10
the
connector_data_1
connector_data_1
be
only
append
to
the
component_13
and
connector_9
be
quality_attribute_9
all
such
be
o

zero
copy
connector_21
—
connector_data_12
the
o
kernel
directly
rather
than
at
the
component_12
pattern_16
to
move
connector_data_1
fastuses
standardize
binary
connector_data_1
technology_5
for
component_6
pattern_4
and
component_18
so
connector_data_1
can
be
pass
without
modification
technology_2
guaranteesto
summarize
—
when
consider
all
it
property
technology_2
provide
some
very
valuable
guarantee
connector_data_3
connector_22
to
a
topic
component_5
will
be
append
to
the
connector_6
requirement_6
in
the
order
they
be
connector_16
a
single
component_7
instance
will
see
connector_data_4
in
the
order
they
appear
in
the
requirement_6
a
connector_data_3
be
connector_6
when
all
“in
pattern_11
replicas”
have
apply
it
to
their
requirement_6
any
connector_6
connector_data_3
will
not
be
lose
if
at
least
one
“in
pattern_11
replica”
be
alive
with
these
guarantee
one
can
design
different
type
of
very
valuable
component_13
real
time
connector_23
component_3
component_20
fraud
detection
requirement_3
recommendation
component_23
component_20
connector_data_1
extraction
to
technology_2
through
cdc
connector_8
connector_data_1
capture
technology_19
extract
—
transform
—
load
connector_data_1
pipeline
for
requirement_8
intelligence
and
report
component_13
“event
sourcing”
component_20
ledger
type
of
component_12
micro
component_4
component_24
etc
technology_2
ecosystemthere
be
some
other
excite
technology_3
which
have
emerge
around
technology_2
some
be
part
of
regular
technology_2
installation
some
must
be
instal
separately
although
they
be
very
much
worth
look
into
we
be
mention
them
now
and
we
will
describe
them
in
more
detail
in
one
of
follow

technology_2
connector_23
a
component_15
technology_20
for
build
technology_11
and
technology_21
component_24
where
input
and
output
be
connector_13
to
technology_2
more
about
it
here
technology_2
connector_24
be
a
technology_22
for
connector_24
technology_2
with
external
component_20
such
a
component_11
key
requirement_7
component_10
search
index
and
component_20
documentation
confluent
schema
registry
be
a
quality_attribute_6
storage
pattern_16
for
technology_10
schema
which
us
technology_2
a
it
underlie
storage
mechanism
documentation
confluent
pattern_17
pattern_18
provide
a
pattern_19
to
a
technology_2
cluster
make
it
easy
to
produce
and
connector_18
connector_data_3
and
perform
administrative
action
without
use
the
requirement_9
technology_2
technology_8
or
component_25
documentation
final
wordsi
personally
believe
that
one
of
the
big
benefit
of
technology_2
be
that
it
decrease
“time
to
value”
for
connector_data_1
by
be
a
back
bone
for
all
the
connector_data_1
in
organization
remove
“silos”
around
connector_data_1
from
different
domain
enabling
connector_data_1
scientist
and
connector_data_1
engineer
to
connector_2
quick
connector_4
to
connector_data_1
—
all
this
provide
a
tremendous
competitive
advantage
to
any
requirement_1
in
this
“age
of
data”
that
we
be
live
in
that
be
why
i
wholeheartedly
recommend
to
every
it
professional
to
dive
more
into
technology_2
how
to
use
it
and
build
some
excite
component_12
by
vajo
lukicoriginally
publish
at
press
webstep
se
more
from
webstepwebstep
be
an
it
consultant
requirement_1
compose
of

requirement_10
locate
in
sweden
and
norway
we
have
consultant
who
be
expert
within
component_13
development
requirement_8
intelligence
iot
connector_data_1
science
requirement_11
requirement_12
and
it
requirement_13
we
love
to
thing
and
connector_25
it
wread
more
from
websteprecommended
from
mediumfelix
blaschkeintroducing
animationcontrollerx
for
flutterhilaal
alamopenfoam
—
tip
2linuxbaberun
openconnect
vpn
component_19
&
technology_1
technology_23
on
the
same
component_26
with
haproxycorey
sheesleywelcome
to
railsamaaira
johnsthe
requirement_7
of
connector_26
a
citrix
certificationamaaira
johnsupgrade
your
skill
with
the
technology_24
requirement_14
specialty
certificatione^{i}
venturesannouncing
the
solana
technology_25
sdktesting
curatortesting
bit

—
jan
24th

—
jan
30th
2021abouthelptermsprivacyget
the
appget
startedvajo
lukic42
followerssolution
architect
for
connector_data_1
and
requirement_15
at
sebfollowmore
from
mediumrahul
patidarfrom
the
above
component_27
we
can
easily
understand
that
1st
offset
will
component_3
the

row
4+12+08
…lokesh
alamuriin
this

i
be
go
to
explain
you
how
state
component_10
in
technology_2
connector_27
be
manage
in…all
about
codethe

major
component_28
in
technology_1
kafkadominik
lieblerinyazio
engineeringintegrating
confluent
schema
registry
with
technology_1
technology_26
applicationshelpstatuswritersblogcareersprivacytermsaboutknowable
