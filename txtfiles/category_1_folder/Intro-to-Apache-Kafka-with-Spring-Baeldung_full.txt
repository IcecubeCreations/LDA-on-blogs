intro
to
technology_1
technology_2
with
technology_3
|
baeldung
start
herecourses
▼▲
pattern_1
with
technology_3
the
canonical
reference
for
build
a
production
grade
component_1
with
technology_3
technology_3
quality_attribute_1
▼▲
the
unique
technology_3
quality_attribute_1
education
if
you’re
work
with
technology_4
today
technology_3
quality_attribute_1
core
focus
on
the
core
of
technology_3
quality_attribute_1

technology_3
quality_attribute_1
oauth
focus
on
the
oauth2
technology_5
in
technology_3
quality_attribute_1

technology_3
from
no
experience
to
actually
build
stuff​
technology_3
connector_data_1
technology_6
the
full
guide
to
persistence
with
technology_3
connector_data_1
technology_6
guide
▼▲
persistence
the
persistence
with
technology_3
guide
pattern_1
the
guide
on
build
pattern_1
component_2
with
technology_3
quality_attribute_1
the
technology_3
quality_attribute_1
guide
about
▼▲
full
archive
the
high
level
overview
of
all
the

on
the

baeldung
ebooks
discover
all
of
our
ebooks
about
baeldung
about
baeldung
intro
to
technology_1
technology_2
with
technology_3
last
modify


by
baeldung
persistencespring+
kafkamessaging
technology_3
top
connector_1
start
with
technology_3

and
technology_3

through
the
reference
technology_3

technology_3
persistence
top
connector_1
start
with
technology_3
connector_data_1
technology_6
through
the
reference
technology_3
connector_data_1
technology_6

connector_2
out
the

overview
technology_1
technology_2
be
a
quality_attribute_2
and
fault
tolerant
connector_3
component_3
component_4
in
this

we
ll
cover
technology_3
support
for
technology_2
and
the
level
of
abstraction
it
provide
over
requirement_1
technology_2
technology_4
component_5
apis
technology_3
technology_2
bring
the
quality_attribute_3
and
typical
technology_3
template
programming
component_6
with
a
kafkatemplate
and
connector_data_2
drive
pojos
via
@kafkalistener
annotation
further
connector_4
build
a
connector_data_1
pipeline
with
flink
and
kafkalearn
how
to
component_3
connector_3
connector_data_1
with
flink
and
kafkaread
more
→kafka
connector_5
example
with
technology_7
and
mongodbhave
a
look
at
a
practical
example
use
technology_2
connector
connector_4
more
→

installation
and
setup
to
download
and
install
technology_2
please
refer
to
the
official
guide
here
we
also
need
to
the
technology_3
technology_2
connector_6
to
our
pom
technology_8
connector_6


springframework
technology_2


technology_3
technology_2

version



version
connector_6
the
late
version
of
this
artifact
can
be
find
here
our
example
component_7
will
be
a
technology_3
component_7
this
assume
that
the
component_8
be
start
use
the
default
configuration
and
that
no
component_8
port
be
connector_7

configure
topic
previously
we
run
command
line
technology_9
to
create
topic
in
technology_2
$
bin
technology_2
topic
sh
create
\
technology_10
localhost

\
pattern_2
factor

component_9

\
topic
mytopic
but
with
the
introduction
of
adminclient
in
technology_2
we
can
now
create
topic
programmatically
we
need
to
the
kafkaadmin
technology_3
component_10
which
will
automatically
topic
for
all
component_11
of
type
newtopic
@configuration
kafkatopicconfig
{
@value
requirement_2
=
${kafka
bootstrapaddress}
private
bootstrapaddress
@bean
kafkaadmin
kafkaadmin
{
connector_data_3

connector_data_4
configs
=
hashmap
configs
put
adminclientconfig
bootstrap_servers_config
bootstrapaddress
kafkaadmin
configs
}
@bean
newtopic
topic1
{
newtopic
baeldung

short

}
}

produce
connector_data_5
to
create
connector_data_2
we
first
need
to
configure
a
producerfactory
this
set
the
strategy
for
create
technology_2
component_12
instance
then
we
need
a
kafkatemplate
which
wrap
a
component_12
instance
and
provide
convenience
for
connector_8
connector_data_5
to
technology_2
topic
component_12
instance
be
component_13
quality_attribute_4
so
use
a
single
instance
throughout
an
component_7
component_14
will
give
high
requirement_3
consequently
kakfatemplate
instance
be
also
component_13
quality_attribute_4
and
use
of
one
instance
be
recommend


component_12
configuration
@configuration
kafkaproducerconfig
{
@bean
producerfactory


producerfactory
{
connector_data_3

connector_data_4
configprops
=
hashmap
configprops
put
producerconfig
bootstrap_servers_config
bootstrapaddress
configprops
put
producerconfig
key_serializer_class_config
stringserializer

configprops
put
producerconfig
value_serializer_class_config
stringserializer

defaultkafkaproducerfactory
configprops
}
@bean
kafkatemplate


kafkatemplate
{
kafkatemplate
producerfactory
}
}


publish
connector_data_5
we
can
connector_9
connector_data_5
use
the
kafkatemplate

@autowired
private
kafkatemplate


kafkatemplate
sendmessage

msg
{
kafkatemplate
connector_9
topicname
msg
}
the
connector_9
component_1

a
listenablefuture
connector_data_4
if
we
want
to
block
the
connector_8
component_13
and
connector_1
the
connector_data_6
about
the
connector_10
connector_data_2
we
can
connector_data_7
the
connector_1
component_1
of
the
listenablefuture
connector_data_4
the
component_13
will
wait
for
the
connector_data_6
but
it
will
slow
down
the
component_12
technology_2
be
a
fast
connector_3
component_3
component_15
therefore
it
s
quality_attribute_5
to
handle
the
connector_data_8
asynchronously
so
that
the
subsequent
connector_data_5
do
not
wait
for
the
connector_data_6
of
the
previous
connector_data_2
we
can
do
this
through
a
pattern_3
sendmessage

connector_data_2
{
listenablefuture
sendresult


future
=
kafkatemplate
connector_9
topicname
connector_data_2
future
addcallback

listenablefuturecallback
sendresult


{
@override
onsuccess
sendresult


connector_data_6
{
component_4
out

connector_9
message=
+
connector_data_2
+
with
offset=
+
connector_data_6
getrecordmetadata
offset
+
}
@override
onfailure
throwable
ex
{
component_4
out

unable
to
connector_9
message=
+
connector_data_2
+
due
to
+
ex
getmessage
}
}
}

connector_11
connector_data_5


component_16
configuration
for
connector_11
connector_data_2
we
need
to
configure
a
consumerfactory
and
a
kafkalistenercontainerfactory
once
these
component_11
be
quality_attribute_6
in
the
technology_3
component_10
factory
pojo
base
component_17
can
be
configure
use
@kafkalistener
annotation
@enablekafka
annotation
be
require
on
the
configuration
to
enable
detection
of
@kafkalistener
annotation
on
technology_3
manage
component_10
@enablekafka
@configuration
kafkaconsumerconfig
{
@bean
consumerfactory


consumerfactory
{
connector_data_3

connector_data_4
prop
=
hashmap
prop
put
consumerconfig
bootstrap_servers_config
bootstrapaddress
prop
put
consumerconfig
group_id_config

prop
put
consumerconfig
key_deserializer_class_config
stringdeserializer

prop
put
consumerconfig
value_deserializer_class_config
stringdeserializer

defaultkafkaconsumerfactory
prop
}
@bean
concurrentkafkalistenercontainerfactory


kafkalistenercontainerfactory
{
concurrentkafkalistenercontainerfactory


factory
=
concurrentkafkalistenercontainerfactory
factory
setconsumerfactory
consumerfactory
factory
}
}


connector_11
connector_data_5
@kafkalistener
topic
=
topicname
=
foo
listengroupfoo

connector_data_2
{
component_4
out

connector_12
connector_data_2
in
group
foo
+
connector_data_2
}
we
can
connector_13
multiple
component_18
for
a
topic
each
with
a
different
group

furthermore
one
component_16
can
listen
for
connector_data_5
from
various
topic
@kafkalistener
topic
=
topic1
topic2
=
foo
technology_3
also
support
retrieval
of
one
or
more
connector_data_2

use
the
@header
annotation
in
the
component_18
@kafkalistener
topic
=
topicname
listenwithheaders
@payload
connector_data_2
@header
kafkaheaders
received_partition_id
component_9
{
component_4
out

connector_12
connector_data_2
+
connector_data_2
+
from
component_9
+
component_9
}


connector_11
connector_data_5
from
a
specific
component_9
notice
that
we
create
the
topic
baeldung
with
only
one
component_9
for
a
topic
with
multiple
component_9
however
a
@kafkalistener
can
explicitly
subscribe
to
a
particular
component_9
of
a
topic
with
an
initial
offset
@kafkalistener
topicpartitions
=
@topicpartition
topic
=
topicname
partitionoffsets
=
{
@partitionoffset
component_9
=

initialoffset
=

@partitionoffset
component_9
=

initialoffset
=

}
containerfactory
=
partitionskafkalistenercontainerfactory
listentopartition
@payload
connector_data_2
@header
kafkaheaders
received_partition_id
component_9
{
component_4
out

connector_12
connector_data_2
+
connector_data_2
+
from
component_9
+
component_9
}
since
the
initialoffset
have
be
set
to

in
this
component_18
all
the
previously
connector_14
connector_data_5
from
component_9

and

will
be
re
connector_14
every
time
this
component_18
be
initialize
if
we

t
need
to
set
the
offset
we
can
use
the
component_9
property
of
@topicpartition
annotation
to
set
only
the
component_9
without
the
offset
@kafkalistener
topicpartitions
=
@topicpartition
topic
=
topicname
component_9
=
{


}



connector_data_2
pattern_4
for
component_19
we
can
configure
component_18
to
connector_14
specific
type
of
connector_data_5
by

a
custom
pattern_4
this
can
be
do
by
set
a
recordfilterstrategy
to
the
kafkalistenercontainerfactory
@bean
concurrentkafkalistenercontainerfactory


filterkafkalistenercontainerfactory
{
concurrentkafkalistenercontainerfactory


factory
=
concurrentkafkalistenercontainerfactory
factory
setconsumerfactory
consumerfactory
factory
setrecordfilterstrategy
component_20
component_20
requirement_2
contain
world
factory
}
we
can
then
configure
a
component_18
to
use
this
container
factory
@kafkalistener
topic
=
topicname
containerfactory
=
filterkafkalistenercontainerfactory
listenwithfilter

connector_data_2
{
component_4
out

connector_12
connector_data_2
in
pattern_4
component_18
+
connector_data_2
}
in
this
component_18
all
the
connector_data_5
match
the
pattern_4
will
be
discard

custom
connector_data_2
converter
so
far
we
have
only
cover
connector_8
and
connector_15

a
connector_data_2
however
we
can
also
connector_9
and
connector_12
custom
technology_4
connector_data_4
this
require
configure
appropriate
serializer
in
producerfactory
and
deserializer
in
consumerfactory

s
look
at
a
quality_attribute_3
component_10

which
we
will
connector_9
a
connector_data_2
greet
{
private
msg
private
name
technology_11
getters
setter
and
constructor
}


produce
custom
connector_data_5
in
this
example
we
will
use
jsonserializer

s
look
at
the
for
producerfactory
and
kafkatemplate
@bean
producerfactory

greet
greetingproducerfactory
{
configprops
put
producerconfig
value_serializer_class_config
jsonserializer

defaultkafkaproducerfactory
configprops
}
@bean
kafkatemplate

greet
greetingkafkatemplate
{
kafkatemplate
greetingproducerfactory
}
we
can
use
this
kafkatemplate
to
connector_9
the
greet
connector_data_2
kafkatemplate
connector_9
topicname
greet
hello
world


connector_11
custom
connector_data_5
similarly

s
modify
the
consumerfactory
and
kafkalistenercontainerfactory
to
deserialize
the
greet
connector_data_2
correctly
@bean
consumerfactory

greet
greetingconsumerfactory
{
defaultkafkaconsumerfactory
prop
stringdeserializer
jsondeserializer
greet

}
@bean
concurrentkafkalistenercontainerfactory

greet
greetingkafkalistenercontainerfactory
{
concurrentkafkalistenercontainerfactory

greet
factory
=
concurrentkafkalistenercontainerfactory
factory
setconsumerfactory
greetingconsumerfactory
factory
}
the
technology_3
technology_2
technology_12
serializer
and
deserializer
us
the
technology_13
technology_14
which
be
also
an
optional
technology_15
connector_6
for
the
technology_3
technology_2
project
so

s
it
to
our
pom
technology_8
connector_6

technology_16
fasterxml
technology_13
core


technology_13
databind

version



version
connector_6
instead
of
use
the
late
version
of
technology_13
it
s
recommend
to
use
the
version
that
be

to
the
pom
technology_8
of
technology_3
technology_2
finally
we
need
to
connector_16
a
component_18
to
connector_14
greet
connector_data_2
@kafkalistener
topic
=
topicname
containerfactory
=
greetingkafkalistenercontainerfactory
greetinglistener
greet
greet
{
component_3
greet
connector_data_2
}

conclusion
in
this

we
cover
the
basic
of
technology_3
support
for
technology_1
technology_2
we
take
a
brief
look
at
the
use
for
connector_8
and
connector_15
connector_data_2
complete
component_21
for
this
can
be
find
over
on
technology_17
before
run
the

please
make
sure
that
technology_2
component_8
be
run
and
that
the
topic
be
create
manually
technology_3
bottom
connector_1
start
with
technology_3

and
technology_3

through
the
technology_3

the
persistence
bottom
connector_1
start
with
technology_3
connector_data_1
technology_6
through
the
reference
technology_3
connector_data_1
technology_6

connector_2
out
the
persistence
footer
banner
an
intro
technology_3
connector_data_1
technology_6
and
transaction
semantics
detail
with
jpaget
persistence
right
with
technology_3
download
the
e
book

be
close
on
this

persistence
sidebar
banner
how
to
do
persistence
with
technology_3
download
the
e
book
coursesall

all
bulk

the

component_15
seriesjava
“back
to
basics”
technology_13
technology_12
technology_1
httpclient
pattern_1
with
technology_3
technology_3
persistence
quality_attribute_1
with
technology_3
technology_3
reactive

aboutabout
baeldung
the
full
archive
editor
our
partner
partner
with
baeldung
term
of
component_22
privacy
requirement_4
requirement_5
info
follow
the
technology_3
category
follow
the
technology_3
category
to
connector_1
regular
info
about
the

and

we
publish
here
follow
the
technology_3
