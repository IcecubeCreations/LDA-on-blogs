pattern_1
component_1
quality_attribute_1
part

technology_1
technology_2
coding_keyword_1
close
home
archive
linkedin
technology_3
subscribe
pattern_1
component_1
quality_attribute_1
part

technology_1
technology_2



—

min
connector_1
#kafka
#messaging
#low
quality_attribute_1
most
developer
i
talk
to
about
technology_2
agree
on
a
catchphrase
“kafka
be
design
for
throughput”
that’s
fair
and
you
can
find
plenty
of
benchmark
that
show
700k
s
quality_attribute_2
for
single
component_2
without
pattern_2
but
do
that
mean
we
should
discard
technology_2
when
talk
about
low
quality_attribute_1
connector_data_1
after
quick

i
find
this
outdated
so
question
that
question
be
very
old
and
include
very
old
version
of
technology_2



whereas
current
version
be



and
also
this
state
that
very
decent
quality_attribute_1

3ms

percentile
be
achievable
have
such
controversial
info
be
not
enough
to
make
final
decision
so
i
decide
to
create
a
little
benchmark
myself
to
finally
conclude
whether
technology_2
be
quality_attribute_3
for
low
quality_attribute_1
component_3
what
be
measure
for
all
test
i
run
component_2
component_4
and
pattern_3
on
the
same
component_5
for
these
test
i
use
laptop
i7
7820hq
16gb
window

yes
i
know…
this
be
why
pre
allocation
be
on
in
pattern_3
setting
and
you
will
need
to
disable
it
should
you
run
provide
on
linux
component_6
also
i
didn’t
connector_2
default
technology_2
startup
script
which
mean
pattern_3
have
1gb
heap
maximum
quality_attribute_1
test
intent
be
to
test
follow
scenario
light
quality_attribute_2
of

connector_data_1
second
+
non
quality_attribute_4
pattern_3
light
quality_attribute_2
of

connector_data_1
second
+
fault
tolerant
pattern_3
moderate
quality_attribute_2
of

connector_data_1
second
+
non
quality_attribute_4
pattern_3
moderate
quality_attribute_2
of

connector_data_1
second
+
fault
tolerant
pattern_3
this
test
do
not
measure
quality_attribute_1
drop
due
to
cluster
technology_4
failovers
a
these
scenario
be
very
different
quality_attribute_5
on
your
partitioning
schema
and
pattern_2
factor
hopefully
technology_4
failure
be
not
part
of
your
normal
day
to
day
a
usual
all
can
be
find
here
if
you
want
to
play
around
and
see
how
your
setup
compare
all
scenario
be
locate
in
test
directory
under
benchmark
latencybenchmark
for
exact
pattern_3
component_7
configuration
see
above
also
i’ll
put
a
little
explanation
why
these
setting
be
use
connector_data_2
low
quality_attribute_1
possible
measurement
@

connector_data_1
s
total
connector_3

total
connector_4

connector_5
rate



percentile



percentile


min
quality_attribute_1


max
quality_attribute_1


avg
quality_attribute_1


measurement
@

connector_data_1
s
total
connector_3

total
connector_4

connector_5
rate



percentile



percentile


min
quality_attribute_1


max
quality_attribute_1


avg
quality_attribute_1


so
these
be
low
quality_attribute_1
possible
on
my
component_5
configuration
for
these
no
pattern_4
on
component_2
component_4
always
fetch
all
quality_attribute_6
connector_data_3
up
to
configure
size
no
acks
on
component_2
no
connector_6
after
each
connector_data_1
but
us
pattern_5
background
connector_7
on
component_4
single
technology_4
cluster
no
pattern_2
pattern_3
have
delay
pattern_6
to
disk
all
internal
topic
be
single
component_8
a
you
can
see
most
connector_data_3
make
a
quality_attribute_7
within


m
there
be
always
outlier
at
rare
occasion
which
be
cause
by
different
quality_attribute_8
and
probably
some
interference
from
o
for
example
expire
offset
removal
take
around

m
also
it’s
possible
to
decrease
component_4
pattern_7
timeout
to
connector_8
small
max
quality_attribute_1
at
cost
of
high

percentile
non
fault
tolerant
setup
with
component_4
connector_7
after
each
connector_1
measurement
@

connector_data_1
s
and
pattern_8
connector_7
total
connector_3

total
connector_4

connector_5
rate



percentile



percentile


min
quality_attribute_1


max
quality_attribute_1


avg
quality_attribute_1


i
make
these
measurement
a
i
be
curious
how
pattern_8
connector_7
affect
quality_attribute_1
and
it’s
roughly
30%
overhead
fault
tolerant
setup
with
pattern_8
component_4
connector_7
measurement
@

connector_data_1
s
and
pattern_8
connector_7
total
connector_3

total
connector_4

connector_5
rate



percentile



percentile


min
quality_attribute_1


max
quality_attribute_1


avg
quality_attribute_1


measurement
@

connector_data_1
s
and
pattern_8
connector_7
total
connector_3

total
connector_4

connector_5
rate



percentile



percentile


min
quality_attribute_1


max
quality_attribute_1


avg
quality_attribute_1


fault
tolerant
config
pattern_3
make
out
of

technology_4
component_2
wait
for
ack
from
each
pattern_3
technology_4
pattern_6
to
disk
be
still
delay
for
the
high
quality_attribute_2
scenario
i
have
to
turn
pattern_4
on
and
put
a
set
to
pattern_4
at
most

component_9
otherwise
maximum
quality_attribute_2
would
be

min_latency
=


=

connector_data_1
s
conclusion
look
these

about
huge
quality_attribute_1
of
100ms
magnitude
relate
to
old
version
of
technology_2
replicate
show
pretty
decent
connector_data_4
which
should
be
enough
for
most
requirement_1
please
note
that
these
connector_data_2
be
not
make
on
dedicate
hardware
and
i
didn’t
do
any
memory
o
setting
affinity
tune
so
very
likely
it’s
possible
to
connector_8
even
quality_attribute_3
connector_data_4
there
be
no
measurement
for
quality_attribute_4
connector_data_3
force
flush
each
connector_data_1
on
disk
and
i
think
test
for
such
setup
be
extremely
hardware
dependent
and
should
be
make
use
proper
hdd
ssd
my
takeaway
from
this
be
that
unless
you
need
sub
millisecond
quality_attribute_1
i
could
do
with
technology_2
unless
you
be
in
that
outlier
part
of
spectrum
technology_5
solution
selection
must
be
do
base
on
requirement_2
it
provide
and
not
on
specific
requirement_3
parameter
and
of
quality_attribute_9
well

technology_5
be
much
quality_attribute_3
than
have
a
zoo
of
trendy
name
that
barely
anyone
in
team
understand
properly
p
s
come
soon
follow
up
coding_keyword_2
where
same
test
be
perform
with
technology_1
artemis
former
technology_6
connector_9
connector_9
on
twitter
connector_9
on
connector_1
next
previous
introduction
to
technology_7
coroutines


next
monty
hall
problem


about
i
be
rom
a
technology_7
developer
focus
on
high
quality_attribute_2
component_1
this
be
a
collection
of
tech
requirement_3
and
design
tip
broadly
cover
my
experience
out
in
the

recommend
book
a
an
associate
i
earn
from
qualify
purchase
late
coding_keyword_2
reduce
technology_8
heap
size
part

manual
memory
requirement_4


reduce
technology_8
heap
size
part

optimize


reduce
technology_8
heap
size
part

profile


technology_9
mix
in


connector_10
start
with
dropwizard


tag
buildconcurrencycore
javacoroutinesdesigndropwizardgradlejacksonjavakafkalow
latencymemorymessagingmicroservicesmultithreadingnon
block
ioperformanceprotocolsquasar
back
to
the
top
