develop
a
technology_1
component_1
with
technology_2
technology_1
technology_1
zone
thanks
for
visit
today
edit
profile
manage
subscription
how
to
to
submission
guideline
sign
out
pattern_1
profile
an
manage
my
draft
over
million
developer
have
join
requirement_1
in
join
refcardz
trend
report
webinars
zone
|
agile
requirement_2
requirement_3
requirement_4
component_2
devops
requirement_5
iot
technology_1
pattern_2
open_source
requirement_6
quality_attribute_1
web
dev
technology_1
zone
develop
a
technology_1
component_1
with
technology_2
develop
a
technology_1
component_1
with
technology_2
by
daniel
pereira
·
mar
·
technology_1
zone
·
connector_1
tweet
43k
pattern_1
join
the
and
connector_2
the
full
member
experience
join
for
free
today’s
component_3
component_4
demand
the
very
best
requirement_7
they
be
accustomed
to
connector_3
their
component_5
from
all
their
component_6
component_7
requirement_8
phone
tablet
etc
a
component_8
continue
to
transition
to
a
a
component_9
saas
developer
be
constantly
collaborate
with
powerful
technology_3
that
scope
to
handle
thousand
of
connector_data_1
every
second
this
be
where
technology_4
technology_2
a
quality_attribute_2
technology_3
that
be
for
handle
highly
intense
environment
come
in
in
this
we’ll
introduce
you
to
the
basic
of
technology_4
technology_2
and
move
on
to
build
a
quality_attribute_3
quality_attribute_4
pattern_3
component_3
with
technology_1
and
technology_2
prerequisite
technology_1
8+
an
internet
connector_4
and
a
free
okta
developer
account
a
brief
overview
of
technology_4
technology_2
technology_4
technology_2
be
a
quality_attribute_5
connector_5
component_10
that
utilize
the
pattern_4
connector_data_2
pattern_5
to
connector_6
with
component_1
it’s
design
to
create
quality_attribute_6
connector_data_2
let’s
break
down
those
concept
in
more
detail
quality_attribute_5
connector_5
component_10
when
you
want
to
run
technology_2
you
need
to
start
it
pattern_6
a
quality_attribute_7
instance
of
technology_2
run
on
a
component_11
any
other
component_12
the
pattern_6
be
responsible
to
connector_7
connector_8
and
component_13
connector_data_3
into
the
disk
a
single
pattern_6
be
not
enough
to
ensure
technology_2
can
handle
a
high
quality_attribute_8
of
connector_data_2
that
goal
be
achieve
through
many
pattern_6
work
together
at
the
same
time
connector_9
and
coordinate
with
each
other
a
technology_2
cluster
group
together
one
or
more
pattern_6
instead
of
connector_10
to
a
single
technology_5
your
component_1
connector_11
to
a
cluster
that
manage
all
the
quality_attribute_5
detail
for
you
you
also
a
technology_2
for
everyone
no
matter
your
stage
in
development
pattern_4
pattern_3
component_14
with
quality_attribute_6
connector_data_3
the
pattern_4
be
a
common
pattern_5
in
quality_attribute_5
component_14
the
image
below
illustrate
the
basic
connector_data_4
of
this
pattern_5
within
technology_2
technology_2
component_15
and
component_16
the
image
include
two
component_17
not
mention
so
far
component_15
and
component_18
a
component_19
be
an
component_1
that
connector_12
connector_data_3
to
the
cluster
in
this
example
component_19
and
be
connector_13
connector_data_2
the
cluster
then
elect
which
pattern_6
should
component_13
them
and
connector_12
it
to
the
one
selected
on
the
other
side
you
have
component_18
a
component_18
be
an
component_1
that
connector_11
to
the
cluster
and
connector_14
the
connector_data_3
from
component_19
any
component_1
that
be
interest
in
connector_15
connector_data_3
connector_16
by
component_15
must
connector_10
into
the
technology_2
component_18
a
technology_2
connector_17
connector_data_3
for
long
duration
the
default
requirement_9
be
seven
day
you
can
have
many
component_16
connector_18
the
same
connector_data_2
even
if
they
be
not
there
when
the
connector_data_2
be
connector_7
technology_2
topic
when
you
connector_7
a
connector_data_2
to
a
technology_2
pattern_6
you
need
to
specify
where
the
connector_data_2
will
be
connector_16
by
specify
a
topic
a
topic
be
a
category
of
connector_data_3
that
a
component_18
can
subscribe
to
this
mechanism
ensure
that
component_16
only
connector_8
connector_data_3
relevant
to
them
rather
than
connector_18
every
connector_data_2
publish
to
the
cluster
now
that
you
understand
kafka’s
basic
architecture
let’s
download
and
install
it
install
and
run
technology_2
to
download
technology_2
go
to
the
technology_2
extract
the
content
of
this
compress
into
a
folder
of
your
preference
inside
the
technology_2
directory
go
to
the
bin
folder
here
you’ll
find
many
bash
script
that
will
be
useful
for
run
a
technology_2
component_1
if
you
be
use
window
you
also
have
the
same
script
inside
the
window
folder
this
u
linux
command
but
you
need
to
use
the
equivalent
window
version
if
you’re
run
a
o
start
technology_6
to
manage
your
technology_2
cluster
technology_4
technology_2
be
always
run
a
a
quality_attribute_5
component_1
this
mean
your
cluster
have
to
deal
with
some
quality_attribute_5
challenge
along
the
way
synchronize
configuration
or
elect
a
leader
to
take
care
of
the
cluster
technology_2
u
technology_6
to
keep
track
of
those
detail
don’t
worry
about
download
it
though
technology_2
already
ship
with
technology_6
allow
you
to
connector_2
up
and
run
very
fast
let’s
start
a
technology_6
instance
inside
the
bin
folder
in
your
technology_2
directory
run
the
follow
command
shell
x
technology_6
component_12
start
sh
config
technology_6
property
this
command
start
a
technology_6
component_12
on
port
by
default
technology_6
be
responsible
to
coordinate
the
technology_2
pattern_6
inside
your
cluster
you’ll
use
the
default
configuration
inside
the
technology_2
project
for
this
but
you
can
always
connector_19
those
requirement_9
a
need
run
a
technology_2
pattern_6
the
next
step
be
to
run
the
pattern_6
itself
from
another
terminal
run
the
follow
command
from
the
bin
folder
shell
xxxxxxxxxx
technology_2
component_12
start
sh
config
component_12
property
a
you
might
have
guess
this
command
run
the
technology_2
component_12
with
the
default
configuration
on
the
default
port
create
a
technology_2
topic
now
that
you
have
the
pattern_6
and
technology_6
run
you
can
specify
a
topic
to
start
connector_13
connector_data_3
from
a
component_19
you’re
go
to
run
a
command
inside
the
bin
folder
you
do
in
the
previous
step
shell
xxxxxxxxxx
technology_2
topic
sh
create
topic
mytopic
technology_6
\
localhost
pattern_7
factor
component_20
this
command
create
a
topic
name
mytopic
point
to
the
technology_6
instance
you
start
with
the
first
command
there
be
also
two
different
parameter
you
have
to
specify
pattern_7
factor
and
component_20
don’t
worry
about
them
right
now
they
be
use
to
control
specific
aspect
relate
to
quality_attribute_5
component_21
in
technology_2
a
you
be
run
a
quality_attribute_7
setup
you
can
specify
“1”
for
both
parameter
now
that
you
have
everything
up
and
run
you
can
start
quality_attribute_9
technology_2
with
a
technology_1
component_1
create
a
technology_1
+
technology_2
component_1
let’s
start
with
the
project
connector_data_4
use
technology_7
initializer
to
create
the
component_1
go
to
technology_8
start
technology_7
io
and
fill
in
the
follow
connector_data_5
project
technology_9
project
technology_10
technology_1
group
technology_11
okta
javakafka
artifact
technology_2
technology_1
connector_20
technology_7
web
technology_7
for
technology_4
technology_2
you
can
also
generate
the
project
use
the
command
line
paste
the
follow
command
in
your
terminal
and
it
will
download
the
project
with
the
same
configuration
define
above
shell
xxxxxxxxxx
curl
technology_8
start
technology_7
io
starter
zip
technology_12
language=java
\
technology_12
dependencies=web
technology_2
\
technology_12
packagename=com
okta
javakafka
\
technology_12
name=kafka
technology_1
\
technology_12
type=maven
project
\
o
technology_2
technology_1
zip
this
u
technology_9
but
you
can
easily
follow
it
with
gradle
if
you
prefer
that’s
it
now
your
technology_1
project
connector_data_4
be
create
and
you
can
start
develop
your
component_3
connector_21
connector_data_3
to
a
technology_2
topic
in
your
technology_1
component_3
the
first
step
to
create
a
component_19
that
can
connector_21
connector_data_3
be
to
configure
the
component_15
inside
your
technology_1
component_1
let’s
create
a
configuration
to
do
that
create
a
src
technology_1
technology_11
okta
javakafka
configuration
folder
and
a
producerconfiguration
in
it
technology_1
xxxxxxxxxx
technology_4
technology_2
component_22
component_19
producerconfig
technology_4
technology_2
common
serialization
stringserializer
springframework
component_23
annotation
component_24
springframework
component_23
annotation
configuration
springframework
technology_2
core
defaultkafkaproducerfactory
springframework
technology_2
core
kafkatemplate
springframework
technology_2
core
producerfactory
technology_1
util
hashmap
technology_1
util
connector_data_6
@configuration
producerconfiguration
{
private
final
kafka_broker
=
localhost
@bean
producerfactory
producerfactory
{
defaultkafkaproducerfactory
producerconfigurations
}
@bean
connector_data_6
connector_data_7
producerconfigurations
{
connector_data_6
connector_data_7
configuration
=
hashmap
configuration
put
producerconfig
bootstrap_servers_config
kafka_broker
configuration
put
producerconfig
key_serializer_class_config
stringserializer
configuration
put
producerconfig
value_serializer_class_config
stringserializer
configuration
}
@bean
kafkatemplate
kafkatemplate
{
kafkatemplate
producerfactory
}
}
this
create
a
producerfactory
which
how
to
create
component_15
base
on
the
configuration
you
provide
you’ve
also
specify
to
connector_10
to
your
local
technology_2
pattern_6
and
to
serialize
both
the
key
and
the
requirement_9
with
you
also
declare
a
kafkatemplate
component_24
to
perform
high
level
on
your
component_19
in
other
word
the
template
be
able
to
do
such
a
connector_13
a
connector_data_2
to
a
topic
and
efficiently
hide
under
the
hood
detail
from
you
the
next
step
be
to
create
the
to
connector_7
the
connector_data_2
to
the
component_19
inside
the
src
technology_1
technology_11
okta
javakafka
pattern_8
package
create
the
follow
technology_1
x
springframework
technology_2
core
kafkatemplate
springframework
web
bind
annotation
getmapping
springframework
web
bind
annotation
requestparam
springframework
web
bind
annotation
restcontroller
technology_1
util
connector_data_8
@restcontroller
kafkacontroller
{
private
kafkatemplate
template
kafkacontroller
kafkatemplate
template
{
this
template
=
template
}
@getmapping
technology_2
produce
produce
@requestparam
connector_data_2
{
template
connector_7
mytopic
connector_data_2
}
note
since
you’re
connector_13
connector_data_9
to
be
component_25
the
produce
really
ought
to
be
a
for
demo
purpose
it’s
easy
to
leave
it
a
a
connector_2
so
you
can
exercise
it
in
the
browser
a
you
can
see
this
be
very
quality_attribute_7
it
inject
the
kafkatemplate
configure
early
and
connector_12
a
connector_data_2
to
mytopic
when
a
connector_2
connector_data_10
be
make
to
technology_2
produce
let’s
test
if
everything
be
work
a
expect
run
the
inside
the
javakafkaapplication
to
run
from
the
command
line
connector_22
the
follow
command
shell
xxxxxxxxxx
mvnw
technology_7
boot
run
your
component_12
should
be
run
on
port
and
you
can
already
make
component_26
connector_data_1
against
it
go
to
your
web
browser
and
connector_23
technology_8
localhost
technology_2
produce
message=this
be
my
connector_data_2
when
you
make
a
connector_data_11
with
the
command
above
your
component_1
will
connector_22
the
technology_2
produce
which
connector_12
a
connector_data_2
to
mytopic
topic
inside
technology_2
but
how
do
you
the
command
successfully
connector_16
a
connector_data_2
to
the
topic
right
now
you
don’t
connector_24
connector_data_3
inside
your
component_3
which
mean
you
cannot
be
sure
fortunately
there
be
an
easy
way
to
create
a
component_18
to
test
right
away
inside
the
bin
folder
of
your
technology_2
directory
run
the
follow
command
shell
xxxxxxxxxx
technology_2
console
component_18
sh
bootstrap
component_12
localhost
topic
mytopic
connector_23
technology_8
localhost
technology_2
produce
message=this
be
my
connector_data_2
again
to
see
the
follow
connector_data_2
in
the
terminal
run
the
technology_2
component_18
shell
xxxxxxxxxx
this
be
my
connector_data_2
great
you
can
stop
this
command
for
now
instead
of
connector_22
from
a
terminal
let’s
some
technology_1
to
connector_24
the
connector_data_3
inside
your
component_3
connector_24
connector_data_3
from
a
technology_2
topic
in
a
technology_1
component_3
a
with
the
component_19
you
need
to
configuration
to
enable
the
component_18
to
find
the
technology_2
pattern_6
inside
the
src
technology_1
technology_11
okta
javakafka
configuration
create
the
follow
technology_1
xxxxxxxxxx
technology_4
technology_2
component_22
component_18
consumerconfig
technology_4
technology_2
common
serialization
stringdeserializer
springframework
component_23
annotation
component_24
springframework
component_23
annotation
configuration
springframework
technology_2
config
concurrentkafkalistenercontainerfactory
springframework
technology_2
core
consumerfactory
springframework
technology_2
core
defaultkafkaconsumerfactory
technology_1
util
hashmap
technology_1
util
connector_data_6
@configuration
consumerconfiguration
{
private
final
kafka_broker
=
localhost
private
final
group_id
=
technology_2
sandbox
@bean
consumerfactory
consumerfactory
{
defaultkafkaconsumerfactory
consumerconfigurations
}
@bean
connector_data_6
connector_data_7
consumerconfigurations
{
connector_data_6
connector_data_7
configuration
=
hashmap
configuration
put
consumerconfig
bootstrap_servers_config
kafka_broker
configuration
put
consumerconfig
group_id_config
group_id
configuration
put
consumerconfig
key_deserializer_class_config
stringdeserializer
configuration
put
consumerconfig
value_deserializer_class_config
stringdeserializer
configuration
}
@bean
concurrentkafkalistenercontainerfactory
kafkalistenercontainerfactory
{
concurrentkafkalistenercontainerfactory
factory
=
concurrentkafkalistenercontainerfactory
factory
setconsumerfactory
consumerfactory
factory
}
}
the
above
create
a
factory
that
how
to
connector_10
to
your
local
pattern_6
it
also
configure
your
component_18
to
deserialize
a
for
both
the
key
and
the
requirement_9
match
the
component_19
configuration
the
group
be
mandatory
and
use
by
technology_2
to
allow
parallel
connector_data_9
consumption
the
concurrentkafkalistenercontainerfactory
component_24
allow
your
component_3
to
connector_24
connector_data_3
in
more
than
one
component_27
now
that
your
technology_1
component_3
be
configure
to
find
component_16
inside
your
technology_2
pattern_6
let’s
start
listen
to
the
connector_data_3
connector_16
to
the
topic
create
a
src
technology_1
technology_11
okta
javakafka
component_18
directory
and
the
follow
in
it
technology_1
xxxxxxxxxx
springframework
technology_2
annotation
kafkalistener
springframework
stereotype
component_28
technology_1
util
arraylist
technology_1
util
connector_data_8
@component
mytopicconsumer
{
private
final
connector_data_8
connector_data_3
=
arraylist
@kafkalistener
topic
=
mytopic
=
technology_2
sandbox
listen
connector_data_2
{
synchronize
connector_data_2
{
connector_data_2
connector_data_2
}
}
connector_data_8
getmessages
{
connector_data_2
}
}
this
be
responsible
for
listen
to
connector_25
inside
the
mytopic
topic
it
do
so
by
use
the
kafkalistener
annotation
every
time
a
connector_data_2
be
connector_16
from
a
component_19
to
the
topic
your
component_3
connector_14
a
connector_data_2
inside
this
it
a
connector_data_2
to
the
connector_data_8
of
connector_data_3
connector_8
make
it
quality_attribute_10
to
other
through
the
getmessages
next
let’s
create
an
that
display
a
connector_data_8
of
connector_24
connector_data_2
go
back
to
the
kafkacontroller
to
mytopicconsumer
a
a
connector_20
and
a
getmessages
technology_1
xxxxxxxxxx
technology_11
okta
javakafka
component_18
mytopicconsumer
springframework
technology_2
core
kafkatemplate
springframework
web
bind
annotation
getmapping
springframework
web
bind
annotation
requestparam
springframework
web
bind
annotation
restcontroller
technology_1
util
connector_data_8
@restcontroller
kafkacontroller
{
private
kafkatemplate
template
private
mytopicconsumer
mytopicconsumer
kafkacontroller
kafkatemplate
template
mytopicconsumer
mytopicconsumer
{
this
template
=
template
this
mytopicconsumer
=
mytopicconsumer
}
@getmapping
technology_2
produce
produce
@requestparam
connector_data_2
{
template
connector_7
mytopic
connector_data_2
}
@getmapping
technology_2
connector_data_2
connector_data_8
getmessages
{
mytopicconsumer
getmessages
}
}
this
now
have
a
to
display
the
connector_data_3
component_13
in
your
component_18
when
this
be
connector_data_11
it
connector_12
the
current
connector_data_3
it
already
component_25
from
the
technology_2
topic
your
technology_1
component_3
now
have
both
a
technology_2
component_19
and
a
component_18
so
let’s
test
it
all
together
restart
your
component_1
and
go
to
technology_8
localhost
technology_2
connector_data_2
right
now
no
connector_data_5
be
be
the
reason
be
pretty
quality_attribute_7
your
component_18
be
configure
only
to
connector_8
connector_data_3
and
you
haven’t
connector_16
a
connector_data_2
yet
let’s
fix
this
problem
by
go
to
your
web
browser
and
connector_3
technology_8
localhost
technology_2
produce
message=message
connector_16
by
my
component_3
when
technology_2
connector_14
the
connector_data_2
it
will
your
component_18
about
it
right
away
go
ahead
and
go
to
technology_8
localhost
technology_2
connector_data_2
in
your
browser
you
will
now
see
that
your
connector_data_2
be
successfully
connector_8
connector_data_2
successfully
connector_26
great
you
have
a
technology_1
component_3
capable
of
produce
and
connector_15
connector_data_3
from
technology_2
before
we
connector_data_11
it
a
day
though
there
be
one
last
step
and
it’s
a
very
important
one
quality_attribute_3
your
technology_1
technology_2
component_1
your
component_3
be
not
very
quality_attribute_3
right
now
although
you
be
prepare
to
handle
many
connector_data_3
in
a
quality_attribute_5
environment
those
connector_data_3
be
still
quality_attribute_10
to
anyone
who
can
find
the
connector_27
to
your
this
be
a
critical
vulnerability
so
let’s
make
sure
it’s
connector_28
the
right
way
you’re
go
to
use
oauth
to
make
sure
only
pattern_9
component_4
can
see
your
the
best
part
it’s
go
to
take
only
minute
to
this
feature
in
your
component_3
by
use
okta
to
pattern_9
your
component_29
create
an
okta
account
if
you
don’t
already
have
an
okta
account
go
ahead
and
create
one
after
complete
registration
go
through
the
follow
step
login
to
your
account
go
to
component_30
component_1
you
will
be
redirect
to
the
follow
component_31
component_1
to
okta
account
select
web
and
click
next
fill
in
the
follow
option
in
the
form
name
bootiful
technology_2
base
uris
technology_8
localhost
login
redirect
url
technology_8
localhost
login
oauth2
okta
click
do
now
that
you
have
your
okta
component_1
you
can
use
it
to
pattern_9
component_4
in
your
technology_1
+
technology_2
component_3
quality_attribute_3
your
technology_1
component_3
with
component_29
auth
let’s
start
by
okta’s
technology_13
to
your
project
open
your
pom
technology_14
and
the
follow
connector_20
inside
the
connector_20
tag
connector_data_12
xxxxxxxxxx
connector_20
technology_11
okta
technology_7
okta
technology_7
boot
starter
version
version
connector_20
this
technology_13
will
quality_attribute_9
with
the
okta
component_3
you
create
it
will
also
technology_7
quality_attribute_1
to
your
current
component_1
configure
it
with
the
follow
variable
in
src
resource
component_1
property
property
xxxxxxxxxx
okta
oauth2
issuer
technology_8
{youroktadomain}
oauth2
default
okta
oauth2
component_22
{yourclientid}
okta
oauth2
component_22
secret
{yourclientsecret}
important
this
should
only
be
use
locally
do
not
connector_29
your
client’s
secret
to
git
or
any
other
version
control
component_14
to
avoid
accidentally
connector_30
these
credential
you
can
also
specify
your
okta
application’s
requirement_9
a
environment
variable
create
an
okta
env
in
the
root
directory
of
your
component_3
with
the
follow
environment
variable
then
run
component_32
okta
env
before
start
your
component_3
shell
xxxxxxxxxx
export
okta_oauth2_issuer=https
{youroktadomain}
oauth2
default
export
okta_oauth2_client_id={yourclientid}
export
okta_oauth2_client_secret={yourclientsecret}
you
can
find
{yourclientid}
and
{yourclientsecret}
in
the
okta
ui’s
component_30
component_31
to
connector_23
it
follow
the
step
below
in
your
okta
go
to
component_1
select
the
bootiful
technology_2
component_1
click
on
the
general
tab
you
should
see
both
requirement_9
inside
the
component_22
credential
area
connector_31
component_22
credential
the
requirement_9
{youroktadomain}
for
will
be
visible
in
your
okta
requirement_10
click
on
the
requirement_10
on
the
you
will
see
the
url
in
the
right
upper
corner
that’s
it
restart
your
technology_7
component_1
and
go
to
technology_8
localhost
technology_2
connector_data_2
your
component_3
will
now
redirect
you
to
the
login
component_31
final
sign
in
component_31
note
if
you’re
not
prompt
to
requirement_1
in
it’s
because
you’re
already
requirement_1
in
open
your
component_3
in
an
incognito
window
and
you’ll
see
the
login
screen
show
above
enter
your
username
and
password
if
your
login
attempt
be
successful
you’ll
be
redirect
back
to
your
component_1
again
congratulation
you
now
have
a
quality_attribute_3
technology_1
component_1
that
can
produce
and
connector_24
connector_data_3
from
technology_2
if
you
want
to
connector_32
out
the
complete
component_32
for
this
head
over
to
oktadeveloper
okta
technology_1
technology_2
example
on
technology_15
want
to
more
about
technology_1
quality_attribute_1
and
oauth
here
be
a
few
connector_33
you
might
be
interest
in
oauth
technology_1
guide
quality_attribute_3
your
component_3
in
minute
an
illustrate
guide
to
oauth
and
technology_16
connector_10
quality_attribute_3
reactive
pattern_2
with
technology_7
requirement_4
gateway
for
more
this
one
follow
@oktadev
on
twitter
we
also
regularly
publish
screencasts
to
our
youtube
pattern_10
further
connector_34
technology_2
architecture
how
to
setup
a
technology_2
cluster
an
overview
of
the
technology_2
quality_attribute_5
connector_data_2
component_14
part
technology_2
requirement_8
component_3
technology_1
programming
technology_10
technology_7
technology_17
technology_7
quality_attribute_1
cluster
command
computing
publish
at
with
permission
of
daniel
pereira
see
the
original
here
opinion
express
by
contributor
be
their
own
popular
on
extraordinary
terraform
best
practice
that
will
connector_19
your
infra
world
debug
the
technology_1
connector_data_2
component_9
technology_18
component_26
use
lightrun
role
of
development
team
in
an
agile
environment
functional
vs
non
functional
requirement
the
full
guide
definition
and
technical
example
technology_1
partner
resource
x
about
u
about
connector_7
feedback
career
sitemap
advertise
advertise
with
contribute
on
submission
guideline
mvb
component_33
become
a
contributor
visit
the
writer
zone
legal
term
of
component_9
privacy
requirement_11
u
park
office
drive
suite
durham
nc
support@dzone
technology_11
+1
s
be
friend
technology_11
be
powered
by
