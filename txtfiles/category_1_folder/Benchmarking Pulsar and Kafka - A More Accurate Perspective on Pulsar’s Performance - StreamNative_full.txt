benchmarking
technology_1
and
technology_2
a
more
quality_attribute_1
perspective
on
pulsar’s
requirement_1
streamnative
connector_1
your
free
copy
of
the
*new*
technology_3
technology_1
vs
technology_3
technology_2

benchmark
download
nowcloseproductsexpand_more
open
sourceexpand_more
resourcesexpand_more
login
shareall

benchmarking
technology_1
and
technology_2
a
more
quality_attribute_1
perspective
on
pulsar’s
performancenovember


note
this
present
streamnative’s
connector_2
to
confluent’s
recent
“benchmarking
technology_3
technology_2
technology_3
technology_1
and
technology_4
which
be
the
fast
”
for
a
brief
overview
of
these
component_1
see
our
review
of
technology_1
vs
technology_2
part

part

executive
summary
today
many
requirement_2
be
look
at
real
time
connector_data_1
connector_3
component_2
to
develop
technology_5
and
component_3
organization
must
first
understand
the
advantage
and
differentiator
of
the
different
connector_3
component_4
before
they
can
select
the
technology_6
best
suit
to
meet
their
requirement_3
need
benchmark
be
one
organization
use
to
compare
and
measure
the
requirement_1
of
different
technology_6
in
order
for
these
benchmark
to
be
meaningful
they
must
be
do
correctly
and
provide
quality_attribute_1
connector_data_2
unfortunately
it
be
all
too
easy
for
benchmark
to
fail
to
provide
quality_attribute_1
insight
due
to
any
number
of
issue
confluent
recently
run
a
benchmark
to
evaluate
how
technology_2
technology_1
and
technology_4
compare
in
term
of
quality_attribute_2
and
quality_attribute_3
accord
to
confluent’s

kakfa
be
able
to
achieve
the
“best
throughput”
with
“low
latency”
and
technology_4
be
able
to
provide
“low
latency”
at
“lower
throughputs”
overall
their
benchmark
declare
technology_2
the
clear
winner
in
term
of
“speed”
while
technology_2
be
an
establish
technology_6
technology_1
be
the
top
connector_3
technology_6
of
choice
for
many
requirement_2
today
from
global
corporation
to
innovative
start
up
in
fact
at
the
recent
splunk
summit
conf20
sendur
sellakumar
splunk’s
chief
technology_5
officer
discuss
their
decision
to
adopt
technology_1
over
technology_2
we
ve
shift
to
technology_3
technology_1
a
our
underlie
connector_4
it
be
our
bet
on
the
long
term
architecture
for
requirement_4
grade
pattern_1
connector_4
sendur
sellakumar
cpo
splunk
this
be
one
of
many
example
of
requirement_2
adopt
technology_1
these
requirement_2
choose
technology_1
because
it
provide
the
ability
to
horizontally
and
cost
effectively
quality_attribute_4
to
massive
connector_data_1
volume
with
no
single
point
of
failure
in
modern
elastic
requirement_5
environment
technology_7
at
the
same
time
build
in
feature
automatic
connector_data_1
rebalancing
multi
tenancy
geo
pattern_2
and
tiered
storage
with
infinite
retention
simplify
and
make
it
easy
for
team
to
focus
on
requirement_3
goal
ultimately
developer
be
adopt
technology_1
for
it
feature
requirement_1
and
because
all
of
the
unique
aspect
of
technology_1
mention
above
make
it
well
suit
to
be
the
technology_8
for
connector_3
connector_data_1

what
we

we
have
to
take
a
close
look
at
confluent’s
benchmark
to
try
to
understand
their
connector_data_3
we
find
two
issue
that
be
highly
problematic
first
and
the
large
component_5
of
inaccuracy
be
confluent’s
limit
knowledge
of
technology_1
without
understand
the
technology_6
they
be
not
able
to
set
up
the
test
in
a
way
that
could
accurately
measure
pulsar’s
requirement_1
second
their
requirement_1
measurement
be
base
on
a
narrow
set
of
test
parameter
this
limit
the
applicability
of
the
connector_data_4
and
fail
to
provide
reader
with
an
quality_attribute_1
picture
of
the
technologies’
capability
across
different
workload
and
real
world
use
requirement_6
in
order
to
provide
the
a
more
quality_attribute_1
picture
we
decide
to
connector_5
these
issue
and
repeat
the
test
key
connector_data_5
include
we
update
the
benchmark
setup
to
include
all
of
the
quality_attribute_5
level
support
by
technology_1
and
technology_2
this
allow
u
to
compare
quality_attribute_2
and
quality_attribute_3
at
the
same
level
of
quality_attribute_5
we
fix
the
openmessaging
benchmark
omb
technology_9
to
eliminate
the
variant
introduce
by
use
different
instance
and
correct
configuration
error
in
their
omb
technology_1
driver
finally
we
measure
additional
requirement_1
factor
and
condition
such
a
vary
number
of
component_6
and
mix
workload
that
contain
connector_6
tail
connector_7
and
catch
up
connector_8
to
provide
a
more
comprehensive
pattern_3
of
requirement_1
with
these
connector_data_5
make
we
repeat
the
test
the
connector_data_3
technology_1
significantly
outperform
technology_2
in
scenario
that
more
closely
resemble
real
world
workload
and
match
kafka’s
requirement_1
in
the
basic
scenario
confluent
use
the
follow
section
highlight
the
most
important
find
a
more
comprehensive
requirement_1
report
in
the
section
streamnative
benchmark
connector_data_4
also
give
detail
of
our
test
setup
and
additional
commentary
streamnative
benchmark
connector_data_3
highlight
#1
with
the
same
quality_attribute_5
guarantee
a
technology_2
technology_1
achieve

connector_data_6
s
publish
and
end
to
end
quality_attribute_2
same
a
technology_2
and


gb
s
catch
up
connector_7
quality_attribute_2


time
high
than
technology_2
increasing
the
number
of
component_6
and
connector_9
quality_attribute_5
level
have
no
impact
on
technology_1
s
quality_attribute_2
however
the
technology_2
s
quality_attribute_2
be
severely
impact
when
connector_9
the
number
of
component_6
or
connector_9
quality_attribute_5
level
component_7

quality_attribute_2
difference
between
technology_1
and
technology_2
under
different
workload
with
different
quality_attribute_5
guarantee
quality_attribute_5
level
component_6
technology_1
technology_2
peak
publish
+
tail
connector_8
quality_attribute_2
connector_data_6
s
level

quality_attribute_5


connector_data_6
s

connector_data_6
s


connector_data_6
s

connector_data_6
s


connector_data_6
s

connector_data_6
s
level

quality_attribute_5


connector_data_6
s

connector_data_6
s


connector_data_6
s

connector_data_6
s


connector_data_6
s

connector_data_6
s
peak
catch
up
connector_8
quality_attribute_2
connector_data_6
s
level

quality_attribute_5



gb
s

gb
s
level

quality_attribute_5



gb
s

gb
s
for
detail
on
level

quality_attribute_5
see
an
overview
of
quality_attribute_5
in
quality_attribute_6
component_4
section
for
detail
discussion
on
quality_attribute_5
difference
between
technology_1
and
technology_2
#2
technology_1
connector_10
significantly
quality_attribute_7
quality_attribute_3
than
technology_2
in
each
of
the
different
test
requirement_6
include
different
number
of
subscription
different
number
of
topic
and
different
quality_attribute_5
guarantee
pulsar’s
99th
percentile
quality_attribute_3
be
within
the
range
of

and

millisecond
kafka’s
99th
percentile
quality_attribute_3
can
go
up
to
second
and
be
hugely
impact
by
the
number
of
topic
subscription
and
different
quality_attribute_5
guarantee
component_7

end
to
end
p99
quality_attribute_3
between
technology_1
and
technology_2
of
different
number
of
subscription
with
different
quality_attribute_5
guarantee
component_6
&
subscription
local
quality_attribute_5
pattern_2
quality_attribute_5
technology_1
technology_2
end
to
end
p99
quality_attribute_3
m
publish
+
tail
connector_7

component_6

subscription
pattern_4
ack





ack





pattern_5
ack





ack






component_6

subscription
pattern_4
ack





ack





pattern_5
ack





ack





component_7

end
to
end
p99
quality_attribute_3
between
technology_1
and
technology_2
of
different
number
of
topic
with
different
quality_attribute_5
guarantee
local
quality_attribute_5
pattern_2
quality_attribute_5
component_6
technology_1
technology_2
end
to
end
p99
quality_attribute_3
m
publish
+
tail
connector_7
pattern_4
ack














ack














pattern_5
ack














ack














#3
technology_1
provide
significantly
quality_attribute_7
i
o
isolation
than
technology_2
pulsar’s
99th
percentile
publish
quality_attribute_3
remain
around

millisecond
when
there
be
component_8
catch
up
on
connector_11
historic
connector_data_1
in
contrast
kafka’s
quality_attribute_3
be
severely
impact
by
catchup
connector_7
kafka’s
99th
percentile
publish
quality_attribute_3
can
increase
from
millisecond
to
multiple
second
component_7

publish
p99
quality_attribute_3
between
technology_1
and
technology_2
with
catch
up
connector_8
local
quality_attribute_5
pattern_2
quality_attribute_5
technology_1
technology_2
publish
p99
quality_attribute_3
m
mix
workload
pattern_4
ack





ack





pattern_5
ack





ack





all
of
our
benchmark
be
open_source
so
curious
reader
can
repeat
the
test
for
themselves
additionally
you
can
dig
deep
into
the
connector_data_4
and
metric
which
be
quality_attribute_8
in
the
pattern_6
although
our
benchmark
be
more
quality_attribute_1
and
more
comprehensive
than
confluent’s
it
doesn’t
cover
every
scenario
ultimately
no
benchmark
can
replace
test
do
on
your
own
hardware
with
your
own
workload
we
encourage
you
to
evaluate
additional
variable
and
scenario
and
to
test
use
your
own
setup
and
environment
content
a
deep
look
confluent
benchmark
issue
with
confluent
setup
issue
with
omb
technology_9
issue
with
confluent
methodology
an
overview
of
quality_attribute_5
in
quality_attribute_6
component_4
pattern_2
quality_attribute_5
and
local
quality_attribute_5
quality_attribute_5
mode
pattern_4
vs
pattern_5
quality_attribute_5
level
measure
quality_attribute_5
guarantee
quality_attribute_5
in
technology_1
quality_attribute_5
in
technology_2
quality_attribute_5
difference
between
technology_1
and
technology_2
streamnative
benchmark
streamnative
setup
streamnative
technology_9
streamnative
methodology
testbed
disk
quality_attribute_2
disk
connector_data_1
pattern_4
quality_attribute_3
streamnative
benchmark
connector_data_4
maximum
quality_attribute_2
test
publish
and
end
to
end
quality_attribute_3
test
catch
up
connector_7
test
mix
workload
test
conclusion
a
deep
look
at
confluent
benchmark
confluent
use
the
openmessaging
benchmark
omb
technology_9
a
the
basis
for
their
benchmark
with
a
few
modification
in
this
section
we
describe
the
issue
we
find
in
confluent’s
benchmark
and
explain
how
they
impact
confluent’s
test
connector_data_4
and
lead
to
erroneous
conclusion
issue
with
confluent
setup
a
fundamental
problem
with
confluent’s
benchmark
be
that
technology_1
be
not
set
up
properly
we
will
talk
more
about
this
in
the
section
on
the
streamnative
benchmark
in
addition
to
the
issue
tune
technology_1
technology_1
and
technology_2
be
set
up
with
different
quality_attribute_5
guarantee
because
the
level
of
quality_attribute_5
impact
requirement_1
the
quality_attribute_5
setting
on
both
component_4
must
be
equivalent
for
a
comparison
to
be
meaningful
confluent’s
engineer
use
the
default
quality_attribute_5
guarantee
for
technology_1
which
be
a
much
strong
guarantee
than
the
configuration
which
be
use
for
technology_2
because
increasing
quality_attribute_5
negatively
impact
quality_attribute_3
and
quality_attribute_2
confluent’s
test
place
a
much
high
demand
on
technology_1
than
it
do
on
technology_2
in
the
version
of
technology_1
use
by
confluent
there
be
not
yet
support
for
reduce
the
quality_attribute_5
down
to
a
level
to
match
technology_2
but
such
a
future
will
be
release
a
part
of
technology_1
in
an
upcoming
release
and
be
use
in
this
test
have
their
engineer
use
this
equivalent
quality_attribute_5
set
on
both
component_1
the
test
connector_data_4
would
have
allow
for
an
quality_attribute_1
comparison
we
certainly
don’t
fault
confluent’s
engineer
for
not
use
a
not
yet
release
feature
however
the
writeup
fail
to
provide
the
necessary
component_9
for
these
connector_data_4
and
treat
that
a
though
they
be
equivalent
that
additional
component_9
which
will
be
provide
here
issue
with
omb
technology_9
confluent’s
benchmark
follow
omb
technology_9
guideline
which
recommend
use
the
same
instance
type
across
multiple
connector_3
component_1
however
in
our
test
we
find
large
amount
of
variance
among
different
instance
of
the
same
type
particularly
when
it
come
to
disk
io
in
order
to
minimize
this
variance
we
use
the
same
instance
from
run
to
run
for
both
technology_1
and
technology_2
which
we
find
significantly
help
to
increase
the
quality_attribute_9
of
the
connector_data_3
a
even
small
variation
in
disk
io
requirement_1
can
connector_data_3
in
much
large
variance
in
overall
component_1
requirement_1
we
would
suggest
the
omb
technology_9
guideline
be
update
to
include
this
recommendation
in
the
future
issue
with
confluent
methodology
confluent’s
benchmark
measure
only
a
few
limit
scenario
for
example
real
world
workload
consist
of
connector_6
tail
connector_7
and
catch
up
connector_7
tail
connector_7
occur
when
a
component_10
be
connector_11
recent
connector_data_7
near
the
“tail”
of
the
requirement_7
which
be
the
only
scenario
test
by
confluent
in
contrast
a
catch
up
connector_7
be
when
a
component_10
have
a
large
amount
of
backlog
it
must
connector_12
to
“catch
up”
to
the
tail
of
the
requirement_7
which
be
a
common
and
critical
connector_data_8
in
a
real
world
component_1
catch
up
connector_7
when
not
take
into
account
can
severely
impact
the
quality_attribute_3
of
connector_13
and
tail
connector_7
a
confluent’s
benchmark
focus
only
on
quality_attribute_2
and
end
to
end
quality_attribute_3
it
fail
to
give
a
complete
picture
of
expect
behavior
across
a
variety
of
workload
likewise
to
further
give
a
connector_data_3
close
to
real
world
use
requirement_6
we
also
consider
it
important
to
run
the
benchmark
with
vary
number
of
subscription
and
component_6
very
few
organization
only
care
about
a
few
topic
with
a
handful
of
component_6
and
component_10
they
need
the
ability
to
have
large
number
of
different
component_8
with
a
large
number
of
distinct
topic
component_6
to
connector_data_9
to
their
requirement_3
use
requirement_6
to
summarize
we
have
outline
specific
issue
with
confluent’s
methodology
in
the
follow
component_7
component_7

issue
with
confluent’s
benchmark
methodology
parameter
test
exclusion
limitation
connector_13
and
tail
connector_8
catch
up
connector_8
while
maximum
quality_attribute_2
and
end
to
end
quality_attribute_3
be
useful
to
illustrate
the
basic
requirement_1
characteristic
of
an
connector_3
component_1
limit
the
study
to
two
parameter
provide
only
a
partial
pattern_3
of
component_1
requirement_1

subscription
vary
number
of
subscription
component_10
group
do
not
show
how
the
number
of
subscription
impact
quality_attribute_2
and
quality_attribute_3

component_6
vary
number
of
component_6
do
not
show
how
the
number
of
component_6
impact
quality_attribute_2
and
quality_attribute_3
many
of
the
issue
with
confluent’s
benchmark
stem
from
a
limit
understand
of
technology_1
to
help
others
avoid
these
problem
when
run
benchmark
in
the
future
we’ll
provide
some
insight
on
the
technology_6
understand
pulsar’s
quality_attribute_5
guarantee
be
require
in
order
to
run
an
quality_attribute_1
benchmark
so
we
will
begin
our
discussion
there
we’ll
start
with
a
general
overview
of
quality_attribute_5
in
quality_attribute_6
component_1
and
then
explain
the
difference
between
the
quality_attribute_5
guarantee
offer
by
technology_1
and
technology_2
an
overview
of
quality_attribute_5
in
quality_attribute_6
component_4
quality_attribute_5
refer
to
maintain
component_1
consistency
and
quality_attribute_10
in
the
face
of
external
problem
such
a
a
hardware
or
operate
component_1
failure
single
technology_10
storage
component_4
such
a
technology_11
will
“fsync”
connector_13
to
disk
to
ensure
maximum
quality_attribute_5
operate
component_4
will
typically
buffer
connector_6
which
can
be
lose
in
the
of
failure
but
an
fsync
will
ensure
these
connector_data_1
be
connector_6
to
physical
storage
in
quality_attribute_6
component_1
quality_attribute_5
typically
come
from
pattern_2
with
multiple
copy
of
the
connector_data_1
be
quality_attribute_6
to
different
technology_10
that
can
fail
independently
however
it
be
important
not
to
conflate
local
quality_attribute_5
fsyncing
connector_data_1
with
pattern_2
quality_attribute_5
a
they
both
have
a
distinct
purpose
in
the
follow
section
we
explain
some
key
difference
between
these
feature
and
why
both
be
important
pattern_2
quality_attribute_5
and
local
quality_attribute_5
quality_attribute_6
component_4
typically
provide
both
pattern_2
quality_attribute_5
and
local
quality_attribute_5
separate
mechanism
control
each
type
of
quality_attribute_5
you
can
use
these
mechanism
in
various
combination
to
set
the
desire
level
of
quality_attribute_5
pattern_2
quality_attribute_5
be
achieve
by
use
an
algorithm
to
create
multiple
copy
of
connector_data_1
so
the
same
connector_data_1
can
be
component_11
in
several
location
to
improve
quality_attribute_10
and
quality_attribute_11
the
number
of
replica
n
determine
the
system’s
failure
tolerance
with
many
component_4
require
a
“quorum”
or
n

+

technology_10
to
acknowledge
a
connector_6
some
component_4
offer
the
ability
to
continue
to
serve
exist
connector_data_1
with
any
single
replica
still
quality_attribute_8
this
pattern_2
mechanism
be
key
to
handle
the
total
loss
of
an
instance
with
a
instance
able
to
re
replicate
connector_data_1
from
the
exist
replica
while
also
be
critical
to
quality_attribute_10
and
consensus
which
be
beyond
the
scope
of
this
discussion
by
contrast
local
quality_attribute_5
determine
what
an
acknowledgement
mean
at
the
individual
technology_10
level
this
require
fsyncing
connector_data_1
to
a
persistent
to
ensure
no
connector_data_1
be
lose
even
if
a
power
failure
or
hardware
failure
occur
an
fsync
of
connector_data_1
ensure
that
in
the
of
transient
failure
where
the
component_12
can
recover
the
technology_10
have
all
the
connector_data_1
for
it’s
previous
acknowledgement
quality_attribute_5
mode
pattern_4
vs
pattern_5
different
type
of
component_4
offer
vary
level
of
quality_attribute_5
guarantee
in
general
the
level
of
overall
quality_attribute_5
any
give
component_1
can
provide
quality_attribute_12
on
the
follow
whether
the
component_1
fsyncs
connector_data_1
to
local
disk
whether
the
component_1
replicate
connector_data_1
to
multiple
location
when
the
component_1
acknowledge
pattern_2
to
a
peer
when
the
component_1
acknowledge
connector_13
to
the
component_13
among
different
component_1
these
choice
vary
widely
and
not
all
component_4
give
component_14
the
option
to
control
these
requirement_8
but
in
general
component_4
that
lack
some
of
these
mechanism
such
a
pattern_2
in
non
quality_attribute_6
component_1
offer
le
quality_attribute_5
to
discus
this
more
concretely
we
can
define
two
quality_attribute_5
mode
which
control
when
a
component_1
acknowledge
connector_6
both
internally
for
pattern_2
and
to
the
component_13
these
be
“sync”
and
“async”
these
mode
operate
a
describe
below
pattern_4
quality_attribute_5
the
component_1

a
connector_6
connector_2
to
the
peer
component_13
only
after
the
connector_data_1
have
be
successfully
f
pattern_4
to
local
disk
local
quality_attribute_5
or
replicate
to
multiple
location
pattern_2
quality_attribute_5
pattern_5
quality_attribute_5
the
component_1

a
connector_6
connector_2
to
the
peer
component_13
before
the
connector_data_1
have
be
successfully
f
pattern_4
to
local
disk
local
quality_attribute_5
or
replicate
to
multiple
location
pattern_2
quality_attribute_5
quality_attribute_5
level
measure
quality_attribute_5
guarantee
quality_attribute_5
guarantee
can
take
many
form
and
quality_attribute_12
on
the
follow
variable
whether
connector_data_1
be
component_11
locally
replicate
in
multiple
location
or
both
when
connector_13
be
acknowledge
pattern_4
vs
pattern_5
with
quality_attribute_5
mode
we
define
some
quality_attribute_5
“levels”
which
we
can
use
to
differentiate
between
different
quality_attribute_6
component_1
we
define
four
level
component_7

describe
each
from
the
high
level
of
quality_attribute_5
to
the
low
component_7

quality_attribute_5
level
of
quality_attribute_6
component_4
level
pattern_2
local

pattern_4
pattern_4
the
component_1

a
connector_6
connector_2
to
the
component_13
only
after
the
connector_data_1
have
be
replicate
to
multiple
at
least
the
majority
of
location
and
each
replica
have
be
successfully
fsync
ed
to
local
disk

pattern_4
pattern_5
the
component_1

a
connector_6
connector_2
to
the
component_13
only
after
the
connector_data_1
have
be
replicate
to
multiple
at
least
the
majority
of
location
there
be
no
guarantee
that
each
replica
have
successfully
fsync
ed
to
local
disk

pattern_5
pattern_4
the
component_1

a
connector_6
connector_2
to
the
component_13
when
one
replica
have
be
successfully
fsync
ed
to
a
local
disk
there
be
no
guarantee
that
connector_data_1
be
replicate
to
the
other
location

pattern_5
pattern_5
the
component_1

a
connector_6
connector_2
to
the
component_13
immediately
after
the
connector_data_1
have
be
replicate
to
multiple
location
there
be
no
pattern_2
or
local
quality_attribute_5
guarantee
most
quality_attribute_6
relational
component_15
requirement_9
component_4
such
a
newsql
component_15
guarantee
the
high
level
of
quality_attribute_5
therefore
they
would
be
categorize
a
level

much
a
component_15
technology_1
be
a
level

component_1
that
provide
the
high
level
of
quality_attribute_5
by
default
in
addition
technology_1
allow
the
option
to
customize
the
desire
quality_attribute_5
level
for
each
component_16
individually
by
contrast
most
of
technology_2
production
deployment
be
configure
to
operate
a
either
a
level

or
level

component_1
base
on
our
limit
knowledge
on
technology_2
technology_2
can
be
configure
to
operate
a
a
level

component_1
by
set
flush
connector_data_10
to

and
flush
m
to

but
configure
those

setting
have
a
severe
impact
on
both
quality_attribute_2
and
quality_attribute_3
we
will
discus
it
more
in
our
benchmark
connector_data_3
we’ll
look
at
the
quality_attribute_5
capability
of
each
in
detail
begin
with
technology_1
quality_attribute_5
in
technology_1
technology_1
offer
quality_attribute_5
guarantee
at
all
level
it
can
replicate
connector_data_1
to
multiple
location
and
fsync
connector_data_1
to
local
disk
technology_1
have
two
quality_attribute_5
mode
pattern_4
and
pattern_5
describe
early
each
option
be
individually
quality_attribute_13
you
can
use
them
in
various
combination
to
customize
setting
for
individual
use
requirement_6
technology_1
control
pattern_2
quality_attribute_5
use
a
raft
equivalent
quorum
base
pattern_2
technology_12
you
can
tune
the
quality_attribute_5
mode
for
pattern_2
quality_attribute_5
by
adjust
the
ack
quorum
size
and
connector_6
quorum
size
parameter
the
setting
for
these
parameter
be
describe
in
component_7

below
the
quality_attribute_5
level
support
by
technology_1
be
describe
in
component_7

below
a
detail
discussion
of
pulsar’s
pattern_2
technology_12
and
consensus
algorithm
be
beyond
the
scope
of
this

however
we
will
explore
these
area
in
depth
in
a
future

component_7

quality_attribute_5
configuration
setting
in
technology_1
configuration
setting
quality_attribute_5
mode
pattern_2
ackquorumsize
=

pattern_5
ackquorumsize
≥
writequorumsize

+

pattern_4
local
default
journalwritedata
=
truejournalsyncdata
=
true
pattern_4
journalwritedata
=
truejournalsyncdata
=
false
pattern_5
journalwritedata
=
falsejournalsyncdata
=
false
pattern_5
component_7

quality_attribute_5
level
in
technology_1
quality_attribute_5
level
pattern_2
quality_attribute_5
local
quality_attribute_5
level

pattern_4
ackquorumsize
≥
writequorumsize

+

pattern_4
journalwritedata
=
truejournalsyncdata
=
true
level

pattern_5
ackquorumsize
=

pattern_4
journalwritedata
=
truejournalsyncdata
=
true
level

pattern_4
ackquorumsize
≥
writequorumsize

+

pattern_5
journalwritedata
=
truejournalsyncdata
=
false
level

pattern_5
ackquorumsize
=

pattern_5
journalwritedata
=
truejournalsyncdata
=
false
level

pattern_4
ackquorumsize
≥
writequorumsize

+

pattern_5
journalwritedata
=
falsejournalsyncdata
=
false
level

pattern_5
ackquorumsize
=

pattern_5
journalwritedata
=
falsejournalsyncdata
=
false
technology_1
control
local
quality_attribute_5
by
connector_14
and
or
fsyncing
connector_data_1
to
a
journal
disk
s
technology_1
also
provide
option
for
tune
the
local
quality_attribute_5
mode
use
the
configuration
parameter
in
component_7

component_7

pulsar’s
local
quality_attribute_5
mode
parameter
parameter
description
requirement_8
journalwritedata
control
whether
a
bookie
connector_13
connector_data_1
to
it
journal
disk
before
persist
connector_data_1
to
the
ledger
disk
true
=
enable
journalingfalse=
disable
journaling
journalsyncdata
control
whether
a
bookie
fsyncs
connector_data_1
to
journal
disk
before

a
connector_6
acknowledgement
to
pattern_7
true
=
enable
fsyncfalse=
disable
fsync
quality_attribute_5
in
technology_2
technology_2
offer
three
quality_attribute_5
level
level

level

and
level

technology_2
can
provide
pattern_2
quality_attribute_5
at
level

default
setting
but
offer
no
quality_attribute_5
guarantee
at
level

because
it
lack
the
ability
to
fsync
connector_data_1
to
disk
before
acknowledge
connector_6
technology_2
can
be
configure
to
operate
a
a
level

component_1
by
set
flush
connector_data_10
to

and
flush
m
to

however
such
setup
be
rarely
see
in
technology_2
production
deployment
kafka’s
isr
pattern_2
technology_12
control
pattern_2
quality_attribute_5
you
can
tune
kafka’s
pattern_2
quality_attribute_5
mode
by
adjust
the
acks
and
min
insync
replica
parameter
associate
with
this
technology_12
the
setting
for
these
parameter
be
describe
in
component_7

below
the
quality_attribute_5
level
support
by
technology_2
be
describe
in
component_7

below
a
detail
explanation
of
kafka’s
pattern_2
technology_12
be
beyond
the
scope
of
this

however
we
will
explore
how
kafka’s
technology_12
differ
from
pulsar’s
in
a
future

component_7

quality_attribute_5
configuration
setting
in
technology_2
configuration
setting
quality_attribute_5
mode
pattern_2
acks
=

pattern_5
acks
=
all
pattern_4
local
default
fsync
setting
pattern_5
flush
connector_data_10
=
1flush
m
=

pattern_4
component_7

quality_attribute_5
level
in
technology_2
quality_attribute_5
level
pattern_2
quality_attribute_5
local
quality_attribute_5
level

pattern_4
acks
=
all
pattern_5
default
fsync
setting
level

pattern_5
acks
=

pattern_5
default
fsync
setting
level

pattern_4
acks
=
all
pattern_4
flush
connector_data_10
=
1flush
m
=

level

pattern_5
acks
=

pattern_4
flush
connector_data_10
=
1flush
m
=

unlike
technology_1
technology_2
do
not
connector_6
connector_data_1
to
a
separate
journal
disk
s
instead
technology_2
acknowledge
connector_13
before
fsyncing
connector_data_1
to
disk
this
minimize
i
o
contention
between
connector_13
and
connector_7
and
prevent
requirement_1
degradation
kafka’s
do
offer
the
ability
to
fsync
after
every
connector_data_10
with
the
above
flush
connector_data_10
=

and
flush
m
=

and
while
this
can
be
use
to
greatly
reduce
the
likelihood
of
connector_data_10
loss
however
it
severely
impact
the
quality_attribute_2
and
quality_attribute_3
which
ultimately
mean
such
setting
be
rarely
use
in
production
deployment
kafka’s
inability
to
journal
connector_data_1
make
it
vulnerable
to
connector_data_1
loss
in
the
of
a
component_12
failure
or
power
outage
this
be
a
significant
weakness
and
one
of
the
reason
why
tencent
choose
technology_1
for
their
bill
component_1
quality_attribute_5
difference
between
technology_1
and
technology_2
pulsar’s
quality_attribute_5
setting
be
highly
quality_attribute_13
and
allow
component_14
to
optimize
quality_attribute_5
setting
to
meet
the
requirement
of
an
individual
component_16
use
requirement_6
or
hardware
configuration
because
technology_2
offer
le
quality_attribute_14
quality_attribute_12
on
the
scenario
it
be
not
always
possible
to
establish
equivalent
quality_attribute_5
setting
in
both
component_1
this
make
benchmarking
difficult
to
connector_5
this
the
omb
technology_9
recommend
use
the
close
setting
quality_attribute_8
with
this
background
we
can
now
describe
the
gap
in
confluent’s
benchmark
confluent
attempt
to
simulate
pulsar’s
fsyncing
behavior
in
technology_2
the
setting
confluent
choose
provide
pattern_5
quality_attribute_5
however
the
setting
they
choose
for
technology_1
provide
pattern_4
quality_attribute_5
this
discrepancy
produce
flaw
test
connector_data_4
that
inaccurately
portray
pulsar’s
requirement_1
a
inferior
a
you
will
see
when
we
review
the
connector_data_4
of
our
own
benchmark
late
technology_1
perform
a
well
a
or
quality_attribute_7
than
technology_2
while
offer
strong
quality_attribute_5
guarantee
streamnative
benchmark
to
connector_1
a
more
quality_attribute_1
picture
of
pulsar’s
requirement_1
we
need
to
connector_5
the
issue
with
the
confluent
benchmark
we
focus
on
tune
pulsar’s
configuration
ensure
the
quality_attribute_5
setting
on
both
component_4
be
equivalent
and
include
additional
requirement_1
factor
and
condition
such
a
vary
number
of
component_6
and
mix
workload
to
enable
u
to
measure
requirement_1
across
different
use
requirement_6
the
follow
section
explain
the
connector_15
we
make
in
detail
streamnative
setup
our
benchmarking
setup
include
all
the
quality_attribute_5
level
support
by
technology_1
and
technology_2
this
allow
u
to
compare
quality_attribute_2
and
quality_attribute_3
at
the
same
level
of
quality_attribute_5
the
quality_attribute_5
setting
we
use
be
describe
below
pattern_2
quality_attribute_5
setup
our
pattern_2
quality_attribute_5
setup
be
identical
to
confluent’s
although
we
make
no
connector_9
we
be
connector_16
the
specific
setting
we
use
in
component_7

for
completeness
component_7

pattern_2
quality_attribute_5
setup
setting
quality_attribute_5
mode
configuration
technology_1
pattern_4
ensemble
size=3write
quorum
size=3ack
quorum
size=2
pattern_5
ensemble
size=3write
quorum
size=3ack
quorum
size=1
technology_2
pattern_4
replicas=3acks=allmin
insync
replicas=2
pattern_5
replicas=3acks=1min
insync
replicas=2
a
technology_1
feature
give
component_2
the
option
to
skip
journaling
which
relax
the
local
quality_attribute_5
guarantee
avoid
connector_6
amplification
and
improve
connector_6
quality_attribute_2
this
feature
will
be
quality_attribute_8
in
the
next
release
of
technology_3
bookkeeper
however
this
feature
will
not
be
make
the
default
nor
do
we
recommend
it
for
most
scenario
a
it
still
introduce
the
potential
for
connector_data_10
loss
we
use
this
feature
in
our
benchmark
to
ensure
an
quality_attribute_1
requirement_1
comparison
between
the
two
component_1
bypass
journaling
on
technology_1
provide
the
same
local
quality_attribute_5
guarantee
a
kafka’s
default
fsync
setting
pulsar’s
feature
include
a
local
quality_attribute_5
mode
pattern_5
bypass
journal
we
use
this
mode
to
configure
technology_1
to
match
kafka’s
default
level
of
local
quality_attribute_5
component_7

show
the
specific
setting
for
our
benchmark
component_7

local
quality_attribute_5
setup
setting
for
streamnative’s
benchmark
quality_attribute_5
mode
configuration
technology_1
pattern_4
default
journalwritedata=truejournalsyncdata=truejournalmaxgroupwaitmsec=1
pattern_5
connector_6
to
journal
journalwritedata=truejournalsyncdata=falsejournalmaxgroupwaitmsec=1journalpagecacheflushintervalmsec=1000
pattern_5
bypass
journaling
journalwritedata=falsejournalsyncdata=false
technology_2
pattern_4
flush
messages=1flush
ms=0
pattern_5
default
flush
messages=10000
default
flush
ms=1000
default
streamnative
technology_9
we
fix
some
issue
in
confluent’s
omb
technology_9
fork
and
correct
configuration
error
in
their
omb
technology_1
driver
the
benchmarking
we
develop
include
the
fix
describe
below
be
quality_attribute_8
a
open_source
fix
in
the
omb
technology_9
confluent
follow
the
omb
framework’s
recommendation
to
use
two
set
of
instances—one
for
technology_2
and
another
for
technology_1
for
our
benchmark
we
allocate
one
set
of
three
instance
to
eliminate
variation
in
our
first
test
we
quality_attribute_15
all
three
instance
on
technology_1
then
we
repeat
the
test
on
technology_2
use
the
same
set
of
instance
because
we
use
the
same
component_17
for
benchmarking
different
component_1
we
clear
the
filesystem
pagecache
before
each
run
this
ensure
the
current
test
would
not
be
impact
by
previous
activity
fix
in
the
omb
technology_1
driver
configuration
we
fix
a
number
of
error
in
confluent’s
omb
technology_1
driver
configuration
the
follow
section
explain
the
specific
connector_15
we
make
to
the
pattern_7
bookie
component_18
component_10
and
technology_1
image
pattern_7
connector_15
technology_1
pattern_7
use
the
managedledgernewentriescheckdelayinmillis
parameter
to
determine
the
length
of
time
in
millisecond
a
catch
up
subscription
must
wait
before
dispatch
connector_data_7
to
it
component_10
in
the
omb
technology_9
the
requirement_8
for
this
parameter
be
set
to

this
be
the
reason
why
confluent’s
benchmark
inaccurately
show
technology_1
to
have
high
quality_attribute_3
than
technology_2
we
connector_9
the
requirement_8
to

to
emulate
kafka’s
quality_attribute_3
behavior
on
technology_1
after
make
this
connector_9
technology_1
show
significantly
quality_attribute_7
quality_attribute_3
than
technology_2
in
all
test
requirement_6
additionally
to
optimize
requirement_1
we
increase
the
requirement_8
of
the
bookkeepernumberofchannelsperbookieparameter
from

to

to
prevent
any
single
technology_13
pattern_8
between
a
pattern_7
and
a
bookie
from
become
a
bottleneck
such
bottleneck
cause
high
quality_attribute_3
when
large
volume
of
connector_data_7
accumulate
in
a
technology_13
io
component_19
we
intend
on
provide
this
guidance
more
clearly
in
the
technology_1
documentation
to
help
component_14
who
be
look
to
optimize
entirely
for
end
to
end
quality_attribute_3
bookie
connector_15
we

a
bookie
configuration
to
test
pulsar’s
requirement_1
when
bypass
journaling
see
the
quality_attribute_5
section
for
a
discussion
on
this
and
recall
that
with
this
feature
we
more
closely
match
kafka’s
quality_attribute_5
guarantee
to
test
the
requirement_1
of
this
feature
we
build
a
customize
image
base
on
the
official
technology_1



release
to
include
this
connector_9
for
more
detail
see
technology_1
image
we
configure
the
follow
setting
manually
to
bypass
journaling
in
technology_1
journalwritedata=false
journalsyncdata=false
additionally
we
connector_9
the
requirement_8
of
the
journalpagecacheflushintervalmsec
parameter
from

to

to
benchmark
pattern_5
local
quality_attribute_5
journalsyncdata=false
in
technology_1
increasing
the
requirement_8
enable
technology_1
to
simulate
kafka’s
flush
behavior
a
describe
below
technology_2
ensure
local
quality_attribute_5
by
flush
dirty
component_20
in
the
filesystem
component_20
pattern_9
to
disk
connector_data_1
be
flush
by
a
set
of
background
component_21
connector_17
pdflush
pdflush
be
quality_attribute_13
and
the
wait
time
between
flush
be
typically
set
to

second
set
pulsar’s
journalpagecacheflushintervalmsec
parameter
to

be
equivalent
to
a

second
pdflush
interval
on
technology_2
make
this
connector_9
enable
u
to
benchmark
pattern_5
local
quality_attribute_5
more
precisely
and
achieve
a
more
quality_attribute_1
comparison
between
technology_1
and
technology_2
component_18
connector_15
our
pattern_10
configuration
be
identical
to
confluent’s
with
one
exception
we
increase
the
switch
interval
to
make
it
long
than
the
pattern_10
interval
specifically
we
connector_9
the
requirement_8
of
the
batchingpartitionswitchfrequencybypublishdelay
parameter
from

to

this
connector_9
ensure
pulsar’s
component_18
would
focus
on
only
one
component_6
during
each
pattern_10
period
set
the
switch
interval
and
the
pattern_10
interval
to
the
same
requirement_8
can
cause
technology_1
to
switch
component_6
more
often
than
necessary
which
generate
too
many
small
pattern_10
and
can
potentially
impact
quality_attribute_2
make
the
switch
interval
large
than
the
pattern_10
interval
minimize
this
risk
component_10
connector_15
technology_1
component_22
use
receiver
component_23
to
apply
back
pressure
when
component_2
be
unable
to
component_24
incoming
connector_data_7
fast
enough
the
size
of
the
component_10
receiver
component_19
can
affect
end
to
end
quality_attribute_3
a
large
component_19
can
pre
fetch
and
buffer
more
connector_data_7
than
a
small
one
two
parameter
determine
the
size
of
the
receiver
component_19
receiverqueuesize
and
maxtotalreceiverqueuesizeacrosspartitions
technology_1
calculate
the
receiver
component_19
size
a
follow
math
min
receiverqueuesize
maxtotalreceiverqueuesizeacrosspartitions
number
of
component_6
for
example
if
maxtotalreceiverqueuesizeacrosspartitions
be
set
to

and
you
have

component_6
the
technology_1
component_13
set
the
consumer’s
receiver
component_19
size
to

on
each
component_6
for
our
benchmark
we
increase
maxtotalreceiverqueuesizeacrosspartitions
from

to

this
tune
optimization
ensure
component_8
would
not
apply
back
pressure
technology_1
image
we
build
a
customize
technology_1
release
v



sn

to
include
the
technology_1
and
bookkeeper
fix
describe
above
version



sn

be
base
on
the
official
technology_1



release
and
quality_attribute_8
to
download
at
here
streamnative
methodology
we
update
confluent’s
benchmarking
methodology
to
connector_1
a
more
comprehensive
pattern_3
of
requirement_1
use
real
world
workload
specifically
we
make
the
follow
connector_15
for
our
test

catch
up
connector_8
to
evaluate
the
follow
the
maximum
level
of
quality_attribute_2
each
component_1
can
achieve
when
component_24
catch
up
connector_8
how
connector_8
impact
publish
and
end
to
end
quality_attribute_3
vary
the
number
of
component_6
to
see
how
each
connector_9
impact
quality_attribute_2
and
quality_attribute_3
vary
the
number
of
subscription
to
see
how
each
connector_9
impact
quality_attribute_2
and
quality_attribute_3
our
benchmark
scenario
measure
the
follow
type
of
workload
maximum
quality_attribute_2
what
be
the
maximum
quality_attribute_2
each
component_1
can
achieve
publish
and
tail
connector_7
quality_attribute_3
what
be
the
minimum
publish
and
end
to
end
tail
quality_attribute_3
level
each
component_1
can
achieve
for
a
give
quality_attribute_2
catch
up
connector_7
what
be
the
maximum
quality_attribute_2
each
component_1
can
achieve
when
connector_11
connector_data_7
from
a
large
backlog
mix
workload
what
be
the
minimum
publish
and
end
to
end
tail
quality_attribute_3
level
each
component_1
can
achieve
while
component_8
be
catch
up
how
do
catch
up
connector_8
impact
publish
quality_attribute_3
and
end
to
end
tail
quality_attribute_3
testbed
the
omb
technology_9
recommend
specific
testbed
definition
for
instance
type
and
technology_14
configuration
and
workload
driver
configuration
for
the
component_18
component_10
and
component_25
side
our
benchmark
use
the
same
testbed
definition
a
confluent’s
these
testbed
definition
can
be
find
in
our
fork
within
confluent’s
omb
pattern_6
below
we
highlight
the
disk
quality_attribute_2
and
disk
fsync
quality_attribute_3
we
observe
these
hardware
metric
be
important
to
consider
when
interpret
benchmark
connector_data_3
disk
quality_attribute_2
our
benchmark
use
the
same
instance
type
a
confluent’s—specifically
i3en
2xlarge
with

vcores

gb
ram

x


gb
nvme
ssds
we
confirm
that
i3en
2xlarge
instance
can
support
up
to
~655
connector_data_6
s
of
connector_6
quality_attribute_2
across
two
disk
see
the
dd
connector_data_3
below
disk

dd
if=
dev
zero
of=
mnt
connector_data_1

test
bs=1m
count=65536
oflag=direct
65536+0
component_26
in
65536+0
component_26
out

byte

gb
copy


s

connector_data_6
s
disk

dd
if=
dev
zero
of=
mnt
connector_data_1

test
bs=1m
count=65536
oflag=direct
65536+0
component_26
in
65536+0
component_26
out

byte

gb
copy


s

connector_data_6
s
disk
connector_data_1
pattern_4
quality_attribute_3
it
be
critical
to
capture
the
fsync
quality_attribute_3
on
nvme
ssds
when
run
quality_attribute_3
relate
test
we
observe
that
the
99th
percentile
fsync
quality_attribute_3
on
these

instance
vary
from

millisecond
to

millisecond
a
show
in
the
follow
diagram
a
be
mention
early
we
saw
large
amount
of
variance
of
disk
from
different
instance
that
be
primarily
manifest
in
this
quality_attribute_3
and
we
find
a
set
of
instance
that
exhibit
consistent
quality_attribute_3
figure

99th
percentile
fsync
quality_attribute_3
on

different
instance
streamnative
benchmark
connector_data_4
we
have
summarize
our
benchmark
connector_data_4
below
you
can
find
our
complete
benchmark
report
maximum
quality_attribute_2
test
see
the
full
report
of
“maximum
quality_attribute_2
test”
here
the
maximum
quality_attribute_2
test
be
design
to
determine
the
maximum
quality_attribute_2
each
component_1
can
achieve
when
component_24
workload
that
include
publish
and
tail
connector_7
under
different
quality_attribute_5
guarantee
we
also
vary
the
number
of
topic
component_6
to
see
how
each
connector_9
impact
the
maximum
quality_attribute_2
we
find
that
when
configure
to
provide
level

quality_attribute_5
pattern_4
pattern_2
quality_attribute_5
and
pattern_4
local
quality_attribute_5
technology_1
achieve
a
quality_attribute_2
of
~300
connector_data_6
s
which
reach
the
physical
limit
of
the
journal
disk’s
bandwidth
technology_1
be
connector_18
on
top
of
a
quality_attribute_16
and
quality_attribute_17
requirement_7
storage
technology_3
bookkeeper
to
make
maximum
use
of
disk
bandwidth
without
sacrifice
quality_attribute_5
guarantee
technology_2
be
able
to
achieve
~420
connector_data_6
s
with

component_6
it
should
be
note
that
when
provide
level

quality_attribute_5
technology_1
be
configure
to
use
one
disk
a
journal
disk
for
connector_13
and
the
other
disk
a
ledger
disk
for
connector_7
compare
to
technology_2
use
both
disk
for
connector_13
and
connector_7
while
technology_1
s
setup
be
able
to
provide
quality_attribute_7
i
o
isolation
it
quality_attribute_2
be
also
limit
by
the
maximum
bandwidth
of
a
single
disk
~300
connector_data_6
s
alternative
disk
configuration
can
be
beneficial
to
technology_1
and
allow
for
more
cost
quality_attribute_18

which
will
be
discuss
in
a
late

when
configure
to
provide
level

quality_attribute_5
pattern_4
pattern_2
quality_attribute_5
and
pattern_5
local
quality_attribute_5
technology_1
and
technology_2
each
achieve
a
max
quality_attribute_2
of
~600
connector_data_6
s
both
component_4
reach
the
physical
limit
of
disk
bandwidth
the
maximum
quality_attribute_2
of
technology_2
on
one
component_6
be
only
½
of
the
max
quality_attribute_2
of
technology_1
vary
the
number
of
component_6
have
no
effect
on
pulsar’s
quality_attribute_2
but
it
do
affect
kafka’s
technology_1
sustain
maximum
quality_attribute_2
~300
connector_data_6
s
under
a
level

quality_attribute_5
guarantee
and
~600
connector_data_6
s
under
a
level

quality_attribute_5
guarantee
a
the
number
of
component_6
be
increase
from

to

kafka’s
quality_attribute_2
decrease
by
half
a
the
number
of
component_6
be
increase
from

to

publish
and
end
to
end
quality_attribute_3
test
see
the
full
report
of
“publish
and
end
to
end
quality_attribute_3
test”
here
the
publish
and
end
to
end
quality_attribute_3
test
be
design
to
determine
the
low
quality_attribute_3
each
component_1
can
achieve
when
component_24
workload
that
consist
of
publish
and
tail
connector_7
under
different
quality_attribute_5
guarantee
we
vary
the
number
of
subscription
and
the
number
of
component_6
to
see
how
each
connector_9
impact
both
publish
and
end
to
end
quality_attribute_3
we
find
that
pulsar’s
publish
and
end
to
end
quality_attribute_3
be
significantly
up
to
hundred
of
time
lower
than
kafka’s
in
all
test
requirement_6
which
evaluate
various
quality_attribute_5
guarantee
and
vary
number
of
component_6
and
subscription
pulsar’s
99th
percentile
publish
quality_attribute_3
and
end
to
end
quality_attribute_3
stay
within

millisecond
even
a
the
number
of
component_6
be
increase
from

to

or
a
the
number
of
subscription
be
increase
from

to

kafka’s
publish
and
end
to
end
quality_attribute_3
be
greatly
affect
by
variation
in
the
number
of
subscription
and
component_6
both
publish
and
end
to
end
quality_attribute_3
increase
from
~5
millisecond
to
~13
second
a
the
number
of
subscription
be
increase
from

to

both
publish
and
end
to
end
quality_attribute_3
increase
from
~5
millisecond
to
~200
second
a
the
number
of
topic
component_6
be
increase
from

to

catch
up
connector_7
test
see
the
full
report
of
“catch
up
connector_7
test”
here
the
catch
up
connector_7
test
be
design
to
determine
the
maximum
quality_attribute_2
each
component_1
can
achieve
when
component_24
workload
that
contain
catch
up
connector_8
only
at
the
begin
of
the
test
a
component_18
connector_19
connector_data_7
at
a
fix
rate
of
200k
per
second
when
the
component_18
have
connector_19
512gb
of
connector_data_1
component_8
begin
to
connector_7
the
connector_data_7
that
have
be
connector_20
the
component_8
component_24
the
accumulate
connector_data_7
and
have
no
difficulty
keep
up
with
the
component_18
which
continue
to
connector_21
connector_data_7
at
the
same
quality_attribute_19
when
component_24
catch
up
connector_7
pulsar’s
maximum
quality_attribute_2
be


time
fast
than
kafka’s
technology_1
achieve
a
maximum
quality_attribute_2
of


gb
s


million
connector_data_10
second
while
technology_2
achieve
a
quality_attribute_2
of
only

gb
s

million
connector_data_10
second
mix
workload
test
see
the
full
report
of
“mixed
workload
test”
here
this
mix
workload
test
be
design
to
determine
the
impact
of
catch
up
connector_8
on
publish
and
tail
connector_8
in
mix
workload
at
the
begin
of
the
test
component_27
connector_19
connector_data_7
at
a
fix
rate
of
200k
per
second
and
component_8
connector_12
connector_data_7
in
tail
mode
after
the
component_18
produce
512gb
of
connector_data_10
it
will
start
a
set
of
catch
up
component_8
to
connector_7
all
the
connector_data_7
from
the
begin
at
the
same
time
component_27
and
exist
tail
connector_7
component_8
continue
to
publish
and
connector_12
connector_data_7
at
the
same
quality_attribute_19
we
test
technology_2
and
technology_1
use
different
quality_attribute_5
setting
and
find
that
catch
up
connector_8
seriously
affect
kafka’s
publish
quality_attribute_3
but
have
little
impact
on
technology_1
kafka’s
99th
percentile
publish
quality_attribute_3
increase
from

millisecond
to


second
however
technology_1
maintain
a
99th
percentile
publish
quality_attribute_3
range
from
several
millisecond
to
ten
of
millisecond
the
connector_22
below
provide
convenient
connector_23
to
individual
section
of
our
benchmark
report
max
quality_attribute_2
test

component_6

subscription

component_27

component_8

component_6

subscription

component_27

component_8

component_6

subscription

component_27

component_8

component_6

subscription

component_18

component_10
publish
and
end
to
end
quality_attribute_3
test

component_6

subscription

component_6

subscription
different
component_6






catchup
connector_7
quality_attribute_2
test
mix
workload
test
all
the
raw
connector_data_1
of
the
benchmark
connector_data_4
be
also
quality_attribute_8
at
here
conclusion
a
tricky
aspect
of
benchmark
be
that
they
often
represent
only
a
narrow
combination
of
requirement_3
component_28
and
configuration
option
which
or
not
reflect
real
world
use
requirement_6
or
best
practice
benchmark
can
further
be
compromise
by
issue
in
their
technology_9
set
up
and
methodology
we
note
all
of
these
issue
in
the
recent
confluent
benchmark
at
the
community’s
connector_data_11
the
team
at
streamnative
set
out
to
run
this
benchmark
in
order
to
provide
knowledge
insight
and
quality_attribute_20
into
pulsar’s
true
requirement_1
capability
in
order
to
run
a
more
quality_attribute_1
benchmark
we
identify
and
fix
the
issue
with
the
confluent
benchmark
and
also

test
parameter
that
would
provide
insight
into
how
the
technology_6
compare
in
more
real
world
use
requirement_6
the
connector_data_4
to
our
benchmark
show
that
with
the
same
quality_attribute_5
guarantee
a
technology_2
technology_1
be
able
to
outperform
technology_2
in
workload
resemble
real
world
use
requirement_6
and
to
achieve
the
same
end
to
end
through
a
technology_2
in
confluent’s
limit
use
requirement_6
furthermore
technology_1
connector_10
significantly
quality_attribute_7
quality_attribute_3
than
technology_2
in
each
of
the
different
test
requirement_6
include
vary
subscription
topic
and
quality_attribute_5
guarantee
and
quality_attribute_7
i
o
isolation
than
technology_2
a
note
no
benchmark
can
replace
test
do
on
your
own
hardware
with
your
own
workload
we
encourage
you
to
test
technology_1
and
technology_2
use
your
own
setup
and
workload
in
order
to
understand
how
each
component_1
perform
in
your
particular
production
environment
if
you
have
any
question
on
technology_1
best
practice
a
you
go
through
please
reach
out
to
u
directly
or
feel
free
to
join
the
technology_1
slack
pattern_8
in
the
next
few
month
we
will
publish
a
series
of

to
help
the
quality_attribute_7
understand
and
leverage
technology_1
to
meet
their
requirement_3
need
specifically
we
will
show
the
requirement_1
of
technology_1
in
different
workload
and
setup
how
to
select
and
size
your
hardware
across
different
requirement_5
technology_15
and
on
prem
environment
and
show
how
you
can
use
technology_1
to
build
the
most
cost
quality_attribute_18
connector_3
component_29
if
you
have
any
question
about
pulsar’s
storage
architecture
it
requirement_1
characteristic
or
the
connector_data_4
of
this
benchmark
we
encourage
you
to
join
the
technology_1
slack
pattern_8
to
discus
companysuccess
storiesaboutcareerscontactnewsdeveloperspulsar
summiteventspulsar
weeklyconnectgithubtwittermediumlinkedinslideshareyoutubestay
updated©
streamnative
inc
2022apache
technology_3
technology_1
technology_3
bookkeeper
technology_3
flink
and
associate
open_source
project
name
be
trademark
of
the
technology_3
foundation
termsprivacy
