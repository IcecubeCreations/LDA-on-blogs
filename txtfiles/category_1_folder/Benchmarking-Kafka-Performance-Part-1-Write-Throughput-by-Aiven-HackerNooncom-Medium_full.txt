benchmarking
technology_1
requirement_1
part

connector_1
quality_attribute_1
|
by
aiven
|
hackernoon
technology_2
|
mediumget
unlimited
accessopen
in
apphomenotificationslistsstorieswritepublished
inhackernoon
comaivenfollowmar

2017·8
min
readbenchmarking
technology_1
requirement_1
part

connector_1
throughputto
connector_2
our
late
benchmark
see
our

update
herewe
have
offer
a
fully
manage
technology_1
component_1
for
some
time
now
and
we
be
quite
often
ask
about
how
many
connector_data_1
can
you
pattern_1
through
a
give
component_1
plan
tier
on
a
selected
requirement_2
so
here’s
a
benchmark
we
conduct
to
give
you
a
rough
idea
on
how
well
technology_3
technology_1
perform
in
the
requirement_2
what
be
technology_1
technology_3
technology_1
be
a
high
requirement_1
open
component_2
connector_3
component_3
component_4
for
connector_4
and
component_3
large
number
of
connector_data_1
in
real
time
it
enable
you
to
connector_5
connector_6
connector_data_2
such
a
click
connector_3

transaction
or
other
telemetry
in
real
time
and
at
quality_attribute_2
and
serve
it
downstream
to
connector_3
component_3
component_5
technology_1
be
build
quality_attribute_3
for
both
quality_attribute_4
a
well
a
fault
tolerance

more
horizontal
technology_4
to
tackle
grow
load
be
fairly
straightforward
and
automatic
pattern_2
of
the
connector_data_2
over
more
than
one
technology_4
maintain
quality_attribute_5
when
technology_4
fail
the
basic
concept
in
technology_1
be
component_6
and
component_7
a
component_8
be
an
component_5
that
generate
connector_data_2
but
only
to
provide
it
to
some
other
component_5
an
example
of
a
component_8
component_5
could
be
a
web
component_9
that
produce
“page
hits”
that
tell
when
a
web
component_10
be
connector_7
from
which
ip
connector_8
what
the
component_10
be
and
how
long
it
take
to
render
the
component_10
by
the
web
component_9
on
the
component_7
side
there
could
be
multiple
component_11
interest
in
the
same
component_10
hit
connector_data_2
connector_3
a
time
series
component_12
that
be
use
to
plot
the
total
number
of
component_10
hit
over
timea
report
component_5
connector_4
summary
of
the
component_10
connector_9
and
connector_10
them
to
a
connector_data_2
requirement_3
component_12
systema
ddos
detection
component_13
try
to
find
abnormal
connector_7
patternsa
rate
limit
pattern_3
count
the
number
of
hit
from
a
specific
component_2
addressand
so
on…kafka
suit
these
kind
of
component_14
very
well
it
provide
a
of
connector_11
the
connector_data_2
out
of
the
hand
of
the
produce
component_5
quickly
and
safely
once
the
component_8
have
connector_1
the
connector_data_3
to
technology_1
it
can
be
sure
that
it
part
of
the
be
do
the
component_8
component_5
do
not
need
to
how
the
connector_data_2
be
use
and
by
which
component_5
it
connector_12
it
in
technology_1
and
move
on
on
the
component_7
side
a
powerful
feature
of
technology_1
be
that
it
allow
multiple
component_15
to
connector_13
the
same
connector_data_3
in
our
web
component_10
hit
example
above
each
of
the
component_7
component_14
connector_2
their
own
connector_13
cursor
to
the
connector_data_2
and
they
can
component_3
the
connector_data_1
at
their
own
pace
all
without
cause
any
requirement_1
issue
or
delay
for
the
component_8
component_5
here’s
what
it
roughly
look

the
technology_5
cluster
be
a
critical
piece
in
keep
technology_1
healthy
and
up
and
run
it
maintain
kafka’s
metadata
and
most
importantly
a
consensus
between
the
technology_1
technology_4
of
who
be
do
what
aiven
technology_1
a
a
serviceaiven
technology_1
be
a
a
fully
manage
component_1
base
on
the
technology_3
technology_1
technology_6
our
aim
be
to
make
it
a
easy
a
possible
to
use
technology_1
cluster
with
the
least
amount
of
operational
effort
possible
we
handle
the
technology_1
and
technology_5
setup
and
for
you
so
you
can
focus
on
requirement_4

component_5
component_16
instead
of
infrastructure
quality_attribute_6
aiven
technology_1
component_17
can
be
launch
in
minute
and
we’ll
ensure
they
remain
operational
well
perform
up
to
date
and
quality_attribute_7
at
all
time
technology_4
be
automatically
quality_attribute_3
evenly
across
the
quality_attribute_8
quality_attribute_5
zone
in
order
to
minimize
the
impact
of
lose
any
of
the
zone
aiven
technology_1
be
quality_attribute_8
in
web
component_1
technology_7
requirement_2
component_4
upcloud
and
digitalocean
with
a
total
coverage
of

requirement_2
region
in
this
requirement_1
comparison
we
run
the
benchmark
on
all
of
these
except
digitalocean
where
our
technology_1
offer
be
limit
by
the
quality_attribute_8
plan
each
technology_1
component_1
use
in
these
test
be
a
regular
aiven
provide
component_1
with
no
alteration
to
it
default
setting
benchmark
setupin
this
first
technology_1
benchmark

we
set
out
to
estimate
maximum
connector_1
quality_attribute_1
rat
for
various
aiven
technology_1
plan
tier
in
different
requirement_2
we
want
to
use
a
typical
requirement_5
connector_data_3
size
and
technology_8
technology_9
for
produce
load
we
also
want
to
generate
the
load
from
separate
component_11
over
the
requirement_6
to
make
sure
the
load
could
mimic
the
actual
requirement_5
workload
a
closely
a
possible
high
level
pattern_4
of
the
test
setup
a
single
aiven
technology_1
component_1
with
five
technology_4
quality_attribute_3
evenly
over
the
quality_attribute_5
zone
we
pick
connector_data_3
size
of

byte
for
our
test
base
on
our
experience
one
of
the
most
typical
connector_data_4
be
a
technology_10
encode
connector_data_3
range
somewhere
between

byte
to

kilobyte
in
size
in
these
test
we
use
a
single
topic
with
the
component_18
count
match
the
technology_4
count
of
each
aiven
plan
tier
for
more
complex
topic
component_18
setup
aiven
actively
balance
the
placement
of
the
component_18
try
to
achieve
a
“perfect”
distribution
of
component_18
in
the
requirement_7
of
this
test
there
be
a
single
component_18
for
each
technology_4
so
this
be
rather
quality_attribute_9
we
set
the
pattern_2
factor
to
one

in
the
requirement_7
of
this
test
mean
each
of
the
connector_data_1
only
reside
on
a
single
technology_1
technology_4
technology_3
technology_1
version
use
be




for
load
generation
we
choose
to
use
librdkafka
and
rdkafka_performance
from
the
provide
example
we
be
use
default
setting
for
the
most
part
but
bump
up
single
connector_data_5
timeout
to

second
a
we
expect
the
technology_1
pattern_5
to
be
under
extreme
load
and
connector_data_5
component_3
to
take
long
than
under
a
normal
healthy
load
level
also
since
aiven
technology_1
component_17
be
offer
only
over
pattern_6
tl
connector_14
we
include
the
configuration
for
these
namely
the
require
certificate
and
key
librdkafka
default
to
a
maximum
pattern_7
size
of

connector_data_1
or
to
a
maximun
connector_data_5
size
of
one
million
byte
per
connector_data_5
whichever
be
meet
first
in
these
test
we
do
not
employ
compression
component_8
prop
configuration
metadata
pattern_5
list=target
technology_1
benchmark
aivencloud
technology_2
10947security
protocol=sslssl
key
location=client
keyssl
certificate
location=client
crtssl
ca
location=ca
crtrequest
timeout
ms=60000we
run
several
instance
of
rdkafka_performance
on
multiple
vms
on
a
different
requirement_2
technology_11
from
the
one
be
test
so
all
of
the
test
load
be
come
from
the
internet
thru
the
nodes’
requirement_6

we
keep
increasing
the
number
of
instance
until
we
could
find
the
saturation
point
and
the
maximum
connector_data_3
rat
for
each
plan
each
rdkafka_performance
instance
be
start
on
the
command
line
with
rdkafka_performance
p
s

t
target
topic
x
file=producer
propsbenchmark
resultsfirst
set
of
test
be
run
on
an
aiven
technology_1
requirement_8

plan
which
be
a
three
technology_4
cluster
and
a
common
start
point
for
many
of
our
requirement_5
each
technology_4
in
this
plan
have

gigabyte
of
ram
a
single
cpu
core
and

gigabyte
of
disk
on
each
technology_4
provide
a
total

gigabyte
of
raw
technology_1
storage
capacity
in
the
cluster
connector_1
requirement_1

technology_4
@

gb
ram

cpu

gb
disk
each
on
upcloud
we
hit


connector_data_1
per
second
technology_7
and
plan
saturated
at


and


connector_data_1
per
second
and
the
deployment
reach


connector_data_1
per
second
the
requirement_1
be
pretty
respectable
the
requirement_1
on
be
a
bit
behind
the
others
because
of
the
technology_4
type
quality_attribute_8
and
we
will
be
look
at
way
to
optimize
that
in
the
future
a
you
will
see
in
the
next
graph
for
the
test
with
the
big
plan
the
technology_12
requirement_1
be
already
more
in
line
with
the
other
technology_11
next
we
test
three
technology_4
cluster
but
with
large
underlie
instance
use
the
requirement_8

plan
this
plan
have
technology_4
with

gigabyte
of
ram
two
cpu
core
and

gigabyte
of
disk
per
technology_4
i
e
all
the
primary
resource
be
double
when
compare
to
the
requirement_8

plan
this
test
indicate
how
well
technology_1
quality_attribute_2
vertically
with
increase
resource
connector_1
requirement_1

technology_4
@

gb
ram

cpu

gb
disk
each
we
see
a
nice
increase
in
requirement_1
with


connector_data_1
per
second
on
upcloud


on
technology_7


on
and


connector_data_1
per
second
on
technology_13
in
the
last
test
we
want
to
verify
how
well
technology_1
quality_attribute_2
horizontally
with
this
test
we
go
from
the
requirement_8
plan
tier
to
the
premium
tier
which
bump
the
technology_4
count
from
three
to
five
while
keep
the
technology_4
spec
otherwise
identical
also
the
test
setup
be
update
to
utilize
a
component_18
count
of
five
vs
three
for
this
test
connector_1
requirement_1

technology_4
@

gb
ram

cpu

gb
disk
each
the
connector_data_6
here
be
solid
for
technology_1
a
two
third
increase
in
the
number
of
technology_4
connector_data_7
in
a
straight


increase
in
connector_1
requirement_1
awesome
aiven
technology_1
premium

on
upcloud
handle


connector_data_1
per
second
technology_7




and


connector_data_1
second
benchmark
conclusionsapache
technology_1
perform
a
well
a
we
expect
and
quality_attribute_2
nicely
with

resource
and
increase
cluster
size
we
welcome
you
to
benchmark
your
own
workload
with
aiven
and
to
connector_15
your
connector_data_7
we
utilize
technology_1
a
a
connector_data_3
pattern_5
within
aiven
a
well
a
use
it
a
a
for
pip
all
of
our
telemetry
metric
and
requirement_9
we
be
happy
with
with
our
technical
choice
and
can
recommend
technology_3
technology_1
for
handle
all
kind
of
connector_6
connector_data_2
find
out
more
about
aiven
technology_1
at
technology_14
aiven
io
technology_1
hacker
noon
be
how
hacker
start
their
afternoon
we’re
a
part
of
the
@ami
family
we
be
now
connector_16
submission
and
happy
to
discus
advertising
&
sponsorship
opportunity
if
you
enjoy
this
story
we
recommend
connector_17
our
late
tech
story
and
trend
tech
story
until
next
time
don’t
take
the
reality
of
the
world
for
grant

5more
from
hackernoon
comelijah
mcclain
george
floyd
eric
garner
breonna
taylor
ahmaud
arbery
michael
brown
oscar
grant
atatiana
jefferson
tamir
rice
bettie
jones
botham
jeanread
more
from
hackernoon
comrecommended
from
mediumenric
delgado
samperan
component_19
to
connector_18
reminder
connector_data_1
to
my
confine
mom
through
whatsapp
do
with
from
ibm…andrew
khouryhow
to
connector_19
quality_attribute_10
delivery
in

secondsyash
pawarinartificialisunderstanding
the
different
number
systemshpb
globalinhpb
foundationhpb
monthly
progress
report
—
2021steve
kbeginners
guide
to
firebaseaivenredis
and
the
secret
of
fluctuate
readsgamedevdigestgame
dev
digest
issue
#118
—
what’s
newidle
mysticidle
mystic
development
plan
updateabouthelptermsprivacyget
the
appget
startedaiven225
followersyour
component_12
in
the
requirement_2
www
aiven
iofollowmore
from
mediumkai
waehnerapache
technology_1
a
requirement_2
requirement_10
ipaas
requirement_11
middlewareedu
technology_6
watchinevent
drive
utopiabuild
serverless
connector_6
architecture
with
upstash
kafkadatastaxinbuilding
the
open
connector_data_2
stackapache
technology_15
requirement_1
test
with
nosqlbenchsandeep
mehtainsoftrock
iomigrating
to
technology_12
manage
connector_6
technology_1
msk
helpstatuswritersblogcareersprivacytermsaboutknowable
