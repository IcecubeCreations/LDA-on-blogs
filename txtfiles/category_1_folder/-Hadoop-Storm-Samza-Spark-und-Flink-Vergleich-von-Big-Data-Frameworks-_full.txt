technology_1
storm
samza
technology_2
und
flink
vergleich
von
requirement_1
technology_3
home
toc
technology_1
storm
samza
technology_2
und
flink
vergleich
von
requirement_1
technology_3
requirement_1
conceptual
einführung
requirement_1
*
ist
ein
sammelbegriff
für
die
nicht
traditionellen
strategien
und
technologien
die
zum
sammeln
organisieren
verarbeiten
und
sammeln
von
erkenntnissen
au
großen
datenmengen
erforderlich
sind
während
da
problem
der
arbeit
mit
daten
die
die
rechenleistung
oder
den
speicherplatz
eines
einzelnen
component_1
überschreiten
nicht
neu
ist
haben
sich
die
verbreitung
der
umfang
und
der
wert
dieser
art
von
datenverarbeitung
in
den
letzten
jahren
erheblich
erweitert
in
einem
früheren
leitfaden
haben
wir
einige
der
in
technology_4
www
digitalocean
technology_5
an
introduction
to
big
connector_data_1
concept
and
terminology
verwendeten
allgemeinen
konzepte
verarbeitungsstufen
und
terminologie
besprochen
big
connector_data_1
systeme
in
diesem
artikel
befassen
wir
un
mit
einer
der
wichtigsten
komponenten
eines
big
connector_data_1
component_2
der
verarbeitung
von
technology_3
verarbeitungs
technology_3
berechnen
die
daten
im
component_2
indem
sie
entweder
au
dem
nichtflüchtigen
speicher
lesen
oder
wenn
sie
in
da
component_2
aufgenommen
werden
beim
berechnen
von
daten
werden
informationen
und
erkenntnisse
au
großen
mengen
einzelner
datenpunkte
extrahiert
wir
werden
die
folgenden
technology_3
abdecken
*
nur
pattern_1
technology_3
*
*
connector_1
#
technology_6
technology_1
technology_6
technology_1
*
*
nur
connector_2
technology_3
*
*
connector_1
#
technology_7
technology_6
storm
*
*
connector_1
#
technology_6
samza
technology_6
samza
*
*
hybride
technology_3
*
*
connector_1
#
technology_8
technology_6
technology_2
*
*
connector_1
#
technology_6
flink
technology_6
flink
*
be
sind
requirement_1
component_3
technology_3
component_3
technology_3
*
und
*
component_3
component_4
*
sind
für
da
rechnen
über
daten
in
einem
datensystem
verantwortlich
während
e
keine
autorisierende
definition
gibt
die
component_5
von
technology_3
unterscheidet
ist
e
manchmal
nützlich
die
erstere
al
die
eigentliche
komponente
zu
definieren
die
für
da
verarbeiten
von
daten
verantwortlich
ist
und
die
letztere
al
eine
gruppe
von
komponenten
die
dafür
ausgelegt
sind
zum
beispiel
kann
*
technology_6
technology_1
*
al
prozess
technology_3
mit
*
mapreduce
*
al
technology_9
prozess
component_5
betrachtet
werden
motoren
und
technology_3
können
häufig
ausgetauscht
oder
zusammen
verwendet
werden
zum
beispiel
kann
sich
*
technology_6
technology_2
*
ein
anderes
technology_3
in
technology_1
einbinden
um
mapreduce
zu
ersetzen
diese
interoperabilität
zwischen
komponenten
ist
einer
der
gründe
für
die
große
flexibilität
von
big
connector_data_1
systemen
während
die
systeme
die
diese
phase
de
datenlebenszyklus
bewältigen
komplex
sein
können
sind
die
ziele
auf
breiter
ebene
sehr
ähnlich
arbeiten
sie
über
daten
um
da
verständnis
zu
verbessern
oberflächenmuster
zu
erhalten
und
einblicke
in
komplexe
interaktionen
zu
erhalten
um
die
erörterung
dieser
komponenten
zu
vereinfachen
werden
diese
verarbeitungsframeworks
nach
dem
status
der
daten
gruppiert
für
die
sie
entwickelt
wurden
einige
systeme
verarbeiten
daten
in
stapeln
während
andere
daten
in
einem
kontinuierlichen
datenstrom
verarbeiten
während
sie
in
da
component_2
fließen
wieder
andere
können
auf
eine
dieser
arten
mit
daten
umgehen
wir
werden
jede
art
der
verarbeitung
al
konzept
vorstellen
bevor
wir
auf
die
besonderheiten
und
konsequenzen
verschiedener
implementierungen
eingehen
stapelverarbeitungssysteme
stapelverarbeitung
*
hat
eine
lange
geschichte
in
der
big
connector_data_1
welt
bei
der
stapelverarbeitung
wird
ein
großer
statischer
datensatz
bearbeitet
und
da
ergebnis
nach
abschluss
der
berechnung
zu
einem
späteren
zeitpunkt
zurückgegeben
die
datensätze
in
der
stapelverarbeitung
sind
in
der
regel…
begrenzt
pattern_1
datasets
repräsentieren
eine
endliche
sammlung
von
daten
persistent
daten
werden
fast
immer
durch
eine
art
permanenten
speicher
gesichert
groß
stapelverarbeitungen
sind
häufig
die
einzige
option
für
die
verarbeitung
extrem
großer
datenmengen
die
stapelverarbeitung
eignet
sich
gut
für
berechnungen
bei
denen
zugriff
auf
einen
vollständigen
datensatz
erforderlich
ist
beispielsweise
müssen
bei
der
berechnung
von
summen
und
durchschnitten
datensätze
ganzheitlich
und
nicht
al
sammlung
einzelner
datensätze
behandelt
werden
diese
operationen
erfordern
da
der
status
für
die
dauer
der
berechnungen
beibehalten
wird
aufgaben
die
sehr
große
datenmengen
erfordern
lassen
sich
häufig
be
besten
im
stapelbetrieb
erledigen
egal
ob
die
datensätze
direkt
au
dem
permanenten
speicher
verarbeitet
oder
in
den
speicher
geladen
werden
pattern_1
systeme
sind
auf
große
mengen
ausgelegt
und
verfügen
über
die
ressourcen
um
diese
zu
verarbeiten
da
bei
der
stapelverarbeitung
große
mengen
persistent
daten
verarbeitet
werden
werden
diese
häufig
mit
verlaufsdaten
verwendet
der
kompromiss
für
die
verarbeitung
großer
datenmengen
ist
eine
längere
rechenzeit
au
diesem
grund
ist
die
stapelverarbeitung
in
situationen
in
denen
die
verarbeitungszeit
besonders
wichtig
ist
nicht
geeignet
technology_6
technology_1
technology_6
technology_1
ist
ein
verarbeitungsframework
da
ausschließlich
stapelverarbeitung
bietet
technology_1
war
da
erste
big
connector_data_1
technology_3
da
in
der
open
component_6
beachtliche
fortschritte
erzielte
basierend
auf
mehreren
beiträgen
und
präsentationen
von
zum
umgang
mit
enormen
datenmengen
zu
dieser
zeit
hat
technology_1
die
algorithmen
und
den
komponentenstapel
neu
implementiert
um
die
stapelverarbeitung
in
großem
maßstab
zugänglicher
zu
machen
moderne
versionen
von
technology_1
bestehen
au
mehreren
komponenten
oder
schichten
die
zur
verarbeitung
von
chargendaten
zusammenarbeiten
*
technology_10
*
technology_10
ist
die
verteilte
dateisystemschicht
die
die
speicherung
und
replikation
auf
den
clusterknoten
koordiniert
technology_10
stellt
sicher
da
die
daten
trotz
unvermeidlicher
hostfehler
verfügbar
bleiben
e
wird
al
datenquelle
verwendet
um
zwischenverarbeitungsergebnisse
zu
speichern
und
die
endgültigen
berechneten
ergebnisse
beizubehalten
*
technology_11
*
technology_11
steht
für
another
resource
negotiator
und
ist
die
cluster
koordinierungskomponente
de
technology_1
technology_12
e
ist
für
die
koordination
und
verwaltung
der
zugrunde
liegenden
ressourcen
und
die
planung
der
auszuführenden
verantwortlich
mit
technology_11
können
auf
einem
technology_1
cluster
wesentlich
mehr
workload
ausgeführt
werden
al
in
früheren
iterationen
da
e
al
schnittstelle
zu
den
clusterressourcen
fungiert
*
mapreduce
*
mapreduce
ist
die
requirement_2
stapelverarbeitungs
component_5
von
technology_1
stapelverarbeitungsmodell
die
verarbeitungsfunktionalität
von
technology_1
stammt
von
der
mapreduce
component_5
die
verarbeitungstechnik
von
mapreduce
folgt
dem
connector_data_2
shuffle
und
reduction
algorithmus
unter
verwendung
von
schlüssel
wert
paaren
da
grundlegende
verfahren
umfasst
lesen
de
datensatzes
au
dem
technology_10
dateisystem
teilen
sie
den
datensatz
in
blöcke
auf
und
verteilen
sie
ihn
auf
die
verfügbaren
knoten
anwenden
der
berechnung
auf
jeden
knoten
auf
die
teilmenge
der
daten
die
zwischenergebnisse
werden
in
technology_10
zurückgeschrieben
umverteilung
der
zwischenergebnisse
auf
gruppierung
nach
schlüssel
reduzieren
sie
den
wert
jedes
schlüssels
indem
sie
die
von
den
einzelnen
knoten
berechneten
ergebnisse
zusammenfassen
und
kombinieren
schreiben
sie
die
berechneten
endergebnisse
zurück
in
technology_10
vorteile
und
einschränkungen
da
diese
methode
die
permanente
speicherung
da
mehrmalige
lesen
und
schreiben
pro
connector_data_3
in
hohem
maße
nutzt
ist
sie
in
der
regel
relativ
langsam
auf
der
anderen
seite
bedeutet
die
da
mapreduce
enorme
datenmengen
verarbeiten
kann
da
speicherplatz
normalerweise
eine
der
be
häufigsten
vorkommenden
serverressourcen
ist
die
bedeutet
auch
da
mapreduce
von
technology_1
in
der
regel
auf
kostengünstigerer
hardware
al
manche
alternativen
ausgeführt
werden
kann
da
nicht
versucht
wird
alles
im
speicher
zu
speichern
mapreduce
verfügt
über
ein
unglaubliches
skalierbarkeitspotenzial
und
wurde
in
der
produktion
auf
zehntausenden
von
knoten
verwendet
mapreduce
ist
al
entwicklungsziel
dafür
bekannt
eine
ziemlich
steile
lernkurve
zu
haben
andere
ergänzungen
de
technology_1
ökosystems
können
die
auswirkungen
in
unterschiedlichem
maße
verringern
können
aber
dennoch
ein
faktor
für
die
schnelle
implementierung
einer
idee
in
einem
technology_1
cluster
sein
technology_1
verfügt
über
ein
umfangreiches
ökosystem
wobei
der
technology_1
cluster
selbst
häufig
al
baustein
für
andere
verwendet
wird
viele
andere
verarbeitungsframeworks
und
component_4
verfügen
über
technology_1
integrationen
um
technology_10
und
den
technology_11
ressourcenmanager
zu
verwenden
zusammenfassung
technology_6
technology_1
und
seine
mapreduce
verarbeitungsengine
bieten
ein
bewährtes
stapelverarbeitungsmodell
da
sich
be
besten
für
die
verarbeitung
sehr
großer
datenmengen
eignet
bei
denen
die
zeit
keine
rolle
spielt
die
geringen
kosten
für
komponenten
die
für
ein
gut
funktionierendes
technology_1
cluster
erforderlich
sind
machen
diese
verarbeitung
für
viele
anwendungsfälle
kostengünstig
und
effektiv
durch
die
kompatibilität
und
requirement_3
mit
anderen
technology_3
und
component_4
kann
technology_1
häufig
al
grundlage
für
mehrere
verarbeitungs
workload
mit
unterschiedlichen
technologien
dienen
connector_2
verarbeitungssysteme
pattern_2
*
systeme
rechnen
beim
eintritt
in
da
component_2
über
daten
die
erfordert
ein
anderes
verarbeitungsmodell
al
da
pattern_1
paradigma
anstatt
operationen
zu
definieren
die
auf
ein
gesamtes
dataset
angewendet
werden
sollen
definieren
connector_2
prozessoren
operationen
die
auf
jedes
einzelne
datenelement
angewendet
werden
wenn
e
da
component_2
durchläuft
die
datensätze
in
der
connector_2
verarbeitung
gelten
al
unbegrenzt
die
hat
einige
wichtige
auswirkungen
der
gesamtdatensatz
ist
nur
al
die
datenmenge
definiert
die
bisher
in
da
component_2
eingegangen
ist
da
work
dataset
ist
möglicherweise
relevant
und
auf
jeweils
ein
element
beschränkt
die
verarbeitung
erfolgt
ereignisbasiert
und
endet
erst
wenn
sie
explizit
gestoppt
wird
die
ergebnisse
sind
sofort
verfügbar
und
werden
laufend
aktualisiert
sobald
neue
daten
eingehen
connector_2
verarbeitungssysteme
können
eine
nahezu
unbegrenzte
datenmenge
verarbeiten
verarbeiten
jedoch
jeweils
nur
ein
true
connector_2
verarbeitung
oder
nur
sehr
wenige
micro
pattern_1
verarbeitung
elemente
wobei
der
minimale
status
zwischen
den
datensätzen
beibehalten
wird
während
die
meisten
systeme
methoden
zur
aufrechterhaltung
eines
bestimmten
zustands
bereitstellen
ist
die
dampfverarbeitung
für
eine
*
funktionsfähigere
*
verarbeitung
mit
wenigen
nebenwirkungen
stark
optimiert
funktionale
operationen
konzentrieren
sich
auf
diskrete
schritte
die
begrenzte
zustände
oder
nebenwirkungen
haben
wenn
sie
dieselbe
für
dasselbe
datenelement
ausführen
wird
die
gleiche
ausgabe
unabhängig
von
anderen
faktoren
erstellt
diese
art
der
verarbeitung
passt
gut
zu
connector_2
da
der
status
zwischen
elementen
normalerweise
eine
kombination
au
schwierig
begrenzt
und
manchmal
unerwünscht
ist
während
also
normalerweise
eine
art
von
zustandsmanagement
möglich
ist
sind
diese
technology_3
in
ihrer
abwesenheit
viel
einfacher
und
effizienter
diese
art
der
verarbeitung
eignet
sich
für
bestimmte
arten
von
workload
die
verarbeitung
mit
nahezu
echtzeitanforderungen
wird
vom
connector_2
modell
gut
unterstützt
requirement_4
component_7
oder
anwendungsfehlerprotokollierung
und
andere
zeitbasierte
metriken
sind
eine
selbstverständlichkeit
da
da
reagieren
auf
änderungen
in
diesen
bereichen
für
geschäftsfunktionen
von
entscheidender
bedeutung
sein
kann
die
connector_2
verarbeitung
eignet
sich
gut
für
daten
bei
denen
sie
auf
änderungen
oder
spitzen
reagieren
müssen
und
bei
denen
sie
über
einen
längeren
zeitraum
an
trend
interessiert
sind
technology_6
technology_13
technology_6
technology_13
ist
ein
technology_3
für
die
connector_2
verarbeitung
da
sich
auf
extrem
niedrige
latenz
konzentriert
und
möglicherweise
die
beste
option
für
workload
ist
die
eine
zeitnahe
verarbeitung
erfordern
e
kann
sehr
große
datenmengen
verarbeiten
und
ergebnisse
mit
einer
geringeren
latenz
al
andere
lösungen
liefern
connector_2
verarbeitungsmodell
die
technology_13
connector_2
verarbeitung
funktioniert
indem
dag
direct
acyclic
graph
in
einem
technology_3
orchestriert
werden
da
sie
*
topologien
*
nennt
diese
topologien
beschreiben
die
verschiedenen
transformationen
oder
schritte
die
für
jedes
eingehende
datenelement
beim
eintritt
in
da
component_2
ausgeführt
werden
die
topologien
setzen
sich
zusammen
au
*
connector_3
*
konventionelle
datenströme
die
sind
unbegrenzte
daten
die
ständig
im
component_2
ankommen
*
ausläufe
*
quellen
von
datenströmen
be
rande
der
topologie
die
können
apis
warteschlangen
usw
sein
die
zu
bearbeitende
daten
erzeugen
*
bolzen
*
bolzen
stellen
einen
verarbeitungsschritt
dar
der
connector_3
verbraucht
eine
auf
sie
anwendet
und
da
ergebnis
al
connector_2
ausgibt
die
bolzen
werden
mit
jedem
auslauf
verbunden
und
dann
miteinander
verbunden
um
die
gesamte
erforderliche
verarbeitung
zu
veranlassen
be
ende
der
topologie
kann
die
endgültige
schraubenausgabe
al
eingabe
für
ein
verbundenes
component_2
verwendet
werden
die
idee
hinter
technology_13
ist
e
kleine
diskrete
operationen
unter
verwendung
der
obigen
komponenten
zu
definieren
und
diese
dann
zu
einer
topologie
zusammenzusetzen
standardmäßig
bietet
technology_13
garantien
für
die
mindestens
einmalige
verarbeitung
die
bedeutet
da
garantiert
werden
kann
da
jede
nachricht
mindestens
einmal
verarbeitet
wird
in
einigen
fehlerszenarien
kann
e
jedoch
zu
duplikaten
kommen
technology_13
garantiert
nicht
da
nachrichten
in
der
richtigen
reihenfolge
verarbeitet
werden
um
eine
genau
einmalige
zustandsbehaftete
verarbeitung
zu
erreichen
steht
auch
eine
abstraktion
mit
dem
namen
*
trident
*
zur
verfügung
um
genau
zu
sein
wird
technology_13
without
trident
oft
al
*
core
technology_13
*
bezeichnet
trident
ändert
die
verarbeitungsdynamik
von
technology_13
erheblich
erhöht
die
latenz
fügt
der
verarbeitung
einen
status
hinzu
und
implementiert
ein
mikro
pattern_1
modell
anstelle
eines
reinen
element
für
element
connector_2
component_2
storm
benutzer
empfehlen
normalerweise
die
verwendung
von
core
storm
wann
immer
die
möglich
ist
um
diese
nachteile
zu
vermeiden
vor
diesem
hintergrund
ist
die
garantie
von
trident
da
artikel
genau
einmal
verarbeitet
werden
in
fällen
nützlich
in
denen
da
component_2
doppelte
nachrichten
nicht
intelligent
verarbeiten
kann
trident
ist
auch
die
einzige
option
in
storm
wenn
sie
den
status
zwischen
elementen
beibehalten
müssen
z
b
wenn
sie
zählen
wie
viele
benutzer
innerhalb
einer
stunde
auf
einen
connector_1
klicken
trident
gibt
technology_13
flexibilität
obwohl
e
die
natürlichen
stärken
de
technology_3
nicht
ausnutzt
dreizack
topologien
bestehen
au
*
connector_2
pattern_1
*
hierbei
handelt
e
sich
um
mikro
pattern_1
von
connector_2
daten
die
aufgeteilt
werden
um
eine
semantik
für
die
stapelverarbeitung
bereitzustellen
*
vorgänge
*
die
sind
stapelvorgänge
die
mit
den
daten
ausgeführt
werden
können
vorteile
und
einschränkungen
technology_13
ist
wahrscheinlich
die
beste
derzeit
verfügbare
lösung
für
die
echtzeitverarbeitung
e
ist
in
der
lage
daten
mit
extrem
geringer
latenz
für
workload
zu
verarbeiten
die
mit
minimal
verzögerung
verarbeitet
werden
müssen
technology_13
ist
häufig
eine
gute
wahl
wenn
sich
die
verarbeitungszeit
direkt
auf
die
benutzererfahrung
auswirkt
z
b
wenn
da
feedback
au
der
verarbeitung
direkt
auf
die
seite
eines
besuchers
auf
einer
zurückgeführt
wird
technology_13
with
trident
bietet
ihnen
die
möglichkeit
micro
pattern_1
anstelle
der
reinen
connector_2
verarbeitung
zu
verwenden
die
gibt
dem
benutzer
zwar
mehr
flexibilität
bei
der
anpassung
de
technology_14
an
die
beabsichtigte
verwendung
negiert
jedoch
tendenziell
einige
der
größten
vorteile
der
gegenüber
anderen
lösungen
trotzdem
ist
e
immer
noch
hilfreich
eine
auswahl
für
den
connector_2
verarbeitungsstil
zu
haben
core
technology_13
bietet
keine
bestellgarantie
für
nachrichten
core
technology_13
bietet
mindestens
einmalige
verarbeitungsgarantien
dh
die
verarbeitung
jeder
nachricht
kann
garantiert
werden
e
können
jedoch
duplikate
auftreten
trident
bietet
genau
einmalige
garantien
und
kann
bestellungen
zwischen
chargen
anbieten
jedoch
nicht
innerhalb
im
hinblick
auf
die
interoperabilität
kann
technology_13
in
hadoops
technology_11
ressourcen
negotiator
integriert
werden
wodurch
die
anbindung
an
eine
vorhandene
technology_1
bereitstellung
vereinfacht
wird
technology_13
bietet
mehr
al
die
meisten
verarbeitungsframeworks
eine
umfassende
sprachunterstützung
und
bietet
benutzern
viele
optionen
zum
definieren
von
topologien
zusammenfassung
für
reine
connector_2
verarbeitungs
workload
mit
sehr
hohen
latenzanforderungen
ist
technology_13
wahrscheinlich
die
ausgereifteste
option
e
kann
die
nachrichtenverarbeitung
gewährleisten
und
kann
mit
einer
großen
anzahl
von
programmiersprachen
verwendet
werden
da
technology_13
keine
stapelverarbeitung
durchführt
müssen
sie
zusätzliche
verwenden
wenn
sie
diese
funktionen
benötigen
wenn
sie
einen
hohen
bedarf
an
garantien
für
die
einmalige
bearbeitung
haben
kann
trident
die
bereitstellen
zu
diesem
zeitpunkt
könnten
jedoch
auch
andere
connector_2
component_3
technology_3
besser
passen
technology_6
samza
technology_6
samza
ist
ein
connector_2
component_3
technology_3
da
eng
mit
dem
technology_6
technology_15
connector_data_4
component_2
verbunden
ist
während
technology_15
von
vielen
connector_2
verarbeitungssystemen
verwendet
werden
kann
wurde
samza
speziell
entwickelt
um
die
einzigartige
architektur
und
die
garantien
von
technology_15
zu
nutzen
e
verwendet
technology_15
um
fehlertoleranz
pufferung
und
zustandsspeicherung
bereitzustellen
samza
verwendet
technology_11
für
die
ressourcenverhandlung
die
bedeutet
da
standardmäßig
ein
technology_1
cluster
erforderlich
ist
mindestens
technology_10
und
technology_11
die
bedeutet
jedoch
auch
da
samza
sich
auf
die
umfangreichen
funktionen
von
technology_11
verlassen
kann
connector_2
verarbeitungsmodell
samza
verwendet
die
semantik
von
technology_15
um
die
art
und
weise
zu
definieren
in
der
connector_3
verarbeitet
werden
technology_15
verwendet
im
umgang
mit
daten
die
folgenden
konzepte
*
themen
*
jeder
datenstrom
der
in
ein
technology_15
component_2
eingeht
wird
al
thema
bezeichnet
ein
thema
ist
im
grunde
genommen
ein
strom
verwandter
informationen
die
verbraucher
abonnieren
können
*
partitionen
*
um
ein
thema
auf
knoten
zu
verteilen
unterteilt
technology_15
die
eingehenden
nachrichten
in
partitionen
die
partitionsunterteilungen
basieren
auf
einem
schlüssel
soda
garantiert
wird
da
jede
nachricht
mit
demselben
schlüssel
an
dieselbe
component_8
gesendet
wird
partitionen
haben
die
bestellung
garantiert
*
pattern_3
*
die
einzelnen
knoten
au
denen
ein
technology_15
cluster
besteht
werden
al
pattern_3
bezeichnet
*
produzent
*
jede
komponente
die
zu
einem
technology_15
thema
schreibt
wird
al
produzent
bezeichnet
der
produzent
stellt
den
schlüssel
bereit
der
zum
partitionieren
eines
themas
verwendet
wird
*
verbraucher
*
verbraucher
sind
alle
komponenten
die
au
einem
technology_15
thema
lesen
verbraucher
sind
dafür
verantwortlich
informationen
über
ihren
eigenen
offset
zu
pflegen
damit
sie
wissen
welche
datensätze
verarbeitet
wurden
wenn
ein
fehler
auftritt
da
technology_15
ein
unveränderliches
protokoll
darstellt
handelt
samza
mit
unveränderlichen
connector_2
die
bedeutet
da
alle
transformationen
neue
connector_3
erstellen
die
von
anderen
komponenten
verwendet
werden
ohne
da
die
auswirkungen
auf
den
ursprünglichen
connector_2
hat
vorteile
und
einschränkungen
samzas
vertrauen
in
ein
technology_15
ähnliches
warteschlangensystem
scheint
auf
den
ersten
blick
restriktiv
e
bietet
dem
component_2
jedoch
einige
einzigartige
garantien
und
funktionen
die
in
anderen
connector_2
verarbeitungssystemen
nicht
üblich
sind
beispielsweise
bietet
technology_15
bereits
die
replizierte
speicherung
von
daten
an
auf
die
mit
geringer
latenz
zugegriffen
werden
kann
e
bietet
auch
ein
sehr
einfaches
und
kostengünstiges
mehrteilnehmermodell
für
jede
einzelne
datenpartition
die
gesamte
ausgabe
einschließlich
der
zwischenergebnisse
wird
ebenfalls
an
technology_15
geschrieben
und
kann
von
den
nachgeschalteten
stufen
unabhängig
verwendet
werden
in
vielerlei
hinsicht
spiegelt
diese
enge
abhängigkeit
von
technology_15
die
art
und
weise
wide
in
der
die
mapreduce
component_5
häufig
auf
technology_10
verweist
während
da
verweisen
auf
technology_10
zwischen
den
einzelnen
berechnungen
zu
schwerwiegenden
leistungsproblemen
bei
der
stapelverarbeitung
führt
werden
bei
der
connector_2
verarbeitung
eine
reihe
von
problemen
behoben
die
enge
beziehung
von
samza
zu
technology_15
ermöglicht
e
die
verarbeitungsschritte
selbst
sehr
locker
miteinander
zu
verknüpfen
eine
beliebige
anzahl
von
teilnehmern
kann
ohne
vorherige
koordination
zu
der
ausgabe
jedes
schritts
hinzugefügt
werden
die
kann
für
organisationen
sehr
nützlich
sein
in
denen
mehrere
team
möglicherweise
auf
ähnliche
daten
zugreifen
müssen
alle
team
können
da
thema
der
daten
abonnieren
die
in
da
component_2
eingegeben
werden
oder
sie
können
problemlos
themen
abonnieren
die
von
anderen
team
erstellt
wurden
die
sich
einer
bestimmten
verarbeitung
unterzogen
haben
die
ist
möglich
ohne
die
lastsensitive
infrastruktur
wie
datenbanken
zusätzlich
zu
belasten
da
direkte
schreiben
an
technology_15
beseitigt
auch
die
probleme
de
*
gegendrucks
*
der
gegendruck
tritt
auf
wenn
lastspitzen
einen
datenfluss
mit
einer
geschwindigkeit
verursachen
die
größer
ist
al
die
der
komponenten
die
in
echtzeit
verarbeitet
werden
können
be
zu
verarbeitungsstillständen
und
potenziellem
datenverlust
führt
technology_15
ist
darauf
ausgelegt
daten
für
sehr
lange
zeiträume
zu
speichern
die
bedeutet
da
komponenten
nach
belieben
verarbeitet
und
ohne
konsequenzen
neu
gestartet
werden
können
samza
kann
den
status
mithilfe
eines
fehlertoleranten
prüfpunktsystems
speichern
da
al
lokaler
schlüsselwertspeicher
implementiert
ist
auf
diese
weise
kann
samza
eine
mindestens
einmalige
zustellgarantie
anbieten
die
jedoch
keine
genaue
wiederherstellung
de
aggregierten
zustands
z
b
anzahl
im
falle
eines
ausfalls
ermöglicht
da
daten
möglicherweise
mehrmals
zugestellt
werden
samza
bietet
abstraktionen
auf
hoher
ebene
mit
denen
in
vielerlei
hinsicht
einfacher
gearbeitet
werden
kann
al
mit
den
von
systemen
wie
technology_13
bereitgestellten
grundelementen
samza
unterstützt
derzeit
nur
technology_16
sprachen
be
bedeutet
da
e
nicht
die
gleiche
sprachflexibilität
wie
technology_13
hat
zusammenfassung
technology_6
samza
ist
eine
gute
wahl
für
connector_2
workload
bei
denen
technology_1
und
technology_15
entweder
bereits
verfügbar
sind
oder
sinnvoll
implementiert
werden
können
samza
selbst
eignet
sich
gut
für
organisationen
mit
mehreren
team
die
datenströme
in
verschiedenen
phasen
der
verarbeitung
verwenden
aber
nicht
unbedingt
eng
koordinieren
samza
vereinfacht
viele
teile
der
connector_2
verarbeitung
erheblich
und
bietet
eine
geringe
latenzzeit
die
ist
möglicherweise
keine
gute
lösung
wenn
die
bereitstellungsanforderungen
nicht
mit
ihrem
aktuellen
component_2
kompatibel
sind
wenn
sie
eine
verarbeitung
mit
extrem
geringer
latenz
benötigen
oder
wenn
sie
ein
starkes
bedürfnis
nach
genau
einmaliger
semantik
haben
hybride
verarbeitungssysteme
pattern_1
und
connector_2
prozessoren
einige
verarbeitungsframeworks
können
sowohl
pattern_1
al
auch
connector_2
workload
verarbeiten
diese
technology_3
vereinfachen
die
verschiedenen
verarbeitungsanforderungen
indem
für
beide
datentypen
dieselben
oder
verwandte
komponenten
und
component_9
verwendet
werden
können
wie
sie
sehen
werden
variiert
die
art
und
weise
wie
die
erreicht
wird
erheblich
zwischen
technology_2
und
flink
den
beiden
technology_3
die
wir
diskutieren
werden
die
hängt
im
wesentlichen
davon
ab
wie
die
beiden
verarbeitungsparadigmen
zusammengeführt
werden
und
welche
annahmen
über
die
beziehung
zwischen
festen
und
nicht
festgelegten
datensätzen
getroffen
werden
während
projekte
die
sich
auf
einen
verarbeitungstyp
konzentrieren
für
bestimmte
anwendungsfälle
gut
geeignet
sind
versuchen
die
hybrid
technology_3
eine
allgemeine
lösung
für
die
datenverarbeitung
anzubieten
sie
stellen
nicht
nur
methoden
zur
datenverarbeitung
bereit
sondern
verfügen
auch
über
eigene
integrationen
bibliotheken
und
technology_14
mit
denen
sie
beispielsweise
diagrammanalysen
maschinelles
lernen
und
interaktive
abfragen
durchführen
können
technology_6
technology_2
technology_6
technology_2
ist
ein
stapelverarbeitungsframework
der
nächsten
generation
mit
connector_2
verarbeitungsfunktionen
technology_2
basiert
auf
vielen
der
gleichen
prinzipien
der
mapreduce
component_5
von
technology_1
und
konzentriert
sich
hauptsächlich
auf
die
beschleunigung
der
stapelverarbeitungs
workload
indem
e
vollständige
in
memory
berechnung
und
prozessoptimierung
bietet
technology_2
kann
al
eigenständiger
cluster
bereitgestellt
werden
wenn
eine
verbindung
mit
einer
leistungsfähigen
speicherebene
besteht
oder
al
alternative
zur
mapreduce
component_5
in
technology_1
eingebunden
werden
stapelverarbeitungsmodell
im
gegensatz
zu
mapreduce
verarbeitet
technology_2
alle
daten
im
speicher
und
interagiert
nur
mit
der
speicherebene
um
die
daten
zunächst
in
den
speicher
zu
lade
und
be
ende
die
endgültigen
ergebnisse
beizubehalten
alle
zwischenergebnisse
werden
im
speicher
verwaltet
während
die
in
memory
verarbeitung
wesentlich
zur
geschwindigkeit
beiträgt
ist
technology_2
auch
bei
festplattenbezogenen
aufgaben
schneller
da
eine
ganzheitliche
optimierung
erzielt
werden
kann
indem
der
gesamte
aufgabensatz
vorab
analysiert
wird
die
wird
durch
die
erstellung
von
gerichteten
azyklischen
diagrammen
direct
acyclic
graph
dag
erreicht
die
alle
auszuführenden
vorgänge
die
zu
bearbeitenden
daten
sowie
die
beziehungen
zwischen
ihnen
darstellen
auf
diese
weise
kann
der
prozessor
die
arbeit
intelligent
koordinieren
zur
implementierung
der
in
memory
pattern_1
berechnung
verwendet
technology_2
ein
modell
mit
dem
namen
resilient
quality_attribute_1
datasets
*
rdds
*
um
mit
daten
zu
arbeiten
hierbei
handelt
e
sich
um
unveränderliche
strukturen
im
speicher
die
datensammlungen
darstellen
operationen
an
rdds
erzeugen
neue
rdds
jedes
technology_17
kann
seine
herkunft
über
seine
übergeordneten
rdds
und
letztendlich
pattern_4
zu
den
daten
auf
der
festplatte
zurückverfolgen
grundsätzlich
bieten
rdds
eine
möglichkeit
für
technology_2
die
fehlertoleranz
aufrechtzuerhalten
ohne
nach
jedem
vorgang
auf
die
festplatte
zurückschreiben
zu
müssen
connector_2
verarbeitungsmodell
connector_2
verarbeitungsfunktionen
werden
von
technology_2
connector_4
bereitgestellt
technology_2
selbst
wurde
für
chargenorientierte
workload
entwickelt
um
die
diskrepanz
zwischen
dem
motorkonzept
und
den
merkmalen
von
connector_2
workload
zu
beseitigen
implementiert
technology_2
ein
konzept
mit
dem
namen
micro
pattern_1
*
diese
strategie
dient
dazu
datenströme
al
eine
reihe
sehr
kleiner
stapel
zu
behandeln
die
unter
verwendung
der
nativen
semantik
der
pattern_1
component_5
verarbeitet
werden
können
technology_2
connector_4
puffert
den
connector_2
in
schritten
von
weniger
al
einer
sekunde
diese
werden
al
kleine
feste
datensätze
für
die
stapelverarbeitung
gesendet
in
der
praxis
funktioniert
die
recht
gut
aber
e
führt
zu
einem
anderen
leistungsprofil
al
bei
echten
connector_2
component_3
technology_3
vorteile
und
einschränkungen
der
offensichtliche
grund
für
die
verwendung
von
technology_2
über
technology_1
mapreduce
ist
die
geschwindigkeit
technology_2
kann
dieselben
datasets
aufgrund
seiner
speicherinternen
berechnungsstrategie
und
seiner
fortschrittlichen
dag
planung
erheblich
schneller
verarbeiten
ein
weiterer
großer
vorteil
von
technology_2
ist
seine
vielseitigkeit
e
kann
al
eigenständiger
cluster
bereitgestellt
oder
in
einen
vorhandenen
technology_1
cluster
integriert
werden
e
kann
sowohl
pattern_1
al
auch
connector_2
verarbeitung
ausführen
soda
sie
einen
einzelnen
cluster
betreiben
können
um
mehrere
verarbeitungsstile
zu
verarbeiten
abgesehen
von
den
funktionen
der
component_5
selbst
verfügt
technology_2
auch
über
ein
bibliothekssystem
da
für
maschinelles
lernen
interaktive
abfragen
usw
verwendet
werden
kann
e
wird
allgemein
anerkannt
da
technology_2
aufgaben
einfacher
zu
schreiben
sind
al
mapreduce
be
erhebliche
auswirkungen
auf
die
produktivität
haben
kann
da
anpassen
der
pattern_1
methode
für
die
connector_2
verarbeitung
umfasst
da
puffern
der
daten
beim
eintritt
in
da
component_2
mit
dem
puffer
kann
ein
hohes
datenaufkommen
verarbeitet
werden
wodurch
der
gesamtdurchsatz
erhöht
wird
da
warten
auf
da
leeren
de
puffer
führt
jedoch
auch
zu
einer
deutlichen
erhöhung
der
latenz
die
bedeutet
da
technology_2
connector_4
möglicherweise
nicht
für
die
verarbeitung
geeignet
ist
bei
der
eine
geringe
latenz
erforderlich
ist
da
ram
im
allgemeinen
teurer
ist
al
festplattenspeicher
kann
der
betrieb
von
technology_2
mehr
kosten
al
bei
festplattenbasierten
systemen
die
höhere
verarbeitungsgeschwindigkeit
bedeutet
jedoch
da
aufgaben
viel
schneller
erledigt
werden
können
be
die
kosten
vollständig
ausgleichen
kann
wenn
sie
in
einer
umgebung
arbeiten
in
der
sie
stündlich
für
ressourcen
zahlen
eine
weitere
konsequenz
de
in
memory
design
von
technology_2
ist
da
die
ressourcenknappheit
bei
der
bereitstellung
in
gemeinsam
genutzten
clustern
ein
problem
darstellen
kann
im
vergleich
zu
mapreduce
von
technology_1
verbraucht
technology_2
deutlich
mehr
ressourcen
wodurch
andere
aufgaben
beeinträchtigt
werden
können
die
möglicherweise
versuchen
den
cluster
zu
diesem
zeitpunkt
zu
verwenden
im
wesentlichen
ist
technology_2
möglicherweise
ein
weniger
rücksichtsvoller
nachbar
al
andere
komponenten
die
auf
dem
technology_1
stapel
ausgeführt
werden
können
zusammenfassung
technology_2
ist
eine
großartige
option
für
benutzer
mit
unterschiedlichen
verarbeitungsaufgaben
die
technology_2
pattern_1
verarbeitung
bietet
unglaubliche
geschwindigkeitsvorteile
und
sorgt
für
eine
hohe
speichernutzung
technology_2
connector_4
ist
eine
gute
connector_2
verarbeitungslösung
für
workload
bei
denen
durchsatz
und
latenz
gleichermaßen
wichtig
sind
technology_6
flink
technology_6
flink
ist
ein
connector_2
component_3
technology_3
da
auch
pattern_1
connector_data_3
verarbeiten
kann
pattern_1
werden
einfach
al
datenströme
mit
endlichen
grenzen
betrachtet
und
die
pattern_1
verarbeitung
wird
daher
al
teilmenge
der
connector_2
verarbeitung
behandelt
dieser
connector_2
first
ansatz
für
die
gesamte
verarbeitung
hat
eine
reihe
interessanter
nebenwirkungen
dieser
connector_2
first
ansatz
wird
al
*
kappa
architektur
*
bezeichnet
im
gegensatz
zur
bekannteren
lambda
architektur
bei
der
die
stapelverarbeitung
al
primäre
verarbeitungsmethode
mit
connector_3
verwendet
wird
um
frühe
aber
nicht
verfeinerte
ergebnisse
zu
ergänzen
und
bereitzustellen
die
kappa
architektur
in
der
connector_3
für
alles
verwendet
werden
vereinfacht
da
modell
und
ist
erst
seit
kurzem
möglich
da
die
connector_2
component_3
component_5
immer
ausgefeilter
werden
connector_2
verarbeitungsmodell
da
connector_2
verarbeitungsmodell
von
flink
behandelt
eingehende
daten
element
für
element
al
echten
connector_2
flink
stellt
seine
datastream
technology_18
zur
verfügung
um
mit
unbegrenzten
datenströmen
zu
arbeiten
die
grundlegenden
komponenten
mit
denen
flink
arbeitet
sind
*
connector_3
*
sind
unveränderliche
unbegrenzte
datensätze
die
durch
da
component_2
fließen
*
operatoren
*
sind
funktionen
die
datenströme
verarbeiten
um
andere
datenströme
zu
erzeugen
*
quellen
*
sind
der
einstiegspunkt
für
connector_2
die
in
da
component_2
gelangen
*
senken
*
sind
der
ort
an
dem
connector_3
au
dem
flink
component_2
fließen
sie
können
eine
datenbank
oder
einen
connector
für
ein
anderes
component_2
darstellen
connector_2
verarbeitungs
connector_data_3
erstellen
während
der
berechnung
momentaufnahmen
zu
festgelegten
zeitpunkten
die
bei
problemen
zur
wiederherstellung
verwendet
werden
können
zum
speichern
de
status
kann
flink
mit
einer
reihe
von
status
back
end
arbeiten
die
sich
durch
unterschiedliche
komplexität
und
persistenz
auszeichnen
darüber
hinaus
kann
die
connector_2
verarbeitung
von
flink
da
konzept
der
„ereigniszeit“
verstehen
dh
die
zeit
zu
der
da
ereignis
tatsächlich
eingetreten
ist
und
auch
sitzungen
verarbeiten
die
bedeutet
da
die
bestellung
und
gruppierung
auf
interessante
weise
garantiert
werden
kann
stapelverarbeitungsmodell
da
stapelverarbeitungsmodell
von
flink
ist
in
vielerlei
hinsicht
nur
eine
erweiterung
de
connector_2
verarbeitungsmodells
anstatt
au
einem
kontinuierlichen
connector_2
zu
lesen
wird
ein
begrenzter
datensatz
au
dem
persistenten
speicher
al
connector_2
gelesen
flink
verwendet
für
beide
verarbeitungsmodelle
genau
dieselbe
laufzeit
flink
bietet
einige
optimierungen
für
pattern_1
workload
da
pattern_1
vorgänge
beispielsweise
durch
dauerhaften
speicher
gesichert
sind
entfernt
flink
snapshot
au
pattern_1
ladevorgängen
die
daten
können
weiterhin
wiederhergestellt
werden
die
normale
verarbeitung
wird
jedoch
schneller
abgeschlossen
eine
weitere
optimierung
besteht
darin
pattern_1
aufgaben
aufzulösen
soda
phasen
und
komponenten
nur
bei
bedarf
beteiligt
sind
die
hilft
flink
gut
mit
anderen
benutzern
de
cluster
zu
spielen
durch
die
vorbeugende
analyse
der
aufgaben
kann
flink
auch
optimieren
indem
der
gesamte
vorgangssatz
die
größe
de
datensatzes
und
die
anforderungen
der
nachfolgenden
schritte
angezeigt
werden
vorteile
und
einschränkungen
flink
ist
derzeit
eine
einzigartige
option
in
der
welt
der
verarbeitungs
technology_3
während
technology_2
die
stapel
und
connector_2
verarbeitung
durchführt
ist
da
connector_4
aufgrund
seiner
mikro
pattern_1
architektur
für
viele
anwendungsfälle
nicht
geeignet
der
connector_2
first
ansatz
von
flink
bietet
niedrige
latenzzeiten
hohen
durchsatz
und
echte
verarbeitung
von
einträgen
zu
einträgen
flink
erledigt
viele
dinge
für
sich
etwas
unkonventionell
verwaltet
e
seinen
eigenen
speicher
anstatt
sich
au
leistungsgründen
auf
die
systemeigenen
garbage
collection
mechanismen
von
technology_19
zu
verlassen
im
gegensatz
zu
technology_2
mu
flink
nicht
manuell
optimiert
und
angepasst
werden
wenn
sich
die
eigenschaften
der
verarbeiteten
daten
ändern
e
übernimmt
auch
die
automatische
partitionierung
und
zwischenspeicherung
von
daten
flink
analysiert
seine
arbeit
und
optimiert
aufgaben
auf
verschiedene
weise
ein
teil
dieser
analyse
ähnelt
dem
be
technology_20
abfrageplaner
in
beziehungsdatenbanken
tun
um
die
effektivste
methode
zum
implementieren
einer
bestimmten
aufgabe
zu
ermitteln
e
ist
in
der
lage
phasen
die
parallel
abgeschlossen
werden
können
zu
parallelisieren
und
gleichzeitig
daten
für
blockierende
aufgaben
zusammenzuführen
bei
iterativen
aufgaben
versucht
flink
au
performancegründen
berechnungen
auf
den
knoten
durchzuführen
auf
denen
die
daten
gespeichert
sind
e
kann
auch
eine
delta
iteration
oder
eine
iteration
nur
für
die
teile
von
daten
durchgeführt
werden
die
änderungen
aufweisen
in
bezug
auf
die
benutzertools
bietet
flink
eine
webbasierte
planungsansicht
mit
der
aufgaben
einfach
verwaltet
und
da
component_2
angezeigt
werden
können
benutzer
können
auch
den
optimierungsplan
für
übermittelte
aufgaben
anzeigen
um
zu
sehen
wie
er
tatsächlich
im
cluster
implementiert
wird
für
analyseaufgaben
bietet
flink
technology_20
ähnliche
abfrage
grafikverarbeitungs
und
maschinenlernbibliotheken
sowie
in
memory
berechnungen
flink
funktioniert
gut
mit
anderen
komponenten
e
wird
geschrieben
um
ein
guter
nachbar
zu
sein
wenn
e
innerhalb
eines
technology_1
technology_12
verwendet
wird
und
nur
die
erforderlichen
ressourcen
zu
einem
bestimmten
zeitpunkt
beansprucht
e
lässt
sich
problemlos
in
technology_11
technology_10
und
technology_15
integrieren
flink
kann
aufgaben
ausführen
die
für
andere
verarbeitungsframeworks
wie
technology_1
und
technology_13
mit
kompatibilitätspaketen
geschrieben
wurden
einer
der
größten
nachteile
von
flink
ist
derzeit
da
e
sich
um
ein
noch
sehr
junges
projekt
handelt
großeinsatz
in
freier
wildbahn
ist
immer
noch
nicht
so
verbreitet
wie
bei
anderen
verarbeitungs
technology_3
und
die
skalierungsbeschränkungen
von
flink
wurden
nicht
eingehend
untersucht
mit
dem
schnellen
entwicklungszyklus
und
funktionen
wie
den
kompatibilitätspaketen
gibt
e
möglicherweise
mehr
flink
bereitstellungen
da
unternehmen
die
möglichkeit
haben
damit
zu
experimentieren
zusammenfassung
flink
bietet
sowohl
connector_2
verarbeitung
mit
geringer
latenz
al
auch
unterstützung
für
herkömmliche
pattern_1
aufgaben
flink
ist
wahrscheinlich
be
besten
für
unternehmen
geeignet
die
hohe
anforderungen
an
die
connector_2
verarbeitung
und
einige
stapelorientierte
aufgaben
haben
die
kompatibilität
mit
nativen
storm
und
technology_1
programmen
und
die
fähigkeit
auf
einem
technology_11
verwalteten
cluster
ausgeführt
zu
werden
können
die
evaluierung
vereinfachen
aufgrund
seiner
rasanten
entwicklung
lohnt
e
sich
ein
auge
darauf
zu
werfen
fazit
innerhalb
eines
big
connector_data_1
component_2
gibt
e
zahlreiche
verarbeitungsmöglichkeiten
für
reine
pattern_1
workload
die
nicht
zeitkritisch
sind
ist
technology_1
eine
gute
wahl
deren
implementierung
wahrscheinlich
kostengünstiger
ist
al
bei
einigen
anderen
lösungen
für
reine
connector_2
workload
bietet
technology_13
eine
breite
sprachunterstützung
und
kann
eine
sehr
geringe
latenzzeit
für
die
verarbeitung
bereitstellen
kann
jedoch
duplikate
bereitstellen
und
die
bestellung
in
der
standardkonfiguration
nicht
garantieren
samza
arbeitet
eng
mit
technology_11
und
technology_15
zusammen
um
flexibilität
einfache
verwendung
in
mehreren
team
sowie
eine
unkomplizierte
replikation
und
statusverwaltung
zu
gewährleisten
für
gemischte
workload
bietet
technology_2
hochgeschwindigkeits
stapelverarbeitung
und
mikro
stapelverarbeitung
für
da
connector_2
e
bietet
umfassende
unterstützung
integrierte
bibliotheken
und
technology_14
sowie
quality_attribute_2
integrationen
flink
bietet
eine
echte
connector_2
verarbeitung
mit
unterstützung
für
die
stapelverarbeitung
e
ist
stark
optimiert
kann
aufgaben
ausführen
die
für
andere
plattformen
geschrieben
wurden
und
bietet
eine
verarbeitung
mit
geringer
latenz
steckt
jedoch
noch
in
den
anfängen
der
einführung
die
optimale
anpassung
an
ihre
situation
hängt
in
hohem
maße
vom
zu
verarbeitenden
datenstatus
der
zeitlichen
beschränkung
ihrer
anforderungen
und
den
gewünschten
ergebnissen
ab
e
gibt
kompromisse
zwischen
der
implementierung
einer
all
in
one
lösung
und
der
arbeit
mit
eng
fokussierten
projekten
und
e
gibt
ähnliche
überlegungen
wenn
neue
und
innovative
lösungen
gegenüber
ihren
ausgereiften
und
erprobten
kollegen
bewertet
werden
relate
so
richten
sie
die
titan
graph
datenbank
mit
technology_21
und
elasticsearch
unter
ubuntu
ein
so
drehen
sie
einen
technology_1
cluster
mit
digitalocean
tröpfchen
auf
eine
einführung
in
technology_1
so
installieren
sie
technology_1
im
standalone
modus
unter
debian
eine
einführung
in
requirement_1
konzepte
und
terminologie
so
installieren
und
verwenden
sie
clickhouse
unter
debian
so
installieren
sie
technology_1
im
standalone
modus
unter
ubuntu
benutzerdatenerfassung
abwägen
von
geschäftsanforderungen
und
datenschutz
so
installieren
sie
technology_1
im
standalone
modus
unter
ubuntu
eine
einführung
in
den
technology_22
dns
component_10
grundlegendes
zu
technology_23
component_7
und
standortblockauswahlalgorithmen
eine
einführung
in
component_10
mesh
be
ist
eine
unveränderliche
infrastruktur
warum
möchten
sie
möglicherweise
keinen
eigenen
mail
component_7
betreiben
eine
einführung
in
technology_24
ein
vergleich
von
let’s
pattern_5
kommerziellen
und
privaten
zertifizierungsstellen
und
selbstsignierten
technology_25
zertifikaten
eine
einführung
in
die
kontinuierliche
requirement_3
bereitstellung
und
bereitstellung
eine
einführung
in
let’s
pattern_5
eine
einführung
in
technology_1
dmca
dmca#codeflow
stie
copyright
©
