technology_1
vs
technology_2
comparison
and
myth
explore
kai
waehner
home
highlight
activity
talk
at
international
conference
video
component_1
publication
requirement_1
requirement_1
technology_3
technology_4
requirement_2
requirement_3
intelligence
deep

technology_5
in
memory
jupyter
requirement_4
technology_6
open_source
technology_2
connector_1
technology_7
social
requirement_5
technology_8
requirement_6
requirement_6
technology_3
mesos
requirement_6
requirement_7
technology_9
technology_10
open_source
persistence
component_2
mesh
internet
of
thing
internet
of
thing
requirement_2
iiot
technology_11
open_source
plc4x
requirement_8
requirement_8
component_3
requirement_9
component_4
component_5
blockchain
bpm
eai
esb
it
certification
it
conference
technology_12
jee
pattern_1
pattern_2
technology_13
open_source
technology_3
technology_2
technology_2
connector_2
persistence
component_2
mesh
pattern_3
social
requirement_5
web
technology_14
connector_3
component_6
connector_3
component_6
technology_3
technology_2
requirement_2
confluent
technology_2
connector_2
technology_2
connector_1
ksql
persistence
about
me
stay
in
technology_15
evangelist
–
requirement_2
requirement_1
–
technology_13
–
technology_3
technology_2
technology_15
evangelist
–
requirement_2
requirement_1
–
technology_13
–
technology_3
technology_2
home
highlight
activity
talk
at
international
conference
video
component_1
publication
requirement_1
requirement_6
internet
of
thing
requirement_8
connector_3
component_6
technology_3
sparkbig
databusiness
intelligencedeep
learninghadoopin
memoryjupyterkafka
streamsmachine
learningnosqlopen
sourcepythonsocial
networktensorflow
technology_3
mesoscloud
nativedockerkubernetesopen
sourcepersistenceservice
mesh
big
dataiiotmqttopen
sourceplc4x
technology_3
kafkaapi
managementapplication
serverblockchainbpmeaiesbit
certificationsit
conferencesjava
jeekafka
connectmessagingmicroservicesmiddlewareopen
sourcepersistenceservice
meshsoasocial
networkweb
technology_14
technology_3
kafkabig
dataconfluentkafka
connectkafka
streamsksqlpersistence
about
me
stay
in
search
for
search
technology_3
technology_2
technology_3
technology_1
comparison
connector_4
connector_data_1
component_7
connector_3
component_6
technology_1
vs
technology_2
–
comparison
and
myth
explore

minute
connector_5
bykai
waehner9

total

connector_6



connector_7

people
connector_8
the
story




technology_1
vs
technology_2
–
which
one
be
quality_attribute_1
this
explore
pro
and
con
popular
myth
and
non
technical
criterion
to
find
the
best
technology_16
for
your
requirement_3
problem
my
discussion
be
usually
around
technology_3
technology_2
and
it
ecosystem
a
i
work
for
confluent
the
only
question
i
connector_9
about
technology_1
in
the
last
year
come
from
technology_1
committers
and
contributor
they
ask
me
deep
technical
question
so
a
to
be
able
to
explain
where
technology_2
suck
and
why
technology_1
be
the
much
quality_attribute_1
option
discussion
about
this
topic
on
component_8
reddit
be
typically
very
opinionated
often
inaccurate
and
brutal
the
follow
be
my
point
of
pattern_4
base
on
year
of
experience
with
open_source
connector_4
component_9
tech
comparison
be
the
black
technology_2
vs
technology_13
connector_4
and
component_3
component_8
tech
comparison
be
mean
to
guide
people
to
choose
the
right
solution
and
architecture
for
their
requirement_3
problem
there
be
no
all
rounder
and
there
should
be
no
bias
choose
the
right
technology_16
for
the
problem
however
technical
comparison
be
almost
always
bias
even
if
the
author
do
not
work
for
a
vendor
and
be
an
“independent”
consultant
he
or
she
be
still
likely
to
have
a
bias
opinion
from
past
experience
and
knowledge
whether
purposely
or
unknowingly
still
comparison
from
different
perspective
be
useful
and
we’ve
see
technology_3
technology_1
discuss
in
a
few
place
on
the
internet
so
i
want
to
connector_7
my
personal
pattern_4
of
how
technology_2
and
technology_1
compare
i
work
for
confluent
the
lead
expert
behind
technology_3
technology_2
and
it
ecosystem
so
keep
that
in
mind
but
the
aim
of
this
be
not
to
provide
opinion
it’s
to
weigh
up
fact
rather
than
myth
technical
comparison
of
open_source
technology_14
and
commercial
technology_17
happen
all
the
time
i
do
several
comparison
in
the
past
on
my
or
other
component_8
infoq
include
a
comparison
of
requirement_8
technology_14
choose
the
right
esb
for
your
requirement_8
need
technology_2
vs
technology_18
esb
mq
technology_2
vs
component_10
and
technology_3
technology_2
and
component_3
requirement_9
component_3
gateway
all
these
comparison
be
do
because
requirement_10
want
to
understand
when
to
use
which
technology_16
for
technology_1
vs
technology_2
the
situation
be
a
little
bit
different
why
compare
technology_1
and
technology_2
talk
to
prospect
or
requirement_10
i
rarely
connector_9
ask
about
technology_1
to
be
fair
this
increase
slightly
in
the
last
month
i
guess
the
question
come
up
in
every
~15th
or
~20th
meet
due
to
the
overlap
feature
set
and
use
requirement_11
however
this
seem
to
be
mostly
due
to
a
few

on
the
internet
that
claim
technology_1
be
in
some
way
quality_attribute_1
than
technology_2
there
be
no
fact
connector_10
and
very
little
material
if
any
for
the
oppose
pattern_4
i
have
not
talk
to
a
single
organization
that
seriously
consider
quality_attribute_2
technology_1
in
production
although
i
there
be
a
large
number
of
component_11
out
there
in
the
world
who
need
a
quality_attribute_3
pattern_1
technology_15
technology_2
or
technology_1
but
i
also
think
that
pulsar’s
allege
reference
component_11
be
not
particularly
quality_attribute_4
for
example
their
flagship
component_12
be
tencent
a
large
chinese
tech
requirement_12
but
tencent
be
a
huge
technology_2
component_12
whereas
pulsar’s
use
be
limit
to
one
project
tencent
component_13
trillion
connector_data_2
per
day
in
digit





with
technology_2
a
it
turn
out
tencent
us
technology_2
1000x
more
than
technology_1
ten
trillion
msg
day
vs
ten
of
billion
msg
day
the
tencent
team
discuss
their
technology_2
deployment
in
more
detail
how
tencent
pcg
us
technology_3
technology_2
to
handle

trillion+
connector_data_2
per
day
comparison
of
two
competitive
open_source
technology_14
technology_3
technology_2
and
technology_3
technology_1
be
two
excite
and
compete
technology_15
therefore
it
make
a
lot
of
sense
to
compare
them
period
both
technology_3
technology_2
and
technology_3
technology_1
have
very
similar
feature
set
i
recommend
that
you
evaluate
both
technology_14
for
quality_attribute_5
feature
maturity
requirement_13
adoption
open_source
technology_16
and
project
train
material
quality_attribute_6
of
local
meetups
video

etc
reference
use
requirement_11
from
your
requirement_14
or
requirement_3
problem
help
make
the
right
decision
confluent
publish
such
a
comparison
of
“kafka
vs
technology_1
vs
technology_19
requirement_15
architecture
and
feature
compared“
i
be
involve
in
create
this
comparison
so
we
have
that
comparison
already…
what
be
this
here
about
then
i
want
to
explore
the
myth
from
some
‘kafka
vs
pulsar’
argument
which
i
see
regularly
in

and
forum
discussion
afterwards
i
will
give
a
more
comprehensive
comparison
beyond
technical
aspect
because
most
technology_1
discussion
focus
purely
on
tech
feature
technology_2
vs
technology_1
–
technology_15
myth
explore
the
follow
discus
some
myth
i
have
come
across
i
agree
with
some
of
them
but
also
counter
some
others
with
hard
fact
of

different
opinion
can
exist
for
some
of
these
statement
again
this
be
totally
fine
the
follow
be
my
point
of
pattern_4
myth

“pulsar
have
differentiate
build
in
feature
compare
to
kafka”
true
if
you
compare
technology_3
technology_2
to
technology_3
technology_1
feature
it
tiered
architecture
component_7
and
multi
tenancy
be
mention
a
differentiator
but
technology_2
have
many
differentiate
feature
too
half
a
many
component_14
to
run
connector_data_3
connector_11
to
disk
only
once
connector_data_3
pattern_5
in
memory
only
once
battle
test
pattern_6
technology_20
zero
copy
requirement_15
transaction
build
in
connector_3
component_6
long
term
storage
in
the
work
technology_21
removal
kip

which
make
technology_2
even
more
quality_attribute_7
to
operate
and
quality_attribute_2
than
technology_1
which
have
a
four
component_15
architecture
of
technology_1
technology_21
bookkeeper
and
rocksdb
apart
from
make
technology_2
more
quality_attribute_8
more
resilient
etc
etc
in
the
work
tiered
storage
kip

which
make
technology_2
more
elastic
and
cost
quality_attribute_9
also
ask
yourself
should
you
really
compare
the
open_source
technology_14
or
technology_17
and
vendor
with
their
complete
offer
it
be
easy
to
feature
if
you
don’t
have
to
provide
mission
critical
support
for
it
don’t
evaluate
feature
in
a
checklist
but
also
evaluate
how
they
be
battle
test
in
production
scenario
how
many
“differentiating
features”
be
low
quality
and
connector_12
quickly
vs
high
quality
implementation
for
instance
it
take
a
few
year
to
connector_12
and
battle
test
technology_2
connector_1
a
technology_2
requirement_7
connector_3
component_6
component_16
do
you
really
want
to
compare
this
to
technology_1

the
latter
be
a
feature
to
component_12
define
udf
without
any
relation
to
“real
connector_3
processing”
or
be
this
more
single
connector_data_1
transformation
smt
a
core
feature
of
technology_2
connector_2
be
sure
to
a
compare
apple
to
apple
instead
of
apple
to
orange
and
b
don’t
forget
to
think
about
the
maturity
of
a
feature
the
more
powerful
and
critical
the
more
mature
it
should
be…
the
technology_2
spend
a
large
amount
of
effort
to
improve
the
core
project
and
it
ecosystem
confluent
alone
have
over

full
time
engineer
work
on
the
technology_2
project
additional
component_15
commercial
technology_17
and
the
pattern_7
offer
on
major
requirement_6
technology_22
myth

“pulsar
have
a
few
very
big
component_11
tencent
in
china”
true
but
tencent
actually
us
technology_2
more
than
technology_1
the
bill
department
which
us
technology_1
be
only
a
small
fraction
at
tencent
whereas
a
large
portion
of
the
core
requirement_3
be
use
technology_2
and
they
have
a
global
technology_2
architecture
that
combine
1000+
pattern_8
into
a
single
logical
cluster
always
be
cautious
with
open_source
project
connector_10
out
the
success
at
“normal
companies”
because
a
tech
giant
us
it
do
not
mean
it
will
work
for
your
requirement_12
well
how
many
fortune

requirement_12
connector_8
their
success
story
around
technology_1
in
the
past
look
for
proof
point
beyond
tech
giant
proof
point
beyond
the
tech
giant
be
helpful
to
connector_9
insight
and
lesson

from
other
people
not
from
the
vendor
the
technology_2
give
many
example
about
mission
critical
deployment
even
more
impressive
at
the
past
technology_2
summit
conference
in
san
francisco
york
and
london
every
year
various
requirement_16
from
different
requirement_14
present
their
use
requirement_11
and
success
story
include
fortune

requirement_12
mid
size
requirement_16
and
startup
to
give
you
one
specific
example
in
the
technology_2
world
various
different
implementation
exist
for
pattern_6
of
connector_data_3
in
real
time
between
separate
technology_2
cluster
include
mirrormaker

part
of
the
technology_3
technology_2
project
mirrormaker

part
of
the
technology_3
technology_2
project
confluent
replicator
build
by
confluent
and
only
quality_attribute_5
a
part
of
confluent
component_9
or
confluent
requirement_6
ureplicator
open
component_17
by
uber
mirus
open
component_17
by
technology_23
brooklin
open
component_17
by
linkedin
in
practice
only
two
option
be
reasonable
if
you
don’t
want
to
maintain
and
improve
the
by
yourself
mirrormaker

very

not
mature
yet
but
a
great
option
mid
and
long
term
and
confluent
replicator
battle
test
in
many
mission
critical
deployment
but
not
open_source
all
the
other
option
work
too
but
who
maintain
the
project
who
solve
bug
and
quality_attribute_10
issue
who
do
you
connector_data_4
when
you
have
a
problem
in
production
deployment
in
production
for
mission
critical
deployment
be
different
from
evaluate
and
try
out
an
open_source
project
myth

“pulsar
provide
connector_data_1
pattern_9
and
connector_4
in
a
single
solution”
partly
connector_data_1
component_18
be
use
for
point
to
point
connector_13
they
provide
an
pattern_10
connector_14
technology_20
mean
that
the
sender
and
receiver
of
the
connector_data_1
do
not
need
to
connector_15
with
the
connector_data_1
component_7
at
the
same
time
technology_24
technology_1
have
only
limit
support
for
connector_data_1
component_7
and
limit
support
for
connector_3
if
it
want
to
compete
in
either
area
it
still
have
a
long
way
to
go
for
two
reason

technology_1
have
only
limit
support
for
connector_data_1
pattern_9
because
it
miss
popular
pattern_1
feature
connector_data_1
xa
transaction
connector_16
connector_data_1
pattern_11
etc
that
be
commonly
use
with
pattern_1
component_19
mq
technology_19
and
technology_25
pulsar’s
“adapters”
for
pattern_1
component_19
be
similarly
limit
while
they
look
nice
on
paper
they
be
le
useful
in
practice

technology_1
have
only
limit
support
for
connector_3
for
example
it
do
not
support
exactly
once
delivery
and
component_6
semantics
which
disqualify
it
for
most
use
requirement_11
in
practice
–
you
would
never
connector_12
say
a
payment
component_6
component_20
with
technology_1
a
it
cause
duplicate
payment
or
lose
payment
it
also
lack
requirement_17
to
perform
connector_3
component_6
with
feature
join
aggregation
windowing
fault
tolerant
state
requirement_9
and

time
base
component_6
pulsar’s
“topics”
requirement_17
be
also
different
to
kafka’s
and
suffer
from
bookkeeper’s
origin
a
it
be
conceive
and
design
in

a
a
connector_17
ahead
requirement_18
for
hadoop’s
technology_26
namenode
with
only
short
live
connector_data_3
storage
in
mind
side
note
pulsar’s
“kafka
adapter”
it
pattern_1
sibling
be
similarly
limit
while
it
look
nice
on
paper
it
be
le
useful
in
practice
because
it
support
only
a
small
subset
of
technology_2
requirement_17
technology_1
technology_2
have
only
limit
support
for
connector_data_1
component_7
in
technology_2
different
workarounds
can
be
use
to
realize
“real
queuing”
behavior
if
you
want
to
use
separate
connector_data_1
component_18
instead
of
connector_8
technology_2
topic
for
quality_attribute_10
=
use
kafka’s
acls
and
optional
technology_16
confluent’s
role
base
connector_18
control
aka
rbac
semantics
i
e
separate
component_4
=
use
kafka’s
component_21
group
load
balance
=
use
kafka’s
component_22
i
typically
ask
requirement_10
what
exactly
they
want
to
do
with
component_7
often
technology_2
provide
out
of
the
component_23
solution
for
use
requirement_11
which
simply
require
think
of
the
solution
in
term
also
the
number
of
high
quality_attribute_11
use
requirement_11
that
need
pattern_9
be
relatively
small
have
explain
all
these
workarounds
and
limitation
of
technology_1
and
technology_2
for
connector_data_1
let’s
be
clear
neither
technology_2
nor
technology_1
provide
a
“real
pattern_1
solution”
if
you
really
need
a
pattern_1
solution
shouldn’t
you
quality_attribute_1
choose
a
“real
pattern_1
framework”
technology_19
or
nats
for
a
pattern_1
problem
anyway
there
be
no
‘yes
or
no’
answer
to
this
i
see
many
requirement_10
replace
exist
pattern_1
component_19
mq
with
technology_2
for
quality_attribute_12
and
cost
reason
the
option
their
requirement_19
off
and
do
an
evaluation
to
solve
your
problem
the
best
way…
myth

“pulsar
provide
connector_3
processing”
false
or
to
be
fair
it
quality_attribute_13
on
your
definition
of
connector_3
component_6
be
it
only
rudimentary
feature
or
full
fledge
connector_3
component_6
in
one
sentence
i
typically
explain
connector_3
component_6
a
continuous
consumption
component_6
and
aggregation
of
from
different
connector_data_3
component_17
in
real
time
at
quality_attribute_14
and
of

in
a
fault
tolerant
manner
include
and
especially
for
any
stateful
component_6

technology_1
provide
only
rudimentary
requirement_17
for
connector_3
component_6
use
it
technology_1

this
be
suit
for
quality_attribute_7
pattern_12
but
it
isn’t
a
true
connector_3
component_6
offer
you
connector_9
it
with
technology_2
connector_1
or
technology_27
for
build
connector_4
component_24
that
include
stateful
connector_data_5
slide
window
and
other
connector_3
component_6
concept
use
requirement_11
exist
in
every
requirement_14
for
instance
connector_10
out
the
technology_2
connector_1
for
example
from
the
york
time
pinterest
trivago
zalando
and
others
connector_4
requirement_1
example
with
technology_1
typically
use
technology_1
in
conjunction
with
another
“proper”
connector_3
component_6
technology_14
technology_3
technology_4
or
technology_3
flink
which
of
mean
you
now
need
to
operate
even
more
additional
piece
of
quality_attribute_3
infrastructure
and
to
understand
their
complex
connector_19
myth

“pulsar
provide
exactly
once
semantics
kafka”
false
technology_1
provide
a
deduplication
feature
that
ensure
that
a
connector_data_1
will
not
be
component_25
in
the
technology_1
pattern_8
twice
but
nothing
prevent
a
component_21
from
connector_20
this
connector_data_1
multiple
time
this
be
insufficient
for
any
form
of
connector_3
component_6
use
requirement_11
where
both
input
and
output
be
from
technology_1
also
unlike
kafka’s
transaction
feature
it
be
not
possible
to
accurately
tie
connector_data_2
connector_21
to
state
component_1
inside
a
connector_3
processor
exactly
once
semantics
eos
be
quality_attribute_5
since
technology_2


release
three
year
ago
and
use
in
many
production
deployment
kafka’s
eos
support
the
whole
technology_2
ecosystem
include
technology_2
connector_2
technology_2
connector_3
technology_27
and
component_26
technology_12
technology_28
technology_29
go
or
technology_7
technology_2
summit
have
several
talk
about
kafka’s
eos
requirement_17
include
this
great
intro
for
everybody
with
slide
and
video
component_1
myth

“pulsar’s
requirement_15
be
much
quality_attribute_1
than
kafka’s”
false
i
be
not
a
fan
of
most
“benchmarks”
of
requirement_15
and
quality_attribute_11
benchmark
be
almost
always
opinionated
and
configure
for
a
specific
problem
no
matter
if
a
vendor
independent
consultant
or
researcher
conduct
them
for
example
there
be
one
benchmark
publish
by
gigaom
which
compare
the
quality_attribute_15
and
requirement_15
of
technology_2
versus
technology_1
but
this
benchmark
deliberately
slow
technology_2
down
by
force
it
to
synchronize
to
disk
on
every
single
connector_data_1
by
set
the
technology_2
config
‘flush
connector_data_1
=
1’
this
make
every
connector_data_6
cause
an
fsync
the
benchmark
also
force
the
technology_2
component_21
to
acknowledge
synchronously
while
the
technology_1
component_21
acknowledge
asynchronously
unsurprisingly
this
benchmark
setup
make
technology_1
the
seemingly
clear
“winner”
but
this
benchmark
do
not
mention
or
explain
this
significant
configuration
difference
in
the
setup
and
measurement
this
be
what
some
people
connector_data_4
apple
to
orange
comparison
pulsar’s
architecture
actually
require
high
requirement_5
utilization
due
to
the
technology_1
pattern_8
tier
which
act
a
a
pattern_13
in
front
of
bookkeeper
bookie
a
well
a
twice
the
i
o
a
bookkeeper
connector_22
connector_data_3
to
a
connector_17
ahead
requirement_18
a
well
a
to
the
segment
confluent
do
some
benchmark
too
more
an
apple
to
apple
comparison
not
surprisingly
the
connector_data_7
be
different
but
should
you
really
care
about
these
benchmark
fight
from
vendor
think
about
your
requirement_15
requirement
do
a
proof
of
concept
poc
with
technology_2
and
technology_1
if
you
must
i
bet
that
in
99%
of
scenario
both
will
show
acceptable
requirement_15
for
your
use
requirement_11
don’t
trust
opinionated
benchmark
from
others
your
use
requirement_11
will
have
different
requirement
and
characteristic
anyway
and
typically
requirement_15
be
one
of
many
evaluation
dimension
myth

“pulsar
be
easy
to
operate
than
kafka”
false
both
technology_2
and
technology_1
be
hard
to
operate
if
you
don’t
use
additional
technology_16
technology_2
include
two
quality_attribute_3
component_20
technology_2
itself
and
technology_3
technology_21
but
technology_1
include
three
quality_attribute_3
component_19
and
an
additional
storage
technology_15
technology_1
technology_21
and
technology_3
bookkeeper
technology_1
bookkeeper
us
technology_21
too
and
lastly
rocksdb
be
use
for
certain
storage
connector_data_8
this
mean
that
technology_1
have
a
significantly
high
complexity
to
understand
tweak
and
tune
than
technology_2
additionally
technology_1
also
have
more
configuration
parameter
than
technology_2
technology_2
be
firmly
go
into
the
opposite
direction
and
be
remove
technology_21
see
kip

so
that
you
have
one
quality_attribute_3
component_20
to
quality_attribute_2
operate
quality_attribute_14
and
pattern_14
technology_21
be
kafka’s
big
quality_attribute_12
bottleneck
and
come
with
operational
challenge
—
this
be
true
for
technology_2
but
even
more
so
for
technology_1
one
of
the
key
issue
of
my
requirement_10
be
how
to
run
technology_21
in
mission
critical
deployment
at
quality_attribute_14
therefore
i
be
really
look
connector_23
to
kafka’s
simplify
architecture
where
you
will
quality_attribute_2
technology_2
pattern_8
only
this
also
establish
a
unify
quality_attribute_10
component_27
a
zookeeper’s
quality_attribute_10
no
long
need
to
be
separately
configure
this
be
a
huge
benefit
especially
for
large
organization
and
regulate
requirement_14
compliance
and
connector_data_5
quality_attribute_10
department
will
thank
you
for
this
simplify
architecture
be
not
about
architecture
technology_2
be
significantly
quality_attribute_1
document
have
a
tremendously
large
of
expert
and
a
vast
of
support
technology_16
that
make
easy
additionally
there
be
many
option
for
local
and
online
technology_2
train
include
online

book
meetups
and
conference
you
won’t
find
much
for
technology_1
unfortunately
myth

“an
architecture
with
three
tier
be
quality_attribute_1
than
two
tiers”
it
quality_attribute_13
personally
i
be
skeptical
that
pulsar’s
three
tier
architecture
use
technology_1
pattern_8
technology_21
and
bookkeeper
be
an
advantage
for
most
project
it
be
a
requirement_19
off
twitter
describe
their
move
away
from
bookkeeper
+
distributedlog
the
latter
a
component_20
very
similar
to
technology_1
with
comparable
architecture
and
design
over
a
year
ago
cite
the
advantage
of
kafka’s
single
tier
architecture
such
a
cost
quality_attribute_16
and
quality_attribute_1
requirement_15
over
a
two
tier
architecture
that
decouple
storage
and
serve
technology_1
distributedlog
be
build
on
top
of
bookkeeper
and

connector_3

requirement_17
with
an
architecture
and
concept
similar
to
technology_1
e
g
use
decouple
storage
and
serve
tier
distributedlog
be
originally
a
standalone
project
but
eventually
become
a
sub
project
of
bookkeeper
though
nowadays
it
appear
to
be
no
long
actively
develop
only
a
few
connector_24
in
the
past

month
the
reason
twitter
cite
for
switch
to
technology_2
be

significant
cost
connector_11
and
requirement_15
gain
and

kafka’s
huge
and
adoption
for
example
they
conclude
“for
single
component_21
use
requirement_11
we
saw
a
68%
resource
connector_11
and
for
fanout
requirement_11
with
multiple
component_21
we
saw
a
75%
resource
connector_11
”
there
be
benefit
from
a
three
tier
architecture
to
build
a
quality_attribute_8
infrastructure
but
the
extra
pattern_15
also
increase
requirement_5
utilization
by
at
least
33%
and
connector_data_3
hold
in
pulsar’s
pattern_8
must
additionally
be
pattern_5
in
both
pattern_15
for
equivalent
requirement_15
and
also
connector_17
to
disk
twice
because
the
storage
technology_30
of
bookkeeper
be
not
base
on
a
requirement_18
on
the
requirement_6
where
most
technology_2
deployment
be
be
run
the
best
back
storage
tier
be
in
fact
not
a
niche
technology_15
bookkeeper
but
a
widely
use
and
battle
test
connector_data_9
component_25
technology_31
technology_32
or
gcp
gc
tiered
storage
in
confluent
component_9
which
be
back
by
the

of
technology_31
technology_32
and
gcp
gc
provide
the
same
benefit
without
pulsar’s
extra
pattern_15
of
bookkeeper
and
the
connector_data_10
extra
requirement_5
transfer
cost
and
quality_attribute_15
that
this
architecture
incur
it
take
confluent
two
year
to
build
and
make
tiered
storage
for
technology_2
generally
quality_attribute_5
include
global


support
for
your
most
mission
critical
connector_data_3
tiered
storage
be
not
quality_attribute_5
yet
for
open_source
technology_3
technology_2
but
confluent
be
work
with
the
rest
of
the
technology_2
include
some
major
tech
requirement_12
uber
on
kip

to
tiered
storage
to
technology_2
with
different
storage
option
there
be
always
pro
and
con
for
both
architecture
personally
i
think
that
95%
of
project
do
not
need
a
complex
three
tier
architecture
and
where
they
make
sense
it
be
to
the
advantage
of
external
requirement_20
quality_attribute_9
storage
you
should
care
about


component_2
level
agreement
sla
quality_attribute_12
and
throughout
plus
requirement_8
into
your
ecosystem
a
well
a
quality_attribute_10
requirement_9
technology_16
and
support
if
your
requirement
require
a
three
tier
architecture
then
of
give
it
a
go
sub
myth
“pulsar
be
quality_attribute_1
for
lag
component_28
because
of
it
pattern_5
pattern_15
and
storage
layer”
false
the
problem
with
lag
component_28
be
that
they
exhaust
the
component_29
pattern_5
i
e
recent
connector_data_2
be
already
pattern_5
connector_25
from
old
segment
replace
these
reduce
the
requirement_15
of
component_28
connector_20
from
the
head
of
the
requirement_18
pulsar’s
architecture
be
actually
bad
in
this
regard
it
retain
the
same
issue
around
pattern_5
flush
but
now
the
connector_25
must
do
an
extra
requirement_5
hop
+
and
io
rather
than
connector_20
from
the
local

myth

“kafka
do
not
quality_attribute_14
a
well
a
pulsar”
false
this
be
one
of
the
key
argument
by
the
technology_1

a
i
say
before
this
always
quality_attribute_13
on
the
chosen
benchmark
for
example
i
have
see
test
with
equivalent
computing
resource
where
technology_2
do
significantly
quality_attribute_1
at
high
quality_attribute_11
than
technology_1
here
be
a
“pulsar
vs
technology_2
benchmark”
where
technology_2
be
much
fast
than
technology_1
quality_attribute_12
be
not
a
problem
for
most
use
requirement_11
you
can
easily
quality_attribute_14
up
technology_2
to
component_6
several
gigabyte
per
second
a
you
can
see
in
a
demo
to
“scale
technology_3
technology_2
to
10+
gb
per
second
in
confluent
cloud“
honestly
speak
le
than
1%
of
component_11
should
be
worry
about
this
discussion
at
all
if
you
have
requirement
netflix
component_6
petabyte
per
day
or
linkedin
component_6
trillion
of
connector_data_1
let’s
talk
about
and
discus
the
best
architecture
hardware
and
configuration
for
such
a
deployment
for
anybody
else
don’t
be
worry
sub
myth
“kafka’s
current
approach
mean
it
can
only
component_25
~
500k
component_22
per
cluster”
true
technology_2
today
have
not
yet
the
best
architecture
for
large
quality_attribute_14
deployment
with
hundred
of
thousand
of
technology_2
topic
and
component_22
but
technology_1
too
do
not
allow
for
unlimited
quality_attribute_14
it
have
different
limit
kafka’s
component_22
limit
be
impose
by
technology_21
remove
technology_21
from
technology_2
through
the
work
in
kip

remove
this
upper
bind
a
a
side
note
the
right
design
of
your
architecture
be
critical
for
success
most
of
the
requirement_10
i
have
see
in
trouble
with
technology_2
component_22
count
and
quality_attribute_12
be
because
they
design
their
architecture
and
component_24
in
the
wrong
way
they’d
run
into
the
same
issue
if
they
be
use
technology_1
technology_2
be
an
connector_4
component_9
and
not
the
next
mq
if
you
try
to
recreate
your
favorite
mq
solution
and
architecture
with
technology_2
you
will
likely
fail
i
have
see
several
requirement_10
fail
here
and
then
succeed
by
re
architecting
their
setup
with
our
help
chance
be
very
high
that
you
will
not
have
any
issue
with
component_22
number
and
quality_attribute_12
even
today
with
kafka’s
usage
of
technology_21
if
you
design
your
use
requirement_11
right
and
understand
kafka’s
basic
concept
this
experience
of
requirement_10
be
a
common
theme
for
any
technology_15
technology_2
that
introduce
a
technology_15
level
and
paradigm
well
beyond
what
be
do
before
a
prime
example
be
the
adoption
hurdle
face
by
requirement_12
when
they
first
begin
to
move
their
use
requirement_11
to
the
requirement_6
sub
myth
“pulsar
support
a
practically
infinite
number
of
partitions”
false
bookkeeper
have
the
same


per
ledger
limitation
technology_2
have
but
there
be
multiple
ledger
in
one
component_22
pulsar’s
pattern_8
pattern_15
group
component_22
into
bundle
but
it’s
storage
pattern_15
bookkeeper
connector_26
connector_data_3
in
segment
with
many
segment
for
each
component_22
for
technology_2
the
metadata
for
these
segment
be
component_25
in
technology_21
which
impose
a
limit
on
the
total
number
that
can
be
component_25
technology_2
be
remove
this
connector_27
thus
allow
it
to
quality_attribute_14
significantly
further
i
be
really
look
connector_23
to
see
kip

be
connector_12
until
~
the
end
of

“apache
technology_2
need
no
keeper
remove
the
technology_3
technology_21
dependency”
walk
you
through
the
implementation
detail
and
plan
timeline
sub
myth
“kafka
quality_attribute_17
need
to
be
define
when
create
a
technology_2
topic”
partly
true
if
more
quality_attribute_12
be
need
technology_2
topic
can
either
be
over
component_22
i
e
you
configure
a
topic
with
more
component_22
than
you
initially
need
for
a
use
requirement_11
see
connector_1
and
component_30
in
technology_3
technology_2
topic
component_22
and
storage
fundamental
or
they
can
be
re
configure
to
use
more
component_22
if
there
be
requirement
to
quality_attribute_14
in
the
future
this
be
not
perfect
but
a
consequence
of
how
quality_attribute_3
connector_4
work
and
why
it
quality_attribute_14
much
quality_attribute_1
than
traditional
pattern_1
component_19
mq
best
practice
for
create
topic
and
for
connector_28
topic
configuration
during
production
be
quality_attribute_5
so
no
worry
but
technology_1
topic
have
this
restriction
too
connector_17
quality_attribute_11
be
base
on
the
number
of
component_22
allocate
in
a
technology_1
topic
in
the
exact
same
way
it
be
in
a
technology_2
topic
so
technology_1
topic
must
be
over
provision
for
exactly
the
same
reason
that’s
because
for
each
component_22
only
a
single
ledger
of
the
partition’s
potentially
many
ledger
be
writable
at
the
same
time
also
increasing
the
number
of
component_22
dynamically
impact
connector_data_1
order
it
do
in
technology_2
i
e
the
connector_data_1
order
be
lose
both
technology_2
and
technology_1
quality_attribute_14
crazy
this
be
sufficient
for
almost
all
use
requirement_11
if
you
need
even
more
extreme
quality_attribute_14
i
think
a
technology_21
free
implementation
be
the
best
choice
kip

be
thus
the
most
anticipate
technology_2
connector_28
i
see
in
the
and
in
confluent’s
requirement_10
base
myth

“pulsar
recover
from
component_31
failure
instantly
but
technology_2
have
to
reload
data”
true
and
false
kill
a
technology_1
pattern_8
be
indeed
seamless
but
in
contrast
to
a
technology_2
pattern_8
the
technology_1
pattern_8
doesn’t
component_25
any
connector_data_3
but
be
only
a
pattern_13
front
the
actual
storage
pattern_15
which
be
bookkeeper
so
highlight
that
a
technology_1
pattern_8
failure
can
easily
be
resolve
be
a
requirement_13
distraction
because
actually
one
must
talk
about
what
happen
when
a
bookkeeper
technology_33
a
“bookie”
fail
kill
and
restart
a
bookkeeper
bookie
require
the
same
redistribution
of
connector_data_3
see
in
kafka’s
requirement_11
this
be
the
nature
of
quality_attribute_3
component_20
with
concept
pattern_6
and
component_22
elastic
technology_2
be
here
already
elasticity
be
important
confluent’s
founder
jay
kreps
have
recently
blogged
about
this
topic
elastic
technology_3
technology_2
cluster
in
confluent
requirement_6
in
a
pattern_7
requirement_6
component_2
confluent
requirement_6
the
end
component_12
shouldn’t
have
to
care
at
all
about
component_31
failure


uptime
be
expect
and
should
be
guarantee
with

xx
slas
consumption
base
requirement_20
i
e
pay
a
you
go
mean
you
do
not
have
to
worry
about
issue
pattern_8
requirement_9
size
pattern_8
technology_33
expand
or
shrink
cluster
etc
under
the
hood
at
all
self
manage
technology_2
cluster
also
need
similar
capability
tiered
storage
for
technology_2
be
huge
because
most
of
the
connector_data_3
be
not
component_25
on
the
pattern_8
anymore
to
allow
almost
instant
recovery
from
failure
in
conjunction
with
technology_16
self
balance
technology_2
a
confluent
feature
come
in
q3
and
discuss
in
the
above
connector_29

component_11
don’t
have
to
worry
about
elasticity
in
their
self
manage
cluster
at
all
unfortunately
if
you
be
look
for
such
a
modern
offer
for
technology_1
there
be
none
quality_attribute_5
myth

“pulsar
have
quality_attribute_1
inter
cluster
geo
pattern_6
than
kafka”
false
every
quality_attribute_3
component_20
have
to
solve
problem
the
cap
theorem
and
quorum
in
quality_attribute_3
computing
the
quorum
be
the
minimum
number
of
vote
that
a
quality_attribute_3
transaction
have
to
obtain
in
order
to
be
allow
to
perform
an
in
a
quality_attribute_3
component_20
a
quorum
base
technique
be
connector_12
to
enforce
consistent
in
a
quality_attribute_3
component_20
technology_2
require
technology_21
to
solve
the
quorum
problem
even
after
kip

and
technology_21
removal
the
universal
law
of
real
world
physic
be
still
the
same
there
be
quality_attribute_15
issue
quality_attribute_2
a
quality_attribute_3
component_20
over
region
the
u
east
central
and
west
or
even
globally
that’s
because
the
quality_attribute_18
of
light
though
very
high
do
have
a
limit
various
deployment
option
exist
to
work
around
this
problem
include
real
time
pattern_6
technology_16
technology_3
kafka’s
mirrormaker

confluent’s
replicator
or
confluent’s
multi
region
cluster
connector_10
out
“architecture
pattern_16
for
quality_attribute_3
hybrid
edge
and
global
technology_3
technology_2
deployments”
for
various
different
deployment
option
and
best
practice
there
be
no
single
pattern_16
or
implementation
to
provide
global
pattern_6
and
zero
downtime
+
zero
connector_data_3
loss
for
the
most
critical
component_4
confluent’s
multi
region
cluster
allow
rto=0
and
rpo=0
i
e
zero
downtime
and
zero
connector_data_3
loss
with
automatic
disaster
recovery
and
component_32
fail
over
even
if
a
complete
connector_data_3
center
or
requirement_6
region
go
down
here
pulsar’s
architecture
require
even
more
complexity
than
a
“basic”
technology_1
deployment
that’s
because
for
geo
pattern_6
technology_1
require
an
additional
“global”
technology_21
cluster
which
make
technology_1
inappropriate
for
geo
distribution
over
large
distance
there
be
a
workaround
but
the
problem
around
cap
theorem
and
physic
do
not
go
away
no
matter
if
you
use
technology_2
or
technology_1
you
need
a
battle
test
design
to
fight
the
law
of
physic
in
your
global
deployment
myth

“pulsar
be
quality_attribute_19
with
kafka’s
and
api”
partially
true
technology_1
provide
a
very
basic
implementation
that
be
quality_attribute_19
with
only
minor
part
of
the
technology_2
v2

technology_20
technology_1
have
a
converter
for
basic
part
of
the
technology_2
technology_20
so
while
allege
“kafka
compatibility”
sound
nice
on
paper
one
shouldn’t
seriously
consider
this
for
migrate
your
run
technology_2
infrastructure
to
technology_1
i
doubt
someone
will
take
the
risk…
we
have
see
“kafka
compatibility”
claim
in
other
example
such
a
the
much
more
mature
technology_34
hub
component_2
connector_10
out
the
limit
factor
of
their
technology_2
technology_35
and
be
surprise
no
support
for
core
technology_2
feature
transaction
and
thus
exactly
once
semantics
compression
or
requirement_18
compaction
a
it
be
not
technology_2
under
the
hood
also
expect
further
diverge
and
unexpected
behavior
when
you
connector_2
your
exist
technology_2
component_24
against
such
a
“compatible”
setup
no
matter
if
technology_34
hub
technology_1
or
any
other
wrapper
technology_2
vs
technology_1
–
comprehensive
comparison
the
last
section
explore
various
technology_15
myth
we
find
in
many
other

i
think
i
bring
some
clarity
into
these
discussion
now
let’s
not
forget
to
take
a
look
beyond
the
technical
detail
of
technology_2
and
technology_1
non
functional
aspect
be
a
important
when
choose
a
technology_15
i
will
cover
three
critical
aspect
in
the
follow
requirement_13
traction
requirement_16
support
and
requirement_6
offer
requirement_13
traction
of
technology_3
technology_2
and
technology_3
technology_1
take
a
look
at
trend
from
the
last
five
year
confirm
my
personal
experience
i
see
the
interest
in
technology_3
technology_1
be
very
limit
compare
to
technology_3
technology_2
the
picture
look
very
similar
when
you
take
a
look
at
technology_36
overflow
and
similar
component_9
number
and
size
of
support
vendor
the
open
ecosystem
technology_16
requirement_8
wrapper
technology_14
technology_37
technology_2
and
similar
characteristic
for
technology_15
trend
opening
be
another
very
quality_attribute_1
indicator
of
adoption
of
technology_15
not
many
opening
for
technology_1
mean
not
many
requirement_12
be
use
it
search
in
your
favorite
search
component_16
if
you
search
globally
you
will
find

opening
for
technology_1
but
thousand
of
for
technology_2
additionally
most
of
the
one
show
technology_1
say
something
“looking
for
experience
with
technology_2
technology_1
kinesis
or
similar
technologies”
in
most
requirement_11
these
characteristic
be
much
more
relevant
for
the
success
of
your
next
project
than
the
subtle
technical
difference
the
key
goal
be
to
solve
your
requirement_3
problem
isn’t
it
so
with
the
lack
of
adoption
why
be
technology_1
come
up
in
conversation
at
all
one
reason
be
that
independent
consult
requirement_12
research
analyst
and
technology_38
include
me
need
to
talk
about
cut
edge
technology_15
to
keep
their
audience
interested…
and
to
be
honest
it
make
a
quality_attribute_1
story
requirement_16
support
for
technology_2
and
technology_1
there
be
requirement_16
support
for
technology_2
and
technology_1
though
the
situation
be
not
what
you
might
expect
here
be
the
vendor
you
can
connector_data_4
and
ask
for
a
meet
to
discus
the
potential
next
step
for
work
together
on
your
technology_1
journey
streamlio
now
acquire
by
splunk
the
former
requirement_12
behind
technology_3
technology_1
splunk
do
not
yet
announce
a
future
technology_1
strategy
to
support
people
work
on
their
own
technology_1
base
project
splunk
be
well

for
their
widely
adopt
requirement_1
component_9
that’s
their
core
requirement_3
~
$1
8b
in

the
only
thing
people
complain
about
splunk
be
the
requirement_20
splunk
be
a
heavy
technology_2
component_12
under
the
hood
and
now
incorporate
technology_1
into
their
splunk
connector_data_3
connector_3
processor
dsp
it
be
very
doubtful
that
splunk
will
jump
on
the
open_source
bandwagon
to
support
your
next
standalone
technology_1
project
but
a
broad
scope
dsp
might
be
come
of

the
future
will
show
us…
streamnative
found
by
one
of
the
original
developer
of
technology_3
technology_1
provide
an
connector_4
component_9
base
on
technology_1
at
the
time
of
connector_30
this
in

streamnative
have

requirement_21
on
linkedin
i
be
not
sure
if
this
be
the
right
quality_attribute_14
to
support
your
next
mission
critical
deployment
in

but
they
do
offer
it
technology_39
announce
support
for
technology_1
in

their
core
strategy
move
from
requirement_8
to
requirement_1
in
the
last
year
tibco’s
technology_13
requirement_10
be
migrate
away
in
high
number
their
technology_13
team
have
to
do
some
desperate
strategy
decision
support
other
component_8
even
though
have
zero
contribution
and
experience
with
the
project
you
be
right
this
might
be
a
myth
but
hey
a
fact
be
that
technology_39
also
do
the
same
for
technology_2
and
here
be
a
nice
trivia
technology_39
provide
technology_2
and
technology_21
to
you
on
window
something
nobody
else
do
–
because
others
that
this
be
not
quality_attribute_20
and
create
inconsistency
all
the
time
but
hey
technology_39
can
support
you
now
with
technology_2
and
technology_1
why
evaluate
these
two
technology_14
if
one
single
vendor
allow
you
to
use
both
even
on
window
with
exe
download
and
bat
script
for
start
the
component_5
component_15
the
number
of
vendor
support
technology_2
grow
every
quarter
technology_2
have
incredible
huge
requirement_13
adoption
in
the
meantime
the
best
proof
for
this
be
when
the
big
vendor
provide
support
and
technology_16
around
it

technology_40

and
many
other
requirement_12
support
technology_2
and
build
requirement_8
capability
and
own
technology_17
around
it
the
late
“wake
up
call”
for
me
be
at
technology_40
openworld

in
san
francisco
where
i
attend
a
roadmap
component_33
from
the
technology_40
technology_17
manager
for
goldengate
oracle’s
well

great
but
also
very
expensive
cdc
technology_16
most
of
the
talk
focus
on
opening
goldengate
to
make
it
the
connector_data_3
requirement_8
component_9
for
everything
half
the
talk
be
about
connector_3
technology_2
and
how
goldengate
will
provide
requirement_8
with
different
component_34
connector_data_3
lake
and
technology_2
in
both
direction
fully
manage
requirement_6
offer
for
technology_2
and
technology_1
let’s
take
a
look
at
the
requirement_6
offer
quality_attribute_5
for
technology_2
and
technology_1
there
be
a
requirement_6
component_2
quality_attribute_5
for
technology_3
technology_1
it
have
a
very
innovative
name
kafkaesque
no
kid
connector_10
the
link…
update
on
~june
17th
they
rebranded
the
component_2
kafkaesque
be
now
kesque
–
probably
they
realize
how
embarrass
the
name
be
maybe
you
also
connector_10
out
the
various
requirement_6
offer
for
technology_3
technology_2
to
find
out
which
offer
fit
you
quality_attribute_1
confluent
requirement_6
saas
be
a
fully
manage
component_2
provide
consumption
base
requirement_20


slas
and
elastic
serverless
characteristic
for
technology_3
technology_2
and
it
ecosystem
e
g
schema
registry
technology_2
connector_2
connector
and
technology_27
for
connector_3
component_6
msk
paas
provision
technology_21
and
technology_2
pattern_8
so
that
the
end
component_12
can
operate
it
fix
bug
do
roll
upgrade
etc
one
important
fact
everybody
should
be
aware
of
technology_31
exclude
technology_2
issue
from
it


slas
and
support
technology_34
hub
saas
provide
a
technology_2
with
a
proprietary
implementation
under
the
hood
to
connector_15
with
technology_2
component_4
it
be
very
quality_attribute_8
and
performant
a
it
be
not
really
technology_2
but
an
emulation
it
miss
several
core
feature
of
technology_2
exactly
once
semantics
requirement_18
compaction
and
compression
not
to
mention
the
surround
capability
technology_2
connector_2
and
technology_2
connector_1
big
blue

and
big
red
technology_40
have
requirement_6
offer
around
technology_2
and
it
apis
i
have
no
idea
if
anyone
be
use
them
and
how
quality_attribute_1
they
be
never
see
them
in
the
wild
by
myself
plenty
of
small
player
aiven
cloudkarafka
instaclustr
and
others
a
you
can
see
the
current
requirement_6
offer
show
relatively
clear
how
the
requirement_13
adoption
of
technology_2
and
technology_1
look

conclusion
–
technology_3
technology_2
or
technology_3
technology_1
tl
dr
technology_1
be
still
a
long
way
from
kafka’s
level
of
maturity
in
term
of
be
prove
for
high
quality_attribute_14
use
requirement_11
and
build
a

you
should
also
question
whether
technology_1
be
actually
quality_attribute_1
evaluate
technology_2
and
technology_1
if
you
be
go
the
purely
open_source
way
find
out
which
fit
you
best
in
your
evaluation
include
the
technical
feature
set
maturity
vendor
developer

and
other
relevant
factor
which
one
fit
your
situation
best
if
you
need
an
requirement_16
solution
that
cover
much
more
than
what
both
of
these
two
open_source
component_19
offer
technology_2
be
the
only
option
choose
a
technology_2
base
offer
from
one
of
the
various
vendor
or
a
suitable
requirement_6
offer
technology_1
unfortunately
be
not
ready
for
this
today
and
the
foreseeable
future
how
do
you
think
about
technology_3
technology_2
vs
technology_3
technology_1
what
be
your
strategy
let’s
connector_2
on
linkedin
and
discus
stay
inform
about

by
subscribe
to
my
newsletter
total

connector_6
connector_7

tweet

pin
it

please
leave
this
emptydont‘
miss
my
next

subscribe
we
don’t
spam
connector_5
more
in
our
privacy
requirement_22
connector_10
your
inbox
or
spam
folder
to
confirm
your
subscription
relate
tagsapacheawsazurebig
datacloudclouderaconfluentdata
centerevent
hubsevent
streaminggcphortonworkshybridibmkafkakafka
connectkafka
streamsmessage
queuemessagingmulti
regionopen
sourcepulsarpulsar
functionsreal
timered
hatsplunkstream
processingstreaming
analyticsstreamliostreamnativetibcotiered
storage
kai
waehner
build
requirement_6
requirement_7
connector_4
infrastructure
for
real
time
connector_data_3
component_6
and
requirement_1
leave
a
connector_data_11
cancel
replyyour
connector_31
will
not
be
publish
require
be
mark
*comment
*
name
*
*
connector_11
my
name

and
in
this
browser
for
the
next
time
i

pattern_4


you
also
technology_3
technology_2
+
technology_11
=
end
to
end
iot
requirement_8

slide
video
technology_3
technology_2
requirement_2
confluent
eai
internet
of
thing
technology_2
connector_2
pattern_1
pattern_2
technology_11
open_source
connector_3
component_6
bykai
waehner10

technology_11
and
technology_3
technology_2
be
a
perfect
combination
for
end
to
end
iot
requirement_8
from
edge
to
connector_data_3
center
this
discus
two
different
approach
and
refer
to
implementation
on
technology_41
use
technology_3
technology_2
technology_2
connector_2
confluent
technology_11
pattern_13
and
mosquitto
connector_5
more



connector_5
more

2k
views20
minute
connector_5
can
technology_3
technology_2
replace
a
component_34
requirement_1
technology_3
technology_2
architecture
requirement_2
confluent
component_34
requirement_8
technology_2
connector_2
bykai
waehner12

can
and
should
technology_3
technology_2
replace
a
component_34
how
long
can
and
should
i
component_25
connector_data_3
in
technology_2
…
connector_5
more



technology_15
evangelist
kai
waehner
build
requirement_6
requirement_7
connector_4
infrastructure
for
real
time
connector_data_3
component_6
and
requirement_1
subscribe
to
my
newsletter
please
leave
this
empty
stay
inform
about

we
don’t
spam
connector_5
our
privacy
requirement_22
for
more
info
connector_10
your
inbox
or
spam
folder
to
confirm
your
subscription
end
to
end
requirement_8
feature


technology_3
technology_2
ksql
and
technology_3
plc4x
for
iiot
connector_data_3
requirement_8
and
component_6

technology_3
technology_2
vs
technology_13
mq
technology_18
esb
–
slide
+
video

deep

example
technology_3
technology_2
+
technology_7
+
kera
+
technology_8
+
technology_42
categoriescategories
select
category
5g
technology_43
gap
airline
airport
allgemein
msk
requirement_1
technology_3
technology_44
technology_3
technology_2
technology_3
mesos
technology_3
technology_1
technology_3
technology_4
component_3
component_3
gateway
component_3
requirement_9
component_4
component_5
architecture
ariba
asset
track
audio
augment
reality
automation
requirement_14
automotive
aviation
technology_31
technology_31
outpost
technology_31
wavelength
technology_34
bank
technology_45
bet
requirement_2
biotech
biotechnology
bitcoin
blockchain
bookmaker
bpm
bs
requirement_3
intelligence
requirement_23
citizen
requirement_6
requirement_6
requirement_7
technology_46
comparison
concur
condition
pattern_17
confluent
confluent
requirement_6
connector_32
car
connector_32
vehicle
conversational
requirement_24
core
bank
crm
crypto
cryptocurrency
cybersecurity
connector_data_3
at
rest
connector_data_3
historian
connector_data_3
hub
connector_data_3
in
motion
connector_data_3
requirement_8
connector_data_3
lake
connector_data_3
mesh
connector_data_3
science
connector_data_3
connector_4
connector_data_3
requirement_25
component_34
databricks
deep

defi
digital
forensics
digital
twin
disaster
recovery
quality_attribute_3
ledger
technology_9
domain
drive
design
eai
edge
edge
computing
eipaas
elasticsearch
elt
energy
requirement_16
architecture
erp
esb
ethereum
technology_18
connector_4
exactly
once
semantics
feature

finance
requirement_14
food
forensics
fraud
fraud
detection
gamble
game
gaming
gcp
technology_47
government
technology_5
healthcare
hivecell
technology_48
hybrid
requirement_6
hyperledger
mq
idoc
iiot
in
memory
industrial
iot
requirement_14


insurance
insurance
requirement_14
requirement_8
internet
of
thing
intrusion
detection
inventory
requirement_9
iota
ipaas
it
certification
it
conference
technology_12
jee
technology_49
jupyter
technology_2
connector_2
technology_2
connector_1
kappa
architecture
ksql
technology_27
technology_10
lake
house
lambda
architecture
large
connector_data_2
component_35
libra
life
science
live
commerce
logistics
requirement_4
component_31
vision
component_10
manufacture
connector_data_1
component_7
pattern_1
pattern_2
technology_13
military
mining
quality_attribute_21
component_36
technology_11
national
quality_attribute_10
nft
nlp
technology_6
oil
and
gas
omnichannel
opc
ua
open
component_3
open
bank
open_source
technology_40
osisoft
technology_50
os
ott
over
the
top
payment
persistence
pharma
plc4x
predictive
quality_attribute_22
sector
technology_7
qcon
qualitrics
technology_19
ransomware
recommendation
redpanda
pattern_18
retail
reverse
technology_18
ripple
rtls
sale
technology_51
technology_51
technology_52
scm
quality_attribute_10
serverless
component_2
mesh
siem
situational
awareness
smart
build
smart
city
smart
grid
pattern_3
technology_53
soar
social
requirement_5
sparkplug
splunk
connector_3
component_6
connector_4
requirement_1
supply
chain
telco
telecom
telecommunication
requirement_14
technology_8
threat
detection
threat
intelligence
tiered
storage
transaction
transportation
trend
uncategorized
use
requirement_11
v2x
video
video
connector_4
virtual
reality
web
technology_14
web
component_2
web3
technology_54
connector_data_12
zero
trust
tag
–
cloudanalytics
technology_3
technology_3
technology_44
technology_3
technology_2
technology_31
requirement_2
businessworks
requirement_6
requirement_6
requirement_7
confluent
deep

technology_9
eai
edge
requirement_16
component_4
requirement_8
requirement_16
component_2
bus
esb
connector_4
technology_5
hybrid
iiot
requirement_8
iot
j2ee
technology_12
jee
technology_2
technology_2
connector_2
technology_2
connector_1
ksql
technology_10
requirement_4
pattern_2
technology_13
technology_11
open_source
technology_40
real
time
pattern_3
streambase
connector_4
requirement_1
connector_3
component_6
talend
technology_39
connector_5
more

views4
minute
connector_5
technology_3
technology_2
biotechnology
healthcare
omnichannel
open
component_3
pharma
open
component_3
and
omnichannel
with
technology_3
technology_2
in
healthcare
bykai
waehner18

connector_5
more

views19
minute
connector_5
msk
technology_3
technology_2
technology_3
technology_1
technology_46
comparison
confluent
requirement_6
mq
technology_49
technology_19
redpanda
comparison
technology_49
connector_data_1
component_7
vs
technology_3
technology_2
bykai
waehner12

connector_5
more

views5
minute
connector_5
technology_3
technology_2
bitcoin
blockchain
cryptocurrency
cybersecurity
connector_data_3
connector_4
ethereum
fraud
detection
technology_3
technology_2
in
crypto
and
finserv
for
cybersecurity
and
fraud
detection
bykai
waehner29

connector_5
more

views4
minute
connector_5
technology_3
technology_2
biotech
confluent
requirement_6
connector_data_3
science
connector_data_3
connector_4
healthcare
insurance
technology_2
connector_1
life
science
requirement_4
requirement_4
and
connector_data_3
science
with
technology_2
in
healthcare
bykai
waehner18


©
kai
waehner
|
imprint
|
connector_data_3
privacy
by
continue
to
use
the

you
agree
to
the
use
of

more
connector_data_5
acceptthe
setting
on
this
be
set
to
allow

to
give
you
the
best
browse
experience
possible
if
you
continue
to
use
this
without
connector_28
your
setting
or
you
click
connector_33
below
then
you
be

to
this
close
