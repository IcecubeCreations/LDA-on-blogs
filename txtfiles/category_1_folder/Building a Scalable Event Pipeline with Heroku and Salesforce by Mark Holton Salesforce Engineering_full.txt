build
a
quality_attribute_1
pipeline
with
technology_1
and
technology_2
|
by
mark
holton
|
technology_2
engineeringopen
in
apphomenotificationslistsstorieswritepublished
insalesforce
engineeringmark
holtonfollowjan
2019·5
min
readsavebuilding
a
quality_attribute_1
pipeline
with
technology_1
and
salesforcebuilding
a
quality_attribute_1
pipeline
with
technology_1
and
salesforcehave
you
hear
of
chatbots
in
technology_2
component_1
requirement_1
a
surge
number
of
requirement_2
across
the
globe
be
find
chatbots
to
be
a
useful
addition
to
their
component_1
offer
chatbots
be
an
excite
technology_3
and
an
enabler
for
organization
and
team
who
embrace
automation
by
set
up
conversational
dialog
and
rule
custom
script
and
a
sprinkling
of
requirement_3
or
requirement_4
a
carefully
configure
requirement_5
can
answer
many
target
question
for
your
requirement_2
in
order
for
this
to
work
for
our
requirement_2
at
quality_attribute_2
there
be
a
lot
of
work
that
go
in
behind
the
scene
enter
the
pipeline
how
be
chatbots
relate
to
an
pipeline
when
build
an
component_2
at
chatbots
quality_attribute_2
the
need
to
quality_attribute_3
connector_1
connector_data_1
export
requirement_6
and
connector_2
metric
be
critically
important
this
connector_data_1
be
use
to
support
the
component_2
the
component_3
and
their
requirement_7
the
requirement_5
component_4
require
an
architecture
to
quality_attribute_3
export
“event
logs”
or
“debug
logs”
from
our
requirement_5
runtime
component_2
requirement_2
themselves
need
these
requirement_6
for
key
insight
such
a
audit
chatbot’s
logical
flow
—
be
it
work
and
perform
a
intend
pinpoint
any
exception
that
be
occur
within
the
component_5
of
their
botpinpointing
any
exception
occur
in
custom
they
create
a
part
of
an
invocable
action
or
invocable
flowonce
we
define
the
attribute
an
would
contain
we
need
a
way
to
export
these
in
near
real
time
for
each
component_3
component_6
within
an
organization
these
provide
crucial
visibility
into
the
logical
step
a
requirement_8
take
when
respond
to
a
component_3
what
drive
our
architectural
design
the
design
question
be
how
could
we
ensure
the
would
be
quality_attribute_3
connector_3
without
degrade
the
requirement_9
of
the
component_7
how
can
we
ensure
resilient
delivery
of
to
individual
technology_2
orgs
in
a
manner
that
would
quality_attribute_2
out
a
the
volume
of
these
increase
over
time
answer
these
key
design
question
lead
to
an
architectural
design
that
utilize
salesforce’s
own
technology_1
component_4
and
namely
technology_4
technology_5
on
technology_6
an
pipeline
build
on
technology_5
enable
u
to
design
the
pipeline’s
characteristic
to
meet
our
quality_attribute_4
need
target
volume
of
ten
of
million
per
day
figure
schematic
of
debuglogs
pipeline
from
requirement_5
runtime
to
downstream
connector_data_1
connector_4
usedthe
pipeline
build
and
use
today
connector_5
from
an
pattern_1
and
pattern_2
component_8
with
low
quality_attribute_5
rather
than
requirement_5
runtime
be
overload
with
component_9
and
connector_6
connector_data_1
to
external
component_10
via
technology_7
this
design
limit
requirement_5
runtime’s
responsibility
to
simply
construct
and
buffer
these
into
the
pipeline
the
responsibility
of
connector_data_1
connector_7
via
an
technology_7
or
other
mean
be
pass
to
a
downstream
component_11
this
connector_data_2
in
a
clean
separation
of
concern
and
direct
path
to
quality_attribute_6
these
feature
with
le
impact
on
requirement_5
runtime’s
core
responsibility
of
component_9
requirement_8
connector_data_3
these
in
transit
be
component_12
in
a
technology_5
topic
for
up
to
day
with
a
carefully
selected
number
of
component_13
that
allow
u
to
quality_attribute_2
out
and
connector_3
these
in
near
real
time
component_14
connector_8
from
this
topic
connector_2
and
pattern_3
and
upsert
bulk
set
of
connector_data_1
to
downstream
connector_data_1
connector_4
use
by
a
give
organization
benefit
of
this
architecturethis
architecture
allow
u
to
design
the
pipeline
and
component_14
with
large
benefit
in
mind
defer
high
quality_attribute_5
technology_7
callsif
the
number
of
correspond
to
an
increase
in
technology_7
connector_data_4
requirement_9
in
the
component_7
would
quickly
start
to
degrade
instead
of
via
technology_7
from
the
component_7
which
can
involve
high
quality_attribute_5
be
emit
into
a
technology_5
topic
via
an
pattern_1
and
pattern_2
component_8
emit
an
take
about
1ms
even
at
extremely
high
volume
of
this
be
not
impactful
to
the
application’s
performancethe
component_14
then
connector_8
and
pattern_3
to
efficiently
connector_3
those
pattern_3
connector_data_5
downstreamas
an
optimization
the
technology_7
by
the
component_14
happen
asynchronously
via
a
pool
of
executor
allow
multiple
to
happen
in
parallel2
quality_attribute_7
the
size
and
configuration
of
our
technology_5
cluster
and
topic
for
the
project
volume
of
eventsby
carefully
select
the
number
of
component_13
per
pattern_4
you
can
balance
the
need
to
quality_attribute_2
out
component_14
component_9
connector_data_1
alongside
the
requirement_9
of
the
cluster
itself
in
term
of
rebalancing
and
pattern_5
the
number
of
component_13
per
topic
be
a
directly
limit
factor
on
the
number
of
component_14
that
can
connector_8
from
a
give
topic
in
parallel
too
few
component_13
and
you
limit
quality_attribute_8
too
many
and
you
risk
connector_9
high
resource
which
increase
time
to
re
elect
leader
when
pattern_4
be
recover
from
failure
by
connector_data_6
and
component_14
so
that
can
be
component_9
in
any
order
you
can
parallelize
component_14
and
evenly
quality_attribute_9
across
each
component_13
if
order
of
be
vital
you
have
an
option
to
assign
a
of
to
a
give
component_13
by
give
it
a
key
e
g
a
component_6
or
an
other
key
quality_attribute_10
and
requirement_9
consideration
for
your
technology_5
cluster
be
number
of
pattern_4
in
each
quality_attribute_11
zone
pattern_5
factor
connector_data_1
retention
requirement_10
and
compression
allow
for
quality_attribute_12
failover
component_15
and
reprocessingin
the
a
downstream
component_16
be
not
quality_attribute_13
at
the
time
of
publish
connector_10
connector_data_1
you
want
your
component_17
to
try
and
re
connector_3
this
connector_data_1
downstream
at
a
late
timeprocesses
that
rely
on
technology_7
such
a
technology_7
bulk
be
destine
to
have
failure
rat
great
than
for
these
component_9
retry
topic
be
a
great
of
identify
fail
delivery
and
retry
retry
topic
in
your
cluster
act
a
component_15
that
other
retry
component_14
can
connector_10
from
and
attempt
to
re
at
predefined
interval
by
emit
fail
bulk
into
retry
topic
you
can
a
high
degree
of
bulk
resiliency
by
handle
failure
and
retry
via
special
retry
topic
each
component_18
can
be
component_9
efficiently
and
move
connector_11
without
cause
your
pipeline
to
stagnate
or
back
up
figure
example
graph
of
chatbots
pipeline
in
production
connector_12
million
of
per
day
use
by
organization
build
requirement_8
note
these
number
be
not
show
actual
production
number
summarywhen
build
your
component_2
or
component_1
you
will
likely
have
a
need
to
publish
for
a
variety
of
use
requirement_11
and
requirement_7
demand
an
quality_attribute_14
way
to
do
this
and
to
decouple
the
requirement_9
of
your
component_7
from
the
publish
pipeline
be
to
defer
technology_7
publish
downstream
technology_4
technology_5
and
especially
a
manage
technology_5
cluster
such
a
the
one
offer
by
technology_6
be
a
battle
test
component_4
that
provide
this
capability
by
use
this
component_4
and
some
key
design
consideration
you
can
quality_attribute_3
grow
your
pipeline
without
sacrifice
requirement_9
or
quality_attribute_4
of
your
core
component_1
1more
from
technology_2
engineeringfollowsalesforce
engineering
go
behind
the
requirement_1
with
technology_2
engineersread
more
from
technology_2
engineeringrecommended
from
mediumjeremy
keithmistletoe
offlineemilio
morettifix
warn
in
openocd
about
lpc
vector
checksumvishal
padghaninedurekaamazon
athena
the
serverless
connector_data_1
requirement_12
toolchristophe
leborgneinthe
technology_8
codercrud
be
dead
long
live
crud
igor
kosoyinharness
prod
release
highlightsproduction
release
highlight
28th
2021basemelsayedflife
be
a
journey
of
twist
and
turn
peak
and
valley
mountain
to
climb
and
ocean
to
explore
jayinprojectwtcoding
tutor
tip
—
—
technology_9
essentialslulu
kamiliaincompfestsoftware
engineering
academy
camp
be
an
excellent
problem
solver
abouthelptermsprivacyget
the
appget
startedmark
holton123
followersprincipal
member
of
technical
staff
at
technology_2
husband
&
father
of
il
state
golf
champ
6x
marathoner
www
linkedin
technology_10
in
markholtonsoftwarefollowmore
from
mediumjohn
alvin
salamatsql
query
optimization
use
statistic
in
outsystemsanifowoseihechiinstackanatomyokta
vs
other
pattern_6
pattern_7
managerseric
hosickinthe
opinionated
architectpostgresql
pattern_8
with
pg_cron
and
materialize
viewsbobtherdsmansql
component_19
migration
to
rds
instance
size
and
migration
best
practice
helpstatuswritersblogcareersprivacytermsaboutknowable
