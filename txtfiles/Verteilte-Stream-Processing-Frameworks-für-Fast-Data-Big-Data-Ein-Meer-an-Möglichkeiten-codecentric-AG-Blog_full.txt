Verteilte Stream Processing Frameworks f√ºr Fast Data & Big Data - Ein Meer an M√∂glichkeiten - codecentric AG Blog                  LeistungenKarriereWissenBlogAktuelles√úber uns  encodecentric Blog  IT-Expertenwissen von Entwicklern f√ºr Entwickler  0 Posts        codecentric BlogNeuesteAgilit√§tArchitekturDataJavaPerformanceContinuous DeliveryMicroservicesCloud  RSS-FeedXMist, das klappt leider noch nicht! Im Moment testen wir neue Funktionen und du hast uns mit deinem Klick geholfen. Vielen Dank! √úbersicht  Computer-Vision-Techniken in Kofax Transformation Modules (KTM/KTD)  Verteilte Stream Processing Frameworks f√ºr Fast Data & Big Data ‚Äì Ein Meer an M√∂glichkeiten 27.03.2017  von Matthias Niehoff   Keine Kommentare Spark Streaming, Flink, Storm, Kafka Streams ‚Äì das sind nur die popul√§rsten Vertreter einer stetig wachsenden Auswahl zur Verarbeitung von Streaming-Daten in gro√üen Mengen. In diesem Artikel soll es um die wesentlichen Konzepte hinter diesen Frameworks gehen und die drei Apache-Projekte Spark Streaming, Flink und Kafka Streams kurz eingeordnet werden. Warum Stream Processing?Die Verarbeitung von Streaming-Daten gewinnt durch die stetig wachsende Anzahl von Datenquellen, die durchgehend Daten produzieren und zur Verf√ºgung stellen, zunehmend an Bedeutung. Neben dem omnipr√§senten Internet of Things sind dies zum Beispiel Klickstreams, Daten im Werbegesch√§ft oder auch Ger√§te- und Serverlogs. Nun sind unendliche und kontinuierliche Daten kein neues Ph√§nomen. Auch jetzt entsprechen schon viele Daten diesem Schema. Zum Beispiel treten auch √Ñnderungen an Stammdaten kontinuierlich auf, allerdings nur in geringer Frequenz. Stammdaten werden nach dem klassischen Request/Response verarbeitet. Bei zeitunkritischen √Ñnderungen oder gr√∂√üeren Volumen werden die Daten auch gerne gesammelt gespeichert und dann regelm√§√üig durch Batchprozesse verarbeitet. Diese laufen dann beispielsweise jede Nacht oder auch in k√ºrzeren Intervallen. T√§gliche Intervalle reichen aber h√§ufig nicht mehr aus. Gefragt ist Geschwindigkeit: Analysen und Auswertungen werden zeitnah erwartet und nicht Minuten oder gar Stunden sp√§ter. An dieser Stelle kommt das Stream Processing ins Spiel: Daten werden verarbeitet, sobald sie dem System bekannt sind. Begonnen hat dies mit der Lambda Architektur (vgl. [1]), bei der die Stream- und Batch-Verarbeitung parallel erfolgen, da die Stream-Verarbeitung keine konsistenten Ergebnisse garantieren konnte. Mit den heutigen Systemen ist es auch m√∂glich, nur mit Streaming-Verarbeitung konsistente Ergebnisse nahezu in Echtzeit zu erreichen. (vgl. [2])Time MattersEin wichtiger Aspekt beim Streaming ist die Zeit. Dabei kann im Wesentlichen zwischen drei Zeiten unterschieden werden:Eventzeit: Zeitpunkt, zu dem ein Event tats√§chlich auftratIngestionzeit: Zeitpunkt, zu dem das Event im System beobachtet wurdeVerarbeitungszeit: Zeitpunkt, zu dem das Event vom System verarbeitet wurdeAbb. 1: Exemplarische Darstellung von Eventzeit und Verarbeitungszeit. Mit versp√§teten (Gelb, Gr√ºn, Rot) und Out-of-order Events (Blau)In der Praxis ist vor allem Eventzeit im Vergleich zur Ingestion- & Verarbeitungszeit interessant. Die Differenz zwischen der Eventzeit und der Verarbeitungszeit kann stark schwanken. Die Gr√ºnde daf√ºr sind vielf√§ltig: Netzwerk-Latenzen, verteilte Systeme, Hardware-Ausf√§lle oder auch eine unregelm√§√üige Datenanlieferung. Wenn nach der Verarbeitungszeit verarbeitet wird, ist dies nicht wichtig: Die Daten werden auf Basis der Systemzeit der Verarbeitung analysiert: Wenn ein Event um 12 Uhr eintrifft, ist es irrelevant, dass es bereits um 11 Uhr aufgetreten ist. Der normale Use Case ist dies aber nicht: Wenn ein Event um 11 Uhr auftritt, m√∂chte ich es in der Regel auch zeitlich so betrachten. Die Frage hier ist dann: Wann wei√ü ich, dass ich alle Events bis 11 Uhr bekommen habe? Wie lange warte ich auf Events? Hier helfen Strategien wie Watermarks, Trigger und Akkumulatoren: Watermarks: Wann habe ich alle Daten zusammen?Trigger: Wann soll ich die Berechnung ausl√∂sen? Akkumulation: Wie f√ºge ich einzelne Berechnungen zusammen, beispielsweise wenn nachtr√§glich Daten folgen?√úber diese drei Konzepte lie√üe sich problemlos ein eigener Artikel schreiben. Tyler Akidau, der Kopf hinter Streaming bei Google, hat dies bereits hervorragend zusammengefasst. Deshalb sei an dieser Stelle f√ºr Details sein Artikel empfohlen [3].State & WindowJede nicht triviale Anwendung wird eingehende Events miteinander korrelieren. Daf√ºr ist ein Zustand n√∂tig, in dem vorherige Events zwischengespeichert werden. Dieser State kann unendlich gespeichert werden oder explizit zeitlich begrenzt. Ein Beispiel f√ºr einen unendlichen gespeicherten State ist eine Lookup-Tabelle mit Metadaten. Ein zeitlich begrenzt State ist beispielsweise ein Window.Bei einem Window werden Daten f√ºr einen bestimmten Zeitraum zusammengefasst und analysiert. Dies ist in fast jeder Anwendung n√∂tig, da der Datenstrom ja nie endet. Dabei gibt es verschiedene Typen von Windows:Tumbling Window: nicht √ºberlappende, fixe ZeitabschnitteSliding Window: √ºberlappende, fixe ZeitabschnitteSession Window: nicht √ºberlappende Zeitabschnitte unterschiedlicher L√§nge; definiert durch bestimmte Events oder durch √úberschreiten einer bestimmten Zeit zwischen zwei EventsAbb. 2: Tumbling und Sliding Window bei einem Zeitfenster von vier Sekunden und ein Sliding Intervall von zwei Sekunden beim Sliding Window. Innerhalb eines jeden Fensters werden die Werte summiert. Abb. 3: Sessionwindows bei einer Inaktivit√§t von mindestens zwei Minuten zwischen zwei Events f√ºr einen Key.F√ºr die Definition von Windows ist die Unterscheidung zwischen Event- und Verarbeitungszeit wichtig: Windows basierend auf Verarbeitungszeit sind sehr einfach zu realisieren, Windows basierend auf Eventzeit ben√∂tigen die oben genannten Strategien zur Eventzeit, um nicht unendlich zu wachsen. API & LaufzeitumgebungErste Unterschiede bei den Frameworks lassen sich bei der API und dem generellen Verarbeitungsmodell feststellen. Unterscheiden l√§sst sich zwischen einem nativen Streaming-Ansatz und dem Microbatching. Beim nativen Streaming werden eingehende Daten direkt verarbeitet wohingegen beim Microbatching die eingehenden Daten zun√§chst f√ºr eine bestimmte Zeit (typischerweise 1 ‚Äì 30s) gesammelt und anschlie√üend zusammen verarbeitet werden. Der n√§chste Microbatch kann dann entweder direkt nach dem Abschluss des vorherigen Batches gestartet werden oder erst nach Verstreichen des fixen Intervalls. In beiden F√§llen erh√∂ht Microbatching die Latenz, daf√ºr ist das Fehlerhandling etwas einfacher zu realisieren. Der fr√ºher h√§ufig genannte Vorteil des sehr hohen Durchsatzes kann heute aber auch von nativen Streaming Frameworks erreicht werden. Zudem bieten diese mehr Flexibilit√§t bei Windows und States.Sichtbar f√ºr den Entwickler ist vor allem die API. Auch hier kann zwischen zwei Varianten unterschieden werden: einer komponentenbasierten und einer deklarativen, high-level API. Bei ersterer wird der Fluss durch verschiedene Komponenten beschrieben (Quelle -> Verarbeitung 1 -> Verarbeitung 2 -> Senke), bei letzterer werden die Operationen auf Daten beschrieben ( map, filter, reduce), √§hnlich wie bei Scala Collections oder Java 8 Streams. Die Beschreibung von Komponenten bietet mehr Flexibilit√§t bei der Verteilung der Datenstr√∂me, w√§hrend die deklarative API h√§ufig bereits h√∂herwertige Funktion bereitstellt und automatisch Optimierungen vornehmen kann. Zuletzt bleibt noch die Frage: Wo werden die Anwendungen ausgef√ºhrt? Auch hier kann man ‚Äì √úberraschung üôÇ ‚Äì zwei grunds√§tzliche Alternativen unterscheiden. Einige Frameworks brauchen ein spezielles Cluster bestehend aus Master Nodes und Worker Nodes. Diese Cluster k√ºmmern sich dann auch um das Ressourcenmanagement und Fehlerbehandlung, k√∂nnen dies aber auch auslagern an andere Tools (zum Beispiel YARN oder Mesos). Andere Frameworks kommen als einfache Bibliothek daher, die sich in die eigene Anwendung einbinden l√§sst. Das Ausf√ºhren und Skalieren der Anwendung muss dann von anderen Tools √ºbernommen werden. Hier hat man die volle Flexibilit√§t vom Ausf√ºhren eines Jar Files √ºber Docker-L√∂sungen bis hin zu Mesos & Co.Verteilte Systeme sind unzuverl√§ssig!Alle drei Frameworks sind spezialisiert auf die Verarbeitung gro√üer Datenmenge und l√∂sen dies durch horizontale Skalierung. Diese verteilten Systeme sind inh√§rent unzuverl√§ssig: Einzelne Nodes k√∂nnen ausfallen, das Netzwerk ist inkonstant oder die Datenbank, in der die Ergebnisse geschrieben werden sollen, ist nicht erreichbar. Aus diesem Grund hat jedes Framework unterschiedliche Mechanismen, um bestimmte Garantien zu erreichen. Diese reichen vom Microbatching, bei dem kleine Batches wiederholt werden, √ºber Acknowledges f√ºr einzelne Datens√§tze bis hin zu transaktionalen Updates auf Quelle und Senke. Die erreichten Garantien sind dann in der Regal At-Least-Once, also mindestens einmal verarbeitet, oder Exactly-Once, genau einmal verarbeitet. Da Exactly-Once h√§ufig nur schwierig und mit gro√üem Aufwand zu erreichen ist, sind At-Least-Once-Garantien mit idempotenten Operationen h√§ufig ausreichend sowohl in Bezug auf Geschwindigkeit als auch auf Fehlertoleranz. Gibt‚Äôs da nichts von Apache?Zeithandling, State & Windows, eine Laufzeitumgebung und das alles in verteilten Systemen: Streaming-Anwendungen sind komplex. Es gibt eine Reihe von Projekten die bei diesen Problemen helfen sollen. Drei davon kurz vorgestellt:Apache Spark (Streaming) Apache Spark ist aktuell eines der popul√§rsten der Projekte im Streaming-Bereich. Gestartet als besseres MapReduce folgte sp√§ter auch eine Unterst√ºtzung f√ºr Streaming-Daten. Spark Streaming setzt dabei auf Microbatching mit einer deklarativen API. Aktuell wird dabei nur die Verarbeitungszeit vollst√§ndig unterst√ºtzt, mit der neuen Structured Streaming API wird seit der Version 2.0 allerdings auch die Unterst√ºtzung f√ºr Eventzeit-Verarbeitung sukzessive ausgebaut. Das gleiche gilt f√ºr die Unterst√ºtzung von Windows. Der State wird lokal in Memory oder auf Disk gehalten und per Checkpointing regelm√§√üig gesichert. Da Spark inzwischen mit jeder Hadoop Distribution ausgeliefert wird, ist die Verbreitung sehr hoch. Ebenso existiert ein gro√ües √ñkosystem mit vielen Tools und Konnektoren. Apache Flink Wenn es um Eventzeit-Verarbeitung geht, ist Apache Flink aktuell die erste Wahl. Unterst√ºtzt werden Watermarks und Trigger ebenso wie unterschiedliche Window-Operationen. Flink verfolgt dabei einen nativen Streaming-Ansatz und erreicht somit niedrige Latenzen. Ebenso wie bei Spark Streaming wird eine deklarative API genutzt, mit der M√∂glichkeit sogenannte Rich Functions zu nutzen, in denen beispielsweise ein State genutzt wird. Im Gegensatz zu Spark k√∂nnen verschiedene State-Implementierungen genutzt werden: In-Memory, Festplatte oder RocksDB. Flink ist etwas j√ºnger als Spark, gewinnt aber zunehmend an Verbreitung. Ebenso wachsen die Community und das √ñkosystem stetig, sind allerdings noch nicht so gro√ü wie bei Spark. Apache Kafka Streams Das Streaming Framework aus dem Kafka-√ñkosystem ist der j√ºngste Vertreter in dieser √úbersicht. Es basiert auf vielen Konzepten, die bereits in Kafka enthalten sind, wie beispielsweise die Skalierung durch Partitionierung der Topics. Auch aus diesem Grund kommt es als leichtgewichtige Bibliothek daher, die in eine Anwendung eingebunden werden kann. Die Anwendung kann dann nach belieben betrieben werden: Standalone, in einem Applikationsserver, als Docker Container oder √ºber einen Resourcen Manager wie Mesos. Flink & Spark hingegen ben√∂tigen immer ein Cluster, entweder ein mit den Boardmitteln der Frameworks gebautes oder aber YARN/Mesos. Kafka Streams ist allerdings beschr√§nkt auf Kafka als Quelle und auch als Senke. Die Konnektivit√§t zu anderen Systemen wird dann √ºber Kafka Connect hergestellt. Ansonsten besitzt Kafka Streams neben einer deklarativen auch eine komponentenorientierte API, eine rudiment√§re Unterst√ºtzung von Eventtime sowie RocksDB als State-Implementierung. W√§hrend Kafka selbst schon sehr reif ist und h√§ufig auch in Verbindung mit Flink und Spark genutzt wird, ist die Streaming-Komponente noch recht jung. So ist auch die Community eher klein und die Verbreitung eher gering. Es ist aber zu erwarten, dass beides zeitnah wachsen wird.Update:Kafka Streams nutzt die Konzepte des Beam Models, um den Herausforderungen des Eventzeit Handlings zu begegnen. Streams wird entwickelt auf dem Konzept von¬†KTables und¬†KStreams, welches genutzt wird, um Eventzeit Verarbeitung zu unterst√ºtzen.Und was passt zu mir?Nun bleibt zum Schluss die Frage: Welches Framework passt zu mir? Wenn Eventzeit-Verarbeitung ben√∂tigt wird, f√ºhrt aktuell fast kein Weg an Flink vorbei. Ein weiterer Pluspunkt ist die niedrige Latenz. Die wichtigsten Umsysteme (Kafka, Cassandra, Elasticsearch, SQL-Datenbanken) k√∂nnen relativ einfach integriert werden.Die niedrige Latenz und einen einfach zu nutzenden Eventzeit Support¬†erm√∂glicht auch Kafka Streams. Wenn also Kafka bereits im Einsatz ist und die Verarbeitung eher einfach ist, ohne komplexe Anforderungen an Eventzeit-Verarbeitung, ist Kafka Streams eine gute Alternative. Daf√ºr muss ich hier noch die Umsysteme √ºber Kafka Connect anbinden und mich um die Laufzeitumgebung k√ºmmern. Dies kann aber auch ein Vorteil sein, wenn ich vorhandene Tools, zum Beispiel aus dem Docker-√ñkosystem, nutzen kann.Und Spark? Wenn Eventzeit nicht relevant ist und auch Latenzen im Sekundenbereich akzeptabel sind, ist Spark die erste Wahl. Es ist stabil und fast jedes beliebige Umsystem kann einfach eingebunden werden. Au√üerdem ist es bei Hadoop-Installationen schon vorhanden. Zudem kann der Code, der f√ºr Batch-Anwendungen genutzt wird, bei Bedarf auch f√ºr die Streaming-Anwendungen verwendet werden, da die API dieselbe ist. Lediglich bei sehr gro√üen States im Terrabyte-Bereich kann es bei Spark zu Problemen kommen. Die Unterst√ºtzung f√ºr Eventzeit wird mit Spark 2.1 deutlich erweitert.FazitStream Processing Frameworks vereinfachen die Verarbeitung gro√üer Datenmengen signifikant. Die vorgestellten Frameworks l√∂sen dabei vor allem Probleme im Bereich der verteilten Verarbeitung wodurch einfach zu skalierende L√∂sungen entwickelt werden k√∂nnen. Ebenso wichtig sind die unterschiedlichen Aspekte der Zeitverarbeitung, die alle Frameworks unterst√ºtzen. Hier unterscheiden sich Systeme auch am deutlichsten von Bibliotheken wie Akka Streams, RxJava oder Vert.x. Die vorgestellten Frameworks sind vor allem im Big- und Fast-Data-Bereich angesiedelt, w√§hrend mit den Bibliotheken auch einfach kleinere reaktive Anwendungen gebaut werden k√∂nnen ‚Äì dann allerdings in der Regel ohne native Unterst√ºtzung f√ºr Eventzeit und Clustering.So bleibt festzuhalten, dass die vorgestellten Framework allesamt bei aktuellen Herausforderungen im Fast-Data-Bereich unterst√ºtzen k√∂nnen und dabei auch neue Architekturen jenseits der bekannten Lambda-Architektur unterst√ºtzen. Dabei ist die Komplexit√§t dieser verteilten System allerdings keinesfalls zu untersch√§tzen. Dennoch ist davon auszugehen, dass die Verbreitung der Systeme ebenso wie die Funktionalit√§t weiter zunehmen wird. Dieser Artikel erschien zuerst im Softwerker, dem kostenfreien Magazin der codecentric.Links[1] http://nathanmarz.com/blog/how-to-beat-the-cap-theorem.html[2] https://www.oreilly.com/ideas/questioning-the-lambda-architecture[3] https://www.oreilly.com/ideas/the-world-beyond-batch-streaming-102                                                                      TagsbigdatafastdataflinkkafkaSparkSparkstreamingMatthias Niehoff Matthias ist als Data Architect sowie Head of Data & AI f√ºr die codecentric unterwegs und unterst√ºtzt Kunden bei Design und Umsetzung von Datenarchitekturen. Dabei liegt sein Fokus weniger auf dem Modell, sondern viel mehr auf der notwendigen Infrastruktur & Organisation, um Daten & KI Projekte zum Erfolg zu verhelfen.                                                                        Wachse mit uns. Wir m√∂chten uns gerne bei dir bewerben! Oder war es andersherum? Zum Bewerberportal   Techie sch√∂n und gut‚Ä¶ ‚Ä¶ Wir haben noch mehr auf dem Kasten ‚Äì und am liebsten l√∂sen wir deine Probleme. mehr erfahren  Die neuesten Tipps, Tricks, Tools und Technologien. Jede Woche direkt in deine Inbox. Kostenfrei anmelden und immer auf dem neuesten Stand bleiben! (Keine Sorge, du kannst dich jederzeit abmelden.)  Artikel von Matthias NiehoffAllgemeinMachine Learning in der Praxis. Eine Mate mit ‚Ä¶ Matthias Niehoff #EineMateMitLookup additional data in Spark StreamingWeitere Inhalte zu Architektur Architektur Site Reliability Engineering: Software in Produktion betreiben Architektur Automatisch skaliertes Cloud Native Consent Management in der Google Cloud Kommentieren Antworten abbrechenDeine E-Mail-Adresse wird nicht ver√∂ffentlicht. Erforderliche Felder sind mit * markiert Meinen Namen, meine E-Mail-Adresse und meine Website in diesem Browser speichern, bis ich wieder kommentiere.  StartseiteKontaktDatenschutzerkl√§rungBlogNewsletteranmeldung Bleiben Sie immer auf dem neuesten Stand! Newsletter abonnierenKontaktformular Sie haben Fragen oder Anregungen? Nutzen Sie unser Kontaktformular! Kontaktieren Sie uns      Tweets by @codecentric   XLeistungenKarriereWissenBlogAktuelles√úber unsEnglishHDP Operations: Administration Foundations ‚Äì Schulung auf Anfrage                 
