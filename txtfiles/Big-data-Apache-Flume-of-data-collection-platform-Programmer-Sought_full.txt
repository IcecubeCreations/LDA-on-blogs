









Big data: Apache Flume of data collection platform - Programmer Sought











ProgrammerSought


Home
Contact Us
Privacy Policy


☰ 





















Big data: Apache Flume of data collection platform












Big data: Apache Flume of data collection platform



 Apache Flume For details, please read the article: "Big data: Apache Flume of data collection platform》 
 Fluentd For details, please read the article: "Big data: Fluentd of data collection platform》 
 Logstash For details, please read the article: "Big data: Logstash for data collection platforms》 
 Apache Chukwa For details, please read the article: "Big data: Apache Chukwa of the data collection platform 》 
 Scribe For details, please read the article: "Big data: Scribe for data collection platform 》 
 Splunk Forwarder For details, please read the article: "Big data: Splunk Forwarder of data collection platform》 


Official website: https://flume.apache.org/
Flume It is an open source, high-reliability, high-expansion, easy-to-manage, and supports customer expansion data collection system under Apache. Flume is built using JRuby, so it depends on the Java runtime environment.
Flume was originally designed by Cloudera's engineers as a system for merging log data. Later, it was gradually developed to handle streaming data events.  Flume is designed as a distributed pipeline architecture, which can be seen as an agent network between the data source and destination, supporting data routing.  Each agent is composed of Source, Channel and Sink.

 Source: Source is responsible for receiving input data and writing the data to the pipeline. Flume's Source supports HTTP, JMS, RPC, NetCat, Exec, Spooling Directory. Spooling supports monitoring a directory or file and parsing newly generated events. 
 Channel: Channel storage, cache intermediate data from source to Sink. You can use different configurations to do Channel, such as memory, files, JDBC, etc. The use of memory has high performance but is not persistent, and data may be lost. Using files is more reliable, but performance is not as good as memory. 
 Sink: Sink is responsible for reading data from the pipeline and sending it to the next Agent or the final destination. The different destination types supported by Sink include: HDFS, HBASE, Solr, ElasticSearch, File, Logger, or other Flume Agents. 

Flume uses the transaction mechanism on both the source and sink sides to ensure that no data is lost during data transmission.  The data on Source can be copied to different channels. Each Channel can also connect a different number of sinks. In this way, Agents with different configurations can be connected to form a complex data collection network. Through the configuration of the agent, a data transmission network with complex routing can be formed.  Configure the agent structure as shown in the above figure. Flume supports setting the failover and load balance of the sink, so that even if one agent fails, the entire system can still collect data normally.
The content transmitted in Flume is defined as an event, which consists of headers (including metadata, meta data) and payload.  Flume provides SDK, which can support user customized development:
The Flume client is responsible for sending events to the Flume Agent at the source of the event. The client is usually in the same process space as the application that generated the data source. Common Flume clients include Avro, log4J, syslog, and HTTP Post. In addition, ExecSource supports specifying the output of a local process as the input of Flume. Of course, it is very likely that none of the above clients can meet the needs. Users can customize the client to communicate with the existing FLume Source or customize a new Source type.
At the same time, users can use Flume's SDK to customize Source and Sink. It seems that customized channels are not supported. 
reference:

Copyright Complaint      
Spam Report










Intelligent Recommendation










flume+hadoop+hive big data collection and processing



Introduction: The overall architecture of the entire offline analysis is to use Flume to collect log files from an FTP server and store them on the Hadoop HDFS file system, then use Hadoop's mapreduce...















Big Data: Apache Chukwa for data acquisition platform



Big Data: Apache Chukwa for data acquisition platform Apache Flume For details, please see the article:Big Data: Apache Flume for Data Acquisition Platform》 Fluentd For details, please see the article...















Flume of Big Data: Overview of Flume



Flume overview 1.1 Flume definition Flume is a highly available, highly reliable, distributed mass log collection, aggregation and transmission system provided by Cloudera. Flume is based on a streami...















Flume of big data: Flume topology



Simple series Figure 1-3 Flume Agent connection This mode connects multiple flumes sequentially, starting from the initial source to the destination storage system of the final sink. This mode is not ...















Flume of Big Data: Flume Advanced



1.Flume transaction 2 Internal Principles of Flume Agent Important components: 1）ChannelSelector The role of ChannelSelector is to select which Channel the Event will be sent to. There are two types, ...











More Recommendation










Application Apache Kylin big data platform in 4399



Background Before you begin sharing case, briefly explain big data teams of 4399 and 4399 4399 is China's first and leading online casual gaming platform, up to more than 20 million daily active \ t 4...















The practice of Apache Kylin in GAIA big data platform



The practice of Apache Kylin in GAIA big data platform More dry goods Distributed combat (dry goods) spring cloud actual combat (dry goods) mybatis actual combat (dry goods) Spring boot actual combat ...











Big data Hadoop platform construction (Apache)



Hadoop environment construction 1. Node details server Configuration Component hadoop101 8 cores/16.0GB QuorumPeerMain,PrestoServer,Kafka,DataNode,NodeMananger,worker(spark) hadoop102 8 cores/16.0GB Q...















Big Data: A brief overview of the data collection platform



Big Data: A brief overview of the data collection platform First, the understanding of the data acquisition platform Any complete big data platform generally includes the following processes: Data Acq...















Big data: Splunk Forwarder of data collection platform



Big data: Splunk Forwarder of data collection platform Apache Flume For details, please read the article: "Big data: Apache Flume of data collection platform》 Fluentd For details, please read the...















Related Posts
Big data platform-flume development
Deploy Flume for big data collection
Flume data collection framework for big data
Distributed construction of big data platform-Flume deployment
Flume of big data platform operation and maintenance
FLUME installation for CHD big data platform
Big data technology stack_data collection (flume, sqoop)
Big Data-Flume Collection Case Agent Cascading
Big data-Flume collection directory to HDFS
Sunflower Collection of Big Data Interview Questions------flume






Popular Posts
Several ways of eS6 export
Introduction to Spring's three basic components
form an encrypted form the background foreground js java
Spring framework learning three (type data injection)
spring-datesource.xml configuration, spring integration mybatis
Leetcode 592. Score Adjusting C ++
LeetCode2 Add Two Numbers
Introduction to database integrity [Chapter] mind mapping database system
ResNet101V2 network structure
[Minimum path coverage]hdoj 3335: Divisibility






Recommended Posts
Solve Selenium.common.Exceptions.webdriveRexception: Message: Unknown Error: Cannot Find Chrome Binary
JS references text information in the outermost JS
The realization of Window, WindowManager and floating frame video playback in Android
Design Mode - Component mode
Java foundation (20) (thread pool, waiting wake-up mechanism, Voliate keyword, single case design pattern "lazy mode" "Hungry Mode")
Apache common interview
leetcode209. The smallest length sub-array/double pointer, prefix sum, dichotomy
[0CTF 2016]piapiapia
Java string interview questions and answers
Mina develops an example of the udp protocol





Related Tags
Big DataflumeBig data seriesData collection toolssqoopAgent CascadeFlume capture directory to HDFSBig data ------ interview questionsInterviewdata collection








 Copyright  DMCA © 2018-2022 - All Rights Reserved - www.programmersought.com  User Notice 


Top












