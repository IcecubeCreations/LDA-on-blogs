







Streaming Daten: Einführung und Frameworks - datasolut GmbH

























































 



























 












Home
KI Use Cases
Lösungen

Next Best Offer
Kundensegmentierung
Customer Lifetime Value
Kundenanalyse
Forecasting und Prognose


Über uns
Blog
 

 Menü


Home
KI Use Cases
Lösungen

Next Best Offer
Kundensegmentierung
Customer Lifetime Value
Kundenanalyse
Forecasting und Prognose


Über uns
Blog
 













KI-Projekt starten





















 












Home
KI Use Cases
Lösungen
Über uns
Blog
Kontakt
 

 Menü


Home
KI Use Cases
Lösungen
Über uns
Blog
Kontakt
 

















 







Streaming Daten: Einführung und Überblick wichtiger Frameworks 























 











										Laurenz Wuttke					




 


Big Data 







Streaming Daten sind Daten, die mit einem Streaming Framework in „Echtzeit“ verarbeitet werden. Der Unterschied zum reinen Message Processing ist, dass du komplexe Operationen (Aggregationen, Joins etc.) auf den Datenströmen anwenden kannst.
Streaming Daten sind im Big Data Umfeld ein interessantes Entwicklungsfeld, welches sich rapide weiterentwickelt und in vielen Use Cases einen Mehrwert bringt.
In diesem Artikel gebe ich einen tiefen Einblick in die grundlegenden Aspekte, die für Streaming Daten relevant sind und gehe auf die bekanntesten Streaming Daten Frameworks ein.
Was sind Streaming Daten?Arten von Streaming DatenWichtige Aspekte bei Streaming DataStreaming Data Frameworks im VergleichStreaming Daten Use Cases im MarketingStreaming Analytics
Was sind Streaming Daten?
Streaming Daten sind Daten, die ununterbrochen von Quellsystemen generiert und in kleinen Paketen verschickt werden. Ein Big Data Streaming Framework nimmt diesen Stream entgegen und verarbeitet die Informationen im Arbeitsspeicher, bevor diese dann auf eine Fettplatte geschrieben werden.
“a type of data processing engine that is designed with infinite data sets in mind. Nothing more.”Tyler Akidau Software Engineer at Google
Streaming Daten können aus verschiedensten Systemen kommen: Log-Daten aus einem ERP-System, E-Commerce Events (Views, Orders, Baskets), Tracking-Events auf Mobile Apps, Geolocations aus Webanwendungen, Geschäftsvorfälle aus Kundencentern oder Nutzungsdaten von bestimmten Produkten. 
All diese Informationen können mit Streaming-Daten schneller bereitgestellt und verarbeitet werden.
Arten von Streaming Daten
Grundsätzlich lassen sich Streaming Daten in zwei verschiedene Streaming Arten unterscheiden: Natives Streaming (native streaming) und Micro-Batching . Folgend gehe ich auf die Unterschiede dieser zwei Arten ein.
Natives Streaming
Beim nativen Streaming wird jeder ankommende Datensatz von der Streaming Engine sofort verarbeitet, ohne auf andere Datensätze zu warten (Einzelsatzverarbeitung). Natives Streaming reagiert schneller auf einkommende Datensätze, was für eine geringere Latenz und mehr Durchsatz führt. 

Native Streaming Frameworks: Apache Storm, Apache Flink, Kafka Streams, Samza (und Spark Continuous Processing Experimental Release in Apache Spark 2.3.0)
Micro-Batching
Bedeutet, dass alle paar Millisekunden/Sekunden ein Batch ausgeführt wird. Dadurch entsteht ein kleiner Zeitverzug. 

Frameworks: Apache Spark, Apache Storm Trident
Native Streaming vs. Micro Batching
Beide Typen haben Vor- und Nachteile. Natives Streaming hat den Vorteil, dass es sehr geringe Latenzen erreichen kann. Gleichzeitig bedeutet dies, dass es schwer ist eine hohe Fehlertoleranz zu erreichen, ohne dabei auch den Durchsatz zu mindern (Checkpoints müssen geschrieben werden etc.). Zustandsmanagement hingegen ist bei nativem Streaming einfach.
Micro-Batching, verarbeitet die Daten in kleinen Batches und hat den Vorteil, dass dadurch die Fehlertoleranz gegeben ist. Auch der Durchsatz ist per se nicht schlecht. Effizientes Zustandsmanagement ist eine Herausforderung für die Entwickler.
Native StreamingMicro-BatchingDatensätze werden bei Ankunft verarbeitet– geringerer Durchsatz+ geringe Latenz– Fehlertoleranz ist ressourcenintensivDatensätze werden in kleinen Batches verarbeitet+ höherer Durchsatz– höhere Latenz+ einfachere Fehlertoleranz
Wichtige Aspekte bei Streaming Data
Um die Big Data Streaming Frameworks mit den einzelnen Stärken und Schwächen zu verstehen, ist es wichtig, dass wir kurz über die unterschiedlichen Aspekte von Streaming Daten und Probleme, die in der Streamverarbeitung auftreten, reden.
Fehlertoleranz: Im Falle eines Fehlers, wie bspw. Node-Fehler, Netzwerkprobleme, sollte das Framework in der Lage sein, den Prozess ab dem Punkt neu zu starten, an welchem der Prozess gestoppt wurde. Das kann durch so genannte Checkpoints erreicht werden, indem Metadaten zu den verarbeiteten Daten geschrieben werden. So wird der Offset ab dem Checkpoint wieder geladen.State Management: Beim Zustandsmanagement wird ein Zustand gespeichert (bspw. Counts über verschiedene Schlüssel in einer bestimmten Zeitspanne), hier sollte das Framework in der Lage sein den Zustand zu halten und ein Update durchzuführen.Garantierte Verarbeitung: Es gibt grundsätzlich 3 unterschiedliche Arten von Stream Verarbeitung:Bei Atleast-once wird der Datensatz auf jeden Fall einmal verarbeitet – auch bei Cluster-Fehlern.Atmost-once kann die Verarbeitung nicht garantieren.Bei Exactly-once wird die einmalige Verarbeitung garantiert und ist somit die präferierte Variante. Oft leidet die Performance unter diesem Ziel.Geschwindigkeit: Beschreibt die Latenz, mit der ein Datensatz verarbeitet wird (Zeilen pro Sekunde) und die Möglichkeit der Skalierung bei mehr Last. Die Latenz sollte so gering wie möglich und der Durchsatz so hoch wie möglich sein. Beide zu erreichen ist oft schwer, daher geht es um eine gute Balance.Entwicklungsstand-/Marktreife: Im Streamingmarkt gibt es viele „neue“ Player, die verschiedene Ansätze verfolgen. Wichtig ist es bei der Auswahl, auf ein Framework zu setzten, welches bei großen Unternehmen erfolgreich in die Produktion implementiert wurde. Auch eine große Community hilft dabei, das Framework weiterzuentwickeln und ggf. Hilfe aus der Community zu bekommen.Weitere Features: Um komplexe Logik auf Streams abzubilden, brauchst du bestimmte Funktionen:Event Time Processing bezeichnet die Verarbeitung basierend auf der Eventerzeugungszeit. Manche Streaming Frameworks bieten diese Funktion nicht an und verarbeiten nach Ankunftszeitpunkt.Zeitfenster Funktionen (Windowing) sind Aggregationen über ein bestimmtes Zeitfenster (bspw. sum(revenue) in last 4h)Anwendung von analytischen Modellen im Stream. Natürlich bieten einige Streaming Frameworks auch die Möglichkeit der Anwendung eines Machine Learning Modells im Stream.
Streaming Data Frameworks im Vergleich
FrameworkVorteileNachteileApache Storm(Native Streaming)– Natives Streaming– geringe Latenz– hoher Durchsatz– gut für nicht komplexe Streaming Use Cases – Keinen impliziten Support für Zustandsmanagment– keine Feature für Aggregationen, Windows etc.– Verarbeitung nur Atleast-onceApache Spark Structured Streaming(Micro-batching)– Unterstützt Lambda-Architektur– hoher Durchsatz– hohe Fehlertoleranz– einfaches API– große Community– Verarbeitung Exactly Once– Kein nativer Stream– viele Parameter zum Tunen von Streams– Stateless– ist hinter Flink in Bezug auf Advanced FeaturesApache Spark Continuous Processing(Native Streaming) – Unterstützt Lambda-Architektur– hoher Durchsatz– hohe Fehlertoleranz– einfaches API– große Community– Verarbeitung Exactly Once – Weniger Funktionen verfügbar (groupBy etc.) – stark in den AnfängenApache Flink(Native Streaming)– Unterstützt Lambda– Führer in Streaming Umfeld– geringe Latenz und hoher Durchsatz– nicht zu viele Parameter (Auto-adjusting)– Verarbeitung Exactly Once– Späte Entwicklung daher Nachteil im Markt– kleinere Community als Spark– keine Adaption für Batch ModusKafka Streams(Native Streaming)– Kleine einfache API daher gut für Microservices– gute für IoT– Exactly Once– braucht kein dediziertes Cluster – Sehr nah an Kafka (ohne geht’s nicht)– muss sich noch beweisen– keine riesen Prozesse möglich = eher einfache LogikSamza(Native Streaming)– Einfaches API– Gut darin große Zustände von Streams zu speichern (gut für Joins von Streams)– hohe Fehlertoleranz– hoch performant– Starke Verbundenheit zu Kafka und Yarn– Atleast-once processing– wenig erweiterte Streaming Funktionen(Watermarks, Triggers, Sessions)
Streaming Daten Use Cases im Marketing
Streaming Daten sind noch ein sehr neues Thema, welches sich zurzeit stark weiterentwickelt. Für viele Unternehmen sind Use Cases mit Streaming Daten noch Ideen oder Uses Cases, die in kleinen Proof of Concept Projekten erprobt werden. Zunehmender Einsatz von Big Data Plattformen, fördert das Thema allerdings stark und viele Unternehmen zeigen Interesse.
Besonders im Marketing sind die Use Cases nicht so offensichtlich wie im IoT Bereich, aber auch im Marketing gibt es interessante Use Cases:
Personalisierung E-Commerce Checkout: Um die richtige Empfehlung im Checkout Prozess anbieten zu können, braucht man die neusten Daten in Real Time. Dazu zählt die Klickhistorie aus der aktuellen Session, der aktuelle Warenkorb und gespeicherte Interaktionen aus einer längeren Historie. Um hier die richtige Empfehlung abzugeben braucht das Machine Learning Modell die Daten im Moment des Checkouts, so können die wichtigen Sessioninformationen einen UpLift bringen.Streaming ETL: Oft ist die Nacht zu kurz für die bestehenden ETL-Strecken. Auch hier können interessante Use Cases mit Streaming Daten umgesetzt werden. Die Daten können sofort mit Big Data Streaming Frameworks verarbeitet, wertvolle Zeit gespart und Entscheidungen schneller getroffen werden. Hier ist ein interessantes Video zu Streaming-ETL. Trigger Marketing Kampagnen: Die Informationen schnell zu verarbeiten ist ein Wettbewerbsvorteil. Mit Data Streaming können bestimmte Kundenevents in Echtzeit bearbeitet werden um somit den Kunden anlassbezogen über ein Event, anstatt in einer Massenkampagne, anzusprechen.
Streaming Analytics
Streaming Analytics stellt Machine Learning Modelle im Stream bereit, sodass ein Modell Scoring auf die gerade eintreffenden Streaming Daten durchgeführt wird.
Für komplexe Architekturen und Use Cases werden anschließend oft Machine Learning Features für jeden Kunden vorberechnet und in einem Feature Store gespeichert. Bei einem eintreffenden Datensatz wird dann das Profil in Echtzeit abgefragt und mit dem Stream gejoined. Durch die weiteren Informationen, die man bspw. zu einem Kunden hat, kann das Modell mit historischen Daten angereichert und angewendet werden. 
Streaming Analytics wird im Marketing vor allem im Bereich der Personalisierung von Diensten und Online Shops eingesetzt. Jede neue Interaktion führt zu einem neuen Ergebnis im Recommender System und damit zu veränderten Empfehlungen. 

Weitere interessante Artikel:
Künstliche Intelligenz (KI) im B2B Marketing: Anwendung & Praxisbeispiele
Customer Lifetime Value (CLV): Erklärung, Berechnung und Vorteile.
Was macht ein Data Engineer? Überblick über das Berufsbild
Customer Data Platform – Funktionen, Vorteile und Unterschiede
Machine Learning vs. Deep Learning: Wo ist der Unterschied?













Ihr Kontakt: Laurenz Wuttke 




Unternehmen sitzen auf einem ungenutzten Berg von Kundendaten. Wir von datasolut entwickeln KI, die Ihr Marketing optimiert. Damit Sie dem richtigen Kunden zur richtigen Zeit das richtige Angebot machen können. 







Termin vereinbaren














 










Auch interessant für Sie 










				Customer Lifetime Value (CLV): Erklärung, Berechnung und Vorteile.			


			Weiterlesen »		









				Kundensegmentierung: Definition, Methoden und Vorgehen.			


			Weiterlesen »		









				Next Best Offer (NBO): für jeden Kunden das richtige Angebot?			


			Weiterlesen »		









				CRM-Kennzahlen Ratgeber: Die wichtigsten KPI’s im Überblick			


			Weiterlesen »		









				Künstliche Intelligenz im Vertrieb: Vorteile, Nutzen und Anwendungsmöglichkeiten			


			Weiterlesen »		









				Machine Learning: Definition, Algorithmen, Methoden und Beispiele			


			Weiterlesen »		









				Data Mining: Algorithmen, Definition, Methoden und Anwendungsbeispiele			


			Weiterlesen »		









				Künstliche Intelligenz (KI) im Marketing: Anwendung und Beispiele			


			Weiterlesen »		









				Personalisierung im Marketing: Definition, Vorteile und Beispiele			


			Weiterlesen »		









				Künstliche Intelligenz im CRM			


			Weiterlesen »		









				Kundendaten: sammeln, richtig nutzen und Anwendungen im Marketing.			


			Weiterlesen »		









				Kundenwert: wie wertvoll ist jeder einzelne Kunde?			


			Weiterlesen »		









				Kohortenanalyse: Definition, Anwendungsfälle und Beispiel			


			Weiterlesen »		









				ABC-Analyse: Definition, Berechnung und Beispiele			


			Weiterlesen »		









				Churn Rate: Definition, Gründe und Berechnung für Kundenabwanderung			


			Weiterlesen »		









				RFM-Analyse: Marketing optimieren durch intelligente Segmentierung			


			Weiterlesen »		









				Kundenanalyse: Methoden, Nutzen und Beispiele			


			Weiterlesen »		









				Churn Prevention: Kundenabwanderung durch gezielte Maßnahmen senken			


			Weiterlesen »		









				Künstliche Intelligenz (KI) im B2B Marketing: Anwendung & Praxisbeispiele			


			Weiterlesen »		









				Was macht ein Data Engineer? Überblick über das Berufsbild			


			Weiterlesen »		


























 





datasolut GmbH - Mehr Wert mit KI. 






 
hello@datasolut.com



 
+49 221 17040365









Linkedin
 



Youtube
 



Xing
 



Facebook-f
 






Mitglied im KI-Bundesverband: 





 











Navigation 






Lösungen





 
KI Use Cases




Über uns




Karriere




Kontakt




Blog




datasolut Wiki













Unsere Lösungen 






Kundenanalyse




Churn Management




Customer Lifetime Value (CLV)




Next Best Offer (NBO)




Kundensegmentierung





 
Forecasting













Blog 











				Künstliche Intelligenz (KI) im Marketing: Anwendung und Beispiele			










				Kundenanalyse: Methoden, Nutzen und Beispiele			










				Churn Prevention: Kundenabwanderung durch gezielte Maßnahmen senken			










				Customer Lifetime Value (CLV): Erklärung, Berechnung und Vorteile.			










				Kundensegmentierung: Definition, Methoden und Vorgehen.			










				Next Best Offer (NBO): für jeden Kunden das richtige Angebot?			










				CRM-Kennzahlen Ratgeber: Die wichtigsten KPI’s im Überblick			










				Künstliche Intelligenz im Vertrieb: Vorteile, Nutzen und Anwendungsmöglichkeiten			










				Machine Learning: Definition, Algorithmen, Methoden und Beispiele			










				Data Mining: Algorithmen, Definition, Methoden und Anwendungsbeispiele			










				Personalisierung im Marketing: Definition, Vorteile und Beispiele			










				Künstliche Intelligenz im CRM			










				Kundendaten: sammeln, richtig nutzen und Anwendungen im Marketing.			










				Kundenwert: wie wertvoll ist jeder einzelne Kunde?			










				Kohortenanalyse: Definition, Anwendungsfälle und Beispiel			










				ABC-Analyse: Definition, Berechnung und Beispiele			










				Churn Rate: Definition, Gründe und Berechnung für Kundenabwanderung			










				RFM-Analyse: Marketing optimieren durch intelligente Segmentierung			




















© 2020 datasolut 












Impressum




Datenschutzerklärung










































 










Download:  



KI Use Cases für Marketing und Vertrieb 






 
Mehr Umsatz durch gezielte Vorhersagen



 
Durch Automatisierung mehr Zeit gewinnen



 
Budget und Ressourcen gezielt einsetzen






Jetzt eintragen und spannende KI-Projektbeispiele aus der Praxis erhalten: 











								Email							







Jetzt PDF herunterladen










				Mit der Anmeldung stimmen Sie unserer Datenschutzerklärung zu. 					



















































