





  




Real-time data processing with data streaming: new tools for a new era | InfoWorld























































































































infoworld

UNITED STATES 


United States 


United Kingdom 















Welcome! Here are the latest Insider stories.

Review: Redpanda gives Kafka a run for its money
Review: YugabyteDB does PostgreSQL proud
Review: Databricks Lakehouse Platform 
Review: The 10 best JavaScript editors


More Insider
Sign Out




Sign In
Register
























Sign Out

Sign In
Register









NEW Insider PRO
								Learn More



Latest Insider

Review: The 6 best JavaScript IDEs
15 tools that make Kubernetes easier
13 tools that make Kubernetes better
How to evaluate software asset management tools



NEW FROM IDG

Learn More
















Welcome! Check out the latest Insider stories here.
Sign Out

Sign In
Register







More from the Foundry Network








About Us |
Contact |
Republication Permissions |
Privacy Policy |
Cookie Policy |
Member Preferences |
Advertising |
Foundry Careers |
Ad Choices |
E-commerce Links |
California: Do Not Sell My Personal Info |


Follow Us


















×





Close












How to choose a streaming data platform





				RELATED STORIES
			




What is streaming data? Event stream processing explained




SPONSORED BY Advertiser Name Here
Sponsored item title goes here as designed




What is a data lake? Flexible big data management explained




What is Apache Kafka? Scalable event streaming






















Home
Data Management



Real-time data processing with data streaming: new tools for a new era

Real-time data streaming is still early in its adoption, but over the next few years organizations with successful rollouts will gain a competitive advantage














































By Isaac Sacolick


						
							Contributing Editor, 
								
									
								












InfoWorld |



























					    					
							    				
							    				Thinkstock
						    				
				
							    			
							    				
							    				
							    				
												
												  	
												
												  	
												
												  	
												
												  	
												
												  	
												
												  	
												
												  	
												
												  	
												
												  	
												
												  	
												
												  	
												
												  	
												
							    				
							    				
												
											
									
										




















Today, there are many data sources—such at IoT devices, user interaction events from mobile applications, financial service transactions, and health monitoring systems—that broadcast critical information in real time. Developers working with these data sources need to think about the architecture to capture real time streaming data at varying scales and complexities.It used to be that processing real time information at significant scale was hard to implement. Hardware architectures needed to be engineered for low latency while software needed more advanced programming techniques that combined receiving data, processing it, and shipping it efficiently.[ The essentials from InfoWorld: What is Apache Spark? The big data analytics platform explained • Spark tutorial: Get started with Apache Spark • What is data mining? How analytics uncovers insights. | Cut to the key news and issues in cutting-edge enterprise technology with the InfoWorld Daily newsletter. ]The paradigm shift in data processingI recently attended the Strata Data Conference and discovered a paradigm shift: There are multiple frameworks (both open source and commercial) that let developers handle data streaming or real time data-processing payloads. There are also commercial tools that simplify the programming, scaling, monitoring, and data management of data streams.The world isn’t batch anymore, and the tools to process data streams is a lot more accessible today than just two or three years ago.Today’s the tools, architectures, and approaches all are very different from those used historically for data integration and data warehousing, which grew up during an era of batch processing. You developed scripts or jobs that extracted data mostly from flat files, transformed it into a usable structure, and loaded it into a database or other data-management system. These ETL (extract, transform, load) scripts were deployed directly to servers and scheduled to run with tools like Unix cron, or they were services that ran when new data was available, or they were engineered in an ETL platform from Informatica, Talend, IBM, Microsoft, or other provider.


To continue reading this article register now
Get Free Access

Learn More   Existing Users Sign In









 How to choose a low-code development platform
























InfoWorld
 

Follow us














About Us
Contact
Republication Permissions
Privacy Policy
Cookie Policy
Member Preferences
Advertising
Foundry Careers
Ad Choices
E-commerce Links
California: Do Not Sell My Personal Info







Copyright © 2022 IDG Communications, Inc.


Explore the Foundry Network descend

CIO
Computerworld
CSO Online
InfoWorld
Network World











































