











Growing EAI with Apache Camel































































BT









Live Webinar and Q&A: Streaming SQL on Apache Kafka for Real-Time Processing (Live Webinar May 26th, 2022)

                            Register Now
                        



Close
                    





Toggle Navigation 





                        Facilitating the Spread of Knowledge and Innovation in Professional Software Development
                    

English edition 




English edition
Chinese edition
Japanese edition
French edition






                        Contribute
                    





Search








Sign Up / Login











Email



Password





Forgot password ?




InfoQ Account Email





Back to login




Resend Activation





Back to login




Login with:

Google
Microsoft
Twitter
Facebook



Don't have an InfoQ account?
Sign Up







Notifications1




Login to unlock InfoQ's new features





Stay up to date and get notified
Like your favorite content
Follow your favorite editors and peers

Sign Up / Login
Don't have an account? Register Here









                        Logo - Back to homepage
                    

		
			
			
			
		2,429,182 Apr unique visitors
	


News
Articles
Presentations
Podcasts
Guides



Topics


Development


Java
Kotlin
.Net
C#
Swift
Go
Rust
JavaScript




Featured in  Development







Reproducible Development with Containers

Avdi Grimm describes the future of development, which is already here. Get a tour of a devcontainer, and contrast it with a deployment container.








All in  development




Architecture & Design


Architecture
Enterprise Architecture
Scalability/Performance
Design
Case Studies
Microservices
Service Mesh
Patterns
Security




Featured in  Architecture & Design







Oren Eini on RavenDB, including Consistency Guarantees and C# as the Implementation Language

Wesley Reisz talks to Oren Eini about the history of RavenDB. RavenDB is a fully transactional NoSQL Document database that implements both CP and AP guarantees at different times. The two discuss those CP/AP distributed systems challenges, the choice of implementation language (C#), and the current plans for RavenDB 6.0, which includes a server-side sharding implementation.








All in  architecture-design




AI, ML & Data Engineering


Big Data
Machine Learning
NoSQL
Database
Data Analytics
Streaming




Featured in  AI, ML & Data Engineering







Machine Learning at the Edge

Katharine Jarmul discusses utilizing new distributed data science and machine learning models, such as federated learning, to learn from data at the edge.








All in  ai-ml-data-eng




Culture & Methods


Agile
Diversity
Leadership
Lean/Kanban
Personal Growth
Scrum
Sociocracy
Software Craftmanship
Team Collaboration
Testing
UX




Featured in  Culture & Methods







How to Run Your Product Department Like a Coach

Having found what I thought was my calling as an agile coach, I took the tough decision to move sideways into Product Management in the hope of using what I’d learned to one day run my own department. I believed that coming from coaching would allow me to see things others could not and create something special. Time will tell if I have succeeded, this is the story of where I am up to so far.








All in  culture-methods




DevOps


Infrastructure
Continuous Delivery
Automation
Containers
Cloud
Observability




Featured in  DevOps







Panel: Secure Systems

The panelists discuss the security for the software supply chain and software security risk measurement.








All in  devops




EventsNew




Helpful links



                About InfoQ
            



                InfoQ Editors
            



                Contribute
            



                About C4Media
            


Diversity




Choose your language

En
中文
日本
Fr










InfoQ Live June
Learn how cloud architectures achieve cost savings, improve reliability & deliver value. Register Now.





InfoQ Live July
Learn how to migrate an application to serverless and what are the common mistakes to avoid. Register Now.





QCon San Francisco
Understand the emerging software trends you should pay attention to. Attend in-person on Oct 24-28, 2022.















InfoQ Homepage
Articles
Growing EAI with Apache Camel







Web Server and Reverse-Proxy Cache 101 (Live Webinar Jun 16th, 2022) - Save Your Seat 







							Growing EAI with Apache Camel
						



					Lire ce contenu en
					

						français
					





Like

Print
Bookmarks











Mar 06, 2013
								
								
								
									
									20
									min read
								
							


by





Frans van der Lek







Write for InfoQ Join a community of experts. Increase your visibility.  Grow your career.Learn more






Requirements in IT projects are prone to change, and that includes requirements on integrating with other systems. Being able to quickly respond to such changes can be critical to project success, so the software and development process must enable this. Fortunately, Enterprise Application Integration (EAI) provides us with all the knowledge, technology and best practices to build extensible, maintainable and capable integration solutions in a productive fashion.
However, most integration solutions place us in a dilemma: while they are full of features and can be quite productive for large projects and a demanding environment, they also require big investments up front when it comes to learning the system, deploying it and maintaining it.
For this reason, when faced with simple integration requirements, ad hoc solutions seem very appealing. But they become hard to maintain and counter productive should integration needs grow. Applying EAI best practices would cure this, but implementing them yourself requires effort and the knowledge to do it correctly. What seems like the path of least resistance at first can later become a dead end.





Related Sponsored Content



Related Sponsor




vFunction is a patented AI-powered platform for companies that intelligently and automatically transforms legacy monolithic applications into microservices. Request a Demo.



How then can we be productive when faced with simple as well as complex integration tasks, while avoiding big investments early on? In this article I will argue that Apache Camel offers a solution. I will aim to demonstrate that Camel can meet complex integration challenges enabling you to leverage EAI best practices, while being easy to pick up and easy to master. All the while, Camel lets you to concentrate on what provides business value, not dealing with the complexities imposed by some frameworks.
I will show this by looking at practical examples of typical integration challenges and see how Camel helps us meet these challenges. These examples are presented in the context of an integration solution that starts simply but grows over time as new integration needs arise. Each time I will investigate how Camel is be able to meet these demands, primarily from the point of view of managing complexity and staying productive.
I have chosen Apache Camel because, in my opinion, it offers an excellent, lighter-weight alternative to full ESB products such as Service Mix, Mule ESB, OpenESB and JBossESB.  Its closest rival is probably Spring Integration, which is a good option to consider particularly if your project is already using SpringSource technologies.  As you will see, you can also use Camel and Spring together. Gunnar Hillert offers further discussion of the alternatives here.
Humble beginnings

Integration often starts simple. For instance, fetch some file from an FTP server and put it in a local file. At this stage the do-it-yourself solution seems very appealing. But let’s look a bit more closely.
The do-it-yourself solution might look something like this:


public class FTPFetch {     public static void main(String[] args) {        FTPClient ftp = new FTPClient();        try {              ftp.connect("host"); // try to connect              if (!ftp.login("camel", "apache")) // login to server              {                  ftp.disconnect();                  return;              }              int reply = ftp.getReplyCode();              if (!FTPReply.isPositiveCompletion(reply)) {                  ftp.logout();                  ftp.disconnect();                  return;              }               ftp.changeWorkingDirectory("folder");              // get output stream for destination file              OutputStream output = new FileOutputStream("data/outbox/file.xml");              ftp.retrieveFile("file.xml", output); // transfer the file              output.close();              ftp.logout();              ftp.disconnect();        } catch (Exception ex) {                  ex.printStackTrace();        } finally {                  if (ftp.isConnected()) {                     try {                           ftp.disconnect();                     } catch (IOException ioException) {                           ioException.printStackTrace();                     }              }         }      }}
This solution uses the FTPClient class from Apache Commons. As it is just a client and nothing more, we need to set up an FTP connection and do error handling ourselves. But what if the file on the FTP server changes later? I suppose we should schedule this to run periodically.
Now let’s look at Apache Camel. Camel is an integration framework designed to solve this kind of problems by following EAI best practices. Camel should be viewed as both a toolbox of ready made integration components and a runtime which can be customized for specific needs by combining them. With Camel, this is how we would solve the problem above:


public class CamelRunner{     public static void main(String args[]) throws Exception {         Main camelMain = new Main();         camelMain.enableHangupSupport(); //ctrl-c shutdown         camelMain.addRouteBuilder(new RouteBuilder() {                public void configure() {

from("ftp://host/folder?username=camel&password=apache&fileName=file.xml&delay=360000" )       .to("file:data/outbox");                }        });        camelMain.run(); //Camel will keep running indefinitely     }}
Please note the from and to methods. Camel calls this a ‘route’: the path that is traversed by the data from source to destination. Moreover, data is not exchanged in raw form but rather it is wrapped in Messages: containers for the actual data. This is similar to a SOAP envelope, which has sections for a body, attachments and headers.
Message sources and destinations are called ‘endpoints’, and it is through them that Camel receives and sends data. Endpoints are specified with a URI formatted string as seen in the arguments for the from and to methods. Therefore the way we tell Camel what to do is by declaratively creating routes between endpoints, and then registering these routes with Camel.
The rest is just boilerplate which gets reused as more routes are added and is a great deal simpler than talking to an FTP server. Camel will take care of the awkward FTP details and will even poll the server periodically in case the file changes, as it has been set up to keep running indefinitely.
The compactness and clarity of the code comes from the Camel DSL, a Domain Specific Language where the ‘domain’ is EAI. That means that, unlike with other solutions, there is no translation to be made from the EAI problem domain to the Camel application domain: the two are virtually the same. This helps to keep the learning curve gentle and the entry point low in comparison: once you understand your EAI problem, it’s a small step to implement it with Camel.
But the code you write is not the only thing that’s simple: all that is needed to get this running is camel-core.jar and camel-ftp.jar and their dependencies, together just a few MB. This main class can then be run from the command line. No need for an application server with added complexity. In fact, since Camel is so lightweight, it can be embedded just about anywhere. Choosing a do-it-yourself solution on the sole basis that frameworks add a lot of complexity is not valid: Camel is simple to understand, simple to use and simple to run.
Growing complexity
Now let’s say more and more integration needs to be made. We not only want to be able to have more integration, but also to keep it maintainable. How would Camel cope with this?
As more connections need to be made, we just add more routes to Camel. These new routes might need to connect via other endpoints such as HTTP, JMS, SMTP, etc... Fortunately Camel’s list of supported endpoints is extensive. What’s great is that each of these represents reusable code that you don’t have to write.
Of course, sooner or later you will need something which is not on the list. The question then becomes: how easily can I plug my own code into Camel? In this case we can use what Camel calls ‘Components’. Components define a contract which when implemented will make your code available as just another endpoint to be called from the DSL.
So now we know we can add more and more routes, connecting with just about any type of protocol whether Camel provides for it out of the box or not. But at some point routes start to get quite numerous and you find you are repeating yourself. We would like to reuse bits of routes, maybe even split the whole solution into separate, coarse grained parts.
Camel’s strategy for reuse is based on some special, internal endpoints which only Camel can see. Should you need to reuse part of an existing route, it is possible to refactor that route into two, linked by an internal endpoint. Please see below:
Original:
//originalfrom(“ftp://server/path”).     to(“xslt:transform.xsl”).         to(“http://server2/path”);
Refactored:
//receiving from internal endpoint d1from(“direct:d1”).     to(“xslt:transform.xsl”).         to(“http://server2/path”);//sending to d1 from(“ftp://server/path”).     to(“direct:d1”);//also sending to d1from(“file://path”).     to(“xslt:other-transformation.xsl”).         to(“direct:d1”);
The connecting endpoint is the one of type ‘direct’. Endpoints of this type are only addressable from within the same Camel context. Another interesting endpoint type is VM. VM endpoints are addressable from another Camel context, provided both contexts run on the same JVM instance.
A Camel context is like a container for your routes. Each time you run Camel, it instantiates a context and looks for routes inside it. So when we run Camel, we are actually running a context instance.
Being able to address routes in other Camel context instances via VM is quite useful. It opens the possibility to break your entire solution into interconnected modules in a more lightweight fashion than, for instance, via JMS.
The picture below shows the various routes now spread between different Camel instances, each separately running on the same JVM instance and addressing each other with a VM endpoint:
(Click on the image to enlarge it)

We have decomposed our solution into modules. Now we can develop, deploy and run any other module which also sends to ‘Consumer Context’, independently of ‘Producer Context1’ or ‘Producer Context2’. This is key in order to keep even the largest solution manageable.
At this point it might make sense to use an application server, as it is able to fully exploit modularity. Or maybe you already are using one. A very common approach then is packaging Camel into a WAR file and deploying to Tomcat. But you could also deploy it to a full blown Java EE application server like JBoss, WebLogic or WebSphere. Other options include an OSGI container or even Google App Engine.
Mastering complexity
Sheer volume is not the only way in which applications can grow. Routes can also grow in complexity: messages may undergo various amounts and types of transformations, filtering, enrichment, routing, etc in any number of combinations. In order to discuss how Camel can help in that regard, let us consider how we can deal with complex problems in the first place.
Complex problems arise in any field, but the general strategy for solving them is usually the same: divide and conquer. We try to decompose the problem into subproblems that are more simple to solve. These solutions are then combined by reversing the decomposition to yield the total solution.
 Through observation one then notices that certain problems keep recurring; through experience one identifies the most optimal solution. What I am talking about are patterns. The EAI patterns have been catalogued by Gregor Hohpe and Bobby Woolf and summarized online.
EAI patterns can be very simple in nature, often representing basic operations like some transformation or filtering. Most importantly, they can be combined to form complex solutions. These could well be patterns themselves. This ability stems from the fact that all EAI patterns have the same ‘interface’: messages can get in and out of a pattern. Patterns can then be linked together by taking the output of one pattern and using it as the input of another.
That implies that, broadly speaking, EAI problems are in fact just a combination of patterns. Which means solving an EAI problem, even a complex one, is reduced to finding that combination that meets your requirements. Implementing individual patterns can still hold plenty of complexity of course, but that has been isolated and is manageable.
Let’s consider an actual pattern as an example. This pattern is called ‘Composed Message Processor’ and is in fact a combination of more basic patterns. It is used when parts of the same message need to be processed by different components. This pattern is not directly implemented by Camel, but its subpatterns are. So this is a good example of how patterns can be combined by the Camel DSL.
Below is the pattern diagram. ‘Splitter’ will split the incoming message into parts, while ‘Router’ will decide which system to send them to: either ‘Widget Inventory’ or ‘Gadget Inventory’. These systems can be thought of as doing some business related processing, then returning the processed messages. ‘Aggregator’ will then combine the results into one outgoing message again.
(Click on the image to enlarge it)

Here is the Camel implementation:


from("some:input")     .setHeader("msgId") //give each message a unique id based on timestamp         .simple("${date:now:S}")     .split(xpath("//item")) //split the message into parts (msgId is preserved)         .choice() //let each part be processed by the appropriate bean             .when( xpath("/item[@type='widget']") )                 .to("bean:WidgetInventory")             .otherwise()                 .to("bean:GadgetInventory")         .end()     .aggregate(new MyAggregationStrategy()) //collect the parts and reassemble         .header("msgId") //msgId tells us which parts belong together         .completionTimeout(1000L).to("some:output"); //send the result along
In this implementation, the ‘beans’ are actually POJOs registered under the bean name, for example via JNDI. In this way we can do custom logic in the route. MyAggregationStrategy is also custom code, it specifies how to reassemble the processed message parts.
Note the split, choice, and aggregate methods, which directly correspond to the ‘Splitter’, ‘Router’ and ‘Aggregator’ patterns.The Camel implementation of ‘Composed Message Processor’ is essentially a textual representation of the diagram above. So mostly there is no need to think in terms of ‘Camel’, just in terms of EAI. The result is that Camel actually stays relatively out of the way, and more emphasis can be placed on understanding the problem and identifying the appropriate patterns. That helps improve the overall quality of the solution.
However, it’s not all goodness. Camel does have its own ‘way of doing things’, its own behind-the-scenes logic. And there will be moments when the unexpected happens and you will be left clueless. But such setbacks should be viewed in light of the time actually saved by using Camel: other frameworks have a steeper learning curve and quirks of their own, do-it-yourself means you don’t get to reuse all the great features Camel has to offer and keep reinventing the wheel.
No argument about managing complexity and evolving software would be complete without talking about unit tests. Camel can be run embedded in any other class, so it will also run inside a unit test.
Camel also solves one of the most cumbersome things about integration testing: having to set up an FTP or HTTP server in order to be able to run tests. Basically it avoids this because it is possible to alter existing routes at runtime. Here is an example:


public class BasicTest extends CamelTestSupport {     // This is the route we want to test. Setup with anonymous class for     // educational purposes, normally this would be a separate class.     @Override     protected RouteBuilder createRouteBuilder() throws Exception {         return new RouteBuilder() {               @Override               public void configure() throws Exception {                      from("ftp://host/data/inbox").                             routeId("main").                                  to("file:data/outbox");               }         };     }     @Override     public boolean isUseAdviceWith() {         // Indicates we are using advice with, which allows us to advise the route         // before Camel is started         return true;     }     @Test     public void TestMe() throws Exception {         // alter the original route         context.getRouteDefinition("main").adviceWith(context,                      new AdviceWithRouteBuilder() {                             @Override                             public void configure() throws Exception {                                  replaceFromWith("direct:input");                                  interceptSendToEndpoint("file:data/outbox")                                         .skipSendToOriginalEndpoint()                                                      .to("mock:done");                             }                      });         context.start();         // write unit test following AAA (Arrange, Act, Assert)         String bodyContents = "Hello world";         MockEndpoint endpoint = getMockEndpoint("mock:done");         endpoint.expectedMessageCount(1);         endpoint.expectedBodiesReceived(bodyContents);         template.sendBody("direct:input", bodyContents);         assertMockEndpointsSatisfied();     }}
AdviceWithRouteBuilder allows for programmatically changing an existing route in its configure method without altering the original code. In this case we have replaced the original source endpoint with one of type DIRECT, and made sure the original destination gets bypassed in favor of the mockendpoint. In this way, we do not need to have an actual FTP server running in order to test our route, even though it is programmed to pull messages from FTP. The MockEndpoint class then provides a convenient API for setting unit tests up in a declarative way, similar to jMock. Another great feature is the template we use in order to easily send messages to our route under test.
Relying on Camel
One important characteristic of integration solutions is that, as they are the intermediate through which all other systems are connected, by their very nature they are a single point of failure. As more and more systems get connected or the data gets more important system failure, data loss and performance degradation become less tolerable even as the volume increases.
Even though this article is about Camel, a solution that addresses all these challenges is beyond the scope of Camel alone. However, Camel is a central part of such a solution because it contains all the logic for moving the data around. So it is important to know that it can fulfill its duties even in these demanding conditions.
Let’s consider an example to see how these requirements are typically met. In this example there is an incoming JMS queue where messages are placed by external systems. Camel’s job will be to take the messages, do some processing, then deliver them to an outgoing JMS queue. JMS queues can be made persistent as well as highly available separately, so we will focus on Camel, and assume that external systems can ‘always’ put messages on the incoming queue. That is until it fills up, which will happen if Camel cannot pick up and process messages fast enough.
Our aim then is to make Camel resilient to system failures and increase its performance, and we do this by deploying it on more servers, each running a Camel instance connected to the same endpoints. See also the picture below:
(Click on the image to enlarge it)

This is in fact an implementation of another EAI pattern called ‘Competing Consumers’. This pattern has two benefits: first, messages are taken from the queue from multiple instances and get processed in parallel, which improves performance. Second, should one server go down, others are already running and taking messages, so message processing continues automatically and without any intervention, which improves failure resilience.
When one Camel instance takes a message, it is no longer available to others. This ensures messages are processed once. And the workload gets distributed across servers as each server takes messages: faster servers can take messages at a faster rate and automatically take on more of the burden than slower servers. In this way we can achieve the necessary coordination and workload distribution between Camel instances.
However, there is one element missing: should one server go down while processing a message, another must take up its work otherwise the message is lost. Similarly, if all nodes go down, messages that are in the middle of processing should not be lost.
For that to happen, we need transactions. With transactions, the JMS queue will wait for an acknowledgement from the instance that took the message before really discarding it. If the server that took the message fails during processing, that acknowledgement will never come, and eventually a rollback will kick in and the message will reappear on the queue and become available again to the instances that are left running. If none are running, the message just stays there until a server eventually gets back online.
For Camel this means that the routes must be made transactional. Camel does not by itself provide for transactions, but instead makes use of 3rd party solutions. That keeps Camel simple, while enabling reuse of proven technology and making it possible to easily switch implementations.
As an example we will configure a Camel context with transactions inside a Spring container. Note that as we are running inside Spring, it’s more practical to use the Spring XML version of the Camel DSL instead of the Java one, even though the latter is great for starting out.
Of course, changing DSLs mid-project means rework, so it’s important to migrate wisely and at an appropriate time. Fortunately, the Spring DSL also runs from a unit test, so unit tests can help to safely make the transition since they will work on routes regardless of which DSL type was used.


<beans //namespace declarations omitted >     //setup connection to jms server     <jee:jndi-lookup id="jmsConnectionFactory" jndi-name="ConnectionFactory">         <jee:environment>            java.naming.factory.initial=org.jnp.interfaces.NamingContextFactory            java.naming.factory.url.pkgs=org.jboss.naming.client            java.naming.provider.url=jnp://localhost:1099         </jee:environment>     </jee:jndi-lookup>    //configuration for the jms client, including transaction behavior    <bean id="jmsConfig" class="org.apache.camel.component.jms.JmsConfiguration">         <property name="connectionFactory" ref="jmsConnectionFactory"/>         <property name="transactionManager" ref="jmsTransactionManager"/>         <property name="transacted" value="true"/>         <property name="acknowledgementModeName" value="TRANSACTED"/>         <property name="cacheLevelName" value="CACHE_NONE"/>         <property name="transactionTimeout" value="5"/>    </bean>   //register camel jms component bean<bean id="jboss" class="org.apache.camel.component.jms.JmsComponent">      <property name="configuration" ref="jmsConfig" />   </bean>   //register spring transactionmanager bean   <bean id="jmsTransactionManager" class="org.springframework.jms.connection.JmsTransactionManager">         <property name="connectionFactory" ref="jmsConnectionFactory"/>   </bean>     <camelContext xmlns="http://camel.apache.org/schema/spring">          <route>               <from uri="jboss:queue:incoming"/>               <transacted/>               <log loggingLevel="INFO" message="processing started." />               <!-- complex processing -->               <to uri="jboss:queue:outgoing?exchangePattern=InOnly" />          </route>     </camelContext></beans>
With the <transacted/> tag the route is marked as transactional, so Camel will enlist resources in the transaction through the transaction manager for that route. In case of failure during processing, the transaction manager will make sure the transaction is rolled back and the message reappears in the incoming queue.
However, not every route can be marked transactional because some endpoints, FTP for instance, do not support transactions. Fortunately, Camel has error handling that works even without transactions. Of particular interest is the DeadLetterChannel, an error handler which implements the Dead Letter Channel pattern. This pattern states that messages that could not, or should not, be delivered to their intended destination must be moved to a separate location, so as not to clutter the system. The messaging system then decides what to do with such messages.
For instance, suppose that delivery to an endpoint such as an FTP location fails. If configured on that route, the DeadLetterChannel will first attempt to redeliver the message a few times. If the failure persists then the message is called ‘poison’, meaning nothing useful can be done with it and it should be taken out of the system. By default Camel will then log the error and drop the message. Naturally, this mechanism can be customized: for instance you could specify that Camel should perform at most 3 redelivery attempts, and store the message in a JMS queue if they are exhausted. And yes, the DeadLetterChannel can be combined with transactions, bringing the best of both.
Conclusion
Unmaintainable integration usually begins with simple integration needs which are met in an ad-hoc fashion. Such approaches do not scale to more rigorous demands, and making them do so is a considerable investment in itself. Early on investment on specialized EAI middleware carries a great risk due to the complexity they often bring, and has a high probability of not paying off.
In this article I have investigated a third option: using Camel in order to keep things simple in the beginning while still being able to meet higher demands later. In this regard I believe Camel has shown itself quite capable: it has an easy learning curve and is lightweight in use and in deployment, so early on investments are small. Even in simple cases, learning Camel can actually be a faster path to integration than do-it-yourself solutions. Camel is therefore great as a low threshold entry to EAI.
I also think that Camel is a good choice for the greater demands that can be placed on an integration solution. In regards to productivity it has extensibility and reuse, and an amazing integration DSL. Because of it there is almost no complexity overhead in using Camel, so you can focus on the actual problem. When you reach the limits of what can be done with out-of-the-box Camel, it has a plugin infrastructure for Components and POJO invocation empowering you to take matters into your own hands.
Unit test support with Camel is invaluable. Camel also proved itself as part of a High Availability solution.
On the whole, Camel is a great option for integrations of virtually any size and complexity: you can start out small and simple with minimal upfront investment, confident in the knowledge that should integration needs get more complex Camel can still deliver. In the meantime you can stay productive while reaping the benefits of a mature and complete integration framework.
About the Author
Frans van der Lek is a software engineer with experience in web, mobile and EAI solutions. He is currently employed by Capgemini in the Netherlands where he has worked as a designer, developer and specifier on a number of projects. When not writing or thinking about software he enjoys a good book, a fine cup of coffee and spending time with his family.
 
 


Inspired by this content? Write for InfoQ.
Becoming an editor for InfoQ was one of the best decisions of my career. It has challenged me and helped me grow in so many ways. We'd love to have more people join our team.

Thomas BettsLead Editor, Software Architecture and Design @InfoQ; Senior Principal Engineer

Write for InfoQ












Rate this Article


Adoption










Style


































 Author Contacted










                
                
                    
                This content is in the Enterprise Architecture topic
            

Related Topics:


Development


Architecture & Design


JMS


Java EE


Java


EAI


Enterprise Architecture


Infrastructure


Architecture








Related Editorial





Popular across InfoQ




									Go Native with Spring Boot and GraalVM
								





									Why You Should Care about Software Architecture
								





									Java News Roundup: JEPs for JDK 19, Project Lilliput Milestone, Spring Framework, Quarkus 2.9.0
								





									State of the Java Ecosystem Report from New Relic
								





									ML Tools to Accelerate Your Work with Cassie Breviu
								





									Microsoft Releases Azure DNS Private Resolver in Public Preview
								











Related Content





JEP 405: Record Classes to Extend Pattern Matching in Java








Java News Roundup: OpenJDK, Spring Updates and CVEs, Payara Platform, Apache Tomcat Updates








Kalix: Build Serverless Cloud-Native Business-Crtical Applications with No Databases








State of the Java Ecosystem Report from New Relic








Microsoft + Java = ♡:  a Story Told by Martijn Verburg at Devoxx UK








MicroStream 7.0 Delivers Support for CDI








Java News Roundup: JEPs for JDK 19, Project Lilliput Milestone, Spring Framework, Quarkus 2.9.0








The Future of Java as Seen by Mark Little at Devoxx UK 22: Native Java, Adoptium and Faster Pace








11 Puzzles from JDK11: Hanno Embregts on Java Certification at Devoxx UK








JEP 425: Java Virtual Threads to Deliver Improved Throughput








Java News Roundup: JEPs for Projects Loom and Panama, JobRunr 5.1.0, Kotlin 1.7.0 Preview








Quarkus 2.8.0 Introduces Fine-Grained Transaction API








Static Java Current State: Compiled Native Executables for Startup Speed and Small Footprint








JetBrains IntelliJ IDEA 2022.1 Introduces Dependency Analysis








Java News Roundup: JEP Updates for JDK 19, Project Loom, MicroStream 7.0, New Relic Java Survey








Kotlin Asynchronous Framework, Ktor 2.0, Released with New Plugins Feature








Go Native with Spring Boot and GraalVM











JobRunr 5.0.0 Delivers Improved Framework Support








Article Series: Native Compilations Boosts Java











Cloud Native Java with the Micronaut Framework











Getting Started to Quarkus Reactive Messaging with Apache Kafka











Native Java in the Real World











Kubernetes Native Java with Quarkus











Revolutionizing Java with GraalVM Native Image











Two Must-Have Tools for Jakarta EE Developers











Level up Your Java Performance with TornadoVM











The Angular Mini-Book 2.0











Java InfoQ Trends Report—December 2021











Java & JVM Panel











Six Features From Java 12 to 17 to Get Excited About!











Lightweight External Business Rules











Building an Effective Digital Platform: Adam Hansrod on the Benefits, Challenges, and Approach











HashiCorp Vault Improves Eventual Consistency with Server-Side Consistent Tokens








Microsoft Announces the General Availability of Azure Container Apps at Build 2022








Machine Learning at the Edge











How Getting Feedback from Angry Users Helps to Develop Better Products








Cloudflare D1 Provides Distributed SQLite for Cloudflare Workers








Amazon Releases 51-Language AI Training Dataset MASSIVE








How to Run Your Product Department Like a Coach











Google Jetpack Brings Updated Architectural and UI Components and Improved Performance Tools








The InfoQ Newsletter


        A round-up of last week’s content on InfoQ sent out every Tuesday. Join a community of over 250,000 senior developers.

        

			View an example




Enter your e-mail address








Select your country

Select a country





I consent to InfoQ.com handling my data as explained in this Privacy Notice.





We protect your privacy.

















Hello stranger!
You need to Register an InfoQ account or  Login or login to post comments. But there's so much more behind being registered.
Get the most out of the InfoQ experience.





Tell us what you think







Allowed html: a,b,br,blockquote,i,li,pre,u,ul,p





 Email me replies to any of my messages in this thread
                            










Community comments


Watch thread




Excellent Article
by Pradeep Tiwari, 


Re: Excellent Article
by Nurali Virani, 








Excellent Article
by
                                        Pradeep Tiwari,
                                        


Your message is awaiting moderation. Thank you for participating in the discussion.
This is really an excellent article.


Like
Reply


Back to top










Re: Excellent Article
by
                                        Nurali Virani,
                                        


Your message is awaiting moderation. Thank you for participating in the discussion.
Yes, Frans has explained as simply as Camel is .. :)Step by step increase in complexity for Integration .. and cover many different scenario where Camel shown it's value.  Thanks Frans .. :)


Like
Reply


Back to top












Close





Your Reply


Quote original message








Allowed html: a,b,br,blockquote,i,li,pre,u,ul,p





 Email me replies to any of my messages in this thread
                    






                        Cancel
                    






Close





Your Reply








Allowed html: a,b,br,blockquote,i,li,pre,u,ul,p





 Email me replies to any of my messages in this thread
                    







                        Cancel
                    






Close




                   OK
                



2 












Development




How to Prepare for the Unexpected: an InfluxData Outage Story Told at KubeConEU 22


Reproducible Development with Containers


Green Software Development: Terminology and Climate Commitments Explained by Microsoft at Devoxx UK






Architecture & Design




Oren Eini on RavenDB, including Consistency Guarantees and C# as the Implementation Language


Kalix: Build Serverless Cloud-Native Business-Crtical Applications with No Databases


Architecting for the Edge






Culture & Methods




How Getting Feedback from Angry Users Helps to Develop Better Products


How to Run Your Product Department Like a Coach


Building a Culture of Accountability and Curiosity






AI, ML & Data Engineering




Machine Learning at the Edge


Amazon Releases 51-Language AI Training Dataset MASSIVE


AI for Software Developers: a Future or a New Reality?






DevOps




HashiCorp Vault Improves Eventual Consistency with Server-Side Consistent Tokens


Cloudflare D1 Provides Distributed SQLite for Cloudflare Workers


Effectively Monitoring Your Monitoring - Miedwar Meshbesher on Using Vigilance Controls












The InfoQ Newsletter
	
A round-up of last week’s content on InfoQ sent out every Tuesday. Join a community of over 250,000 senior developers.
		
			View an example


Get a quick overview of content published on a variety of innovator and early adopter technologies
Learn what you don’t know that you don’t know
Stay up to date with the latest information from the topics you are interested in




Enter your e-mail address








Select your country

Select a country





I consent to InfoQ.com handling my data as explained in this Privacy Notice.





We protect your privacy.








QCon Software Development Conference 



Real-world technical talks. No product pitches.Practical ideas to inspire you and your team.QCon San Francisco - Oct 24-28, In-person.QCon San Francisco brings together the world's most innovative senior software engineers across multiple domains to share their real-world implementation of emerging trends and practices.Uncover emerging software trends and practices to solve your complex engineering challenges, without the product pitches.Save your spot now








Home
Create account
Login
QCon Conferences
Events
Contribute
InfoQ Editors
About InfoQ
About C4Media

            Media Kit
        
InfoQ Developer Marketing Blog
Diversity



Events




InfoQ Live

JUNE 21, 2022





InfoQ Live

JULY 19, 2022





							InfoQ Live
							
AUGUST 23, 2022





QCon San Francisco

OCTOBER 24-28, 2022





								QCon Plus
							
NOVEMBER 29 - DECEMBER 9, 2022





Follow us on 

Youtube212K Followers
Linkedin18K Followers
RSS19K Readers
Twitter50k Followers
Facebook20K Likes
AlexaNew



Stay in the know

The InfoQ Podcast
Engineering Culture Podcast
The Software Architects' Newsletter









						General Feedback
						feedback@infoq.com


						Advertising
						sales@infoq.com


						Editorial
						editors@infoq.com


						Marketing
						marketing@infoq.com




InfoQ.com and all content copyright © 2006-2022 C4Media Inc. InfoQ.com hosted at Contegix, the best ISP we've ever worked with.
Privacy Notice, Terms And Conditions, Cookie Policy








BT














